<html class="gs_el_sm gs_pfcs"><head><title>‪Richard Bowden‬ - ‪Google Scholar‬</title><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><meta name="referrer" content="origin-when-cross-origin"><meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=2"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="https://scholar.google.co.uk/citations?user=mvvgDvcAAAAJ&amp;hl=en"><meta name="description" content="‪Professor of Computer Vision and Machine Learning, CVSSP, University of Surrey‬ - ‪‪Cited by 12,402‬‬ - ‪Computer Vision‬ - ‪Machine learning‬ - ‪Artificial Intelligence‬"><meta property="og:description" content="‪Professor of Computer Vision and Machine Learning, CVSSP, University of Surrey‬ - ‪‪Cited by 12,402‬‬ - ‪Computer Vision‬ - ‪Machine learning‬ - ‪Artificial Intelligence‬"><meta property="og:title" content="Richard Bowden"><meta property="og:image" content="https://scholar.googleusercontent.com/citations?view_op=medium_photo&amp;user=mvvgDvcAAAAJ&amp;citpid=2"><meta property="og:type" content="website"><meta name="twitter:card" content="summary"><style>html,body,form,table,div,h1,h2,h3,h4,h5,h6,img,ol,ul,li,button{margin:0;padding:0;border:0;}table{border-collapse:collapse;border-width:0;empty-cells:show;}html,body{height:100%}#gs_top{position:relative;box-sizing:border-box;min-height:100%;min-width:964px;-webkit-tap-highlight-color:rgba(0,0,0,0);}#gs_top>*:not(#x){-webkit-tap-highlight-color:rgba(204,204,204,.5);}.gs_el_ph #gs_top,.gs_el_ta #gs_top{min-width:320px;}#gs_top.gs_nscl{position:fixed;width:100%;}body,td,input,button{font-size:13px;font-family:Arial,sans-serif;line-height:1.24;}body{background:#fff;color:#222;-webkit-text-size-adjust:100%;-moz-text-size-adjust:none;}.gs_gray{color:#777777}.gs_red{color:#dd4b39}.gs_grn{color:#006621}.gs_lil{font-size:11px}.gs_med{font-size:16px}.gs_hlt{font-weight:bold;}a:link{color:#1a0dab;text-decoration:none}a:visited{color:#660099;text-decoration:none}a:hover,a:hover .gs_lbl{text-decoration:underline}a:active,a:active .gs_lbl,a .gs_lbl:active{color:#d14836}.gs_el_tc a:hover,.gs_el_tc a:hover .gs_lbl{text-decoration:none}.gs_pfcs a:focus,.gs_pfcs button:focus,.gs_pfcs input:focus,.gs_pfcs label:focus{outline:none}.gs_a,.gs_a a:link,.gs_a a:visited{color:#006621}.gs_a a:active{color:#d14836}a.gs_fl:link,.gs_fl a:link{color:#1a0dab}a.gs_fl:visited,.gs_fl a:visited{color:#660099}a.gs_fl:active,.gs_fl a:active{color:#d14836}.gs_fl{color:#777777}.gs_ctc,.gs_ctu{vertical-align:middle;font-size:11px;font-weight:bold}.gs_ctc{color:#1a0dab}.gs_ctg,.gs_ctg2{font-size:13px;font-weight:bold}.gs_ctg{color:#1a0dab}a.gs_pda,.gs_pda a{padding:7px 0 5px 0}.gs_alrt{background:#f9edbe;border:1px solid #f0c36d;padding:0 16px;text-align:center;box-shadow:0 2px 4px rgba(0,0,0,.2);border-radius:2px;}.gs_spc{display:inline-block;width:12px}.gs_br{width:0;font-size:0}.gs_ibl{display:inline-block;}.gs_scl:after{content:"";display:table;clear:both;}.gs_ind{padding-left:8px;text-indent:-8px}.gs_ico,.gs_icm{display:inline-block;background:no-repeat url(/intl/en/scholar/images/1x/sprite_20161020.png);background-position:-23px -161px;background-size:169px;width:21px;height:21px;}@media(-webkit-min-device-pixel-ratio:1.5),(min-resolution:144dpi){.gs_ico,.gs_icm{background-image:url(/intl/en/scholar/images/2x/sprite_20161020.png);}}.gs_el_ta .gs_nta,.gs_ota,.gs_el_ph .gs_nph,.gs_oph{display:none}.gs_el_ta .gs_ota,.gs_el_ph .gs_oph{display:inline}.gs_el_ta div.gs_ota,.gs_el_ph div.gs_oph{display:block}.gs_sth_g{visibility:hidden;max-height:0;}.gs_sth_vis .gs_sth_g{max-height:1000px;}.gs_sth_vis .gs_sth_b{position:fixed;top:0;}@keyframes gs_anm_spin{0%{transform:rotate(0deg);}100%{transform:rotate(360deg);}}.gs_rimg{display:block;background-color:#e5e5e5;border-radius:50%;overflow:hidden;position:relative;z-index:1;}.gs_rimg>img{position:absolute;margin:auto;left:0;top:0;bottom:0;right:0;}.gs_in_txtw{display:inline-block;vertical-align:middle;}.gs_in_txtb{display:block;}.gs_in_txt{color:#000;background-color:#fff;font-size:16px;box-sizing:border-box;height:29px;line-height:23px;border:1px solid #d9d9d9;border-top-color:#c0c0c0;padding:3px 6px 1px 8px;border-radius:1px;outline:none;-webkit-appearance:none;-moz-appearance:none;}.gs_el_tc .gs_in_txt{font-size:18px;}.gs_in_txtb .gs_in_txt{width:100%;}.gs_in_txt:hover{border-color:#b9b9b9;border-top-color:#a0a0a0;box-shadow:inset 0 1px 2px rgba(0,0,0,.1);}.gs_in_txte .gs_in_txt{border-color:#dd4b39;}.gs_in_txt:focus{border-color:#4d90fe;box-shadow:inset 0 1px 2px rgba(0,0,0,.3);}.gs_in_txt:disabled{color:#b8b8b8;border-color:#f1f1f1;box-shadow:none;}.gs_in_txtm .gs_in_txt{font-size:13px;height:24px;line-height:16px;padding:3px 6px;}.gs_el_tc .gs_in_txtm .gs_in_txt{height:29px;line-height:21px;}.gs_in_txts{font-size:13px;line-height:18px;color:#666;}.gs_in_txte .gs_in_txts{color:#dd4b39;}button{position:relative;z-index:1;box-sizing:border-box;font-size:13px;cursor:pointer;height:29px;line-height:normal;min-width:72px;padding:0 8px;color:#444;border:1px solid rgba(0,0,0,.1);border-radius:3px;text-align:center;background-color:#f5f5f5;-webkit-user-select:none;user-select:none;}button.gs_btn_rnd{border-radius:14px;padding:0 12px;}button.gs_btn_rnd.gs_btn_rndci{padding-left:4px;}button.gs_btn_lrge{height:41px;min-width:82px;padding:0 9px;}button.gs_btn_lrge.gs_btn_rnd{border-radius:20px;padding:0 16px;}button.gs_btn_lrge.gs_btn_rnd.gs_btn_rndci{padding-left:10px;}button.gs_btn_cir{border-radius:14.5px;min-width:29px;}button.gs_btn_lrge.gs_btn_cir{border-radius:20.5px;min-width:41px;}button.gs_btn_mini{padding:0;border:0;}.gs_el_ph button.gs_btn_mph,.gs_el_ta button.gs_btn_mta{height:41px;}button .gs_wr{position:relative;display:inline-block;width:100%;height:100%;}button .gs_wr:before{content:"";width:0;height:100%;}button .gs_wr:before,button .gs_ico,button .gs_rdt,button .gs_lbl,button .gs_icm{display:inline-block;vertical-align:middle;}button .gs_wr{font-size:13px;text-transform:none;}.gs_btn_lrge .gs_wr{font-size:15px;}.gs_btn_lsb .gs_wr{font-size:11px;font-weight:bold;}.gs_btn_lsu .gs_wr{font-size:11px;text-transform:uppercase;}.gs_btn_lrge.gs_btn_lsb .gs_wr,.gs_btn_lrge.gs_btn_lsu .gs_wr{font-size:13px;}.gs_btn_half,.gs_el_ta .gs_btn_hta,.gs_el_ph .gs_btn_hph{min-width:36px;}.gs_btn_lrge.gs_btn_half,.gs_el_ta .gs_btn_lrge.gs_btn_hta,.gs_el_ph .gs_btn_lrge.gs_btn_hph,.gs_el_ta .gs_btn_mta,.gs_el_ph .gs_btn_mph{min-width:41px;}.gs_btn_slt{border-radius:3px 0 0 3px;}.gs_btn_srt{margin-left:-1px;border-radius:0 3px 3px 0;}.gs_btn_smd{margin-left:-1px;border-radius:0;}button:hover{z-index:2;color:#222;border-color:rgba(0,0,0,.2);background-color:#f8f8f8;}button.gs_sel{background-color:#dcdcdc;}button:active{z-index:2;background-color:#f1f1f1;}button:focus{z-index:2;}button::-moz-focus-inner{padding:0;border:0}button:-moz-focusring{outline:1px dotted ButtonText}.gs_pfcs button:-moz-focusring{outline:none}a.gs_in_ib{position:relative;display:inline-block;line-height:16px;padding:6px 0 7px 0;-webkit-user-select:none;user-select:none;}a.gs_btn_lrge{height:40px;padding:0;}a.gs_in_ib .gs_lbl{display:inline-block;padding-left:21px;color:#222;}a.gs_in_ib .gs_lbl:not(:empty){padding-left:29px;}button.gs_in_ib .gs_lbl:not(:empty){padding-left:4px;}a.gs_in_ib:active .gs_lbl,a.gs_in_ib .gs_lbl:active,a.gs_in_ib :active~.gs_lbl{color:#d14836;}.gs_el_ta .gs_btn_hta .gs_lbl,.gs_el_ph .gs_btn_hph .gs_lbl,.gs_el_ta .gs_btn_mta .gs_lbl,.gs_el_ph .gs_btn_mph .gs_lbl,.gs_el_ta .gs_btn_cta .gs_lbl,.gs_el_ph .gs_btn_cph .gs_lbl{display:none;}a.gs_in_ib .gs_ico{position:absolute;top:3px;left:0;}.gs_in_ib.gs_md_li .gs_ico{left:14px;}.gs_el_tc .gs_in_ib.gs_md_li .gs_ico{top:11px;}.gs_in_ib.gs_md_li.gs_md_lix .gs_ico{top:10px;left:16px;}a.gs_btn_lrge .gs_ico{top:50%;left:50%;margin:-10.5px 0 0 -10.5px;}.gs_in_ib .gs_ico{opacity:.55;}.gs_in_ib:hover .gs_ico{opacity:.72;}.gs_in_ib:active .gs_ico,.gs_in_ib .gs_ico:active,.gs_in_ib :active~.gs_ico{opacity:1;}.gs_in_ib:disabled .gs_ico,.gs_in_ib.gs_dis .gs_ico{opacity:.28;}.gs_in_ib.gs_btn_act .gs_ico,.gs_in_ib.gs_btn_cre .gs_ico{opacity:1;}.gs_btn_act:disabled .gs_ico,.gs_btn_cre:disabled .gs_ico{opacity:.72;}.gs_rdt{position:relative;width:0;height:21px;}.gs_rdt:before{content:"";position:absolute;top:2px;right:1px;width:5px;height:5px;border-radius:50%;background-color:#dd4b39;}button.gs_btn_flat{border-color:transparent;background-color:transparent;}button.gs_btn_flat:hover{background-color:rgba(0,0,0,.05);}button.gs_btn_flat:active{background-color:rgba(0,0,0,.1);}button.gs_btn_flat.gs_btn_flact{color:#1a0dab;}button.gs_btn_act{color:#fff;-webkit-font-smoothing:antialiased;background-color:#4d90fe;}button.gs_btn_act:hover{color:#fff;background-color:#3983fe;}button.gs_btn_act.gs_sel{background-color:#2f6bcc;}button.gs_btn_act:active{background-color:#357ae8;}button.gs_btn_cre{color:#fff;-webkit-font-smoothing:antialiased;background-color:#d14836;}button.gs_btn_cre:hover{color:#fff;background-color:#c53727;}button.gs_btn_cre.gs_sel{background-color:#992b1e;}html:not(.gs_pfcs) .gs_btn_act:focus:not(:active){box-shadow:inset 0 0 0 1px rgba(255,255,255,.5);}button.gs_btn_cre:active{background-color:#b0281a;}button:disabled,button:disabled:hover,button:disabled:active{cursor:default;color:#b8b8b8;border-color:rgba(0,0,0,.05);background-color:transparent;z-index:0;}button.gs_btn_flat:disabled{color:#b8b8b8;border-color:transparent;}button.gs_btn_act:disabled{color:#fff;background-color:#a6c8ff;}button.gs_btn_cre:disabled{color:#fff;background-color:#e8a49b;}a.gs_in_ib.gs_dis{cursor:default;pointer-events:none}a.gs_in_ib.gs_dis .gs_lbl{color:#b8b8b8;text-decoration:none}.gs_ttp{position:absolute;top:100%;right:50%;z-index:10;pointer-events:none;visibility:hidden;opacity:0;transition:visibility 0s .13s,opacity .13s ease-out;}button:hover .gs_ttp,button:focus .gs_ttp,a:hover .gs_ttp,a:focus .gs_ttp{transition:visibility 0s .3s,opacity .13s ease-in .3s;visibility:visible;opacity:1;}.gs_md_tb.gs_sel .gs_ttp{transition:none;visibility:hidden;}button.gs_btn_lrge.gs_btn_cir .gs_ttp{top:75%;}.gs_ttp .gs_aro,.gs_ttp .gs_aru{position:absolute;top:-2px;right:-5px;width:0;height:0;line-height:0;font-size:0;border:5px solid transparent;border-top:none;border-bottom-color:#595959;z-index:1;}.gs_ttp .gs_aro{top:-3px;right:-6px;border-width:6px;border-top:none;border-bottom-color:white;}.gs_ttp .gs_txt{display:block;position:relative;top:2px;right:-50%;padding:4px 6px;background:#595959;color:white;font-size:11px;font-weight:bold;line-height:normal;white-space:nowrap;border:1px solid white;border-radius:3px;box-shadow:inset 0 1px 4px rgba(0,0,0,.2);}.gs_press,.gs_in_se,.gs_tan{touch-action:none;}.gs_in_se .gs_lbl:not(:empty){padding-right:14px;}.gs_in_se .gs_icm{position:absolute;top:50%;margin-top:-5.5px;right:0;width:7px;height:11px;background-position:-21px -88px;opacity:.55;}.gs_in_se:hover .gs_icm{opacity:.72;}.gs_in_se:active .gs_icm{opacity:1;}.gs_in_se:disabled .gs_icm{opacity:.28;}.gs_el_ta .gs_btn_hta .gs_icm,.gs_el_ph .gs_btn_hph .gs_icm,.gs_el_ta .gs_btn_mta .gs_icm,.gs_el_ph .gs_btn_mph .gs_icm,.gs_el_ta .gs_btn_cta .gs_icm,.gs_el_ph .gs_btn_cph .gs_icm{display:none;}.gs_btn_mnu .gs_icm{margin-top:-3.5px;height:7px;background-position:0 -110px;}.gs_in_se.gs_btn_act .gs_icm,.gs_in_se.gs_btn_cre .gs_icm{margin-top:-3.5px;height:7px;background-position:-42px -44px;opacity:1;}.gs_btn_act:disabled .gs_icm,.gs_btn_cre:disabled .gs_icm{opacity:.72;}button.gs_btnG .gs_ico{width:21px;height:21px;background-position:-92px -253px;}button .gs_bs{position:absolute;top:50%;left:50%;margin-top:-10px;margin-left:-10px;box-sizing:border-box;width:20px;height:20px;border-radius:50%;border:2px solid #eee;border-top-color:#4d90fe;visibility:hidden;animation:gs_anm_spin .8s linear infinite;}button.gs_bsp .gs_bs{visibility:visible;transition:visibility 0s .4s;}.gs_md_d{text-transform:none;white-space:nowrap;position:absolute;top:0;left:0;border:1px solid #ccc;border-color:rgba(0,0,0,.2);background:#fff;box-shadow:0 2px 4px rgba(0,0,0,.2);z-index:1100;text-align:left;visibility:hidden;max-height:0;margin-top:-1000px;opacity:0;transition:opacity .13s,visibility 0s .13s,max-height 0s .13s,margin-top 0s .13s;}.gs_md_d.gs_vis{visibility:visible;max-height:10000px;margin-top:0;opacity:1;transition:all 0s;}.gs_el_tc .gs_md_d{transform-origin:100% 0;transform:scale(1,0);transition:opacity .218s ease-out,transform 0s .218s,visibility 0s .218s,max-height 0s .218s,margin-top 0s .218s;}.gs_el_ios .gs_md_d{-webkit-backface-visibility:hidden;}.gs_el_tc .gs_md_d.gs_ttzi{transform-origin:50% 50%;transform:scale(0,0);}.gs_el_tc .gs_md_d.gs_ttzr{transform:scale(0,0);}.gs_el_tc .gs_md_d.gs_vis{transform:scale(1,1);transition:transform .218s ease-out;}.gs_md_r{position:relative;display:inline-block;}.gs_md_rmb>.gs_md_d{top:29px}.gs_md_rmbl>.gs_md_d{top:41px}.gs_md_ul{list-style-type:none;word-wrap:break-word;display:inline-block;vertical-align:top;}.gs_md_ul.gs_md_ul_tb{display:block;}.gs_md_li,.gs_in_cb.gs_md_li,.gs_md_li:link,.gs_md_li:visited{display:block;padding:6px 44px 6px 16px;font-size:13px;line-height:16px;color:#222;cursor:pointer;text-decoration:none;position:relative;z-index:0;}a.gs_md_li:hover .gs_lbl,a.gs_md_li:active .gs_lbl{text-decoration:none}.gs_el_tc .gs_md_li{padding-top:14px;padding-bottom:10px;}.gs_md_li.gs_md_lix{font-size:16px;line-height:20px;padding:12px 16px 8px 16px;}.gs_md_li:before{content:"";background-color:#f1f1f1;position:absolute;left:0;right:0;top:0;bottom:0;opacity:0;transition:opacity .13s;z-index:-1;}.gs_md_li:hover:before,.gs_md_li:focus:before{opacity:1;transition:all 0s;}a.gs_in_ib.gs_md_li .gs_lbl{color:#222}a.gs_in_ib.gs_md_li.gs_in_gray .gs_lbl{color:#444}.gs_md_li:active:before{background-color:#ddd}.gs_md_li.gs_sel,a.gs_in_ib.gs_md_li.gs_sel .gs_lbl{color:#d14836}.gs_md_d:focus,.gs_md_li:focus{outline:none}a.gs_md_lix .gs_lbl,a.gs_md_lix .gs_lbl:not(:empty){padding:0 0 0 40px;}a.gs_in_cb:link,a.gs_in_cb:visited,a.gs_in_cb:active,a.gs_in_cb:hover{cursor:pointer;color:#222;text-decoration:none;}.gs_in_cb,.gs_in_ra{position:relative;line-height:16px;display:inline-block;-webkit-user-select:none;user-select:none;}.gs_in_cb.gs_md_li{padding:6px 44px 6px 16px;}.gs_in_cb input,.gs_in_ra input{position:absolute;top:1px;left:1px;width:15px;height:15px;margin:0;padding:0;opacity:0;z-index:2;}.gs_in_ra input{top:0;left:0}.gs_el_tc .gs_in_cb input{top:9px}.gs_el_tc .gs_in_ra input{top:8px}.gs_in_cb.gs_in_cbj input{top:15px;left:15px}.gs_in_cb label,.gs_in_cb .gs_lbl,.gs_in_ra label{display:inline-block;padding-left:21px;min-height:16px;}.gs_in_cb label:empty:before,.gs_in_cb .gs_lbl:empty:before,.gs_in_ra label:empty:before{content:"\200b";}.gs_el_tc .gs_in_cb label,.gs_el_tc .gs_in_cb .gs_lbl,.gs_el_tc .gs_in_ra label{padding-top:8px;padding-bottom:5px;}.gs_in_cb.gs_in_cbj label,.gs_in_cb.gs_in_cbj .gs_lbl{padding:13px 0 12px 41px;}.gs_in_cbb,.gs_in_cbb label,.gs_in_cbb .gs_lbl{display:block;}.gs_in_cb .gs_cbx,.gs_in_ra .gs_cbx{position:absolute}.gs_in_cb .gs_cbx{top:2px;left:2px;width:11px;height:11px;border:1px solid #c6c6c6;border-radius:1px;}.gs_md_li .gs_cbx{top:8px;left:18px}.gs_el_tc .gs_in_cb .gs_cbx{top:10px}.gs_el_tc .gs_md_li .gs_cbx{top:16px}.gs_in_cb.gs_in_cbj .gs_cbx{top:15px;left:15px}.gs_el_tc .gs_in_ra .gs_cbx{top:8px}.gs_in_ra .gs_cbx{top:0;left:0;border:1px solid #c6c6c6;width:13px;height:13px;border-radius:7px;}.gs_in_cb:hover .gs_cbx,.gs_in_ra:hover .gs_cbx{border-color:#666;box-shadow:inset 0 1px 1px rgba(0,0,0,.1);}button.gs_in_cb:hover .gs_cbx{border-color:#c6c6c6;}.gs_in_cb :focus~label,.gs_in_ra :focus~label{outline:1px dotted #222;outline:auto -webkit-focus-ring-color;}.gs_pfcs .gs_in_cb :focus~label,.gs_pfcs .gs_in_ra :focus~label{outline:none;}.gs_in_cb:active .gs_cbx,.gs_in_ra:active .gs_cbx,.gs_in_cb .gs_cbx:active,.gs_in_ra .gs_cbx:active,.gs_in_cb :active~.gs_cbx,.gs_in_ra :active~.gs_cbx{border-color:#666;background-color:#ebebeb;}button.gs_in_cb:active .gs_cbx{border-color:#a6a6a6;}.gs_in_cb :disabled~.gs_cbx,.gs_in_ra :disabled~.gs_cbx,button.gs_in_cb:disabled .gs_cbx{border-color:#f1f1f1;box-shadow:none;}.gs_in_cb :disabled~label,.gs_in_ra :disabled~label{color:#b8b8b8;}.gs_in_cb.gs_err .gs_cbx{border-color:#eda29b;}.gs_in_cb .gs_chk,.gs_in_ra .gs_chk{position:absolute;z-index:1;top:-3px;left:-2px;width:21px;height:21px;}.gs_md_li .gs_chk{top:3px;left:14px}.gs_el_tc .gs_in_cb .gs_chk{top:5px}.gs_el_tc .gs_md_li .gs_chk{top:11px}.gs_in_cb.gs_in_cbj .gs_chk{top:10px;left:11px}.gs_in_ra .gs_chk{top:4px;left:4px;width:7px;height:7px;border-radius:4px;}.gs_el_tc .gs_in_ra .gs_chk{top:12px}.gs_in_cb input:checked~.gs_chk,.gs_in_cb.gs_sel .gs_chk{background:no-repeat url(/intl/en/scholar/images/1x/sprite_20161020.png) -69px -67px;opacity:.62;}.gs_in_ra input:checked~.gs_chk{background-color:#666}.gs_in_cb.gs_par .gs_chk{background:no-repeat url(/intl/en/scholar/images/1x/sprite_20161020.png) -21px -44px;opacity:.55;}@media(-webkit-min-device-pixel-ratio:1.5),(min-resolution:144dpi){.gs_in_cb input:checked~.gs_chk,.gs_in_cb.gs_sel .gs_chk,.gs_in_cb.gs_par .gs_chk{background-image:url(/intl/en/scholar/images/2x/sprite_20161020.png);background-size:169px;}}.gs_in_cb input:checked:disabled~.gs_chk{opacity:.22}.gs_in_ra input:checked:disabled~.gs_chk{background-color:#f1f1f1}.gs_ico_x{background-position:-113px -22px;opacity:.55;}.gs_ico_x:hover{opacity:.72;}.gs_ico_x:active{opacity:1;}.gs_ico_X{background-position:-71px 0;opacity:.55;}.gs_ico_X:hover{opacity:.72;}.gs_ico_X:active{opacity:1;}.gs_el_tc .gs_ico_Xt{background-origin:content-box;background-clip:content-box;padding:10px 6px 10px 14px;}.gs_ico_P{background-position:0 0;opacity:.55;}.gs_ico_P:hover{opacity:.72;}.gs_ico_P:active{opacity:1;}.gs_btnP .gs_ico{background-position:-21px 0;}.gs_btnC .gs_ico{background-position:0 -66px;}.gs_btnL .gs_ico{background-position:-92px -44px;}.gs_ico_LB{background-position:-50px -44px;height:16px;}.gs_btnJ .gs_ico{background-position:-92px -22px;}.gs_btnM .gs_ico{background-position:-92px 0;}.gs_btnMW .gs_ico{background-position:-21px -22px;}.gs_btnSB .gs_ico{background-position:0 -44px;}.gs_btnTSB .gs_ico{background-position:-115px -253px;}.gs_btnPL .gs_ico{background-position:-148px -66px;}.gs_btnPR .gs_ico{background-position:-21px -66px;}.gs_btnPLW .gs_ico{background-position:-0 -230px;}.gs_btnPRW .gs_ico{background-position:-23px -230px;}.gs_btnZI .gs_ico{background-position:-148px -22px;}.gs_btnZO .gs_ico{background-position:-127px -44px;}.gs_btnDE .gs_ico{background-position:-134px 0;}.gs_btnFI .gs_ico{background-position:-50px -66px;}.gs_btnAD .gs_ico{background-position:-141px -88px;opacity:.55;}.gs_btnAD:hover .gs_ico{opacity:.72;}.gs_btnAD:active .gs_ico,.gs_btnAD .gs_ico:active,.gs_btnAD :active~.gs_ico{opacity:1;}.gs_btnBA .gs_ico{background-position:-50px -22px;}.gs_btnADD .gs_ico{background-position:-92px -66px;}.gs_btnMRG .gs_ico{background-position:-113px 0;}.gs_btnLBL .gs_ico{background-position:0 -161px;}.gs_btnCNCL .gs_ico{background-position:-71px 0;}.gs_btnDWL .gs_ico{background-position:-28px -88px;}.gs_btnMNU .gs_ico{background-position:0 -88px;}.gs_btnMNT .gs_ico{background-position:-46px -161px;}.gs_btnALT .gs_ico{background-position:-92px -161px;}.gs_btnART .gs_ico{background-position:-115px -161px;}.gs_btnGSL .gs_ico{background-position:-69px -161px;}.gs_btnCLS .gs_ico{background-position:-138px -161px;}.gs_btnXBLU .gs_ico{background-position:-138px -253px;}.gs_btnSSB .gs_ico{background-position:0 -276px;}.gs_btnSSW .gs_ico{background-position:-23px -276px;}.gs_btnFLT .gs_ico{background-position:0 -184px;}.gs_btnXT .gs_ico{background-position:-46px -184px;}.gs_btnPD .gs_ico{background-position:-69px -184px;}.gs_btnPU .gs_ico {background-position:-92px -276px;}.gs_btnCP .gs_ico{background-position:-92px -184px;}.gs_btnTP .gs_ico{background-position:-138px -184px;}.gs_btnML .gs_ico{background-position:-115px -276px;}.gs_btnCHK .gs_ico{background-position:-71px -66px;}.gs_btnDNB .gs_ico{background-position:-115px -230px;}.gs_btnDNW .gs_ico{background-position:0 -207px;}.gs_btnACA .gs_ico{background-position:-23px -207px;}.gs_btnAPT .gs_ico{background-position:-46px -207px;}.gs_btnAPTW .gs_ico{background-position:-92px -230px;}.gs_btnAFL .gs_ico{background-position:-69px -207px;}.gs_btnAN .gs_ico{background-position:-46px -276px;}.gs_btnAI .gs_ico{background-position:-69px -276px;}.gs_btnPBL .gs_ico{background-position:-92px -207px;}.gs_btnUCT .gs_ico{background-position:-115px -207px;}.gs_btnVRF .gs_ico{background-position:-138px -207px;}.gs_btnLSI .gs_ico{background-position:-46px -230px;}.gs_btnLSG .gs_ico{background-position:-69px -230px;}.gs_btnMOR .gs_ico{background-position:-23px -253px;}.gs_btnADV .gs_ico{background-position:-46px -253px;}.gs_btnPRO .gs_ico{background-position:-69px -253px;}.gs_ico_star{background-position:-71px -44px;width:13px;height:13px;}.gs_btnPLSW .gs_ico{background-position:-138px -230px;}.gs_btnPDF .gs_ico{background-position:0 -253px;}.gs_btnS .gs_ico{background-position:-138px -276px;}.gs_btnUNS .gs_ico{background-position:0 -299px;}.gs_btnMORR .gs_ico{background-position:-23px -299px;}.gs_btnTW .gs_ico{background-position:-46px -299px;}.gs_btnIN .gs_ico{background-position:-69px -299px;}.gs_btnFB .gs_ico{background-position:-92px -299px;}#gs_hdr_drs,#gs_hdr_drw{position:fixed;top:0;left:0;width:100%;height:100%;z-index:1200;visibility:hidden;}#gs_hdr_drs{opacity:0;background-color:#fff;transition:opacity .15s,visibility 0s .15s;}.gs_el_ta #gs_hdr_drs,.gs_el_ph #gs_hdr_drs{background-color:#666;}#gs_hdr_drs.gs_vis{visibility:visible;opacity:.5;transition:opacity .15s,visibility 0s;}.gs_el_tc #gs_hdr_drs{transition:opacity .218s,visibility 0s .218s;}.gs_el_tc #gs_hdr_drs.gs_vis{transition:opacity .218s,visibility 0s;}#gs_hdr_drw{overflow:auto;width:228px;background-color:#fff;box-shadow:2px 2px 4px rgba(0,0,0,.15);outline:none;transform:translate(-100%,0);transition:transform .15s ease-in-out,visibility 0s .15s;}#gs_hdr_drw.gs_vis{visibility:visible;transform:translate(0,0);transition:transform .15s ease-in-out,visibility 0s;}.gs_el_tc #gs_hdr_drw{transition:transform .3s cubic-bezier(.4,0,.6,1),visibility 0s .3s;}.gs_el_tc #gs_hdr_drw.gs_vis{transition:transform .225s cubic-bezier(0,0,.2,1),visibility 0s;}#gs_hdr_drw.gs_abt,.gs_el_tc #gs_hdr_drw.gs_abt{transition:none;}#gs_hdr_drw_in{position:relative;box-sizing:border-box;min-height:100%;padding:0 0 8px 0;}.gs_el_ta #gs_hdr_drw_in,.gs_el_ph #gs_hdr_drw_in{padding:0 0 65px 0;}#gs_hdr_drw_top{position:relative;height:63px;border-bottom:1px solid #e5e5e5;margin-bottom:8px;}.gs_el_ta #gs_hdr_drw_top,.gs_el_ph #gs_hdr_drw_top{height:57px;}#gs_hdr_drw_mnu,#gs_hdr_drw_lgo{position:absolute;top:0;height:100%;}#gs_hdr_drw_mnu{left:0;width:55px;}#gs_hdr_drw_lgo{left:56px;}.gs_hdr_drw_sec:before{display:block;content:" ";height:0;border-bottom:1px solid #e5e5e5;margin:8px 0;}.gs_hdr_drw_sec:first-child:before{display:none;}#gs_hdr_drw_bot{display:none;}.gs_el_ta #gs_hdr_drw_bot,.gs_el_ph #gs_hdr_drw_bot{display:block;position:absolute;left:0;bottom:0;width:100%;height:65px;}#gs_hdr_drw_bot .gs_md_li:before{opacity:0;}#gs_hdr_drw_bot .gs_hdr_pp{display:block;position:absolute;bottom:14px;left:15px;pointer-events:none;}#gs_hdr_drw_bot .gs_lbl{display:block;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;}#gs_hdr{position:relative;height:63px;background-color:#f5f5f5;border-bottom:1px solid #e5e5e5;display:flex;}.gs_el_ta #gs_hdr,.gs_el_ph #gs_hdr{height:57px;}#gs_hdr_mnu,#gs_hdr_bck,#gs_hdr_lgo,#gs_hdr_lgt,#gs_hdr_md,#gs_hdr_sre,#gs_hdr_act{display:inline-block;vertical-align:top;position:relative;height:100%;flex:0 0 auto;}#gs_hdr_md{flex:1 1 auto;}#gs_hdr .gs_hdr_mbo,#gs_hdr .gs_hdr_mbo,.gs_el_ta #gs_hdr .gs_hdr_dso,.gs_el_ph #gs_hdr .gs_hdr_dso{display:none;}.gs_el_ta #gs_hdr .gs_hdr_mbo,.gs_el_ph #gs_hdr .gs_hdr_mbo{display:inline-block;}#gs_hdr_mnu,#gs_hdr_bck,#gs_hdr_sre{width:55px;margin-right:1px;}#gs_hdr_lgo,#gs_hdr_drw_lgo{width:149px;background:no-repeat url('/intl/en/scholar/images/1x/scholar_logo_24dp.png') 0% 50%;background-size:149px;}@media(-webkit-min-device-pixel-ratio:1.5),(min-resolution:144dpi){#gs_hdr_lgo,#gs_hdr_drw_lgo{background-image:url('/intl/en/scholar/images/2x/scholar_logo_24dp.png');}}#gs_hdr_lgo{margin-right:31px;}.gs_el_ph #gs_hdr_lgo{margin-right:0;}#gs_hdr_lgt{min-width:164px;margin-right:16px;}#gs_hdr_lgt:empty{display:none;}#gs_hdr_md{margin-right:16px;min-width:1px;}#gs_hdr_lgt,#gs_hdr_md h1{padding:19px 0 0 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;font-size:20px;line-height:25px;font-weight:normal;color:#666;max-width:100%;text-align:left;}.gs_el_ta #gs_hdr_md h1,.gs_el_ph #gs_hdr_md h1{padding:16px 0 0 0;}#gs_hdr_srch{padding:14px 0 0 0;max-width:600px;}.gs_el_ta #gs_hdr_srch,.gs_el_ph #gs_hdr_srch{padding:10px 0 0 0;max-width:none;}#gs_hdr_frm{position:relative;padding-right:39px;}#gs_hdr_tsi{height:38px;border-radius:2px 0 0 2px;}#gs_hdr_tsi::-ms-clear{display:none;}#gs_hdr_tsc{display:none;position:absolute;top:3px;right:41px;width:21px;height:21px;padding:6px 10px 7px 10px;}.gs_in_acw[dir="rtl"]~#gs_hdr_tsc{right:auto;left:1px;}#gs_hdr_tsb{position:absolute;top:0;right:0;width:40px;height:38px;border-radius:0 2px 2px 0;}#gs_hdr_frm_ac{top:37px;right:40px;}.gs_el_ph #gs_hdr_frm_ac{right:0;}.gs_el_ph .gs_hdr_ifc #gs_hdr_mnu,.gs_el_ph .gs_hdr_ifc #gs_hdr_bck,.gs_hdr_src #gs_hdr_srch,.gs_hdr_src #gs_hdr_lgt,.gs_hdr_srx #gs_hdr_sre,.gs_hdr_srx #gs_hdr_md h1,.gs_hdr_srx #gs_hdr_md h1.gs_hdr_mbo,.gs_hdr_srx #gs_hdr_md h1.gs_hdr_dso,.gs_el_ta .gs_hdr_srx #gs_hdr_lgo,.gs_el_ph .gs_hdr_srx #gs_hdr_lgo,.gs_el_ph .gs_hdr_srx #gs_hdr_mnu,.gs_el_ph .gs_hdr_srx #gs_hdr_bck{display:none;}.gs_el_ph .gs_hdr_ifc #gs_hdr_md,.gs_el_ph .gs_hdr_srx #gs_hdr_md{margin-left:16px;}.gs_el_tc .gs_hdr_tsc #gs_hdr_tsi[dir="ltr"]{padding-right:41px;}.gs_el_tc .gs_hdr_tsc #gs_hdr_tsi[dir="rtl"]{padding-left:41px;}.gs_el_tc .gs_hdr_tsc .gs_in_acw~#gs_hdr_tsc{display:block;}#gs_hdr_act{min-width:64px;max-width:200px;text-align:right;float:right;}.gs_el_ta #gs_hdr_act,.gs_el_ph #gs_hdr_act{display:none;}#gs_hdr_act_i,#gs_hdr_act_s{display:inline-block;padding:23px 24px 23px 16px;max-width:100%;box-sizing:border-box;font-size:13px;line-height:17px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;color:#444;}#gs_hdr_act_s{text-transform:uppercase;}.gs_el_sm #gs_hdr_act_i,.gs_el_sm #gs_hdr_act_s{padding:23px 16px;}.gs_el_ta #gs_hdr_act_i,.gs_el_ta #gs_hdr_act_s,.gs_el_ph #gs_hdr_act_i,.gs_el_ph #gs_hdr_act_s{padding:20px 16px;}#gs_hdr_act_i:active,#gs_hdr_act_s:active{color:#d14836;}#gs_hdr_act_i,.gs_el_sm #gs_hdr_act_i{padding-top:15px;padding-bottom:16px;}.gs_el_ta #gs_hdr_act_i,.gs_el_ph #gs_hdr_act_i{padding-top:12px;padding-bottom:13px;}#gs_hdr_act_i .gs_hdr_pp{vertical-align:top;}#gs_hdr_act_d{top:63px;left:auto;right:24px;min-width:288px;max-width:400px;}.gs_el_sm #gs_hdr_act_d{right:16px;}.gs_el_ta #gs_hdr_act_d{top:57px;}.gs_el_ph #gs_hdr_act_d{top:57px;min-width:280px;max-width:280px;max-width:90vw;}/* Account dialog body. */#gs_hdr_act_aw,#gs_hdr_act_ap,.gs_hdr_act_am,#gs_hdr_act_ab{display:block;padding:10px 20px;word-wrap:break-word;white-space:normal;}#gs_hdr_act_aw{background-color:#fef9db;font-size:11px;}#gs_hdr_act_ap,.gs_hdr_act_am{border-bottom:1px solid #ccc;}#gs_hdr_act_ap{padding:20px;}.gs_el_ph #gs_hdr_act_ap{padding:10px;}#gs_hdr_act_apb{margin-top:12px;}#gs_hdr_act_aa:link,#gs_hdr_act_aa:visited{float:right;margin-left:8px;color:#1a0dab;}#gs_hdr_act_aa:active{color:#d14836}.gs_hdr_act_am:link,.gs_hdr_act_am:visited{color:#222;text-decoration:none;background:#fbfbfb;}.gs_hdr_act_am:hover,.gs_hdr_act_am:focus{background:#f1f1f1;}.gs_hdr_act_am:active{background:#eee;}#gs_hdr_act_ab{background:#fbfbfb;padding:10px 0;display:table;width:100%;white-space:nowrap;}#gs_hdr_act_aba,#gs_hdr_act_abs{display:table-cell;padding:0 20px;}#gs_hdr_act_abs{text-align:right;}.gs_el_ph #gs_hdr_act_aba,.gs_el_ph #gs_hdr_act_abs{display:block;padding:10px;text-align:center;}.gs_el_ph #gs_hdr_act_aba button,.gs_el_ph #gs_hdr_act_abs button{width:100%;}#gs_hdr_act_a1,#gs_hdr_act_a2{position:absolute;top:-9px;right:7.5px;width:0;height:0;z-index:1;border:8.5px solid transparent;border-top:none;border-bottom-color:#333;border-bottom-color:rgba(0,0,0,.2);}#gs_hdr_act_a2{top:-8px;border-bottom-color:#fff;}.gs_hdr_act_mw #gs_hdr_act_a2{border-bottom-color:#fef9db;}.gs_hdr_pp{border-radius:50%;overflow:hidden;}#gs_hdr_act_ap .gs_hdr_pp,.gs_hdr_act_am .gs_hdr_pp{float:left;}#gs_hdr_act_ap .gs_hdr_pm{margin-left:116px;}.gs_hdr_act_am .gs_hdr_pm{margin:6px 0 0 58px;}#gs_ab{position:relative;height:41px;border-bottom:1px solid #e5e5e5;display:flex;white-space:nowrap;background-color:#fff;z-index:1000;}.gs_el_ta #gs_ab.gs_nta,.gs_el_ph #gs_ab.gs_nph{display:none;}#gs_ab_g{height:42px;}.gs_sth_vis #gs_ab{position:fixed;}#gs_ab_ico,#gs_ab_ttl,#gs_ab_md,#gs_ab_btns{display:inline-block;vertical-align:top;position:relative;height:100%;flex:0 0 auto;}.gs_el_ph #gs_ab_md{display:block;}#gs_ab_ico{width:55px;margin-right:1px;}#gs_ab_ico .gs_ico{position:absolute;top:50%;left:50%;margin:-10.5px 0 0 -10.5px;}#gs_ab_ttl{min-width:172px;padding-right:8px;}.gs_el_sm #gs_ab_ttl{min-width:68px;}.gs_el_ta #gs_ab_ttl,.gs_el_ph #gs_ab_ttl{min-width:0;}#gs_ab_ttl,#gs_ab_ttll{font-size:18px;color:#666;text-transform:none;}.gs_el_sm #gs_ab_ttl,.gs_el_sm #gs_ab_ttll{font-size:16px;}#gs_ab_ttll{overflow:hidden;text-overflow:ellipsis;max-width:200px;}#gs_ab_md{flex:1 0 auto;}.gs_ab_st #gs_ab_md{flex:1 1 auto;font-size:13px;line-height:17px;padding:0 8px;color:#999;overflow:hidden;text-overflow:ellipsis;}.gs_el_ph .gs_ab_st #gs_ab_md{visibility:hidden;padding:0;}#gs_ab_btns{margin-right:8px;}.gs_el_sm #gs_ab_btns{margin-right:0;}.gs_el_ta #gs_ab_btns,.gs_el_ph #gs_ab_btns{margin-right:4px;}#gs_ab_ttl:before,#gs_ab_md:before,#gs_ab_btns:before{content:"";display:inline-block;width:0;height:100%;vertical-align:middle;}#gs_ab_md>button,#gs_ab_btns>button,#gs_ab_md>.gs_in_ib,#gs_ab_btns>.gs_in_ib,#gs_ab_md>.gs_md_r,#gs_ab_btns>.gs_md_r,#gs_ab .gs_ab_mdw,#gs_ab .gs_ab_btw{margin:0 8px;vertical-align:middle;}#gs_ab .gs_ab_mdw,.gs_ab_btw{display:inline-block;margin:0;}#gs_ab_btns>.gs_in_ib{margin:0 16px 0 8px;}#gs_ab .gs_ab_btw{margin:0 12px 0 16px;}.gs_el_ta .gs_ab_sel #gs_ab_ico,.gs_el_ph .gs_ab_sel #gs_ab_ico,.gs_el_ta .gs_ab_sel #gs_ab_ttl,.gs_el_ph .gs_ab_sel #gs_ab_ttl,.gs_el_ta .gs_ab_sel #gs_ab_btns,.gs_el_ph .gs_ab_sel #gs_ab_btns{display:none;}#gs_bdy{display:table;table-layout:fixed;width:100%;}#gs_bdy_sb{vertical-align:top;width:228px;word-wrap:break-word;display:none;}.gs_el_sm #gs_bdy_sb{}.gs_el_ta #gs_bdy_sb,.gs_el_ph #gs_bdy_sb{}.gs_bdy_sb_sec{margin:0 40px 0 56px;}.gs_bdy_sb_sec:before{display:block;content:" ";height:0;margin:13px 0;border-top:1px solid #eee;}.gs_bdy_sb_sec:first-child:before{margin:21px 0 0 0;border:none;}#gs_bdy_sb ul{list-style-type:none;}.gs_bdy_sb_sec a:link,.gs_bdy_sb_sec a:visited{color:#222;}.gs_bdy_sb_sec a:active{color:#d14836;}.gs_bdy_sb_sel a:link,.gs_bdy_sb_sel a:visited{color:#d14836;text-decoration:none;}.gs_el_tc .gs_bdy_sb_sec li.gs_ind,.gs_el_tc .gs_bdy_sb_sec li.gs_ind a{padding-top:8px;padding-bottom:5px;}.gs_el_tc .gs_bdy_sb_sec:first-child li.gs_ind:first-child{margin-top:-8px;}#gs_bdy_sb .gs_ind,#gs_bdy_sb .gs_inw{margin-bottom:4px;}.gs_el_tc #gs_bdy_sb .gs_ind,.gs_el_tc #gs_bdy_sb .gs_inw{margin-bottom:0;}#gs_bdy_ccl{display:table-cell;vertical-align:top;padding:0 24px 0 16px;}.gs_el_sm #gs_bdy_ccl{padding:0 16px;}.gs_el_ta #gs_bdy_ccl,.gs_el_ph #gs_bdy_ccl{padding:0 16px;}.gs_el_ph #gs_bdy_ccl{padding:0;}#gs_ftr_sp{height:62px;}.gs_el_sm #gs_ftr_sp{height:57px;}#gs_ftr{position:absolute;bottom:0;left:0;width:100%;white-space:nowrap;border-top:1px solid #e4e4e4;background-color:#f2f2f2;display:flex;}#gs_ftr_rt{box-sizing:border-box;max-width:100%;overflow-x:auto;margin-left:auto;padding:0 12px;}.gs_el_sm #gs_ftr_rt{padding:0 8px;}.gs_el_ph #gs_ftr_rt:after{content:" ";position:absolute;top:0;right:0;width:16px;height:100%;background-image:linear-gradient(to right,rgba(242,242,242,0),rgba(242,242,242,1) 80%);}#gs_ftr_rt a{display:inline-block;line-height:16px;padding:12px;white-space:nowrap;}.gs_el_sm #gs_ftr_rt a{padding:12px 8px;}#gs_ftr_rt a:link,#gs_ftr_rt a:visited{color:#666}#gs_ftr_rt a:active{color:#d14836}#gsc_a_t{width:100%;table-layout:fixed;}#gsc_a_tr0,#gsc_a_trh{box-sizing:border-box;}#gsc_a_tr0 th.gsc_a_x,#gsc_a_tr0 th.gsc_a_t,#gsc_a_tr0 th.gsc_a_c,#gsc_a_tr0 th.gsc_a_y{height:0;}#gsc_a_trh{z-index:700;background-color:#f5f5f5;height:42px;}.gs_el_ta #gsc_a_trh,.gs_el_ph #gsc_a_trh,.gs_el_ta #gsc_a_t td,.gs_el_ph #gsc_a_t td{background-color:#fff;border-bottom:1px solid #e5e5e5;}#gsc_a_t th.gsc_a_x,#gsc_a_t th.gsc_a_t,#gsc_a_t th.gsc_a_c,#gsc_a_t th.gsc_a_y{box-sizing:border-box;text-transform:uppercase;vertical-align:middle;padding-top:0;padding-bottom:0;}#gsc_x_all{z-index:1;}.gsc_a_x,.gsc_a_t,.gsc_a_c,.gsc_a_y,.gsc_a_e{font-weight:normal;padding:16px 16px 0 16px;vertical-align:top;text-align:right;}.gsc_a_c{padding:16px 8px 0 8px;}.gs_el_sm .gsc_a_x,.gs_el_sm .gsc_a_t,.gs_el_sm .gsc_a_c{padding:12px 8px 0 8px;}.gs_el_ta .gsc_a_x,.gs_el_ta .gsc_a_t,.gs_el_ta .gsc_a_c,.gs_el_ph .gsc_a_x,.gs_el_ph .gsc_a_t,.gs_el_ph .gsc_a_c{padding:12px 8px;}.gs_el_sm .gsc_a_y{padding:12px 8px 0 8px;}.gs_el_ta .gsc_a_y{padding-bottom:12px;}.gsc_a_x{width:41px;padding:4px 0 0 0;}.gs_el_sm .gsc_a_x{padding:0;}.gsc_a_t{text-align:left;}.gs_el_ph .gsc_a_t{padding-left:16px;}#gsc_a_ta{display:inline-block;vertical-align:middle;margin-right:16px;}.gs_el_ph #gsc_a_ta{display:none}.gs_el_ph .gsc_a_c{padding-right:16px;}th.gsc_a_c{width:64px;white-space:nowrap;}.gsc_art_sel #gsc_a_ta,.gsc_art_sel #gsc_a_ca,.gsc_art_sel .gsc_a_h{display:none;}.gsc_a_ac,.gsc_a_hc{margin-top:3px;}th.gsc_a_y{width:88px;white-space:nowrap;}.gs_el_sm th.gsc_a_y{width:58px;}.gs_el_ph th.gsc_a_y,.gs_el_ph td.gsc_a_y{width:0;padding:0;}.gs_el_ph .gsc_a_h{display:none}@media print{#gs_top th.gsc_a_y{width:58pt;}#gs_top #gsc_a_tr0{display:none}#gs_top #gsc_a_trh{position:static}}.gsc_a_e{padding:16px;text-align:center;}.gsc_a_a{padding:8px 0}.gsc_a_at{padding:8px 0;font-size:16px}a.gsc_a_acm{text-decoration:line-through;}a.gsc_a_acm:hover,a.gs_a_acm:active{text-decoration:underline;}.gsc_a_m{position:absolute;}.gs_el_ph .gsc_a_m{display:block;position:static;}.gsc_a_am{font-size:24px;position:absolute;top:-18px;left:-2px;padding:8px 12px 4px 8px;}.gs_el_ph .gsc_a_am{display:inline-block;position:static;padding:6px 16px;margin-bottom:-6px;}#gsc_a_sp{visibility:hidden;}#gsc_a_sp.gs_vis{visibility:visible;padding:16px 0;height:25px;border-bottom:1px solid #ccc;}#gsc_a_sp:after{display:block;height:100%;content:" ";background:url('/intl/en/scholar/images/spinner.gif') no-repeat 50% 50%;opacity:0;}#gsc_a_sp.gs_vis:after{opacity:1;transition:opacity 0s .4s;}#gsc_a_err{display:none;padding:28px 0;}#gsc_a_err.gs_vis{display:block;}#gsc_md_iad{width:800px;max-width:94%;}.gs_el_ph #gsc_md_iad{width:100%;max-width:100%;}#gsc_md_iad .gs_md_prg{min-height:400px;}.gs_el_ph #gsc_iads_res .gs_md_prg{margin:0 16px;}#gsc_iad_tart,.gsc_iad_tsel.gsc_iad_tart #gsc_iad_tart,.gsc_iad_tart #gsc_iad_tgrp,.gsc_iad_tsel #gsc_iad_tgrp,#gsc_iad_tsel,#gsc_napb_hdr #gsc_iad_tart,#gsc_napb_hdr #gsc_iad_tgrp{display:none;}#gsc_iad_tgrp,.gsc_iad_tart #gsc_iad_tart,.gsc_iad_tsel #gsc_iad_tsel,#gsc_napb_hdr #gsc_iad_tsel{display:inline-block;}#gsc_iad_t:not(.gsc_iad_tsel) #gsc_iad_tsel{pointer-events:none;color:#b5b5b5;}.gs_el_ph #gsc_napb #gsc_iads_frm{margin:0 16px;}#gsc_iads_res{position:relative;margin:8px 0 16px 0;min-height:80px;border-bottom:1px solid #e5e5e5;}.gs_el_ph #gsc_md_iad #gsc_iads_res{margin:8px -16px 16px -16px;}.gs_el_ph #gsc_napb #gsc_iads_pp{margin-right:16px;}#gsc_iadb_hdr{display:table;table-layout:fixed;width:100%;}#gsc_iadb_hdr_cb,#gsc_iadb_hdr_instr{display:table-cell;vertical-align:middle;height:41px;}#gsc_iadb_hdr_cb{width:41px;}#gsc_iadb_hdr_cb:empty{width:0;}.gs_el_ph #gsc_iadb_hdr_cb:empty{width:16px;}#gsc_iadb_hdr_instr{font-size:16px;}.gs_el_ph #gsc_iadb_hdr_instr{padding-right:16px;}.gsc_oic{position:relative;}.gsc_oic_cb{font-weight:normal;border-top:1px solid #e5e5e5;border-bottom:1px solid #e5e5e5;background-color:#fcfcfc;padding-right:16px;}.gsc_oict{display:block;overflow:hidden;}.gsc_oict_name{display:block;font-size:16px;line-height:20px;word-wrap:break-word;}.gsc_oict_inf{display:block;float:right;margin-left:16px;white-space:nowrap;}.gsc_oict_all,.gsc_oict_prf{font-size:13px;text-transform:uppercase;line-height:20px;}.gsc_oict_all[data-a]{color:#1a0dab;cursor:pointer;}.gsc_oict_all[data-a]:hover{text-decoration:underline;}.gsc_oict_all[data-a]:active{color:#d14836;}.gsc_oict_prf{padding-left:8px;margin-left:8px;border-left:1px solid #e0e0e0;}.gsc_oict_prf:empty{display:none;}.gs_el_ph .gsc_oict_all,.gs_el_ph .gsc_oict_prf{float:right;clear:both;margin:0;padding:0;border:none;}.gs_el_ph .gsc_oict_prf{margin-top:2px;}.gsc_oic_res{margin:8px 0 12px 41px;}.gs_el_ph .gsc_oic_res{margin-right:16px;}.gsc_oic_res h4{font-size:13px;font-weight:normal;}.gsc_oic_dis .gsc_oic_name,.gsc_oic_dis .gsc_oic_all,.gsc_oic_dis .gsc_oic_prf{color:#777;}.gsc_oic_dis .gsc_oict_all[data-a]{color:#1a0dab;opacity:.66;}.gsc_oic_dis .gsc_oic_res{opacity:.5;}.gsc_iadb_art{border-top:1px solid #e5e5e5;overflow:hidden;}.gsc_iadb_art_cb{float:left;}.gsc_iadb_art_added{float:right;margin:12px;font-size:11px;text-transform:uppercase;color:#777;}.gs_el_ph .gsc_iadb_art_added{display:block;float:none;text-align:right;margin:8px 16px;}.gsc_iadb_art_added:empty{display:none;}.gsc_iadb_art_body{margin:12px 0 12px 41px;}.gs_el_ph .gsc_iadb_art_body{margin:12px 16px 12px 41px;}.gsc_iadb_art_body h3{font-size:13px;font-weight:normal;}.gsc_iadb_art_dis .gsc_iadb_art_body{opacity:.5;}#gsc_md_mopt,#gsc_md_cbyd,#gsc_md_cbym{width:600px;}.gs_el_ta #gsc_md_mopt,.gs_el_ta #gsc_md_cbyd,.gs_el_ta #gsc_md_cbym{width:500px;}.gs_el_ph #gsc_md_mopt,.gs_el_ph #gsc_md_cbyd,.gs_el_ph #gsc_md_cbym{width:100%;}.gsc_mob_art{vertical-align:top;padding:8px 0;}.gs_el_tc .gsc_mob_art>.gs_in_ra{margin-top:-8px;}.gsc_mob_cby{vertical-align:top;text-align:right;padding:8px 12px;position:relative;}.gsc_mob_ttl,.gsc_mob_pub{display:block;}.gsc_mob_pub{color:#666;}.gsc_mob_cbym{text-decoration:line-through}.gsc_mob_cbm{font-size:24px;position:absolute;padding:4px 0 0 4px;line-height:16px;}.gs_fsvg line{stroke:#222222}a:link .gs_fsvg{fill:#1a0dab;}a:link .gs_fsvg line{stroke:#1a0dab;}a:visited .gs_fsvg{fill:#660099;}a:visited .gs_fsvg line{stroke:#660099;}a:active .gs_fsvg{fill:#d14836;}a:active .gs_fsvg line{stroke:#d14836;}a .gs_fsvg{border-bottom:1px solid transparent;}a:hover .gs_fsvg,a:focus .gs_fsvg{border-bottom-color:inherit;}.gs_fsml{font-size:13px}.gs_fscp{font-variant:small-caps}.gsh_clim{display:table-row}.gsh_clil,.gsh_clic{display:table-cell;padding-bottom:8px}.gsh_clil{padding-right:8px;}.gsh_lla{list-style-type:lower-alpha}.gsh_lua{list-style-type:upper-alpha}.gsh_llr{list-style-type:lower-roman}.gsh_lur{list-style-type:upper-roman}.gsh_l>li{margin-left:32px;}.gsh_h3{font-size:inherit;font-weight:normal}.gsh_h3,.gsh_csp{margin:16px 0}.gsh_h3+.gsh_csp{margin-top:-8px}.gsh_ovln{text-decoration:overline}.gsh_small .gsh_l .gsh_csp{margin:8px 0}.gsh_small .gsh_csp:first-child,.gsh_small .gsh_h3:first-child{margin-top:0}.gsh_small .gsh_csp:last-child{margin-bottom:0}.gsh_dspfr{text-align:center}.gsh_dspfr svg{margin:8px 0}.gs_pp_tn,.gs_el_ta .gs_pp_mo_tn,.gs_el_ph .gs_pp_mo_tn{width:32px;height:32px;}.gs_pp_sm,.gs_el_ta .gs_pp_mo_sm,.gs_el_ph .gs_pp_mo_sm{width:56px;height:56px;}.gs_pp_nm,.gs_el_ta .gs_pp_mo_nm,.gs_el_ph .gs_pp_mo_nm{width:128px;height:128px;}.gs_ai_pho{float:left;}.gs_ai_t{margin-left:72px;}.gs_ai_pho_pst+.gs_ai_t{margin-left:48px;}.gs_ai_t.gs_ai_pss{margin-left:64px;}.gs_ai_pho_pst+.gs_ai_t.gs_ai_pss{margin-left:40px;}.gs_ai_name{font-size:17px;font-weight:normal;margin-bottom:4px;}.gs_ai_name a{padding:6px 0 4px 0;}.gs_ai_name.gs_ai_name_nlsb{font-size:15px;}.gs_ai_name.gs_ai_name_nlsb a:link,.gs_ai_name.gs_ai_name_nlsb a:visited{padding:7px 0 5px 0; color:#222;}.gs_ai_name.gs_ai_name_nlsb a:active{color:#d14836;}.gs_ai_int{margin-top:5px;}.gs_ai_eml:empty,.gs_ai_int:empty,.gs_ai_cby:empty{display:none;}.gs_ai_one_int{vertical-align:top;font-size:13px;margin-right:8px;white-space:nowrap;display:inline-block;max-width:200px;text-overflow:ellipsis;overflow:hidden;}.gs_el_tc a.gs_ai_one_int{padding:8px 0 5px 0;}.gs_el_ph .gs_ai_eml,.gs_el_ph .gs_ai_cby{margin-top:8px;}.gs_ai_ilnl .gs_ai_int,.gs_ai_ilnl .gs_ai_cby{margin-top:8px;color:#666;}.gs_ai.gs_ai_chpr{position:relative;}.gs_ai_chpr .gs_ai_t{margin-right:276px;}.gs_el_sm .gs_ai_chpr .gs_ai_t{margin-right:156px;}.gs_el_ph .gs_ai_chpr .gs_ai_t{margin-right:0;}.gs_ai_chpr .gs_ai_cby{position:absolute;top:4px;right:0;text-align:right;}.gs_el_sm .gs_ai_chpr .gs_ai_cby,.gs_el_ta .gs_ai_chpr .gs_ai_cby{width:132px;word-wrap:break-word;}.gs_el_ph .gs_ai_chpr .gs_ai_cby{text-align:left;position:static;width:auto;}#gsc_bdy{position:relative;max-width:1200px;margin:0 auto;}.gs_el_ph #gsc_bdy,.gs_el_ta #gsc_bdy{display:flex;flex-flow:column;}.gsc_lcl{position:relative;margin:0 350px 0 0;order:3;}.gs_el_sm .gsc_lcl{margin-right:334px;}.gs_el_ta .gsc_lcl,.gs_el_ph .gsc_lcl{margin:0;}#gsc_prf_t_wrp{position:relative;order:2;overflow:hidden;}.gs_el_tc #gsc_prf_t_wrp:after{display:block;content:"";position:absolute;z-index:100;top:0;right:0;width:12px;height:100%;background-image:linear-gradient(to right,rgba(247,247,247,0),rgba(247,247,247,1) 80%);}#gsc_prf_t{width:100%;background-color:#f5f5f5;display:none;white-space:nowrap;overflow-x:auto;padding:0 4px;}.gs_el_ta #gsc_prf_t,.gs_el_ph #gsc_prf_t{display:block;}#gsc_prf_t:after{content:"\00A0";padding:0 4px;}.gsc_prf_tab,.gsc_prf_tab:link{font-size:13px;text-transform:uppercase;padding:13px 12px;display:inline-block;color:#666;cursor:pointer;}.gsc_prf_tab:hover{color:#000;text-decoration:none}.gsc_prf_tab:active{color:#4d90fe;}.gsc_prf_tab[aria-selected="true"]{border-bottom:2px solid #4d90fe;color:#0461f9;cursor:default;}.gs_el_ta #gsc_art,.gs_el_ph #gsc_art,.gs_el_ta #gsc_rsb_cit,.gs_el_ph #gsc_rsb_cit,.gs_el_ta #gsc_rsb_mnd,.gs_el_ph #gsc_rsb_mnd,.gs_el_ta #gsc_rsb_awd,.gs_el_ph #gsc_rsb_awd,.gs_el_ta #gsc_rsb_co,.gs_el_ph #gsc_rsb_co{display:none;}#gsc_bdy[data-tab="gsc_prf_t-art"] #gsc_art,#gsc_bdy[data-tab="gsc_prf_t-cit"] #gsc_rsb_cit,#gsc_bdy[data-tab="gsc_prf_t-mnd"] #gsc_rsb_mnd,#gsc_bdy[data-tab="gsc_prf_t-awd"] #gsc_rsb_awd,#gsc_bdy[data-tab="gsc_prf_t-ath"] #gsc_rsb_co{display:block;}.gsc_rsb{float:right;width:317px;order:4;border-left:1px solid #eee;margin-top:32px;}.gs_el_sm .gsc_rsb{margin-top:16px;}.gs_el_ph .gsc_rsb,.gs_el_ta .gsc_rsb{float:none;width:auto;border:none;margin:0;}.gsc_rsb_s{margin:0 0 48px 16px;position:relative;}.gs_el_sm .gsc_rsb_s{margin:0 0 32px 16px;}.gs_el_ph .gsc_rsb_s,.gs_el_ta .gsc_rsb_s{margin:0;}.gsc_rsb_s:last-child{margin-bottom:0;}.gsc_rsb_header{padding:8px 8px 12px 8px;border-bottom:1px solid #e5e5e5;font-weight:normal;font-size:15px;}.gs_el_sm .gsc_rsb_header{padding:4px 8px 9px 8px;}.gs_el_ph .gsc_rsb_header,.gs_el_ta .gsc_rsb_header{display:none;}.gsc_rsb_action{position:absolute;top:-3px;right:-2px;}.gs_el_sm .gsc_rsb_action{top:-8px;}.gsc_rsb_tap{display:block;position:absolute;right:2px;top:12px;opacity:.5;z-index:1;}.gs_el_ta .gsc_rsb_tap,.gs_el_ph .gsc_rsb_tap{top:24px;right:10px;}.gsc_rsb_hm{border-bottom:1px solid #e5e5e5;padding:3px 6px;}#gsc_rsb_gpl{display:block;margin-top:3px;padding:6px 16px;line-height:15px;color:#0461f9;border:1px solid #4d90fe;border-radius:2px;text-align:center;text-transform:uppercase;}.gs_el_sm #gsc_rsb_gpl{margin-top:0;}.gs_el_ta #gsc_rsb_gpl,.gs_el_ph #gsc_rsb_gpl{display:none;}#gsc_rsb_st{width:100%;}.gsc_rsb_std{text-align:right;padding-right:8px;}.gs_el_ta .gsc_rsb_std,.gs_el_ph .gsc_rsb_std{padding-right:16px;}.gsc_rsb_sc1{text-align:left;padding:2px 8px;}.gs_el_sm .gsc_rsb_sc1{padding:0 8px;}.gs_el_ta .gsc_rsb_sc1,.gs_el_ph .gsc_rsb_sc1{padding:4px 16px;}.gsc_rsb_sth{font-weight:normal;padding:8px 8px 8px 0;border-bottom:1px solid #e5e5e5;text-align:right;}.gs_el_sm .gsc_rsb_sth{padding:4px 8px 4px 0;}.gs_el_ta .gsc_rsb_sth,.gs_el_ph .gsc_rsb_sth{padding:16px 16px 16px 0;}#gsc_rsb_st tbody:before,#gsc_rsb_st tbody:after{content:'';display:block;height:8px;}.gs_el_sm #gsc_rsb_st tbody:before,.gs_el_sm #gsc_rsb_st tbody:after{height:4px;}.gs_el_ph #gsc_hist_opn,.gs_el_ta #gsc_hist_opn{display:none;}.gsc_rsb_f{max-width:118px;word-wrap:break-word;white-space:normal;}.gs_el_ta .gsc_rsb_f{max-width:none;}.gsc_rsb_f:link,.gsc_rsb_f:visited{color:#222;}.gsc_rsb_m_na{color:#dd4b39;}.gsc_rsb_m_a{color:#006621;float:right;position:relative;}.gsc_rsb_m_bar{width:100%;height:4px;margin:8px 0 8px 0;background:#006621;}.gsc_rsb_m_bar_na{background:#dd4b39;width:100%;height:100%;z-index:1;}.gsc_rsb_m{padding:8px;}.gs_el_ta .gsc_rsb_m,.gs_el_ph .gsc_rsb_m{padding:8px 16px;}.gsc_rsb_m_desc{padding-top:16px;color:#777;}.gsc_rsb_m_s{font-size:24px;position:absolute;line-height:0.3;}#gsc_lwp_mndt_lnk{text-transform:uppercase;margin-left:16px;margin-right:-9px;text-align:right;font-size:13px;padding:12px 9px;border-radius:3px;}#gsc_lwp_mndt_lnk:hover,#gsc_lwp_mndt_lnk:active,#gsc_lwp_mndt_lnk:visited{text-decoration:none;color:#1a0dab;}#gsc_lwp_mndt_lnk:hover{background-color:rgba(0,0,0,.05);}#gsc_lwp_mndt_lnk:active{background-color:rgba(0,0,0,.1);}.gsc_rsb_m_title{padding-bottom:12px;}.gsc_rsb_m_header{display:flex;align-items:flex-end;justify-content:space-between;padding:0 8px;}.gs_el_sm .gsc_rsb_m_header{padding:0 8px;}.gsc_rsb_hmv{text-align:center;padding-top:16px;}.gsc_rsb_a{list-style:none;}.gsc_rsb_a>li{position:relative;}.gs_el_ta .gsc_rsb_a>li,.gs_el_ph .gsc_rsb_a>li{border-bottom:1px solid #e5e5e5;}.gsc_rsb_a>li:first-child{margin-top:8px;}.gsc_rsb_a_pht{float:left;width:32px;height:32px;}.gsc_rsb_a_desc{margin:0 33px 0 48px;min-height:32px;display:block;}.gs_el_ph .gsc_rsb_a_desc,.gs_el_ta .gsc_rsb_a_desc{margin:0 33px 0 64px;min-height:56px;}.gsc_rsb_a_desc a{color:#222;}.gsc_rsb_a_ext{display:block;color:#777;font-size:13px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;}.gs_el_ph .gsc_rsb_a_ext,.gs_el_ta .gsc_rsb_a_ext{white-space:normal;}.gsc_rsb_a_ext2{display:none;}.gs_el_ph .gsc_rsb_a_ext2,.gs_el_ta .gsc_rsb_a_ext2{display:block;}.gsc_rsb_aa{display:block;padding:8px;line-height:normal;cursor:pointer;}.gs_el_ph .gsc_rsb_aa,.gs_el_ta .gsc_rsb_aa{font-size:17px;padding:12px 16px;}.gsc_rsb_aa:hover,.gsc_rsb_aa:active{text-decoration:none;background:#f1f1f1;}.gsc_rsb_aa a:hover{text-decoration:none;}#gsc_prf_w{order:1;padding:32px 0;overflow:hidden;}.gs_el_sm #gsc_prf_w{padding:16px 0;}#gsc_prf_pu{float:left;width:128px;height:128px;text-align:center;}.gs_el_ph #gsc_prf_pu{float:none;width:100%;margin:0 0 8px 0;}#gsc_prf_pua{line-height:0;width:128px;height:128px;}.gs_el_ph #gsc_prf_pua{margin:0 auto;}#gsc_prf_pufi{width:0;height:0;overflow:hidden;}.gsc_prf_pufo #gsc_prf_pufi{width:auto;height:auto;overflow:visible;position:relative;z-index:10;}.gsc_prf_pufo #gsc_prf_pufi2{display:inline-block;background:#fcfcfc;padding:8px 8px 8px 0;}.gsc_prf_puic{position:absolute;bottom:0;width:100%;padding:8px 0;background-color:#000;opacity:.6;}.gsc_prf_pel{cursor:pointer;}#gsc_prf_i{margin:0 16px 0 160px;}.gs_el_sm #gsc_prf_i{margin:0 16px 0 144px;}.gs_el_ph #gsc_prf_i{margin:0 16px;text-align:center;}#gsc_prf_btne{vertical-align:top;margin:-9px 4px;}.gs_el_ph #gsc_prf_btne{position:absolute;top:60px;right:8px;margin:0;}#gsc_prf_btnf{float:right;margin:3px 0 16px 16px;}.gs_el_sm #gsc_prf_btnf{margin-top:0;}.gs_el_ph #gsc_prf_btnf{float:none;margin:0;position:absolute;top:8px;right:8px;border-radius:50%;}#gsc_prf_btnf .gs_lbl{padding:0 4px;}#gsc_prf_in{font-size:24px;line-height:24px;padding:3px 0 12px 0;word-wrap:break-word;}.gs_el_sm #gsc_prf_in{font-size:22px;padding:3px 0 8px 0;}.gs_el_ph #gsc_prf_in{font-size:20px;padding:0 0 2px 0;}.gsc_prf_il{font-size:15px;line-height:18px;padding:1px 0;}.gs_el_ph .gsc_prf_il{font-size:13px;line-height:16px;}.gsc_prf_ila:link,.gsc_prf_ila:visited{text-decoration:underline;color:#222;}#gsc_prf_int{margin-top:5px;}#gsc_prf_int:empty{display:none;}.gsc_prf_inta{margin-right:16px;white-space:nowrap;max-width:200px;text-overflow:ellipsis;overflow:hidden;vertical-align:top;}.gsc_prf_inta:last-child{margin:0}.gs_el_tc .gsc_prf_ila,.gs_el_tc .gsc_prf_inta{padding:8px 0 5px 0;}.gsc_md_pro_tt,.gsc_md_pro_ch #gsc_md_pro_lgtm,#gsc_md_pro_save{display:none;}.gsc_md_pro_ed #gsc_md_pro_ted,.gsc_md_pro_aa #gsc_md_pro_taa,.gsc_md_pro_ra #gsc_md_pro_tra,.gsc_md_pro_an #gsc_md_pro_tan,.gsc_md_pro_ai #gsc_md_pro_tai,.gsc_md_pro_ch #gsc_md_pro_save{display:inline-block;}.gsc_md_pro_el{color:#777;}.gsc_md_pro_ev{padding:4px 0 16px 0;}#gsc_dd_add-d,#gsc_dd_exp-d,#gsc_dd_sort-d,#gsc_dd_mor-d{top:42px;}#gsc_dd_add-d,#gsc_dd_mor-d,#gsc_dd_sort-d{white-space:normal;word-wrap:break-word;width:208px;width:-webkit-max-content;width:max-content;min-width:100px;max-width:208px;}.gs_el_ph #gsc_dd_add-d{left:-9px;}.gs_el_ph #gsc_dd_exp-d{left:auto;right:12px;}.gs_el_ph #gsc_dd_mor-d{left:-58px;}.gs_el_ph #gsc_dd_sort-d{left:10px;}.gs_el_ph #gsc_dd_sort-r{margin-left:-10px;}.gsc_dd_sec,#gsc_dd_exp-d{padding:8px 0;}.gs_el_tc .gsc_dd_sec,.gs_el_tc #gsc_dd_exp-d{padding:4px 0 8px 0;}.gsc_dd_sep{border-top:1px solid #ebebeb;}#gsc_dd_mor-s .gsc_dd_mor-sel,#gsc_dd_sort-s .gsc_dd_sort-sel{color:#dd4b39;}#gsc_dd_mor-p{padding:14px 44px 14px 16px;color:#777;}.gs_el_tc #gsc_dd_mor-p{padding:18px 44px 18px 16px;}.gsc_art_sel #gsc_dd_add-r,.gsc_art_sel #gsc_dd_mor-r,#gsc_btn_mer,#gsc_btn_del,#gsc_dd_exp-r{display:none;}#gsc_dd_mor-r,.gsc_art_sel #gsc_btn_mer,.gsc_art_sel #gsc_btn_del,.gsc_art_sel #gsc_dd_exp-r{display:inline-block;}html:not(.gs_el_ph) #gsc_dd_sort-r{display:none;}#gsc_lwp{margin:24px 0;text-align:center;}.gs_el_sm #gsc_lwp{margin:16px 0;}#gsc_bpf{display:inline-block;verticle-align:middle;}#gsc_a_nn{display:inline-block;vertical-align:middle;padding-right:16px;font-size:13px;}.gs_el_ph #gsc_a_nn{display:none;}@media print{#gs_top #gs_md_s,#gs_top #gs_md_w,#gs_top #gs_hdr,#gs_top #gs_hdr_drs,#gs_top #gs_hdr_drw,#gs_top #gs_ftr,#gs_top #gsc_nag,#gs_top #gsc_prf_nbar_btns,#gs_top #gsc_prf_btne,#gs_top #gsc_prf_btnf,#gs_top #gsc_prf_ivh,#gs_top #gsc_prf_puf,#gs_top #gsc_rsb_co,#gs_top #gsc_bdy #gsc_rsb_co,#gs_top .gsc_g_hist_wrp,#gs_top #gsc_prf_t_wrp,#gs_top .gsc_rsb_header,#gs_top .gsc_a_tb,#gs_top .gsc_a_x,#gs_top #gsc_lwp,#gs_top .gsc_prf_puic,#gs_top #gsc_dd_add-r,#gs_top #gsc_dd_mor-r,#gs_top #gsc_dd_sort-r{display:none;}#gs_top,#gs_top #gsc_bdy,#gs_top #gsc_prf_w,#gs_top #gsc_prf,#gs_top #gsc_prf_pu,#gs_top #gsc_prf_pua,#gs_top #gsc_prf_i,#gs_top .gsc_rsb_s,#gs_top .gsc_lcl,#gs_top .gsc_rsb,#gs_top #gsc_a_tw,#gs_top #gsc_a_t,#gs_top .gsc_prf_il,#gs_top .gsc_prf_ila,#gs_top .gsc_prf_inta,#gs_top #gsc_rsb_st{background:none;border:none;padding:0;margin:0;height:auto;width:auto;min-width:0;max-width:none;float:none;display:block;position:static;color:black;font-weight:normal;font-size:12pt;text-decoration:none;}#gs_top .gsc_a_ac,#gs_top .gsc_a_a,#gs_top #gsc_a_ca,#gs_top .gsc_a_at,#gs_top .gsc_rsb_sc1,#gs_top .gsc_rsb_sth,#gs_top .gsc_rsb_std,#gs_top #gsc_bdy .gsc_a_x,#gs_top #gsc_bdy .gsc_a_t,#gs_top #gsc_bdy .gsc_a_c,#gs_top #gsc_bdy .gsc_a_y,#gs_top #gsc_a_trh,#gs_top .gsc_a_m,#gs_top .gsc_a_am{color:black;font-weight:normal;font-size:12pt;padding:0;margin:0;background:none;border:none;}#gs_top #gsc_a_trh,#gs_top #gsc_a_trh th{height:0;}#gs_top #gsc_a_ta,#gs_top #gsc_a_ca,#gs_top #gsc_a_ha,#gs_top .gsc_a_a{font-size:11pt;}#gs_top .gsc_a_ac{font-size:10pt}#gs_top #gsc_prf_pu{width:80pt;height:auto;float:left;margin:0 7pt 7pt 0;}#gs_top #gsc_prf_pua{left:auto;transform:none;border-radius:0;}#gs_top #gsc_prf_pua>img{position:static;}#gs_top #gsc_prf_i{margin:0 7pt 7pt 87pt;text-align:left;}#gs_top #gsc_prf_in{font-size:18pt;line-height:18pt;padding:0 0 4pt 0;}#gs_top .gsc_prf_il{padding:2pt 0;}#gs_top #gsc_prf_w{float:left;width:64%;}#gs_top .gsc_rsb{float:right;width:35%;}#gs_top #gsc_art{clear:both;}#gs_top #gsc_rsb_st{display:table;width:100%;max-width:none;margin-top:3pt;}#gs_top .gsc_rsb_sc1,#gs_top .gsc_rsb_sth,#gs_top .gsc_rsb_std{font-size:10pt;}#gs_top th.gsc_rsb_sc1,#gs_top .gsc_rsb_sth{border-bottom:1pt solid #ccc;}#gs_top .gsc_rsb_f{max-width:60pt;}#gs_top .gsc_rsb_sth{padding-left:14pt;}#gs_top #gsc_bdy .gsc_a_x,#gs_top #gsc_bdy .gsc_a_t,#gs_top #gsc_bdy .gsc_a_c,#gs_top #gsc_bdy .gsc_a_y,#gs_top #gsc_a_trh{padding:6pt 0;}#gs_top #gsc_a_trh{border-bottom:1pt solid #ccc;}#gs_top #gsc_a_ca{display:block;width:auto;}#gs_top #gsc_a_ta{display:inline-block;vertical-align:middle;margin-right:12pt;}#gs_top .gsc_a_h{display:inline;font-size:10pt;}#gs_top .gsc_a_at{color:#008;}#gs_top .gsc_a_m,#gs_top .gsc_a_am{display:inline;position:absolute;}#gs_top .gsc_a_am{padding: 11pt 0 0 8pt;}#gs_top .gsc_a_t .gs_gray{color:black;font-size:10pt;}}.gsc_lwpds_frm{position:relative;height:29px;}.gsc_lwpds_tsiw{position:absolute;top:0;left:0;right:38px;}.gsc_lwpds_tsiw input{border-radius:3px 0 0 3px;}.gsc_lwpds_tsbw{position:absolute;top:0;right:0;}.gsc_lwpds_tsbw button{border-radius:0 3px 3px 0;}.gsc_pgn{text-align:right;font-weight:bold;line-height:29px;}.gsc_pgn_ppn{margin:0 8px;}.gsc_ccb_ck{padding:11px 10px 9px 10px;}.gsc_ccb_svg{stroke:#666;stroke-width:2px;fill:#fff;width:21px;height:21px;vertical-align:top;}.gsc_ccb_lim .gsc_ccb_svg,.gsc_ccb_dis .gsc_ccb_svg{fill:#e2e2e2;stroke:#fff;}.gsc_ccb_lim .gsc_ccb_svg>circle,.gsc_ccb_dis .gsc_ccb_svg>circle{stroke:#e2e2e2;}.gsc_ccb_on .gsc_ccb_svg{fill:#4d90fe;stroke:#fff;}.gsc_ccb_on .gsc_ccb_svg>circle{stroke:#4d90fe;}.gsc_ccb_del:active .gsc_ccb_svg>circle,.gsc_ccb_add:active .gsc_ccb_svg>circle{fill:#2f6de1;}#gsc_md_cod{width:800px;max-width:94%;}.gs_el_ph #gsc_md_cod{width:100%;max-width:100%;}#gsc_md_cod .gs_md_prg{min-height:400px;}.gsc_codb_instr{font-size:16px;margin:1em 0;}#gsc_cods_res{position:relative;margin-bottom:24px;min-height:80px;border-bottom:1px solid #e5e5e5;}.gs_el_ph #gsc_cods_res{margin-bottom:16px;}.gsc_cods_hide,.gsc_cod_sugg #gsc_cod_tedit,.gsc_cod_sugg #gsc_cods_frm,.gsc_cod_sugg #gsc_cods_pp,.gsc_cod_lc #gsc_cod_tadd,.gsc_cod_changed #gsc_cod_tedit,.gsc_cod_changed #gsc_cod_tadd,.gsc_cod_lim #gsc_cod_tedit,.gsc_cod_lim #gsc_cod_tadd{display:none;}#gsc_cods_frm{margin:0 0 24px 0;}.gs_el_ph #gsc_cods_frm{margin:0 0 16px 0;}.gsc_ucoar{padding:24px 0;border-bottom:1px solid #eee;}.gs_el_ph .gsc_ucoar{padding:16px 0px;}.gsc_ucoar:first-child{padding-top:0;}.gsc_ucoar:last-child{border-bottom:none;}.gsc_ucoar_cb{float:right;margin-top:-8px;}#gsc_cod_trev{display:none;color:#666;pointer-events:none;}.gsc_cod_changed #gsc_cod_trev,.gsc_cod_lim #gsc_cod_trev{display:inline-block;}.gsc_cod_changed #gsc_cod_trev{color:#1a0dab;pointer-events:auto;}.gsc_fol_cr{margin:0 0 8px 0;}.gs_el_tc .gsc_fol_cr{margin:0;}.gs_el_tc .gsc_fol_cr:first-child{margin-top:-8px;}#gsc_fol_ml{display:block;color:#777;padding:12px 0 4px 0;}</style><script>!function(GSP){/*

 Copyright The Closure Library Authors.
 SPDX-License-Identifier: Apache-2.0
*/
var aa="function"==typeof Object.create?Object.create:function(a){var b=function(){};b.prototype=a;return new b},ba;if("function"==typeof Object.setPrototypeOf)ba=Object.setPrototypeOf;else{var da;a:{var ea={a:!0},fa={};try{fa.__proto__=ea;da=fa.a;break a}catch(a){}da=!1}ba=da?function(a,b){a.__proto__=b;if(a.__proto__!==b)throw new TypeError(a+" is not extensible");return a}:null}
var ha=ba,ia=function(a,b){a.prototype=aa(b.prototype);a.prototype.constructor=a;if(ha)ha(a,b);else for(var c in b)if("prototype"!=c)if(Object.defineProperties){var d=Object.getOwnPropertyDescriptor(b,c);d&&Object.defineProperty(a,c,d)}else a[c]=b[c];a.na=b.prototype},ja=function(){},ka=function(a,b){var c=Array.prototype.slice.call(arguments,1);return function(){var d=c.slice();d.push.apply(d,arguments);return a.apply(this,d)}};var g=function(){this.o=this.o;this.F=this.F};g.prototype.o=!1;g.prototype.isDisposed=function(){return this.o};g.prototype.T=function(){this.o||(this.o=!0,this.H())};g.prototype.H=function(){if(this.F)for(;this.F.length;)this.F.shift()()};function la(a){var b=[],c=0,d;for(d in a)b[c++]=d;return b};function l(a,b){a.classList.add(b)}function n(a,b){a.classList.remove(b)}function p(a,b){return a.classList?a.classList.contains(b):!1}function q(a,b,c){c=void 0!==c?c:!p(a,b);(c?l:n)(a,b)};function r(a){return 0<=(navigator.userAgent||"").indexOf(a)}var ma=r("iPhone")||r("iPad")||r("iPod"),na=r("iPhone")||r("Android")&&r("Mobile");function oa(){if(void 0===b){var a=window.screen;a={width:window.innerWidth,height:window.innerHeight,ma:a.width,la:a.height}}else a=b;var b=a;a=b.width;var c=b.height,d=b.ma;b=b.la;var e=4;if(600>a||48E4>d*b||na)e=1;else if(982>a)e=2;else if(1136>a||590>c)e=3;return e}var pa,qa=/[?&]tc=([01])/.exec(location.search||"");
pa=qa?0<+qa[1]:r("Android")?!0:window.matchMedia&&window.matchMedia("(pointer)").matches?window.matchMedia("(pointer:coarse)").matches:!r("Firefox")||r("Mobile")||r("Tablet")?ma||"ontouchstart"in window||0<(navigator.msMaxTouchPoints||0):!1;function ra(){if(void 0==sa){sa=!1;try{var a=Object.defineProperty({},"passive",{get:function(){sa=!0}});window.addEventListener("testPassive",ja,a);window.removeEventListener("testPassive",ja,a)}catch(b){}}return sa}var sa;var ta=function(a){this.Y=a},ua=new ta("INPUT"),va=new ta("TABLE");function t(a){return document.getElementById(a)}function x(a){return a.id||(a.id="gs_id"+wa++)}function xa(a){a=(void 0===a?null:a)||document.body;return"rtl"==(a?window.getComputedStyle(a,null):null).direction}
function ya(a){var b=[];a=a.elements;for(var c=a.length,d=0;d<c;d++){var e=a[d],f=encodeURIComponent(e.name||""),h=e.type;!f||e.disabled||!("checkbox"!=h&&"radio"!=h||e.checked)||b.push(f+"="+encodeURIComponent(e.value||""))}return b.join("&")}function za(a,b){var c=a.elements[b];c||(c=document.createElement(ua.Y),c.type="hidden",c.name=b,a.appendChild(c));return c}function Aa(a){t("gsc_md_cbyd_c").href=a&&a.match(Ba)?a:"javascript:void(0)"}function Ca(a){a.match(Ba)&&(window.location.href=a)}
var wa=100,Da=/\S+/g,Ba=/^(?:https?:|[^:/?#]*(?:[/?#]|$))/i,Ea=/^(?:#|\/[a-z0-9_-]*(?:[?].*)?$)/i;function y(a){return a.hasOwnProperty("gs_uid")?a.gs_uid:a.gs_uid=++Fa}var Fa=0;var z=function(){this.i=[];this.A={};this.O=this.v=0};z.prototype.add=function(a){var b=y(a);this.A[b]||(this.i.push(a),this.A[b]=this.i.length,++this.v)};z.prototype.remove=function(a){a=y(a);var b=this.A[a];b&&(this.i[b-1]=null,delete this.A[a],2*--this.v<this.i.length&&!this.O&&Ga(this))};z.prototype.notify=function(a){var b=this.i;try{++this.O;for(var c=0;c<b.length;c++){var d=b[c];d&&d.apply(null,arguments)}}finally{!--this.O&&2*this.v<b.length&&Ga(this)}};
var Ga=function(a){var b=a.i,c=b.length;a=a.A;for(var d=0,e=0;e<c;e++){var f=b[e];f&&(b[d]=f,a[y(f)]=++d)}b.length=d};function B(a,b,c,d,e){Ha(a,b,c,void 0===d?!1:d,void 0===e?!1:e,Ia)}function C(a,b,c,d){Ha(a,b,c,void 0===d?!1:d,!1,Ja)}function Ka(a,b,c,d){function e(h){C(f,a,e,c);b(h)}var f=document;c=void 0===c?!1:c;B(f,a,e,c,void 0===d?!1:d)}function D(a){La?La.add(a):a()}var Ma=window.requestAnimationFrame?function(a){window.requestAnimationFrame(a)}:function(a){setTimeout(a,33)};function Na(a){a.stopPropagation();a.preventDefault()}
function Oa(a){return(a.ctrlKey?1:0)|(a.altKey?2:0)|(a.metaKey?4:0)|(a.shiftKey?8:0)}function Ia(a,b,c,d,e){var f=a.addEventListener;e=e&&ra();f.call(a,b,c,e?{passive:e,capture:d}:d)}function Ja(a,b,c,d){a.removeEventListener(b,c,d)}function Ha(a,b,c,d,e,f){if("string"===typeof b)f(a,b,c,d,e);else for(var h=b.length,k=0;k<h;k++)f(a,b[k],c,d,e)}function Pa(){La.notify();La=null}function Qa(){"complete"==document.readyState&&(C(document,"readystatechange",Qa),Pa())}
var La,Ra=!!document.attachEvent,Sa=document.readyState;if(Ra?"complete"!=Sa:"loading"==Sa)La=new z,Ra?B(document,"readystatechange",Qa):Ka("DOMContentLoaded",Pa);function Ta(){Ka(["mousedown","touchstart"],function(){q(document.documentElement,"gs_pfcs",!0);B(document,"keydown",Ua,!0)},!0,!0)}function Ua(a){9==a.keyCode&&(q(document.documentElement,"gs_pfcs",!1),C(document,"keydown",Ua,!0),Ta())}Ta();function Va(a,b,c,d,e){var f=t(a);Wa(f,function(){l(f,"gs_vis");b&&b()},function(){n(f,"gs_vis");c&&c()},d,e)}function Wa(a,b,c,d,e){var f=x(a);if(!E[f]){var h=document.activeElement;Xa(Ya(a),!0);b&&b();G.push(function(k){delete E[f];try{k||(e||h).focus()}catch(m){}c&&c()});E[f]=G.length;h&&a.contains(h)||setTimeout(function(){var k=d,m=k&&"text"==k.type;if(!k||m&&pa)k=a;try{k.focus(),m&&(k.value=k.value)}catch(w){}},0)}}function H(a){Xa((E[a]||1E6)-1,!1)}
function Za(a){a=void 0===a?!1:a;G.pop()(a)}function Xa(a,b){for(b=void 0===b?!1:b;G.length>a;)Za(b||G.length>a+1)}function Ya(a){for(var b=0;a&&!(b=E[a.id]||0);)a=a.parentNode;return b}var G=[],E={};B(document,"click",function(a){var b=G.length;b&&!Oa(a)&&b>Ya(a.target)&&Za(!0)});B(document,"keydown",function(a){27==a.keyCode&&!Oa(a)&&G.length&&Za()});
B(document,"focus",function(a){var b=G.length;if(b)for(var c=Ya(a.target);c<b;){var d="",e;for(e in E)if(E[e]==b){d=e;break}a:{d=(t(d).getAttribute("data-wfc")||"").match(Da)||[];for(var f=0;f<d.length;f++){var h=t(d[f]);if(h&&h.offsetWidth){d=h;break a}}d=void 0}if(d){Na(a);d.focus();break}else Za(!0),--b}},!0);var $a={},ab={},bb;try{bb=window.sessionStorage}catch(a){};function J(a){return"object"==typeof a?a:null}function cb(a,b){b=db(b);a=eb(a);a=fb(a)||"#";gb=J(b);hb?window.history.pushState(b,"",a):window.location.assign(a)}function ib(a,b){b=db(b);a=eb(a);a=fb(a)||"#";gb=J(b);hb?window.history.replaceState(b,"",a):window.location.replace(a)}function fb(a){var b=[],c;for(c in a)b.push(encodeURIComponent(c)+"="+encodeURIComponent(a[c]));return(a=b.sort().join("&"))?"#"+a:""}
function jb(a){var b={};a=a.split("&");for(var c=0;c<a.length;c++){var d=a[c],e=d.indexOf("=");if(e+1){var f=d.substr(0,e);d=d.substr(e+1)}else f=d,d="";f&&(b[decodeURIComponent(f)]=decodeURIComponent(d))}return b}function kb(a){var b=a.indexOf("#")+1;return jb(b?a.substr(b):"")}function lb(a){var b=a.indexOf("?")+1;a=b?a.substr(b):"";b=a.indexOf("#");return jb(b+1?a.substr(0,b):a)}function mb(a,b){for(var c in b){var d=b[c];void 0!==d?a[c]=d:delete a[c]}}
function eb(a){var b=kb(window.location.hash);mb(b,a);return b}function db(a){var b=gb||J(window.history.state),c={},d;for(d in b)c[d]=b[d];mb(c,a);return c}function nb(){setTimeout(function(){if(!ob){var a=window.history.state;ob=!0;gb=J(a);rb.notify()}sb=!1},0)}var rb=new z,gb,ob=!1,sb=!0,hb="pushState"in window.history,tb;
if("undefined"==typeof GSP)tb=!1;else{var ub=.001*Date.now(),vb=GSP.eventId,wb=!1,K,xb=bb;if(!("nh"in $a)){var yb=xb&&xb.getItem("nh"),zb;if(yb)try{zb=JSON.parse(yb)}catch(a){}ab.nh=zb}K=ab.nh;K instanceof Array||(K=[]);for(var Ab=K.length,Bb=0,Cb=0;Cb<Ab;Cb++){var Db=K[Cb];if(Db instanceof Array&&2==Db.length){var Eb=Db[1]==vb;wb=wb||Eb;10>=Ab-Cb&&+Db[0]>ub-86400&&!Eb&&(K[Bb++]=Db)}}K.length=Bb;K.push([ub,vb]);var Fb=K,Gb=bb;ab.nh=Fb;try{Gb&&Gb.setItem("nh",JSON.stringify(Fb))}catch(a){}tb=wb}
var Hb=tb;"onpageshow"in window?B(window,"pageshow",nb):D(nb);B(window,hb?"popstate":"hashchange",function(a){"loading"!=document.readyState&&(a=a.state,ob=!0,gb=J(a),rb.notify())});function Ib(){Jb&&(C(t("gs_alrt_l"),"click",Jb),Jb=void 0)}function Kb(){var a=Lb();l(a,"gs_anm");l(a,"gs_vis");B(document,"click",Mb);clearTimeout(Nb);Nb=setTimeout(Mb,4E3);++Ob;setTimeout(Pb,0)}function Mb(){Ob||(C(document,"click",Mb),clearTimeout(Nb),Nb=void 0,Ib(),n(Lb(),"gs_vis"))}function Lb(){return t("gs_alrt")}function Pb(){Ob=0}var Nb,Ob=0,Jb;D(function(){var a=t("gs_alrt_m");a&&(a.innerHTML&&!Hb&&Kb(),B(window,"pagehide",function(){Ob=0;Mb();n(Lb(),"gs_anm")}))});function Qb(a,b,c){var d=new XMLHttpRequest;d.onreadystatechange=function(){if(4==d.readyState){var e=d.status,f=d.responseText,h=d.responseURL,k=window.location,m=k.protocol;k="//"+k.host+"/";h&&h.indexOf(m+k)&&h.indexOf("https:"+k)&&(e=0,f="");c(e,f)}};d.open(b?"POST":"GET",a,!0);d.setRequestHeader("X-Requested-With","XHR");b&&d.setRequestHeader("Content-Type","application/x-www-form-urlencoded");b?d.send(b):d.send();return d}function Rb(a){a&&(a.onreadystatechange=ja,a.abort())};var Sb=function(a,b,c){this.type=a;this.currentTarget=this.target=b;this.g=void 0===c?null:c;this.P=!1};Sb.prototype.stopPropagation=function(){this.g&&this.g.stopPropagation();this.P=!0};var L=function(a){a.g&&Na(a.g);a.P=!0};var M=function(a,b){this.R=a;this.ka=b},Tb=function(a,b,c){this.R=a;this.types=b;this.listener=c};function Ub(a,b){var c=b.length;if(c){var d=y(a),e=Vb[d];if(!e){e=Vb[d]=[];d=Wb(b[0].R);for(var f in d){var h=Xb[f];h||(h=Xb[f]=Object.create(null));for(var k in d[f]){var m=h[k];m||(m=h[k]=[]);m.push(a)}}Yb(a,e,b[0],Zb);for(f=1;f<c;f++)Yb(a,e,b[f],$b)}}}function O(a,b,c){ac(new Sb(a,b,void 0===c?null:c))}
function P(a,b,c){var d=bc;"string"===typeof b&&(cc[0]=b,b=cc);var e=b.length;a=Wb(a);for(var f in a)for(var h in a[f])for(var k=0;k<e;k++)d(f,h,b[k],c)}function Wb(a){"string"===typeof a&&(dc[0]=a,a=dc);for(var b=a.length,c=Object.create(null),d=0;d<b;d++){var e=a[d],f=e.charAt(0),h=e.substr(1);if("#"!=f&&"."!=f||!h)throw Error("bad selector: "+e);(e=c[f])||(e=c[f]=Object.create(null));e[h]=!0}return c}
function bc(a,b,c,d){var e=ec[c];e||("touchstart"!=c&&"mouseover"!=c&&"mouseout"!=c&&B(document,c,fc,"focus"==c||"blur"==c),e=ec[c]=Object.create(null));(c=e[a])||(c=e[a]=Object.create(null));(a=c[b])||(a=c[b]=new z);a.add(d)}function fc(a){var b=a.target;b&&3==b.nodeType&&(b=b.parentNode);ac(new Sb(a.type,b,a))}
function ac(a){for(var b=a.target;b&&b!=document&&!b.disabled&&!p(b,"gs_dis");){a.currentTarget=b;var c=b.id;if(c&&!gc("#",c,a))break;c=b.classList||[];for(var d=c.length,e=0;e<d;e++)if(!gc(".",c[e],a))return;b=b.parentNode}}function gc(a,b,c){var d=ec[c.type];(b=(a=d&&d[a])&&a[b])&&b.notify(c);return!c.P}function Yb(a,b,c,d){var e=c.R;c=c.ka;for(var f in c){var h=ka(d,a,c[f]);P(e,f,h);b.push(new Tb(e,f,h))}}function Zb(a,b,c){var d=c.currentTarget;a=hc(a,d)||a;a=ic(a,d);b.call(a,c)}
function $b(a,b,c){a:{for(var d=c.currentTarget;d&&d!=document;){var e=hc(a,d);if(e){a=ic(e,d);break a}d=d.parentNode}a=void 0}a&&b.call(a,c)}function ic(a,b){var c=jc(b),d=kc[c];d||(d=kc[c]=[]);for(var e=d.length,f=0;f<e;f++){var h=d[f];if(h instanceof a)return h}b=new a(b);d.push(b);a=y(a);(d=lc[a])||(d=lc[a]=[]);d.push(c);return b}function hc(a,b){var c,d=b.id;d&&(c=mc(a,c,"#",d));b=b.classList||[];d=b.length;for(var e=0;e<d;e++)c=mc(a,c,".",b[e]);return c}
function mc(a,b,c,d){c=(d=(c=Xb[c])&&c[d])?d.length:0;for(var e=0;e<c;e++){var f=d[e];!(f===a||f.prototype instanceof a)||b&&!(f===b||f.prototype instanceof b)||(b=f)}return b}function jc(a){var b=a.getAttribute("data-duid");b||a.setAttribute("data-duid",b=""+nc++);return b}var ec=Object.create(null),dc=[""],cc=[""],Xb=Object.create(null),Vb=Object.create(null),lc=Object.create(null),kc=Object.create(null),nc=100;window.gs_evt_dsp=fc;function oc(){var a=".gs_md_li";if("string"===typeof a){var b=a.charAt(0),c=a.slice(1);if("#"==b)a=function(d){return d.id==c&&0<d.offsetWidth};else if("."==b)a=function(d){return p(d,c)&&0<d.offsetWidth};else throw Error("bad selector: "+a);}return a}function pc(a,b){return a&&((void 0===b?0:b)?a.lastElementChild:a.firstElementChild)}function qc(a,b){return a&&((void 0===b?0:b)?a.previousElementSibling:a.nextElementSibling)}function rc(a,b,c){c=void 0===c?!1:c;return sc(a,b,oc(),c,!1)}
function sc(a,b,c,d,e){for(var f;b&&a;){if(c(b)){if(e)return b}else for(f=pc(b,d);f;f=qc(f,d))if(e=sc(f,f,c,d,!0))return e;for(e=!0;;){if(b==a)return null;f=b.parentNode;if(b=qc(b,d))break;b=f}}return null};function tc(a){return!!p(a,"gs_sel")+2*!!p(a,"gs_par")}function uc(a){return+a.getAttribute("data-s")}function vc(a,b,c){c=void 0===c?!1:c;q(a,"gs_sel",1==b);q(a,"gs_par",2==b);a.setAttribute("aria-checked",wc[b]);c||a.setAttribute("data-s",""+b)}var wc=["false","true","mixed"];var Q=function(){this.j=Object.create(null);this.l=0};Q.prototype.clear=function(){this.j=Object.create(null);this.l=0};Q.prototype.has=function(a){return a in this.j};Q.prototype.get=function(a){return this.j[a]};Q.prototype.set=function(a,b){this.has(a)||this.l++;this.j[a]=b};Q.prototype.delete=function(a){this.has(a)&&(delete this.j[a],this.l--)};var xc=function(a){var b=window,c=this;this.i=new z;this.V=0;this.S=[b,a,function(){c.V++||Ma(d)},!1];var d=function(){c.V=0;c.i.notify()}};xc.prototype.addListener=function(a){this.i.v||B.apply(null,this.S);this.i.add(a)};xc.prototype.removeListener=function(a){this.i.remove(a);this.i.v||C.apply(null,this.S)};var yc=new xc("scroll"),zc=new xc("resize");var Ac=new z;function Bc(){var a=document.documentElement,b=oa();b={gs_el_ph:1==b,gs_el_ta:2==b,gs_el_sm:4!=b,gs_el_tc:pa||1==b};var c;for(c in b){var d=b[c];if(p(a,c)!=d){var e=!0;q(a,c,d)}}e&&Ac.notify()}q(document.documentElement,"gs_el_ios",ma);Bc();zc.addListener(Bc);B(window,["pageshow","load"],Bc);function R(a,b,c,d){function e(){var u=ca&&p(h,"gs_el_ph");q(F,"gs_vis",!u);h.style.overflowY=Yd&&!u?"scroll":""}function f(){var u=h.clientHeight,I=+A.getAttribute("data-h");I||(w.style.maxHeight="none",I=m.offsetHeight);I=Math.max((u-I)/2,10);u=Math.max(u-48-2*I,10);var Jc=ca&&p(h,"gs_el_ph");m.style.top=Jc?"auto":I+"px";w.style.maxHeight=Jc?"none":u+"px";Cc(w)}b=void 0===b?"":b;c=void 0===c?"":c;d=void 0===d?"":d;var h=document.documentElement,k=t("gs_top"),m=t(a),w=t(a+"-bdy"),v=t(m.getAttribute("data-cid")||
m.id+"-bdy")||m,F=t(m.getAttribute("data-shd")||"gs_md_s"),A=Dc(m),ca=!!A&&p(A,"gs_md_wmw"),N=window.pageYOffset,Yd=k.scrollHeight>h.clientHeight,pb=!!E[a],qb=pb?"":S,Lc=b&&"#"!=b[0]&&!d,$d=a==S&&b==Ec&&c==T;Fc=b;Lc?(pb?q(v,"gs_md_ldg",!0):Gc(m,v,'<div class="gs_md_prg">'+t("gs_md_ldg").innerHTML+"</div>"),O("gs-md-ldin",v)):(d&&Gc(m,v,d),O("gs-md-lded",v));qb&&(++Hc,H(qb),--Hc);S=a;Ec=b;T=c;Ic=d;$d||Hc||(Kc+=1,(qb?ib:cb)(Mc(),Nc()));pb||Wa(m,function(){A&&l(A,"gs_vis");l(m,"gs_vis");q(m,"gs_abt",
sb);Oc(a);Ac.add(e);e();A&&w&&(f(),zc.addListener(f));l(k,"gs_nscl");k.style.top=-N+"px"},function(){Ac.remove(e);zc.removeListener(f);A&&n(A,"gs_vis");n(m,"gs_vis");n(m,"gs_abt");n(F,"gs_vis");h.style.overflowY="";n(k,"gs_nscl");k.style.top="auto";Rb(U);U=null;window.scrollTo(0,N);S=Ec=T=Ic="";var u=Kc;Kc=0;Hc||(0<u?window.history.go(-u):ib(Mc(),Nc()))},Pc(m),Qc(m));Lc&&(Rb(U),U=null,U=Qb(b,c,function(u,I){U=null;u=200==u;Gc(m,v,u?I:Rc());u&&a==S&&b==Ec&&c==T&&(Ic=I,ib(Mc(),Nc()));O("gs-md-lded",
v)}))}function Dc(a){a=a.parentNode;return p(a,"gs_md_wnw")?a:null}function Pc(a){return(a=a.getAttribute("data-ifc"))?t(a):null}function Qc(a){return(a=a.getAttribute("data-cfc"))?t(a):null}
function Gc(a,b,c){q(b,"gs_md_ldg",!1);for(var d=b.querySelectorAll("[data-duid]"),e=d.length,f={},h=0;h<e;h++){for(var k=jc(d[h]),m=kc[k],w=m?m.length:0,v=0;v<w;v++){var F=m[v],A=y(F.constructor),ca=f[A];ca||(ca=f[A]={});ca[k]=!0;F&&"function"==typeof F.T&&F.T()}delete kc[k]}for(var N in f){N=+N;d=f[N];h=(e=lc[N])?e.length:0;for(m=k=0;m<h;m++)w=e[m],w in d||(e[k++]=w);k?e.length=k:delete lc[N]}b.innerHTML=c;Oc(a.id);Rb(U);U=null}
function Oc(a){if(a=document.querySelector("#"+a+">.gs_md_bdy"))a.scrollTop=a.scrollLeft=0,Cc(a)}function Cc(a){var b=a.style,c="padding"+(xa(a)?"Left":"Right");b[c]="";var d=a.offsetWidth-a.clientWidth;2<d&&(a=parseInt(window.getComputedStyle(a,null)[c],10)||0,b[c]=Math.max(a-d,0)+"px")}function Rc(){return'<div class="gs_md_prg"><div class="gs_alrt">'+t("gs_md_err").innerHTML+"</div></div>"}function Mc(){return{d:S||void 0,u:Ec||void 0,p:T?"1":void 0}}function Nc(){return{n:Kc,p:T,h:Ic}}
var U=null,Fc="",S="",Ec="",T="",Ic="",Kc=0,Hc=0;rb.add(function(){var a=kb(window.location.hash),b=a.d||"",c=b?t(b):null;++Hc;if(c){c=a.u||"";a=0<+a.p;var d=gb||J(window.history.state)||{},e=+d.n||0,f=""+(d.p||"");d=""+(d.h||"");c.match(Ea)||(c="");a!=!!f?R(b,"","",Rc()):b==S&&c==Ec&&f==T&&d==Ic||R(b,c,f,d);Kc=e}else S&&H(S);--Hc});var Sc=function(a){g.call(this);this.D=a;this.K=Object.create(null);this.C=null;a=a.querySelectorAll(".gs_in_txtw>input[type=text]");for(var b=a.length;b--;){var c=a[b],d=c.parentNode.querySelector(".gs_in_txts");c=c.name;d&&c&&(this.K[c]=d.innerHTML)}};ia(Sc,g);Sc.prototype.H=function(){Rb(this.C);this.D=this.C=null;g.prototype.H.call(this)};
Sc.prototype.ga=function(a){var b=this;L(a);if((a=this.D)&&!this.C){var c="json=&"+ya(a);Tc(this,!0);this.C=Qb(a.action,c,function(d,e){b.C=null;Tc(b,!1);var f=b.D,h=f.getAttribute("data-alrt");if(h=h?t(h):null)h.innerHTML="";try{var k=200==d&&JSON.parse(e)}catch(A){}k&&"object"==typeof k||(Uc(h,t("gs_md_err").innerHTML),k={});if(d=k.L)Ca(""+d);else{(d=k.M)&&Uc(h,d);d=1E6;if(h&&h.innerHTML){var m=h;d=h.getBoundingClientRect().top}f=f.elements;k=k.E;"object"==typeof k||(k=Object.create(null));for(var w in b.K){h=
f[w];e=void 0;var v=""+(k[w]||""),F=h.parentNode.querySelector(".gs_in_txts");q(h.parentNode,"gs_in_txte",!!v);F&&(F.innerHTML=v||b.K[w]||"");v&&(e=h.getBoundingClientRect().top)<d&&(m=h,d=e)}m&&m.scrollIntoView&&(0>d||d+20>window.innerHeight)&&m.scrollIntoView()}})}};
var Tc=function(a,b){a=a.D;var c=a.getAttribute("data-bsel");a=c?document.querySelectorAll(c):a.querySelectorAll("button");for(c=a.length;c--;){var d=a[c];d.disabled=b;q(d,"gs_bsp",b)}},Uc=function(a,b){if(a)a.innerHTML=b;else{var c=void 0===c?"":c;var d=void 0===d?"":d;var e=void 0===e?[]:e;t("gs_alrt_m").innerHTML=b;Lb().action=d.match(Ba)?d:"";a=t("gs_alrt_l");a.textContent=c;c=t("gs_alrt_h");c.innerHTML="";for(var f in e)b=document.createElement("input"),b.type="hidden",b.name=f,b.value=e[f],
c.appendChild(b);Ib();q(a,"gs_fm_s",!0);Kb()}};Ub(Sc,[new M(".gs_ajax_frm",{submit:Sc.prototype.ga})]);var Vc=[[1,0,1],[2,0,1]];P(".gs_cb_gen","click",function(a){var b=a.currentTarget,c=tc(b),d=2==+b.getAttribute("data-s");vc(b,Vc[+d][c],!0);O("gs-change",b,a.g)});P(".gs_cb_gen",["keydown","keyup"],function(a){var b=a.currentTarget,c=a.g.keyCode;"BUTTON"!=b.tagName||13!=c&&32!=c||(L(a),"keydown"==a.type&&b.click())});P([".gs_cb_gen",".gs_md_li"],"keydown",function(a){var b=a.currentTarget,c=b.tagName,d=a.g.keyCode;"BUTTON"!=c&&(32==d||13==d&&"A"!=c)&&(L(a),b.click())});var Wc=["click","contextmenu","mouseup"].concat(navigator.sendBeacon?[]:["mousedown","touchstart"]),Xc="",Yc=null;function Zc(){Yc=null}function $c(a){navigator.sendBeacon?navigator.sendBeacon(a):Yc&&a==Yc.src||((Yc=new Image).src=a,setTimeout(Zc,1E3))}function ad(){var a=lb(document.location.href).hl||"";a="/scholar_bfnav?url="+encodeURIComponent(document.location.href)+"&hl="+encodeURIComponent(a)+"&ei="+GSP.eventId;$c(a)}D(function(){Xc=Hb?"&bn=1":"";Hb&&ad()});
B(window,"pageshow",function(a){a.persisted&&(Xc="&bn=1",ad())});
B(document,Wc,function(a){if(!("click"==a.type&&a.button||"mouseup"==a.type&&1!=a.button)){var b,c;a:{for(a=a.target;a;){var d=a.nodeName;if("A"==d)break a;if("SPAN"==d||"B"==d||"I"==d||"EM"==d||"IMG"==d)a=a.parentNode;else break}a=null}a&&(b=a.getAttribute("href"))&&(c=a.getAttribute("data-clk"))&&(b="/scholar_url?url="+encodeURIComponent(b)+"&"+c+"&ws="+window.innerWidth+"x"+window.innerHeight+"&at=",c=encodeURIComponent,a=(a=a.getAttribute("data-clk-atid"))&&t(a),b=b+c(a&&a.innerText||"")+Xc,$c(b))}},
!1,!0);P(".gs_fm_s","click",function(a){a=a.currentTarget.getAttribute("data-fm")||"";(a=t(a))&&a.submit()});var V=function(a){this.m=x(a.querySelector(".gs_md_d"));this.G=x(a.querySelector(".gs_md_tb"))};V.prototype.I=function(a){var b=t(this.m);return void 0!==a?rc(b,b,a):null};V.prototype.open=function(a){a=this.I(a);if(p(t(this.G),"gs_sel"))try{a&&a.focus()}catch(c){}else{var b=t(this.G);Va(this.m,function(){l(b,"gs_sel")},function(){n(b,"gs_sel")},a,b)}};V.prototype.close=function(){H(this.m)};V.prototype.Z=function(a){L(a);p(t(this.G),"gs_sel")?this.close():this.open("keydown"==a.g.type?!1:void 0)};
V.prototype.U=function(a){var b=a.g.keyCode;if(38==b||40==b)L(a),this.open(38==b)};V.prototype.aa=function(a){a.target.id==this.m&&this.U(a)};Ub(V,[new M(".gs_md_rmb",{}),new M(".gs_md_tb",{"gs-press":V.prototype.Z,keydown:V.prototype.U}),new M(".gs_md_d",{keydown:V.prototype.aa})]);var W=function(a){V.call(this,a);this.ia=x(a.querySelector(".gs_md_in"));this.ja=x(a.querySelector(".gs_md_tb .gs_lbl"))};ia(W,V);W.prototype.I=function(){return t(this.m).querySelector(".gs_md_li[aria-selected]")};W.prototype.ba=function(a){bd(this,a)};W.prototype.J=function(a){var b=a.g.keyCode;13!=b&&32!=b||bd(this,a)};
var bd=function(a,b){var c=b.currentTarget,d=t(a.ia),e=a.I();c!=e&&(d.value=c.getAttribute("data-v"),t(a.ja).innerHTML=c.innerHTML,e&&cd(e,!1),cd(c,!0));L(b);a.close();O("gs-change",d,b.g)},cd=function(a,b){q(a,"gs_sel",b);b?a.setAttribute("aria-selected","true"):a.removeAttribute("aria-selected")};Ub(W,[new M(".gs_md_ris",{}),new M(".gs_md_li",{click:W.prototype.ba,keydown:W.prototype.J})]);P("#gs_lp","click",function(a){L(a);R("gs_lp_d")});P("#gs_lp_cur","click",function(a){L(a);H("gs_lp_d")});var dd=function(a){this.W=x(a)};dd.prototype.J=function(a){var b=a.currentTarget,c=a.g.keyCode;if(38==c||40==c){var d=t(this.W);d=rc(d,b,38==c)||rc(d,d,38==c)}else if(37==c||39==c)a:{c=!!(37==c^xa(b.parentNode));d=b.parentNode;var e=d.children,f=e.length;if(d.id!=this.W){for(;e[--f]!=b;);d=qc(d,c)||pc(d.parentNode,c);e=d.children;if(f=Math.min(f+1,e.length))if(d=e[f-1],p(d,"gs_md_li")&&d.offsetLeft!=b.offsetLeft)break a}d=void 0}d&&(L(a),d.focus())};
Ub(dd,[new M(".gs_md_ulr",{}),new M(".gs_md_li",{keydown:dd.prototype.J})]);P("#gs_hdr_mnu","click",function(a){L(a);R("gs_hdr_drw")});P("#gs_hdr_drw_mnu","click",function(a){L(a);H("gs_hdr_drw")});P("#gs_hdr_act_i","click",function(a){L(a);1==oa()?Ca(document.querySelector("#gs_hdr_drw_bot>a").href):Va("gs_hdr_act_d")});P("#gs_hdr_drw","keydown",function(a){var b=a.g.keyCode;if(38==b||40==b){var c=a.currentTarget;if(b=rc(c,c,38==b))L(a),b.focus()}});
P("#gs_hdr_tsi",["focus","blur"],function(a){function b(){var h=d.getBoundingClientRect().top-10;10<Math.abs(h)&&window.scrollBy(0,h);clearTimeout(e);c()}function c(){C(window,f,b)}var d=a.target;a="focus"==a.type;q(t("gs_hdr"),"gs_hdr_ifc",a);if(a&&pa&&!(749<window.innerHeight)){var e=setTimeout(c,1E3),f=["scroll","resize"];B(window,f,b)}});P("#gs_hdr_tsi",["input","gs-change"],function(a){q(t("gs_hdr_frm"),"gs_hdr_tsc",!!a.currentTarget.value)});
P("#gs_hdr_tsc","mousedown",function(a){L(a);var b=t("gs_hdr_tsi");b.value="";b.focus();O("input",b,a.g)});P("#gs_hdr_sre","click",function(a){L(a);var b=t("gs_hdr");Va("gs_hdr_frm",function(){n(b,"gs_hdr_src");l(b,"gs_hdr_srx")},function(){l(b,"gs_hdr_src");n(b,"gs_hdr_srx")},t("gs_hdr_tsi"))});P(".gs_md_x","click",function(a){(a=a.currentTarget.getAttribute("data-mdx"))&&H(a)});var X=function(){},ed,fd;X.prototype.$=function(a){a.g.button||(L(a),gd(a))};X.prototype.ca=function(a){hd(a)&&(L(a),gd(a))};X.prototype.da=function(a){hd(a)&&L(a)};X.prototype.ea=function(a){if(!a.g.button){L(a);var b=a.g;b&&(id=b.clientX||0,jd=b.clientY||0,B(document,kd,ld,!0),clearTimeout(ed),ed=setTimeout(md,2E3));gd(a)}};X.prototype.ha=function(a){L(a);if(nd){var b=a.g;if(b=(b=b&&b.touches)&&1==b.length&&b[0])od=b.clientX,pd=b.clientY,B(document,qd,rd,!0),clearTimeout(fd),fd=setTimeout(sd,2E3)}gd(a)};
var hd=function(a){a=a.g.keyCode;return 32==a||13==a},gd=function(a){O("gs-press",a.currentTarget,a.g)},md=function(){C(document,kd,ld,!0);clearTimeout(ed);ed=void 0},ld=function(a){"mousedown"!=a.type&&10>Math.abs(a.clientX-id)&&10>Math.abs(a.clientY-jd)?(Na(a),"click"==a.type&&md()):md()},sd=function(){C(document,qd,rd,!0);clearTimeout(fd);fd=void 0},rd=function(a){"touchstart"!=a.type&&10>Math.abs(a.clientX-od)&&10>Math.abs(a.clientY-pd)?(Na(a),"click"==a.type&&sd()):sd()},id=0,jd=0,kd=["mousedown",
"mouseup","click"],nd=r("Android")&&!r("Chrome"),od=0,pd=0,qd=["touchstart","mousedown","mouseup","click"];Ub(X,[new M(".gs_press",{click:X.prototype.$,keydown:X.prototype.ca,keyup:X.prototype.da,mousedown:X.prototype.ea,touchstart:X.prototype.ha})]);function td(){var a=0>ud.getBoundingClientRect().top;vd!=a&&(vd=a,q(wd,"gs_sth_vis",a),a?xd():(yd.style.left="",yd.style.width="",zd()))}function xd(){if(vd){var a=ud.getBoundingClientRect();yd.style.left=a.left+"px";yd.style.width=a.width+"px";zd()}}function zd(){O("gs-sth-change",t("gs_sth"))}var wd,ud,yd,vd=!1;D(function(){if(wd=t("gs_sth"))ud=wd.querySelector(".gs_sth_g"),yd=wd.querySelector(".gs_sth_b"),yc.addListener(td),zc.addListener(xd),td()});function Ad(){var a=t("gsc_rsb_co");if(a){a=a.querySelectorAll("img.gs_pp_df");for(var b=0;b<a.length;b++){var c=a[b];c.getAttribute("data-srcset")&&(c.setAttribute("srcset",c.getAttribute("data-srcset")),c.removeAttribute("data-srcset"));c.getAttribute("data-src")&&(c.setAttribute("src",c.getAttribute("data-src")),c.removeAttribute("data-src"))}}};var Bd=/\S+@\S+\.\S+/;function Cd(a){return p(a,"gsc_ccb_dis")||p(a,"gsc_ccb_lim")}function Dd(){for(var a=0>=Ed(),b=t("gsc_cods_res").querySelectorAll(".gsc_ccb_add"),c=b.length;c--;){var d=b[c];p(d,"gsc_ccb_on")||q(d,"gsc_ccb_lim",a)}};var Fd=function(a){this.X=a};Fd.prototype.fa=function(a){L(a);a=a.currentTarget.getAttribute("data-a");this.X.setAttribute("data-a",a||"");O("gsc-navigate",this.X)};var Gd=[new M(".gsc_pgn",{}),new M([".gsc_pgn_ppr",".gsc_pgn_pnx"],{click:Fd.prototype.fa})];function Hd(a,b){b=void 0===b?"":b;var c=t("gsc_md_cod");a+=fb({t:Id});R(c.id,a,"",b)}function Jd(a){if(Id!=a){var b=t("gsc_md_cod");n(b,Id);l(b,a);Id=a}}function Kd(){var a=kb(Fc).t;"gsc_cod_sugg"!=a&&"gsc_cod_lc"!=a||Jd(a)}function Ld(){var a=Md();a=a?a.value:"";var b=(t("gsc_cods_urls").getAttribute("data-sa")||"").replace(Nd,"$1"+encodeURIComponent(a));a=a?b:t("gsc_cods_urls").getAttribute("data-lc")||"";Hd(a)}
function Od(a){var b=t("gsc_cods_frm");if(b){b=b.elements;var c=b[1];b[0].disabled=c.disabled=a;q(c,"gs_bsp",a)}a=a?null:t("gsc_codb_data");if(c=t("gsc_cods_pp")){var d=a&&a.getAttribute("data-prev");b=a&&a.getAttribute("data-next");var e=a&&a.getAttribute("data-start"),f=a&&a.getAttribute("data-end");c.querySelector(".gsc_pgn_ppn").textContent=e&&f?e+" - "+f:"";e=c.querySelector(".gsc_pgn_ppr");e.disabled=!d;e.setAttribute("data-a",d||"");c=c.querySelector(".gsc_pgn_pnx");c.disabled=!b;c.setAttribute("data-a",
b||"")}a&&(Pd=+a.getAttribute("data-max")||0,za(t("gsc_cods_save"),"xsrf").value=a.getAttribute("data-xsrf")||"")}function Qd(){var a=0<Y.l||0<Z.l,b=Ed(),c=0>=b;t("gsc_cod_done").disabled=!a||0>b;q(t("gsc_cod_t"),"gsc_cod_changed",a);a=t("gsc_cod_trev");a.textContent=a.getAttribute(c?"data-lim":"data-txt")||"";q(t("gsc_cod_t"),"gsc_cod_lim",c)}function Ed(){return Pd-Y.l+("gsc_cod_sugg"==Id?0:Z.l)}function Md(){return t("gsc_cods_tsi")}
function Rd(a){for(var b="",c=la(a.j),d=c.length;d--;)b+=a.get(c[d]);return b}var Id="gsc_cod_lc",Pd=0,Nd=/([?&]mauthors=)([^&]*)/,Y=new Q,Z=new Q;function Sd(a){q(t("gsc_a_sp"),"gs_vis",0==a);q(t("gsc_a_err"),"gs_vis",2==a)}function Td(){return document.querySelectorAll("#gsc_a_t input[type=checkbox]")}function Ud(){O("gsc-works-change",t("gsc_a_t"))}function Vd(){var a=t("gsc_x_all");if(a){var b=document.querySelectorAll("#gsc_a_t input[type=checkbox]:checked");var c=b.length;var d=Td().length;c=c?c==d?1:2:0;vc(a,c);2==c&&(Wd=b)}Ud()}var Wd=[];var Xd="",Zd=0,ae=0;function be(a){for(var b=[!1,!1,!1],c=0;c<b.length;c++){var d=t(ce[c]);d&&(b[c]=!!a(d))}return b}function de(){var a=t("gsc_fol_m");if(a){var b=t("gsc_fol_b");if(!(a=!Bd.test(a.value))){a:{a=be(tc);for(var c=be(uc),d=0;d<a.length;d++)if(a[d]!=c[d]){a=!0;break a}a=!1}a=!a}b.disabled=a}}var ce=["gsc_fol_a","gsc_fol_c","gsc_fol_r"],ee=["follow_articles_btn","follow_citations_btn","follow_related_btn"];function fe(){p(document.documentElement,"gs_el_ph")||p(document.documentElement,"gs_el_ta")||Ad()};function ge(a){if(a){a.id&&a.removeAttribute("id");for(var b=0;b<a.children.length;b++)ge(a.children[b])}};function he(){var a=t("gsc_prf_pufii");if(r("MSIE ")){var b=t("gsc_prf_puf");Va("gsc_prf_pufi",function(){l(b,"gsc_prf_pufo")},function(){n(b,"gsc_prf_pufo")},a)}else a.click()};function ie(){var a=document.querySelectorAll(".gsc_prf_pnl"),b=document.documentElement;b=p(b,"gs_el_ph")||p(b,"gs_el_ta");for(var c=0;c<a.length;c++)a[c].setAttribute("role",b?"tabpanel":"region")};var je=kb(window.location.hash),ke=je.u||"";"gs_md_cita-d"==je.d&&ke.match(Ea)&&0<=ke.indexOf("view_citation")&&Ca(ke);P("#gsc_md_cod","gs-md-ldin",function(){Kd();Od(!0)});P("#gsc_md_cod","gs-md-lded",function(){Kd();Od(!1);for(var a=t("gsc_cods_res").querySelectorAll(".gsc_ccb_ck"),b=a.length;b--;){var c=a[b];if(!Cd(c)){var d=c.getAttribute("data-authorid")||"";d=(p(c,"gsc_ccb_add")?Y:Z).has(d);q(c,"gsc_ccb_on",d)}}Dd();Qd();a=lb(Fc);(b=Md())&&(b.value=a.mauthors||"")});
P("#gsc_cods_frm","gsc-lwpds-submit",Ld);P("#gsc_cods_pp","gsc-navigate",function(a){(a=a.currentTarget.getAttribute("data-a"))&&Hd(a)});
P([".gsc_ccb_add",".gsc_ccb_del"],"click",function(a){a=a.currentTarget;if(!Cd(a)){var b=!p(a,"gsc_ccb_on");q(a,"gsc_ccb_on",b);var c=p(a,"gsc_ccb_add")?".gsc_ccb_del":".gsc_ccb_add",d=a.parentNode;(c=d&&d.querySelector(c))&&n(c,"gsc_ccb_on");c=a.getAttribute("data-authorid")||"";Y.delete(c);Z.delete(c);b&&(p(a,"gsc_ccb_add")?Y:Z).set(c,t("gsc_ucoar-"+c).outerHTML);Dd();Qd()}});
P("#gsc_cod_trev","click",function(){var a=t("gsc_cods_res").cloneNode(!0),b=a.querySelector("#gsc_codb_content");b||(b=document.createElement("div"),b.id="gsc_codb_content",a.appendChild(b));var c=Rd(Y)+Rd(Z);b.innerHTML=c;(b=Md())&&(b.value="");Hd("",a.innerHTML)});P("#gsc_cod_done","click",function(){var a=t("gsc_cods_save");za(a,"colleague_add").value=la(Y.j).join(",");za(a,"colleague_del").value=la(Z.j).join(",");a.submit()});
P(["#gsc_coauth_opn",".gsc_rsb_btne",".gsc_rsb_btnv"],"click",function(){Jd("gsc_cod_lc");Pd=0;Y.clear();Z.clear();var a=Md();a&&(a.value="");Ld()});P(".gsc_rsb_aa",["click","keydown"],function(a){if("keydown"!=a.type||a.g&&!Oa(a.g)&&13==a.g.keyCode)a.g&&Na(a.g),(a=(a=a.currentTarget.querySelector("a"))?a.getAttribute("href"):"")&&Ca(a)});P("#gsc_prf_t-ath","click",function(){Ad()});D(function(){Ac.add(fe);fe()});P(".gsc_lwpds_frm","submit",function(a){L(a);O("gsc-lwpds-submit",a.target)});
var le=window.location.href.split("#")[0];Xd=le.replace(/([?&])(cstart|pagesize)=[^&]*/g,"$1");Zd=Math.max(+le.replace(/.*[?&]cstart=([^&]*).*/,"$1")||0,0);ae=+le.replace(/.*[?&]pagesize=([^&]*).*/,"$1")||0;ae=Math.max(Math.min(ae,100),20);
P("#gsc_bpf_more","click",function(a){var b=a.currentTarget,c=ae,d=100>c?100-c:100;a=(Xd+"&cstart="+(Zd+c)+"&pagesize="+d).replace(/([?&])&+/g,"$1");Sd(0);b.disabled=!0;Qb(a,"json=1",function(e,f){b.disabled=!1;try{var h=200==e&&JSON.parse(f)}catch(m){}if(h&&"object"==typeof h){ae=c+=d;Sd(1);e=t("gsc_a_b");f=document.createElement(va.Y);f.innerHTML=""+h.B;f=Array.prototype.slice.call(f.rows);for(var k=0;k<f.length;k++)e.appendChild(f[k]);Vd();if(e=t("gsc_a_nn"))f=e.innerHTML.replace(/[0-9]+$/,""+
t("gsc_a_b").rows.length),e.innerHTML=f;b.disabled=!h.N}else Sd(2)})});P(["#gsc_fol_a","#gsc_fol_c","#gsc_fol_r"],"gs-change",de);P("#gsc_fol_m","input",de);P("#gsc_fol_f","submit",function(a){a.g&&a.g.preventDefault();a=t("gsc_fol_f");var b=t("gsc_fol_inp");b.innerHTML="";for(var c=be(tc),d=be(uc),e=0;e<c.length;e++)if(c[e]!=d[e]){var f=ee[e],h=document.createElement("input");h.type="hidden";h.name=c[e]?f:"un"+f;b.appendChild(h)}O("gsc-fol-submit",a)});P("#gsc_fol_f","gsc-fol-submit",function(a){a.currentTarget.submit()});
P("#gsc_md_hist","gs-md-lded",function(){var a=t("gsc_md_hist_c");if(!a.innerHTML){var b=document.getElementsByClassName("gsc_g_hist_wrp");1==b.length&&(a.appendChild(b[0].cloneNode(!0)),ge(a.lastChild))}});P(["#gsc_hist_opn",".gsc_md_hist_b"],"click",function(){var a=document.documentElement;!t("gsc_hist_opn")||p(a,"gs_el_ph")||p(a,"gs_el_ta")||R("gsc_md_hist")});
P("#gsc_lwp_mndt_lnk","click",function(a){var b=a.currentTarget.getAttribute("href")+"&tzom="+(new Date).getTimezoneOffset();window.location.assign(b);a.g.preventDefault()});P("#gsc_prf_btne","click",function(){var a=t("gsc_md_pro-d");a.setAttribute("data-ifc","");R(a.id,fb({t:"gsc_md_pro_ed"}))});P("#gsc_prf_btnf","click",function(){R("gsc_md_fol")});P("#gsc_md_fol_pub","click",function(){t("gsc_fol_mpf").submit()});P("#gsc_prf_iv_tg","click",function(){q(t("gsc_prf_w"),"gsc_prf_why")});
P(".gsc_prf_pel",["click","keydown"],function(a){("keydown"!=a.type||13==a.g.keyCode&&a.g&&!Oa(a.g))&&he()});P("#gsc_prf_pufii","change",function(){t("gsc_prf_puf").submit()});P(".gsc_prf_tab","click",function(a){var b=t("gsc_bdy");b.setAttribute("data-tab",a.currentTarget.id);b=b.querySelectorAll(".gsc_prf_tab");for(var c=0;c<b.length;c++){var d=b[c];d.setAttribute("aria-selected",""+(d==a.currentTarget))}});D(function(){Ac.add(ie);ie()});
P("#gsc_md_cbyd","gs-md-ldin",function(){var a=t("gsc_md_cbyd_merge");a&&(a.disabled=!0);Aa("")});P("#gsc_md_cbyd","gs-md-lded",function(){var a=t("gsc_md_cbyd_f"),b=t("gsc_md_cbyd_merge"),c=Fc,d=lb(c).s||"";c=kb(c).c||"";a.elements.s.value=d;Aa(c);b&&a.elements.choose&&(b.disabled=!1,b.getBoundingClientRect().bottom<window.innerHeight&&b.focus())});
P("#gsc_md_cbym",["gs-md-ldin","gs-md-lded"],function(){var a=lb(Fc).s||"",b=t("gsc_md_cbym_e");b&&a&&0>a.indexOf("&")&&b.setAttribute("data-href",(b.getAttribute("data-href")||"").replace(/(&citation_for_view=)[^&]*/,"$1"+a))});P("#gsc_md_cbym_e","click",function(a){a=a.currentTarget.getAttribute("data-href")||"";R("gs_md_cita-d",a)});Ub(Fd,Gd);D(function(){return setTimeout(Vd,0)});P(".gsc_a_x","change",Vd);
P("#gsc_x_all","gs-change",function(a){a=tc(a.currentTarget);for(var b=2==a?Wd:Td(),c=b.length;c--;)b[c].checked=0!=a;Ud()});P(".gsc_a_acm","click",function(a){L(a);var b=a.currentTarget;a=b.href;var c=b.getAttribute("data-eid")||"";b=b.getAttribute("data-eud")||"";a=t("gsc_md_cbyd_f").action+"&update_op=merge_options&s="+(b+","+c)+fb({c:a});R("gsc_md_cbyd",a)});
P(".gsc_a_am","click",function(a){a=a.currentTarget.getAttribute("data-eid")||"";a=(t("gsc_md_cbym_l").getAttribute("data-act")||"")+"&update_op=merge_options&s="+a;R("gsc_md_cbym",a)});P("#gs_sth","gs-sth-change",function(a){var b=t("gsc_a_tr0"),c=t("gsc_a_trh"),d=b.querySelector(".gsc_a_t"),e=c.querySelector(".gsc_a_t");p(a.currentTarget,"gs_sth_vis")?(e.style.width=d.offsetWidth+"px",b.style.height=c.offsetHeight+"px"):e.style.width=b.style.height="auto"});
P("#gs_md_cita-b-save","click",function(){var a=t("gsc_ecd_form");za(a,"continue").value=window.location.pathname+window.location.search;O("submit",a)});P(".gsc_ecd_form_tsel","click",function(a){var b=t("gsc_ecd_table"),c=za(t("gsc_ecd_form"),"articletype");a=a.currentTarget;c.value=a.getAttribute("data-type")||"";b.className=a.getAttribute("data-class")||"";b=document.querySelectorAll("#gsc_ecd_citation_type button");for(c=b.length;c--;)q(b[c],"gs_sel",b[c]==a)});
}({"customAC":2,"eventId":"K7E0Ycv2NsX_mQGOg4WwDQ"});</script></head><body><div id="gs_top" onclick=""><style>#gs_md_s,.gs_md_wnw{z-index:1200;position:fixed;top:0;left:0;width:100%;height:100%;visibility:hidden;}#gs_md_s{background-color:#fff;opacity:.5;}.gs_el_ta #gs_md_s,.gs_el_ph #gs_md_s{background-color:#666;}.gs_md_wnw{transition:all 0s .218s;}#gs_md_s.gs_vis,.gs_md_wnw.gs_vis{visibility:visible;transition:all 0s;}.gs_md_wnw>.gs_md_d{position:relative;margin:0 auto;width:464px;box-shadow:2px 2px 8px rgba(0,0,0,.2);white-space:normal;}.gs_el_ta .gs_md_wnw>.gs_md_d,.gs_el_ph .gs_md_wnw>.gs_md_d{box-shadow:2px 2px 8px rgba(0,0,0,.65);}.gs_el_ph .gs_md_wnw>.gs_md_d{width:80%;max-width:440px;}.gs_el_ph .gs_md_wmw>.gs_md_d{width:100%;height:100%;max-width:none;border:none;box-shadow:none;transform:translate(0,100%);transform:translate(0,100vh);transition:transform .27s cubic-bezier(.4,0,.6,1),opacity 0s .27s,visibility 0s .27s,max-height 0s .27s;}.gs_el_ph .gs_md_wmw>.gs_md_d.gs_vis{transform:translate(0,0);transition:transform .3s cubic-bezier(0,0,.2,1);}.gs_md_wmw>.gs_md_d.gs_abt,.gs_el_ph .gs_md_wmw>.gs_md_d.gs_abt{transition:none;}.gs_md_hdr{display:flex;align-items:center;height:47px;border-bottom:1px solid #e0e0e0;border-bottom-color:rgba(0,0,0,.12);background-color:#f5f5f5;}.gs_md_hdr>a,.gs_md_hdr>a.gs_btn_lrge{flex:0 0 auto;width:41px;height:47px;}.gs_el_ph .gs_md_hdr>a{margin:0 2px 0 0;}.gs_el_ph a.gs_md_hdr_c{margin:0 0 0 2px;}.gs_md_hdr_b{margin:0 41px 0 16px;}.gs_el_ph .gs_md_hdr_b{margin:0 16px;}.gs_md_hdr_t:empty~.gs_md_hdr_b{margin-left:0;}.gs_md_hdr_b:empty{width:41px;margin:0;}.gs_el_ph .gs_md_hdr_b:empty{margin-right:2px;}.gs_md_hdr_b:empty:not(:last-child){display:none;}.gs_md_hdr_b>button{min-width:51px;height:33px;}.gs_md_hdr_t{flex:1 1 auto;font-size:18px;font-weight:normal;color:#666;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;text-align:center;}.gs_md_bdy{overflow-y:auto;box-sizing:border-box;padding:24px 41px 0 41px;}.gs_md_bdy:after{display:block;content:"";clear:both;padding-bottom:24px;}.gs_el_ph .gs_md_bdy{padding:16px 16px 0 16px;}.gs_el_ph .gs_md_bdy:after{padding-bottom:16px;}.gs_el_ph .gs_md_wmw .gs_md_bdy{position:absolute;width:100%;top:48px;bottom:0;}.gs_md_lbl{display:block;font-size:16px;margin:0 0 16px 0;word-wrap:break-word;}.gs_md_btns{margin:24px 0 0 0;white-space:nowrap;}.gs_el_ph .gs_md_btns{margin:16px 0 0 0;}.gs_md_btns button{margin-right:16px;}.gs_md_btns button:last-child{margin-right:0;}.gs_md_prg{margin:24px 0;text-align:center;}.gs_md_prg .gs_alrt{padding:4px 16px;}.gs_md_ldg:before{content:"";position:absolute;top:0;left:0;bottom:0;right:0;background-color:#fff;opacity:.5;z-index:100;}</style><div id="gs_md_ldg" style="display:none">Loading...</div><div id="gs_md_err" style="display:none">The system can't perform the operation now. Try again later.</div><div id="gs_md_s"></div><div data-h="0" class="gs_md_wnw"><div id="gsc_md_hist" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gsc_md_hist-t" data-wfc="gsc_md_hist-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_hist-x" role="button" aria-label="Cancel" data-mdx="gsc_md_hist" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_hist-t" class="gs_md_hdr_t">Citations per year</h2><div class="gs_md_hdr_b"></div></div><div id="gsc_md_hist-bdy" class="gs_md_bdy"><style>#gsc_md_hist{width:80%;max-width:386px;}#gsc_md_hist_c{position:relative;width:100%;}</style><div id="gsc_md_hist_c"></div></div></div></div><div data-h="600" class="gs_md_wnw gs_md_wmw"><div id="gsc_md_cbyd" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gsc_md_cbyd-t" data-cid="gsc_md_cbyd_l" data-wfc="gsc_md_cbyd-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_cbyd-x" role="button" aria-label="Cancel" data-mdx="gsc_md_cbyd" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_cbyd-t" class="gs_md_hdr_t">Duplicate citations</h2><div class="gs_md_hdr_b"></div></div><div id="gsc_md_cbyd-bdy" class="gs_md_bdy"><form id="gsc_md_cbyd_f" action="/citations?hl=en&amp;user=mvvgDvcAAAAJ&amp;view_op=list_works" method="post"><input type="hidden" name="s" value=""><div class="gs_md_lbl">The following articles are merged in Scholar. Their <a id="gsc_md_cbyd_c" href="javascript:void(0)">combined citations</a> are counted only for the first article.</div><div id="gsc_md_cbyd_l"></div></form></div></div></div><div data-h="600" class="gs_md_wnw gs_md_wmw"><div id="gsc_md_cbym" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gsc_md_cbym-t" data-cid="gsc_md_cbym_l" data-wfc="gsc_md_cbym-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_cbym-x" role="button" aria-label="Cancel" data-mdx="gsc_md_cbym" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_cbym-t" class="gs_md_hdr_t">Merged citations</h2><div class="gs_md_hdr_b"></div></div><div id="gsc_md_cbym-bdy" class="gs_md_bdy"><div class="gs_md_lbl">This "Cited by" count includes citations to the following articles in Scholar. The ones marked <span id="gsc_md_cbym_s">*</span> may be different from the article in the profile.</div><div id="gsc_md_cbym_l" data-act="/citations?hl=en&amp;user=mvvgDvcAAAAJ&amp;view_op=list_works"></div></div></div></div><div data-h="900" class="gs_md_wnw gs_md_wmw"><div id="gsc_md_cod" class="gs_md_d gs_ttzi gsc_cod_lc" role="dialog" tabindex="-1" aria-labelledby="gsc_md_cod-t" data-cid="gsc_cods_res" data-wfc="gsc_md_cod-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_cod-x" role="button" aria-label="Cancel" data-mdx="gsc_md_cod" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_cod-t" class="gs_md_hdr_t"><span id="gsc_cod_t"><span id="gsc_cod_tadd">Add co-authors</span><span id="gsc_cod_tedit">Co-authors</span><a id="gsc_cod_trev" href="javascript:void(0)" data-txt="Review" data-lim="Limit reached"></a></span></h2><div class="gs_md_hdr_b"><button type="button" id="gsc_cod_done" aria-label="Add co-authors" disabled="" class="gs_btnDNW gs_in_ib gs_btn_act gs_btn_half gs_btn_lsb"><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl"></span></span></button></div></div><div id="gsc_md_cod-bdy" class="gs_md_bdy"><div id="gsc_cods_urls" class="gsc_cods_hide" data-ls="" data-lc="/citations?view_op=list_colleagues&amp;hl=en&amp;json=&amp;user=mvvgDvcAAAAJ" data-sa=""></div><form id="gsc_cods_save" action="" method="POST"><input type="hidden" name="colleague_add"><input type="hidden" name="colleague_del"></form><div id="gsc_cods_res"></div></div></div></div><div data-h="800" class="gs_md_wnw gs_md_wmw"><div id="gs_md_cita-d" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gs_md_cita-d-t" data-cid="gs_md_cita-l" data-wfc="gs_md_cita-d-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gs_md_cita-d-x" role="button" aria-label="Cancel" data-mdx="gs_md_cita-d" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gs_md_cita-d-t" class="gs_md_hdr_t"></h2><div class="gs_md_hdr_b"><button type="button" id="gs_md_cita-b-save" aria-label="Save" class="gs_btnDNW gs_in_ib gs_btn_act gs_btn_half gs_btn_lsb"><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl"></span></span></button></div></div><div id="gs_md_cita-d-bdy" class="gs_md_bdy"><style>#gs_md_cita-d{width:90%;max-width:1000px;}.gs_el_ph #gs_md_cita-d{width:100%;max-width:none;}#gs_md_cita-d .gs_md_prg{min-height:600px;}</style><div id="gs_md_cita-l" aria-live="assertive"></div></div></div></div><div data-h="0" class="gs_md_wnw gs_md_wmw"><div id="gsc_md_fol" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gsc_md_fol-t" data-wfc="gsc_md_fol-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_fol-x" role="button" aria-label="Cancel" data-mdx="gsc_md_fol" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_fol-t" class="gs_md_hdr_t">Follow this author</h2><div class="gs_md_hdr_b"></div></div><div id="gsc_md_fol-bdy" class="gs_md_bdy"><form method="post" id="gsc_fol_f" action="/citations?hl=en&amp;user=mvvgDvcAAAAJ&amp;view_op=list_works"><input type="hidden" name="xsrf" value="AMD79ooAAAAAYTYCq6UfReQd8r3ovNdYhGWSPPXwlKEK"><input type="hidden" name="user" value="mvvgDvcAAAAJ"><div id="gsc_fol_inp"></div><div id="gsc_fol_cb"><div class="gsc_fol_cr"><a href="javascript:void(0)" id="gsc_fol_a" role="checkbox" aria-checked="false" data-s="0" class="gs_cb_gen gs_in_cb"><span class="gs_lbl">New articles by this author</span><span class="gs_chk"></span><span class="gs_cbx"></span></a></div><div class="gsc_fol_cr"><a href="javascript:void(0)" id="gsc_fol_c" role="checkbox" aria-checked="false" data-s="0" class="gs_cb_gen gs_in_cb"><span class="gs_lbl">New citations to this author</span><span class="gs_chk"></span><span class="gs_cbx"></span></a></div><div class="gsc_fol_cr"><a href="javascript:void(0)" id="gsc_fol_r" role="checkbox" aria-checked="false" data-s="0" class="gs_cb_gen gs_in_cb"><span class="gs_lbl">New articles related to this author's research</span><span class="gs_chk"></span><span class="gs_cbx"></span></a></div></div><div id="gsc_fol_email"><label id="gsc_fol_ml" for="gsc_fol_m">Email address for updates</label><div class="gs_in_txtw gs_in_txtb"><input type="text" class="gs_in_txt" name="email_for_op" value="" id="gsc_fol_m" maxlength="100" autocapitalize="off" autocorrect="off"></div></div><div class="gs_md_btns"><button type="submit" id="gsc_fol_b" disabled="" class=" gs_btn_act gs_btn_lrge gs_btn_lsu"><span class="gs_wr"><span class="gs_lbl">Done</span></span></button></div></form></div></div></div><!--[if lte IE 9]><div class="gs_alrt" style="padding:16px"><div>Sorry, some features may not work in this version of Internet Explorer.</div><div>Please use <a href="//www.google.com/chrome/">Google Chrome</a> or <a href="//www.mozilla.com/firefox/">Mozilla Firefox</a> for the best experience.</div></div><![endif]--><div id="gs_hdr_drs"></div><div id="gs_hdr_drw" class="gs_md_ulr" role="dialog" tabindex="-1" data-shd="gs_hdr_drs" data-wfc="gs_hdr_drw_mnu" data-cfc="gs_hdr_mnu"><div id="gs_hdr_drw_in"><div id="gs_hdr_drw_top"><a href="javascript:void(0)" id="gs_hdr_drw_mnu" role="button" aria-controls="gs_hdr_drw" aria-label="Options" class="gs_btnMNT gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><a id="gs_hdr_drw_lgo" href="/schhp?hl=en" aria-label="Homepage"></a></div><div><div class="gs_hdr_drw_sec"><a href="/citations?hl=en" role="menuitem" class="gs_btnPRO gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">My profile</span></a><a href="/scholar?scilib=1&amp;hl=en" role="menuitem" class="gs_btnL gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">My library</span></a><a href="/citations?view_op=metrics_intro&amp;hl=en" role="menuitem" class="gs_btnJ gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">Metrics</span></a><a href="/scholar_alerts?view_op=list_alerts&amp;hl=en" role="menuitem" class="gs_btnM gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">Alerts</span></a></div><div class="gs_hdr_drw_sec"><a href="/scholar_settings?hl=en" role="menuitem" class="gs_btnP gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">Settings</span></a></div></div><div id="gs_hdr_drw_bot" class="gs_hdr_drw_sec"><a href="https://accounts.google.com/Login?hl=en&amp;continue=https://scholar.google.com/schhp%3Fhl%3Den" class=" gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">Sign in</span></a></div></div></div><div id="gs_hdr" role="banner" class="gs_hdr_src"><a href="javascript:void(0)" id="gs_hdr_mnu" role="button" aria-controls="gs_hdr_drw" class="gs_btnMNT gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><a id="gs_hdr_lgo" class="" href="/schhp?hl=en" aria-label="Homepage"></a><div id="gs_hdr_md"><div id="gs_hdr_srch"><form id="gs_hdr_frm" action="/citations"><input type="hidden" name="view_op" value="search_authors"><input type="hidden" name="hl" value="en"><div class="gs_in_txtw gs_in_txtb"><input type="text" class="gs_in_txt" name="mauthors" value="" id="gs_hdr_tsi" placeholder="Search profiles" size="50" maxlength="2048" autocapitalize="off" aria-label="Search"></div><span id="gs_hdr_tsc"><span class="gs_ico gs_ico_X"></span></span><button type="submit" id="gs_hdr_tsb" name="btnG" aria-label="Search" class="gs_btnG gs_in_ib gs_btn_act gs_btn_half gs_btn_lsb"><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl"></span></span></button></form></div></div><a href="javascript:void(0)" id="gs_hdr_sre" role="button" aria-controls="gs_hdr_frm" aria-label="Search" class="gs_btnTSB gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><div id="gs_hdr_act"><a id="gs_hdr_act_s" href="https://accounts.google.com/Login?hl=en&amp;continue=https://scholar.google.com/schhp%3Fhl%3Den">Sign in</a></div></div><style>#gs_alrt{position:fixed;bottom:48px;left:16px;max-width:384px;z-index:1250;display:flex;justify-content:space-between;align-items:center;font-size:13px;line-height:16px;color:#e2e2e2;background:#333;text-align:left;border-radius:3px;box-shadow:0 3px 5px -1px rgba(0,0,0,.2),0 6px 10px 0 rgba(0,0,0,.14),0 1px 18px 0 rgba(0,0,0,.12);visibility:hidden;transform-origin:center;transform:scale(0.8,0.8) translate(0,100%);}.gs_el_ph #gs_alrt{bottom:0;left:0;width:100%;max-width:none;border-radius:0;box-shadow:none;transform:scale(1,1) translate(0,100%);}#gs_alrt.gs_vis{visibility:visible;transform:scale(1,1) translate(0,0);}#gs_alrt.gs_anm{transition:transform .067s cubic-bezier(.4,0,1,1),visibility 0s .067s;}#gs_alrt.gs_vis.gs_anm{transition:transform .067s cubic-bezier(0,0,.2,1);}.gs_el_ph #gs_alrt.gs_anm{transition:transform .084s cubic-bezier(.4,0,1,1),visibility 0s .084s;}.gs_el_ph #gs_alrt.gs_vis.gs_anm{transition:transform .1s cubic-bezier(0,0,.2,1);}#gs_alrt_m{display:block;padding:16px;}#gs_alrt_l{display:block;padding:8px;margin:0 8px 0 -8px;border-radius:3px;color:#fcc934;text-transform:uppercase;text-decoration:none;}#gs_alrt_l:hover{background-color:rgba(255,255,255,.05)}#gs_alrt_l:active{background-color:rgba(255,255,255,.1)}#gs_alrt_l:empty{display:none}#gs_alrt_m a{padding:8px 0;color:#e2e2e2;text-decoration:underline;}#gs_alrt_m a:active{color:#f6aea9}</style><form action="" method="post" id="gs_alrt"><span id="gs_alrt_m"></span><span id="gs_alrt_h"></span><a id="gs_alrt_l" href="javascript:void(0)" class="gs_fm_s" data-fm="gs_alrt"></a></form><div id="gs_bdy"><div id="gs_bdy_sb" role="navigation"><div id="gs_bdy_sb_in"></div></div><div id="gs_bdy_ccl" role="main"><div id="gsc_bdy" class="gs_scl" data-tab="gsc_prf_t-art"><div class="gsc_rsb" role="navigation"><a id="gsc_rsb_gpl" class="gsc_rsb_s" href="/citations?hl=en">Get my own profile</a><div class="gsc_rsb_s gsc_prf_pnl" id="gsc_rsb_cit" role="region" aria-labelledby="gsc_prf_t-cit"><h3 class="gsc_rsb_header"><span class="gsc_rsb_title">Cited by</span><button type="button" id="gsc_hist_opn" class=" gs_btn_flat gs_btn_flact gs_btn_lrge gs_btn_half gs_btn_lsu gsc_rsb_action"><span class="gs_wr"><span class="gs_lbl">View all</span></span></button></h3><table id="gsc_rsb_st"><thead><tr><th class="gsc_rsb_sth"></th><th class="gsc_rsb_sth">All</th><th class="gsc_rsb_sth">Since 2016</th></tr></thead><tbody><tr><td class="gsc_rsb_sc1"><a href="javascript:void(0)" class="gsc_rsb_f gs_ibl" title="This is the number of citations to all publications. The second column has the &quot;recent&quot; version of this metric which is the number of new citations in the last 5 years to all publications.">Citations</a></td><td class="gsc_rsb_std">12402</td><td class="gsc_rsb_std">6920</td></tr><tr><td class="gsc_rsb_sc1"><a href="javascript:void(0)" class="gsc_rsb_f gs_ibl" title="h-index is the largest number h such that h publications have at least h citations. The second column has the &quot;recent&quot; version of this metric which is the largest number h such that h publications have at least h new citations in the last 5 years.">h-index</a></td><td class="gsc_rsb_std">51</td><td class="gsc_rsb_std">33</td></tr><tr><td class="gsc_rsb_sc1"><a href="javascript:void(0)" class="gsc_rsb_f gs_ibl" title="i10-index is the number of publications with at least 10 citations. The second column has the &quot;recent&quot; version of this metric which is the number of publications that have received at least 10 new citations in the last 5 years.">i10-index</a></td><td class="gsc_rsb_std">130</td><td class="gsc_rsb_std">88</td></tr></tbody></table><style>.gsc_g_t{position:absolute;bottom:0;color:#777;font-size:11px;}.gsc_g_a{position:absolute;bottom:13px;width:15px;background:#777;}.gsc_g_a:hover,.gsc_g_a:focus,.gsc_g_a:active{text-decoration:none;cursor:default;}.gsc_g_al{position:absolute;bottom:15px;left:7px;color:#222;background:white;font-size:11px;padding:1px;border:1px solid #777;border-radius:1px;visibility:hidden;opacity:0;transition:opacity .218s,visibility 0s .218s;}.gsc_g_a:hover .gsc_g_al,.gsc_g_a:focus .gsc_g_al,.gsc_g_a:active .gsc_g_al{visibility:visible;opacity:1;transition:all 0s;}#gsc_md_hist{max-width:710px;}.gsc_md_hist_w{position:relative;overflow:hidden;margin-right:43px;}.gs_md_bdy .gsc_md_hist_w,.gs_el_ph .gsc_md_hist_w,.gs_el_ta .gsc_md_hist_w{overflow-x:auto;padding-bottom:16px;}.gsc_md_hist_b{position:relative;height:174px;width:100%;}.gsc_md_hist_b .gsc_g_a{bottom:auto;}.gsc_md_hist_b .gsc_g_t{bottom:auto;top:161px;}.gsc_md_hist_b:after{position:absolute;right:664px;content:"\00A0";}.gsc_g_hist_x{position:relative;margin-right:45px;}.gsc_g_hist_xl{position:absolute;right:8px;width:35px;}.gs_el_ta .gsc_g_hist_xl,.gs_el_ph .gsc_g_hist_xl{right:16px;}.gsc_g_hist_wrp{padding-top:32px;position:relative;}.gs_el_ta .gsc_g_hist_wrp,.gs_el_ph .gsc_g_hist_wrp{padding-right:8px;}.gs_md_bdy .gsc_g_hist_wrp{border-top:0;}.gs_el_tc .gs_md_bdy .gsc_g_hist_wrp:after,.gs_el_tc.gs_el_ph .gsc_g_hist_wrp:after,.gs_el_tc.gs_el_ta .gsc_g_hist_wrp:after{display:block;content:"";position:absolute;z-index:100;top:0;left:0;width:20px;height:100%;background-image:linear-gradient(to left,rgba(255,255,255,0),rgba(255,255,255,1) 80%);}.gsc_g_x,.gsc_g_xt{position:absolute;left:0;border-bottom:1px solid #eee;width:100%;text-align:right;}.gsc_g_x{border-bottom:1px solid #eee;}.gsc_g_xtl{position:absolute;color:#777;}.gsc_g_gtr{position:absolute;}.gsc_g_a:last-child .gsc_g_al{right:0;left:auto;}</style><div class="gsc_g_hist_wrp" dir="rtl"><div class="gsc_g_hist_x"><div class="gsc_g_x" style="top:160px;"></div><div class="gsc_g_xt" style="top:0px;"></div><div class="gsc_g_xt" style="top:80px;"></div><div class="gsc_g_xt" style="top:120px;"></div><div class="gsc_g_xt" style="top:40px;"></div></div><div class="gsc_g_hist_xl"><div class="gsc_g_xtl" style="top:153px;">0</div><div class="gsc_g_xtl" style="top:-7px;">1500</div><div class="gsc_g_xtl" style="top:73px;">750</div><div class="gsc_g_xtl" style="top:113px;">375</div><div class="gsc_g_xtl" style="top:33px;">1125</div></div><div class="gsc_md_hist_w"><div class="gsc_md_hist_b"><span class="gsc_g_t" style="right:611px">2002</span><span class="gsc_g_t" style="right:579px">2003</span><span class="gsc_g_t" style="right:547px">2004</span><span class="gsc_g_t" style="right:515px">2005</span><span class="gsc_g_t" style="right:483px">2006</span><span class="gsc_g_t" style="right:451px">2007</span><span class="gsc_g_t" style="right:419px">2008</span><span class="gsc_g_t" style="right:387px">2009</span><span class="gsc_g_t" style="right:355px">2010</span><span class="gsc_g_t" style="right:323px">2011</span><span class="gsc_g_t" style="right:291px">2012</span><span class="gsc_g_t" style="right:259px">2013</span><span class="gsc_g_t" style="right:227px">2014</span><span class="gsc_g_t" style="right:195px">2015</span><span class="gsc_g_t" style="right:163px">2016</span><span class="gsc_g_t" style="right:131px">2017</span><span class="gsc_g_t" style="right:99px">2018</span><span class="gsc_g_t" style="right:67px">2019</span><span class="gsc_g_t" style="right:35px">2020</span><span class="gsc_g_t" style="right:3px">2021</span><a href="javascript:void(0)" class="gsc_g_a" style="right:616px;top:156px;height:4px;z-index:20"><span class="gsc_g_al">46</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:584px;top:153px;height:7px;z-index:19"><span class="gsc_g_al">66</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:552px;top:152px;height:8px;z-index:18"><span class="gsc_g_al">82</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:520px;top:147px;height:13px;z-index:17"><span class="gsc_g_al">128</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:488px;top:139px;height:21px;z-index:16"><span class="gsc_g_al">199</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:456px;top:136px;height:24px;z-index:15"><span class="gsc_g_al">229</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:424px;top:128px;height:32px;z-index:14"><span class="gsc_g_al">300</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:392px;top:126px;height:34px;z-index:13"><span class="gsc_g_al">321</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:360px;top:111px;height:49px;z-index:12"><span class="gsc_g_al">464</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:328px;top:110px;height:50px;z-index:11"><span class="gsc_g_al">474</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:296px;top:99px;height:61px;z-index:10"><span class="gsc_g_al">576</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:264px;top:85px;height:75px;z-index:9"><span class="gsc_g_al">704</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:232px;top:70px;height:90px;z-index:8"><span class="gsc_g_al">849</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:200px;top:76px;height:84px;z-index:7"><span class="gsc_g_al">790</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:168px;top:55px;height:105px;z-index:6"><span class="gsc_g_al">989</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:136px;top:59px;height:101px;z-index:5"><span class="gsc_g_al">955</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:104px;top:42px;height:118px;z-index:4"><span class="gsc_g_al">1108</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:72px;top:32px;height:128px;z-index:3"><span class="gsc_g_al">1209</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:40px;top:3px;height:157px;z-index:2"><span class="gsc_g_al">1479</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:8px;top:35px;height:125px;z-index:1"><span class="gsc_g_al">1175</span></a></div></div></div></div><div class="gsc_rsb_s gsc_prf_pnl" id="gsc_rsb_mnd" role="region" aria-labelledby="gsc_prf_t-mnd"><div class="gsc_rsb_header gsc_rsb_m_header"><div class="gsc_rsb_m_title">Public access</div><a href="/citations?view_op=list_mandates&amp;hl=en&amp;user=mvvgDvcAAAAJ" id="gsc_lwp_mndt_lnk">View all</a></div><div class="gsc_rsb_hm gs_ota gs_oph"><button type="button" onclick="window.location='/citations?view_op\x3dlist_mandates\x26hl\x3den\x26user\x3dmvvgDvcAAAAJ'" class=" gs_btn_flat gs_btn_flact gs_btn_lrge gs_btn_half gs_btn_lsu"><span class="gs_wr"><span class="gs_lbl">View all</span></span></button></div><div class="gsc_rsb_m"><div class="gsc_rsb_m_a"><span>57 articles</span></div><div class="gsc_rsb_m_na"><div>8 articles</div></div><div class="gsc_rsb_m_bar"><div class="gsc_rsb_m_bar_na" style="width:12%"></div></div><div class="gsc_rsb_m_a"><span>available</span></div><div class="gsc_rsb_m_na"><span>not available</span></div><div class="gsc_rsb_m_desc">Based on funding mandates</div></div></div><div class="gsc_rsb_s gsc_prf_pnl" id="gsc_rsb_co" role="region" aria-labelledby="gsc_prf_t-ath"><h3 class="gsc_rsb_header"><span class="gsc_rsb_title">Co-authors</span><button type="button" id="gsc_coauth_opn" class=" gs_btn_flat gs_btn_flact gs_btn_lrge gs_btn_half gs_btn_lsu gsc_rsb_action"><span class="gs_wr"><span class="gs_lbl">View all</span></span></button></h3><ul class="gsc_rsb_a"><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-KuQs_N0AAAAJ-img{width:32px;height:21px;}.gs_el_ta #gsc_rsb-KuQs_N0AAAAJ-img,.gs_el_ph #gsc_rsb-KuQs_N0AAAAJ-img{width:56px;height:37px;}</style><span id="gsc_rsb-KuQs_N0AAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Simon Hadfield" sizes="(max-width:981px) 56px,32px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=KuQs_N0AAAAJ&amp;citpid=4" id="gsc_rsb-KuQs_N0AAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=KuQs_N0AAAAJ&amp;citpid=4 32w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=KuQs_N0AAAAJ&amp;citpid=4 56w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=KuQs_N0AAAAJ&amp;citpid=4 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=KuQs_N0AAAAJ&amp;hl=en">Simon Hadfield</a><span class="gsc_rsb_a_ext">Centre For Vision Speech and Signal Processing, University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-pvU4kjoAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-pvU4kjoAAAAJ-img,.gs_el_ph #gsc_rsb-pvU4kjoAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-pvU4kjoAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Eng-Jon Ong" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-pvU4kjoAAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=pvU4kjoAAAAJ&amp;hl=en">Eng-Jon Ong</a><span class="gsc_rsb_a_ext">University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-Tk5Egv8AAAAJ-img{width:32px;height:31px;}.gs_el_ta #gsc_rsb-Tk5Egv8AAAAJ-img,.gs_el_ph #gsc_rsb-Tk5Egv8AAAAJ-img{width:56px;height:55px;}</style><span id="gsc_rsb-Tk5Egv8AAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Necati Cihan Camgöz" sizes="(max-width:981px) 56px,32px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=Tk5Egv8AAAAJ&amp;citpid=3" id="gsc_rsb-Tk5Egv8AAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=Tk5Egv8AAAAJ&amp;citpid=3 32w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=Tk5Egv8AAAAJ&amp;citpid=3 56w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=Tk5Egv8AAAAJ&amp;citpid=3 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=Tk5Egv8AAAAJ&amp;hl=en">Necati Cihan Camgöz</a><span class="gsc_rsb_a_ext">CVSSP, University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-NNhnVwoAAAAJ-img{width:30px;height:32px;}.gs_el_ta #gsc_rsb-NNhnVwoAAAAJ-img,.gs_el_ph #gsc_rsb-NNhnVwoAAAAJ-img{width:52px;height:56px;}</style><span id="gsc_rsb-NNhnVwoAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Andrew Gilbert" sizes="(max-width:981px) 52px,30px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=NNhnVwoAAAAJ&amp;citpid=4" id="gsc_rsb-NNhnVwoAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=NNhnVwoAAAAJ&amp;citpid=4 30w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=NNhnVwoAAAAJ&amp;citpid=4 52w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=NNhnVwoAAAAJ&amp;citpid=4 119w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=NNhnVwoAAAAJ&amp;hl=en">Andrew Gilbert</a><span class="gsc_rsb_a_ext">University of surrey,</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-vZrN9OgAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-vZrN9OgAAAAJ-img,.gs_el_ph #gsc_rsb-vZrN9OgAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-vZrN9OgAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Oscar Koller" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-vZrN9OgAAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=vZrN9OgAAAAJ&amp;hl=en">Oscar Koller</a><span class="gsc_rsb_a_ext">Microsoft, Applied Scientist, Speech and Language</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at microsoft.com</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-EJCNY6QAAAAJ-img{width:24px;height:32px;}.gs_el_ta #gsc_rsb-EJCNY6QAAAAJ-img,.gs_el_ph #gsc_rsb-EJCNY6QAAAAJ-img{width:42px;height:56px;}</style><span id="gsc_rsb-EJCNY6QAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Jiri Matas" sizes="(max-width:981px) 42px,24px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=EJCNY6QAAAAJ&amp;citpid=2" id="gsc_rsb-EJCNY6QAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=EJCNY6QAAAAJ&amp;citpid=2 24w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=EJCNY6QAAAAJ&amp;citpid=2 42w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=EJCNY6QAAAAJ&amp;citpid=2 97w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=EJCNY6QAAAAJ&amp;hl=en">Jiri Matas</a><span class="gsc_rsb_a_ext">Professor, Czech Technical University</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at cmp.felk.cvut.cz</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-O9mKQacAAAAJ-img{width:24px;height:32px;}.gs_el_ta #gsc_rsb-O9mKQacAAAAJ-img,.gs_el_ph #gsc_rsb-O9mKQacAAAAJ-img{width:42px;height:56px;}</style><span id="gsc_rsb-O9mKQacAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Nicolas Pugeault" sizes="(max-width:981px) 42px,24px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=O9mKQacAAAAJ&amp;citpid=2" id="gsc_rsb-O9mKQacAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=O9mKQacAAAAJ&amp;citpid=2 24w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=O9mKQacAAAAJ&amp;citpid=2 42w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=O9mKQacAAAAJ&amp;citpid=2 96w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=O9mKQacAAAAJ&amp;hl=en">Nicolas Pugeault</a><span class="gsc_rsb_a_ext">Reader, School of Computing Science, University of Glasgow</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at glasgow.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-PZsm1_IAAAAJ-img{width:31px;height:32px;}.gs_el_ta #gsc_rsb-PZsm1_IAAAAJ-img,.gs_el_ph #gsc_rsb-PZsm1_IAAAAJ-img{width:54px;height:56px;}</style><span id="gsc_rsb-PZsm1_IAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Pakorn Kaewtrakulpong" sizes="(max-width:981px) 54px,31px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=PZsm1_IAAAAJ&amp;citpid=2" id="gsc_rsb-PZsm1_IAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=PZsm1_IAAAAJ&amp;citpid=2 31w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=PZsm1_IAAAAJ&amp;citpid=2 54w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=PZsm1_IAAAAJ&amp;citpid=2 125w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=PZsm1_IAAAAJ&amp;hl=en">Pakorn Kaewtrakulpong</a><span class="gsc_rsb_a_ext">Associate Professor of Control System and Instrumentation Engineering, KMUTT</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at kmutt.ac.th</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-lkWfR08AAAAJ-img{width:22px;height:32px;}.gs_el_ta #gsc_rsb-lkWfR08AAAAJ-img,.gs_el_ph #gsc_rsb-lkWfR08AAAAJ-img{width:39px;height:56px;}</style><span id="gsc_rsb-lkWfR08AAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Michael Felsberg" sizes="(max-width:981px) 39px,22px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=lkWfR08AAAAJ&amp;citpid=3" id="gsc_rsb-lkWfR08AAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=lkWfR08AAAAJ&amp;citpid=3 22w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=lkWfR08AAAAJ&amp;citpid=3 39w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=lkWfR08AAAAJ&amp;citpid=3 89w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=lkWfR08AAAAJ&amp;hl=en">Michael Felsberg</a><span class="gsc_rsb_a_ext">Professor of Computer Vision, Linköping University</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at liu.se</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-d1GQBcYAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-d1GQBcYAAAAJ-img,.gs_el_ph #gsc_rsb-d1GQBcYAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-d1GQBcYAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Helen Cooper" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-d1GQBcYAAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=d1GQBcYAAAAJ&amp;hl=en">Helen Cooper</a><span class="gsc_rsb_a_ext">CVSSP, University Of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-6C8rf-0AAAAJ-img{width:27px;height:32px;}.gs_el_ta #gsc_rsb-6C8rf-0AAAAJ-img,.gs_el_ph #gsc_rsb-6C8rf-0AAAAJ-img{width:48px;height:56px;}</style><span id="gsc_rsb-6C8rf-0AAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Hermann Ney" sizes="(max-width:981px) 48px,27px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=6C8rf-0AAAAJ&amp;citpid=2" id="gsc_rsb-6C8rf-0AAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=6C8rf-0AAAAJ&amp;citpid=2 27w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=6C8rf-0AAAAJ&amp;citpid=2 48w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=6C8rf-0AAAAJ&amp;citpid=2 109w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=6C8rf-0AAAAJ&amp;hl=en">Hermann Ney</a><span class="gsc_rsb_a_ext">RWTH Aachen University</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at cs.rwth-aachen.de</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-M6NgjwkAAAAJ-img{width:21px;height:32px;}.gs_el_ta #gsc_rsb-M6NgjwkAAAAJ-img,.gs_el_ph #gsc_rsb-M6NgjwkAAAAJ-img{width:37px;height:56px;}</style><span id="gsc_rsb-M6NgjwkAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Roman Pflugfelder" sizes="(max-width:981px) 37px,21px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=M6NgjwkAAAAJ&amp;citpid=3" id="gsc_rsb-M6NgjwkAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=M6NgjwkAAAAJ&amp;citpid=3 21w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=M6NgjwkAAAAJ&amp;citpid=3 37w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=M6NgjwkAAAAJ&amp;citpid=3 85w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=M6NgjwkAAAAJ&amp;hl=en">Roman Pflugfelder</a><span class="gsc_rsb_a_ext">Scientist at Austrian Institute of Technology (AIT), Lecturer at TU Wien</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at tuwien.ac.at</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb--E946kUAAAAJ-img{width:28px;height:32px;}.gs_el_ta #gsc_rsb--E946kUAAAAJ-img,.gs_el_ph #gsc_rsb--E946kUAAAAJ-img{width:49px;height:56px;}</style><span id="gsc_rsb--E946kUAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="John Illingworth" sizes="(max-width:981px) 49px,28px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=-E946kUAAAAJ&amp;citpid=9" id="gsc_rsb--E946kUAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=-E946kUAAAAJ&amp;citpid=9 28w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=-E946kUAAAAJ&amp;citpid=9 49w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=-E946kUAAAAJ&amp;citpid=9 112w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=-E946kUAAAAJ&amp;hl=en">John Illingworth</a><span class="gsc_rsb_a_ext">Professor of Machine Vision</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-BEFl4j0AAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-BEFl4j0AAAAJ-img,.gs_el_ph #gsc_rsb-BEFl4j0AAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-BEFl4j0AAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Ales Leonardis" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-BEFl4j0AAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=BEFl4j0AAAAJ&amp;hl=en">Ales Leonardis</a><span class="gsc_rsb_a_ext">Professor of Computer Science</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at cs.bham.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-z_8FrEYAAAAJ-img{width:25px;height:32px;}.gs_el_ta #gsc_rsb-z_8FrEYAAAAJ-img,.gs_el_ph #gsc_rsb-z_8FrEYAAAAJ-img{width:44px;height:56px;}</style><span id="gsc_rsb-z_8FrEYAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Matej Kristan" sizes="(max-width:981px) 44px,25px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=z_8FrEYAAAAJ&amp;citpid=2" id="gsc_rsb-z_8FrEYAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=z_8FrEYAAAAJ&amp;citpid=2 25w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=z_8FrEYAAAAJ&amp;citpid=2 44w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=z_8FrEYAAAAJ&amp;citpid=2 102w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=z_8FrEYAAAAJ&amp;hl=en">Matej Kristan</a><span class="gsc_rsb_a_ext">Associate Professor at Faculty of computer and information science, University of Ljubljana</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at fri.uni-lj.si</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-880xqfEAAAAJ-img{width:26px;height:32px;}.gs_el_ta #gsc_rsb-880xqfEAAAAJ-img,.gs_el_ph #gsc_rsb-880xqfEAAAAJ-img{width:46px;height:56px;}</style><span id="gsc_rsb-880xqfEAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Karel Lebeda" sizes="(max-width:981px) 46px,26px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=880xqfEAAAAJ&amp;citpid=2" id="gsc_rsb-880xqfEAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=880xqfEAAAAJ&amp;citpid=2 26w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=880xqfEAAAAJ&amp;citpid=2 46w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=880xqfEAAAAJ&amp;citpid=2 106w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=880xqfEAAAAJ&amp;hl=en">Karel Lebeda</a><span class="gsc_rsb_a_ext">Research Engineer at Synthesia</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at lebeda.sk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-UZ5wscMAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-UZ5wscMAAAAJ-img,.gs_el_ph #gsc_rsb-UZ5wscMAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-UZ5wscMAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Andrew Zisserman" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-UZ5wscMAAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=UZ5wscMAAAAJ&amp;hl=en">Andrew Zisserman</a><span class="gsc_rsb_a_ext">University of Oxford</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at robots.ox.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-nty1xqgAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-nty1xqgAAAAJ-img,.gs_el_ph #gsc_rsb-nty1xqgAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-nty1xqgAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Brian Holt" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-nty1xqgAAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=nty1xqgAAAAJ&amp;hl=en">Brian Holt</a><span class="gsc_rsb_a_ext">CVSSP, University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-_Tzlta0AAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-_Tzlta0AAAAJ-img,.gs_el_ph #gsc_rsb-_Tzlta0AAAAJ-img{width:56px;height:55px;}</style><span id="gsc_rsb-_Tzlta0AAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Timor Kadir" sizes="(max-width:981px) 56px,32px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=_Tzlta0AAAAJ&amp;citpid=3" id="gsc_rsb-_Tzlta0AAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=_Tzlta0AAAAJ&amp;citpid=3 32w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=_Tzlta0AAAAJ&amp;citpid=3 56w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=_Tzlta0AAAAJ&amp;citpid=3 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=_Tzlta0AAAAJ&amp;hl=en">Timor Kadir</a><span class="gsc_rsb_a_ext">Optellum and Oxford University</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at robots.ox.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-p0K-zIsAAAAJ-img{width:24px;height:32px;}.gs_el_ta #gsc_rsb-p0K-zIsAAAAJ-img,.gs_el_ph #gsc_rsb-p0K-zIsAAAAJ-img{width:42px;height:56px;}</style><span id="gsc_rsb-p0K-zIsAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="David Windridge" sizes="(max-width:981px) 42px,24px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=p0K-zIsAAAAJ&amp;citpid=2" id="gsc_rsb-p0K-zIsAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=p0K-zIsAAAAJ&amp;citpid=2 24w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=p0K-zIsAAAAJ&amp;citpid=2 42w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=p0K-zIsAAAAJ&amp;citpid=2 97w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=p0K-zIsAAAAJ&amp;hl=en">David Windridge</a><span class="gsc_rsb_a_ext">Professor of Data Science &amp; Machine Learning, Middlesex University, London (Visiting Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at mdx.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li></ul><div class="gsc_rsb_hmv gs_ota gs_oph"><button type="button" class=" gs_btn_flat gs_btn_flact gs_btn_lrge gs_btn_lsu gsc_rsb_btnv"><span class="gs_wr"><span class="gs_lbl">View all</span></span></button></div></div></div><div class="gsc_lcl" role="main" id="gsc_prf_w"><div id="gsc_prf"><button type="button" id="gsc_prf_btnf" class="gs_btnMW gs_in_ib gs_btn_act gs_btn_lsu gs_btn_mph"><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl">Follow</span></span></button><div id="gsc_prf_pu"><div id="gsc_prf_pua" class="gs_rimg"><style>#gsc_prf_pup-img{width:87px;height:128px;}@media print{#gs_top #gsc_prf_pup-img{width:54pt;height:80pt;}}</style><img alt="Richard Bowden" sizes="print 54px,87px" src="https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=mvvgDvcAAAAJ&amp;citpid=2" id="gsc_prf_pup-img" srcset="https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=mvvgDvcAAAAJ&amp;citpid=2 87w,https://scholar.googleusercontent.com/citations?view_op=medium_photo&amp;user=mvvgDvcAAAAJ&amp;citpid=2 173w"></div></div><div id="gsc_prf_i"><div id="gsc_prf_in">Richard Bowden</div><div class="gsc_prf_il">Professor of Computer Vision and Machine Learning, CVSSP, <a href="/citations?view_op=view_org&amp;hl=en&amp;org=5559442388202218053" class="gsc_prf_ila">University of Surrey</a></div><div class="gsc_prf_il" id="gsc_prf_ivh">Verified email at surrey.ac.uk - <a href="http://www.ee.surrey.ac.uk/Personal/R.Bowden/" rel="nofollow" class="gsc_prf_ila">Homepage</a></div><div class="gsc_prf_il" id="gsc_prf_int"><a href="/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:computer_vision" class="gsc_prf_inta gs_ibl">Computer Vision</a><a href="/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:machine_learning" class="gsc_prf_inta gs_ibl">Machine learning</a><a href="/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:artificial_intelligence" class="gsc_prf_inta gs_ibl">Artificial Intelligence</a></div></div></div></div><div id="gsc_prf_t_wrp" role="navigation"><div id="gsc_prf_t" role="tablist"><a id="gsc_prf_t-art" class="gsc_prf_tab" href="javascript:void(0)" role="tab" aria-controls="gsc_art" aria-selected="true">Articles</a><a id="gsc_prf_t-cit" class="gsc_prf_tab" href="javascript:void(0)" role="tab" aria-controls="gsc_rsb_cit">Cited by</a><a id="gsc_prf_t-mnd" class="gsc_prf_tab" href="javascript:void(0)" role="tab" aria-controls="gsc_rsb_mnd">Public access</a><a id="gsc_prf_t-ath" class="gsc_prf_tab" href="javascript:void(0)" role="tab" aria-controls="gsc_rsb_co">Co-authors</a></div></div><div class="gsc_lcl gsc_prf_pnl" id="gsc_art" role="region" aria-labelledby="gsc_prf_t-art"><form method="post" action="/citations?hl=en&amp;user=mvvgDvcAAAAJ&amp;view_op=list_works"><input type="hidden" name="xsrf" value="AMD79ooAAAAAYTYCq6UfReQd8r3ovNdYhGWSPPXwlKEK"><div id="gsc_a_tw"><table id="gsc_a_t"><thead><tr id="gsc_a_tr0" aria-hidden="true"><th class="gsc_a_t"></th><th class="gsc_a_c"></th><th class="gsc_a_y"></th></tr><tr id="gsc_a_trh"><th class="gsc_a_t" scope="col"><span id="gsc_a_ta"><a href="/citations?hl=en&amp;user=mvvgDvcAAAAJ&amp;view_op=list_works&amp;sortby=title" class="gsc_a_a">Title</a></span><div id="gsc_dd_sort-r" class="gs_md_r gs_md_rmb gs_md_rmbl"><button type="button" id="gsc_dd_sort-b" aria-controls="gsc_dd_sort-d" aria-haspopup="true" ontouchstart="gs_evt_dsp(event)" class=" gs_in_se gs_btn_mnu gs_btn_flat gs_btn_lrge gs_btn_half gs_btn_lsu gs_press gs_md_tb"><span class="gs_wr"><span class="gs_lbl">Sort</span><span class="gs_icm"></span></span></button><div id="gsc_dd_sort-d" class="gs_md_d gs_md_ulr" role="menu" tabindex="-1"><div id="gsc_dd_sort-s" class="gs_oph gsc_dd_sec gsc_dd_sep"><a role="menuitem" href="/citations?hl=en&amp;user=mvvgDvcAAAAJ&amp;view_op=list_works" tabindex="-1" class="gs_md_li gsc_dd_sort-sel">Sort by citations</a><a role="menuitem" href="/citations?hl=en&amp;user=mvvgDvcAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" tabindex="-1" class="gs_md_li">Sort by year</a><a role="menuitem" href="/citations?hl=en&amp;user=mvvgDvcAAAAJ&amp;view_op=list_works&amp;sortby=title" tabindex="-1" class="gs_md_li">Sort by title</a></div></div></div></th><th class="gsc_a_c" scope="col" dir="rtl"><span id="gsc_a_ca"><div class="gs_nph">Cited by</div><div class="gs_oph">Cited by</div></span></th><th class="gsc_a_y" scope="col"><span class="gsc_a_h" id="gsc_a_ha"><a href="/citations?hl=en&amp;user=mvvgDvcAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" class="gsc_a_a">Year</a></span></th></tr></thead><tbody id="gsc_a_b"><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:u5HHmVD_uO8C" class="gsc_a_at">An improved adaptive background mixture model for real-time tracking with shadow detection</a><div class="gs_gray">P KaewTraKulPong, R Bowden</div><div class="gs_gray">Video-based surveillance systems, 135-144<span class="gs_oph">, 2002</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8583666310793212187" class="gsc_a_ac gs_ibl">2109</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2002</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:Dip1O2bNi0gC" class="gsc_a_at">The Visual Object Tracking VOT2017 challenge results</a><div class="gs_gray"></div><div class="gs_gray">EEE International Conference on Computer Vision Workshop (ICCVW), ICCV2017&nbsp;…<span class="gs_oph">, 0</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5030672482439802527,18074209303062712616,7459766142456499508,15520822749755135521,15578739447736699302" class="gsc_a_ac gs_ibl">1712</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="mvvgDvcAAAAJ:Dip1O2bNi0gC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:OTTXONDVkokC" class="gsc_a_at">The visual object tracking vot2017 challenge results</a><div class="gs_gray">M Kristan, A Leonardis, J Matas, M Felsberg, R Pflugfelder, ...</div><div class="gs_gray">Proceedings of the IEEE International Conference on Computer Vision, 1949-1972<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5030672482439802527,18074209303062712616,7459766142456499508,15520822749755135521,6208971158869067788" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="mvvgDvcAAAAJ:OTTXONDVkokC" data-eud="mvvgDvcAAAAJ:Dip1O2bNi0gC">1708</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:IUKN3-7HHlwC" class="gsc_a_at">The Visual Object Tracking VOT2016 challenge results</a><div class="gs_gray"></div><div class="gs_gray">VOT2016, ECCV 2016 Workshops 9914, 777-823<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5030672482439802527,18074209303062712616,7459766142456499508,15520822749755135521" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="mvvgDvcAAAAJ:IUKN3-7HHlwC" data-eud="mvvgDvcAAAAJ:Dip1O2bNi0gC">1707</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="mvvgDvcAAAAJ:IUKN3-7HHlwC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:mlAyqtXpCwEC" class="gsc_a_at">The Visual Object Tracking VOT2017 challenge results</a><div class="gs_gray">Kristan M, Leonardis A, Matas J, Felsberg M, Pflugfelder R, Cehovin Zajc L ...</div><div class="gs_gray">In IEEE International Conference on Computer Vision Workshop (ICCVW), 1949-1972<span class="gs_oph">, 0</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5030672482439802527,18074209303062712616,7459766142456499508,15520822749755135521" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="mvvgDvcAAAAJ:mlAyqtXpCwEC" data-eud="mvvgDvcAAAAJ:Dip1O2bNi0gC">1707</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="mvvgDvcAAAAJ:mlAyqtXpCwEC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:L7CI7m0gUJcC" class="gsc_a_at">The Visual Object Tracking VOT2014 Challenge Results</a><div class="gs_gray">M Kristan, R Pflugfelder, A Leonardis, J Matas, L Čehovin, G Nebehay, ...</div><div class="gs_gray">ECCV 2014: Computer Vision - ECCV 2014 Workshops 8926, 191-217<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5030672482439802527,18074209303062712616" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="mvvgDvcAAAAJ:L7CI7m0gUJcC" data-eud="mvvgDvcAAAAJ:Dip1O2bNi0gC">1678</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:PoWvk5oyLR8C" class="gsc_a_at">The Visual Object Tracking VOT2015 challenge results</a><div class="gs_gray"></div><div class="gs_gray">IEEE Int. Conf on Computer Vision Workshops at ICCV2015, 564-586<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5030672482439802527,11606540366017290494,15578739447736699302" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="mvvgDvcAAAAJ:PoWvk5oyLR8C" data-eud="mvvgDvcAAAAJ:Dip1O2bNi0gC">1303</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="mvvgDvcAAAAJ:PoWvk5oyLR8C">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:edDO8Oi4QzsC" class="gsc_a_at">The sixth visual object tracking vot2018 challenge results</a><div class="gs_gray">M Kristan, A Leonardis, J Matas, M Felsberg, R Pflugfelder, ...</div><div class="gs_gray">Proceedings of the European Conference on Computer Vision (ECCV) Workshops, 0-0<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15781444868292583646" class="gsc_a_ac gs_ibl">399</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:HDshCWvjkbEC" class="gsc_a_at">Local binary patterns for multi-view facial expression recognition</a><div class="gs_gray">S Moore, R Bowden</div><div class="gs_gray">Computer vision and image understanding 115 (4), 541-558<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3282420251150687727" class="gsc_a_ac gs_ibl">387</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:lSLTfruPkqcC" class="gsc_a_at">Spelling it out: Real-time ASL fingerspelling recognition</a><div class="gs_gray">N Pugeault, R Bowden</div><div class="gs_gray">2011 IEEE International conference on computer vision workshops (ICCV&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16195864038915304618" class="gsc_a_ac gs_ibl">377</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:d1gkVwhDpl0C" class="gsc_a_at">A boosted classifier tree for hand shape detection</a><div class="gs_gray">EJ Ong, R Bowden</div><div class="gs_gray">Sixth IEEE International Conference on Automatic Face and Gesture&nbsp;…<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11627673107483673314" class="gsc_a_ac gs_ibl">337</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:u-x6o8ySG0sC" class="gsc_a_at">A linguistic feature vector for the visual interpretation of sign language</a><div class="gs_gray">R Bowden, D Windridge, T Kadir, A Zisserman, M Brady</div><div class="gs_gray">European Conference on Computer Vision, 390-401<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15304956869806253582" class="gsc_a_ac gs_ibl">226</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:3fE2CSJIrl8C" class="gsc_a_at">Action recognition using mined hierarchical compound features</a><div class="gs_gray">A Gilbert, J Illingworth, R Bowden</div><div class="gs_gray">IEEE Transactions on Pattern Analysis and Machine Intelligence 33 (5), 883-897<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8419885332691322370" class="gsc_a_ac gs_ibl">224</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:bFI3QPDXJZMC" class="gsc_a_at">Sign language recognition</a><div class="gs_gray">H Cooper, B Holt, R Bowden</div><div class="gs_gray">Visual analysis of humans, 539-562<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10544317724910931647" class="gsc_a_ac gs_ibl">223</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:eQOLeE2rZwMC" class="gsc_a_at">Fast realistic multi-action recognition using mined dense spatio-temporal features</a><div class="gs_gray">A Gilbert, J Illingworth, R Bowden</div><div class="gs_gray">2009 IEEE 12th international conference on computer vision, 925-931<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15610476951736888769" class="gsc_a_ac gs_ibl">221</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:UeHWp8X0CEIC" class="gsc_a_at">Tracking objects across cameras by incrementally learning inter-camera colour calibration and patterns of activity</a><div class="gs_gray">A Gilbert, R Bowden</div><div class="gs_gray">European conference on computer vision, 125-136<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12097026738501320594" class="gsc_a_ac gs_ibl">211</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:yB1At4FlUx8C" class="gsc_a_at">Deep Hand: How to Train a CNN on 1 Million Hand Images When Your Data Is Continuous and Weakly Labelled.</a><div class="gs_gray">BR Koller O, Ney H</div><div class="gs_gray">In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9447690369747858770" class="gsc_a_ac gs_ibl">202</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="mvvgDvcAAAAJ:yB1At4FlUx8C">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:vRqMK49ujn8C" class="gsc_a_at">Sign language recognition using sub-units</a><div class="gs_gray">H Cooper, EJ Ong, N Pugeault, R Bowden</div><div class="gs_gray">The Journal of Machine Learning Research 13 (1), 2205-2231<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=886900777305079104" class="gsc_a_ac gs_ibl">181</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:9yKSN-GCB0IC" class="gsc_a_at">A real time adaptive visual surveillance system for tracking low-resolution colour targets in dynamically changing scenes</a><div class="gs_gray">P KaewTrakulPong, R Bowden</div><div class="gs_gray">Image and Vision Computing 21 (10), 913-929<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8209283246283794870" class="gsc_a_ac gs_ibl">172</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;citation_for_view=mvvgDvcAAAAJ:MLfJN-KU85MC" class="gsc_a_at">Subunets: End-to-end hand shape and continuous sign language recognition</a><div class="gs_gray">N Cihan Camgoz, S Hadfield, O Koller, R Bowden</div><div class="gs_gray">Proceedings of the IEEE International Conference on Computer Vision, 3056-3065<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12302723271806052838" class="gsc_a_ac gs_ibl">156</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:HbR8gkJAVGIC" class="gsc_a_at">Neural sign language translation</a><div class="gs_gray">NC Camgoz, S Hadfield, O Koller, H Ney, R Bowden</div><div class="gs_gray">Proceedings of the IEEE Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2296982368739717596" class="gsc_a_ac gs_ibl">151</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:XD-gHx7UXLsC" class="gsc_a_at">Deep sign: Hybrid CNN-HMM for continuous sign language recognition</a><div class="gs_gray">O Koller, O Zargaran, H Ney, R Bowden</div><div class="gs_gray">Proceedings of the British Machine Vision Conference 2016<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14645919579750824370" class="gsc_a_ac gs_ibl">141</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:zYLM7Y9cAGgC" class="gsc_a_at">Scale invariant action recognition using compound features mined from dense spatio-temporal corners</a><div class="gs_gray">A Gilbert, J Illingworth, R Bowden</div><div class="gs_gray">European Conference on Computer Vision, 222-233<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8805553783605901094" class="gsc_a_ac gs_ibl">131</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:Tyk-4Ss8FVUC" class="gsc_a_at">Detection and Tracking of Humans by Probabilistic Body Part Assembly.</a><div class="gs_gray">AS Micilotta, EJ Ong, R Bowden</div><div class="gs_gray">BMVC, 429-438<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5921386535254993456" class="gsc_a_ac gs_ibl">129</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:2osOgNQ5qMEC" class="gsc_a_at">Learning statistical models of human motion</a><div class="gs_gray">R Bowden</div><div class="gs_gray">IEEE Workshop on Human Modeling, Analysis and Synthesis, CVPR 2000<span class="gs_oph">, 2000</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3747647328850902757" class="gsc_a_ac gs_ibl">126</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2000</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:YsMSGLbcyi4C" class="gsc_a_at">Minimal Training, Large Lexicon, Unconstrained Sign Language Recognition.</a><div class="gs_gray">T Kadir, R Bowden, EJ Ong, A Zisserman</div><div class="gs_gray">BMVC, 1-10<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=134578183032875883" class="gsc_a_ac gs_ibl">119</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:e_rmSamDkqQC" class="gsc_a_at">The thermal infrared visual object tracking VOT-TIR2015 challenge results</a><div class="gs_gray">M Felsberg, A Berg, G Hager, J Ahlberg, M Kristan, J Matas, A Leonardis, ...</div><div class="gs_gray">Proceedings of the ieee international conference on computer vision&nbsp;…<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4263847520949387597" class="gsc_a_ac gs_ibl">114</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:_xSYboBqXhAC" class="gsc_a_at">Kinecting the dots: Particle based scene flow from depth sensors</a><div class="gs_gray">S Hadfield, R Bowden</div><div class="gs_gray">2011 International Conference on Computer Vision, 2290-2295<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15248630194330825214" class="gsc_a_ac gs_ibl">105</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:V3AGJWp-ZtQC" class="gsc_a_at">Hollywood 3D: Recognizing actions in 3D natural scenes</a><div class="gs_gray">S Hadfield, R Bowden</div><div class="gs_gray">Proceedings of the IEEE Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13792529108743713674" class="gsc_a_ac gs_ibl">102</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:qxL8FJ1GzNcC" class="gsc_a_at">Mutual information for lucas-kanade tracking (milk): An inverse compositional formulation</a><div class="gs_gray">N Dowson, R Bowden</div><div class="gs_gray">IEEE transactions on pattern analysis and machine intelligence 30 (1), 180-185<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3565595985911489639" class="gsc_a_ac gs_ibl">101</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:qjMakFHDy7sC" class="gsc_a_at">Non-linear statistical models for the 3D reconstruction of human pose and motion from monocular image sequences</a><div class="gs_gray">R Bowden, TA Mitchell, M Sarhadi</div><div class="gs_gray">Image and Vision Computing 18 (9), 729-737<span class="gs_oph">, 2000</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11105399572873833288" class="gsc_a_ac gs_ibl">95</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2000</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:9c2xU6iGI7YC" class="gsc_a_at">A survey of deep learning applications to autonomous vehicle control</a><div class="gs_gray">S Kuutti, R Bowden, Y Jin, P Barber, S Fallah</div><div class="gs_gray">IEEE Transactions on Intelligent Transportation Systems 22 (2), 712-733<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8121205098770860018" class="gsc_a_ac gs_ibl">91</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:uc_IGeMz5qoC" class="gsc_a_at">Using convolutional 3d neural networks for user-independent continuous gesture recognition</a><div class="gs_gray">NC Camgoz, S Hadfield, O Koller, R Bowden</div><div class="gs_gray">2016 23rd International Conference on Pattern Recognition (ICPR), 49-54<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12739738635960655355" class="gsc_a_ac gs_ibl">87</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:tS2w5q8j5-wC" class="gsc_a_at">Sign language recognition using sequential pattern trees</a><div class="gs_gray">EJ Ong, H Cooper, N Pugeault, R Bowden</div><div class="gs_gray">2012 IEEE Conference on Computer Vision and Pattern Recognition, 2200-2207<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5608933617321056999" class="gsc_a_ac gs_ibl">87</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:Se3iqnhoufwC" class="gsc_a_at">Large lexicon detection of sign language</a><div class="gs_gray">H Cooper, R Bowden</div><div class="gs_gray">International Workshop on Human-Computer Interaction, 88-97<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14263916884610825494" class="gsc_a_ac gs_ibl">87</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:tKAzc9rXhukC" class="gsc_a_at">Deep learning of mouth shapes for sign language</a><div class="gs_gray">O Koller, H Ney, R Bowden</div><div class="gs_gray">Proceedings of the IEEE International Conference on Computer Vision&nbsp;…<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10057171037455649494" class="gsc_a_ac gs_ibl">84</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:k_IJM867U9cC" class="gsc_a_at">Improving visual features for lip-reading</a><div class="gs_gray">Y Lan, BJ Theobald, R Harvey, EJ Ong, R Bowden</div><div class="gs_gray">Auditory-Visual Speech Processing 2010<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3017064059517506057" class="gsc_a_ac gs_ibl">82</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:YohjEiUPhakC" class="gsc_a_at">Weakly supervised learning with multi-stream CNN-LSTM-HMMs to discover sequential parallelism in sign language videos</a><div class="gs_gray">O Koller, NC Camgoz, H Ney, R Bowden</div><div class="gs_gray">IEEE transactions on pattern analysis and machine intelligence 42 (9), 2306-2320<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12156061411383714670" class="gsc_a_ac gs_ibl">81</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:8k81kl-MbHgC" class="gsc_a_at">Learning signs from subtitles: A weakly supervised approach to sign language recognition</a><div class="gs_gray">H Cooper, R Bowden</div><div class="gs_gray">2009 IEEE Conference on Computer Vision and Pattern Recognition, 2568-2574<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14665363744325552672" class="gsc_a_ac gs_ibl">79</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:aqlVkmm33-oC" class="gsc_a_at">Comparing visual features for lipreading</a><div class="gs_gray">Y Lan, R Harvey, B Theobald, EJ Ong, R Bowden</div><div class="gs_gray">International Conference on Auditory-Visual Speech Processing 2009, 102-106<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=253181622201638229" class="gsc_a_ac gs_ibl">78</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:mB3voiENLucC" class="gsc_a_at">Highly efficient near-infrared hybrid organic-inorganic nanocrystal electroluminescence device</a><div class="gs_gray">KN Bourdakos, D Dissanayake, T Lutz, SRP Silva, RJ Curry</div><div class="gs_gray">Applied Physics Letters 92 (15), 142<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5116686972482387287,1869734348903784451" class="gsc_a_ac gs_ibl">76</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="mvvgDvcAAAAJ:mB3voiENLucC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:ufrVoPGSRksC" class="gsc_a_at">Real-time upper body detection and 3D pose estimation in monoscopic images</a><div class="gs_gray">AS Micilotta, EJ Ong, R Bowden</div><div class="gs_gray">European Conference on Computer Vision, 139-150<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5699213610411899886" class="gsc_a_ac gs_ibl">72</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:W7OEmFMy1HYC" class="gsc_a_at">Viewpoint invariant exemplar-based 3D human tracking</a><div class="gs_gray">EJ Ong, AS Micilotta, R Bowden, A Hilton</div><div class="gs_gray">Computer Vision and Image Understanding 104 (2-3), 178-189<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12342173608135565691" class="gsc_a_ac gs_ibl">69</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:IjCSPb-OGe4C" class="gsc_a_at">Reconstructing 3D Pose and Motion from a Single Camera View.</a><div class="gs_gray">R Bowden, TA Mitchell, M Sarhadi</div><div class="gs_gray">BMVC 98, 904-913<span class="gs_oph">, 1998</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2111691154994477851" class="gsc_a_ac gs_ibl">69</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">1998</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:OR75R8vi5nAC" class="gsc_a_at">Sign language transformers: Joint end-to-end sign language recognition and translation</a><div class="gs_gray">NC Camgoz, O Koller, S Hadfield, R Bowden</div><div class="gs_gray">Proceedings of the IEEE/CVF conference on computer vision and pattern&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3781725358102616609" class="gsc_a_ac gs_ibl">66</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:ruyezt5ZtCIC" class="gsc_a_at">Deep sign: Enabling robust statistical continuous sign language recognition via hybrid CNN-HMMs</a><div class="gs_gray">O Koller, S Zargaran, H Ney, R Bowden</div><div class="gs_gray">International Journal of Computer Vision 126 (12), 1311-1325<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6536981263312849275" class="gsc_a_ac gs_ibl">66</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:Y0pCki6q_DkC" class="gsc_a_at">View-based Location and Tracking of Body Parts for Visual Interaction.</a><div class="gs_gray">AS Micilotta, R Bowden</div><div class="gs_gray">BMVC, 1-10<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7323674189697348010" class="gsc_a_ac gs_ibl">65</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:0EnyYjriUFMC" class="gsc_a_at">A unifying framework for mutual information methods for use in non-linear optimisation</a><div class="gs_gray">N Dowson, R Bowden</div><div class="gs_gray">European Conference on Computer Vision, 365-378<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18438678326816271185" class="gsc_a_ac gs_ibl">60</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:e5wmG9Sq2KIC" class="gsc_a_at">Decentralized sensor fusion for ubiquitous networking robotics in urban areas</a><div class="gs_gray">A Sanfeliu, J Andrade-Cetto, M Barbosa, R Bowden, J Capitán, ...</div><div class="gs_gray">Sensors 10 (3), 2274-2314<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13921941377135268339" class="gsc_a_ac gs_ibl">59</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:F9fV5C73w3QC" class="gsc_a_at">Sign language recognition, generation, and modelling: a research effort with applications in deaf communication</a><div class="gs_gray">E Efthimiou, SE Fotinea, C Vogler, T Hanke, J Glauert, R Bowden, ...</div><div class="gs_gray">International Conference on Universal Access in Human-Computer Interaction&nbsp;…<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14433904088733182225" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="mvvgDvcAAAAJ:F9fV5C73w3QC" data-eud="mvvgDvcAAAAJ:hC7cP41nSMkC">59</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:hC7cP41nSMkC" class="gsc_a_at">Sign language recognition, generation, and modelling: a research effort with applications in deaf communication</a><div class="gs_gray">E Efthimiou, SE Fotinea, C Vogler, T Hanke, J Glauert, R Bowden, ...</div><div class="gs_gray">International Conference on Universal Access in Human-Computer Interaction&nbsp;…<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14433904088733182225" class="gsc_a_ac gs_ibl">59</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:t6usbXjVLHcC" class="gsc_a_at">Chalearn multi-modal gesture recognition 2013: grand challenge and workshop summary</a><div class="gs_gray">S Escalera, J Gonzàlez, X Baró, M Reyes, I Guyon, V Athitsos, ...</div><div class="gs_gray">Proceedings of the 15th ACM on International conference on multimodal&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=283192699461071053" class="gsc_a_ac gs_ibl">56</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:bnK-pcrLprsC" class="gsc_a_at">Scene particles: Unregularized particle-based scene flow estimation</a><div class="gs_gray">S Hadfield, R Bowden</div><div class="gs_gray">IEEE transactions on pattern analysis and machine intelligence 36 (3), 564-576<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14919569016960892782" class="gsc_a_ac gs_ibl">56</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:_FxGoFyzp5QC" class="gsc_a_at">Simultaneous modeling and tracking (smat) of feature sets</a><div class="gs_gray">NDH Dowson, R Bowden</div><div class="gs_gray">2005 IEEE Computer Society Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6670207357877713264" class="gsc_a_ac gs_ibl">55</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:HE397vMXCloC" class="gsc_a_at">Long-term tracking through failure cases</a><div class="gs_gray">K Lebeda, S Hadfield, J Matas, R Bowden</div><div class="gs_gray">Proceedings of the IEEE International Conference on Computer Vision&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12696396808737824400" class="gsc_a_ac gs_ibl">54</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:5nxA0vEk-isC" class="gsc_a_at">Incremental, scalable tracking of objects inter camera</a><div class="gs_gray">A Gilbert, R Bowden</div><div class="gs_gray">Computer Vision and Image Understanding 111 (1), 43-58<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1816549320871633953" class="gsc_a_ac gs_ibl">52</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:WF5omc3nYNoC" class="gsc_a_at">A non-linear model of shape and motion for tracking finger spelt american sign language</a><div class="gs_gray">R Bowden, M Sarhadi</div><div class="gs_gray">Image and Vision Computing 20 (9-10), 597-607<span class="gs_oph">, 2002</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=990115420192698083" class="gsc_a_ac gs_ibl">52</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2002</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:PVgj2kMGcgYC" class="gsc_a_at">Dicta-sign–sign language recognition, generation and modelling: a research effort with applications in deaf communication</a><div class="gs_gray">E Efthimiou, SE Fontinea, T Hanke, J Glauert, R Bowden, A Braffort, ...</div><div class="gs_gray">Proceedings of the 4th Workshop on the Representation and Processing of Sign&nbsp;…<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9791098348133942166" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="mvvgDvcAAAAJ:PVgj2kMGcgYC" data-eud="mvvgDvcAAAAJ:a3BOlSfXSfwC">51</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:a3BOlSfXSfwC" class="gsc_a_at">Dicta-sign–sign language recognition, generation and modelling: a research effort with applications in deaf communication</a><div class="gs_gray">E Efthimiou, SE Fontinea, T Hanke, J Glauert, R Bowden, A Braffort, ...</div><div class="gs_gray">Proceedings of the 4th Workshop on the Representation and Processing of Sign&nbsp;…<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9791098348133942166" class="gsc_a_ac gs_ibl">51</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:L8Ckcad2t8MC" class="gsc_a_at">The effects of pose on facial expression recognition</a><div class="gs_gray">S Moore, R Bowden</div><div class="gs_gray">Proceedings of the British machine vision conference, 1-11<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9846033637426153973" class="gsc_a_ac gs_ibl">51</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:J_g5lzvAfSwC" class="gsc_a_at">Robust facial feature tracking using shape-constrained multiresolution-selected linear predictors</a><div class="gs_gray">EJ Ong, R Bowden</div><div class="gs_gray">IEEE Transactions on Pattern Analysis and Machine Intelligence 33 (9), 1844-1859<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9505151879605325282" class="gsc_a_ac gs_ibl">49</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:NMxIlDl6LWMC" class="gsc_a_at">Putting the pieces together: Connected poselets for human pose estimation</a><div class="gs_gray">B Holt, EJ Ong, H Cooper, R Bowden</div><div class="gs_gray">2011 IEEE international conference on computer vision workshops (ICCV&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5796741096480784480" class="gsc_a_ac gs_ibl">44</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:LgRImbQfgY4C" class="gsc_a_at">Video-based surveillance systems</a><div class="gs_gray">P KaewTraKulPong, R Bowden</div><div class="gs_gray">Chap. An improved adaptive background mixture model for real-time tracking&nbsp;…<span class="gs_oph">, 2002</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13531183576695081426" class="gsc_a_ac gs_ibl">42</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2002</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:QYdC8u9Cj1oC" class="gsc_a_at">Text2Sign: Towards sign language production using neural machine translation and generative adversarial networks</a><div class="gs_gray">S Stoll, NC Camgoz, S Hadfield, R Bowden</div><div class="gs_gray">International Journal of Computer Vision 128 (4), 891-908<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7844215452514295649" class="gsc_a_ac gs_ibl">39</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:ULOm3_A8WrAC" class="gsc_a_at">Estimating the joint statistics of images using nonparametric windows with application to registration using mutual information</a><div class="gs_gray">N Dowson, T Kadir, R Bowden</div><div class="gs_gray">IEEE Transactions on Pattern Analysis and Machine Intelligence 30 (10), 1841&nbsp;…<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6573664885028345880" class="gsc_a_ac gs_ibl">39</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:q3CdL3IzO_QC" class="gsc_a_at">Sign language production using neural machine translation and generative adversarial networks</a><div class="gs_gray">S Stoll, NC Camgöz, S Hadfield, R Bowden</div><div class="gs_gray">Proceedings of the 29th British Machine Vision Conference (BMVC 2018)<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10521136703562267434" class="gsc_a_ac gs_ibl">38</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:eflP2zaiRacC" class="gsc_a_at">Sign Language technologies and resources of the Dicta-Sign project</a><div class="gs_gray">E Efthimiou, SE Fotinea, T Hanke, J Glauert, R Bowden, A Braffort, ...</div><div class="gs_gray">Proc. of the 5th Workshop on the Representation and Processing of Sign&nbsp;…<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14667547783946144201" class="gsc_a_ac gs_ibl">37</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:BrmTIyaxlBUC" class="gsc_a_at">Multi-touchless: Real-time fingertip detection and tracking using geodesic maxima</a><div class="gs_gray">P Krejov, R Bowden</div><div class="gs_gray">2013 10th IEEE International Conference and Workshops on Automatic Face and&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2656014358890275377" class="gsc_a_ac gs_ibl">36</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:_B80troHkn4C" class="gsc_a_at">Sign spotting using hierarchical sequential patterns with temporal intervals</a><div class="gs_gray">EJ Ong, O Koller, N Pugeault, R Bowden</div><div class="gs_gray">Proceedings of the IEEE conference on computer vision and pattern&nbsp;…<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8712926460087579925" class="gsc_a_ac gs_ibl">35</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:HIFyuExEbWQC" class="gsc_a_at">Vision based interpretation of natural sign languages</a><div class="gs_gray">R Bowden12, A Zisserman, T Kadir, M Brady</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4522760046731545774" class="gsc_a_ac gs_ibl">35</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:LkGwnXOMwfcC" class="gsc_a_at">Learning non-linear Models of Shape and Motion</a><div class="gs_gray">R Bowden</div><div class="gs_gray">Brunel University<span class="gs_oph">, 2000</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2650562611488094323" class="gsc_a_ac gs_ibl">35</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2000</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:Wp0gIr-vW9MC" class="gsc_a_at">Robust facial feature tracking using selected multi-resolution linear predictors</a><div class="gs_gray">EJ Ong, Y Lan, B Theobald, R Harvey, R Bowden</div><div class="gs_gray">2009 IEEE 12th International Conference on Computer Vision, 1483-1490<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1911930212346708881" class="gsc_a_ac gs_ibl">34</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:roLk4NBRz8UC" class="gsc_a_at">Towards automated wide area visual surveillance: tracking objects between spatially–separated, uncalibrated views</a><div class="gs_gray">R Bowden, P KaewTraKulPong</div><div class="gs_gray">IEE Proceedings-Vision, Image and Signal Processing 152 (2), 213-223<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9936652525443214123" class="gsc_a_ac gs_ibl">34</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:fPk4N6BV_jEC" class="gsc_a_at">Reading the signs: A video based sign dictionary</a><div class="gs_gray">H Cooper, N Pugeault, R Bowden</div><div class="gs_gray">2011 IEEE international conference on computer vision workshops (ICCV&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2824916364175865077" class="gsc_a_ac gs_ibl">33</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:b0M2c_1WBrUC" class="gsc_a_at">Linear regression and adaptive appearance models for fast simultaneous modelling and tracking</a><div class="gs_gray">L Ellis, N Dowson, J Matas, R Bowden</div><div class="gs_gray">International journal of computer vision 95 (2), 154-179<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13104454795479949088" class="gsc_a_ac gs_ibl">33</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:JQOojiI6XY0C" class="gsc_a_at">Combining discriminative and model based approaches for hand pose estimation</a><div class="gs_gray">P Krejov, A Gilbert, R Bowden</div><div class="gs_gray">2015 11th IEEE international conference and workshops on automatic face and&nbsp;…<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=640149231277730259" class="gsc_a_ac gs_ibl">32</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:UebtZRa9Y70C" class="gsc_a_at">Real-time dynamic deformable meshes for volumetric segmentation and visualisation</a><div class="gs_gray">R Bowden, TA Mitchel, M Sarhadi</div><div class="gs_gray">BMVC97 Electronic Proceedings of the Eighth British Machine Vision&nbsp;…<span class="gs_oph">, 1997</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2112742140780660596" class="gsc_a_ac gs_ibl">31</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">1997</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:WZBGuue-350C" class="gsc_a_at">SMILE Swiss German sign language dataset</a><div class="gs_gray">S Ebling, NC Camgöz, P Boyes Braem, N Calzolari</div><div class="gs_gray">European Language Resources Association (ELRA)<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8567367763414425705" class="gsc_a_ac gs_ibl">30</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:4JMBOYKVnBMC" class="gsc_a_at">Learning sequential patterns for lipreading</a><div class="gs_gray">EJ Ong, R Bowden</div><div class="gs_gray">BMVC 2011-Proceedings of the British Machine Vision Conference 2011<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16886455086855837724" class="gsc_a_ac gs_ibl">30</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:MXK_kJrjxJIC" class="gsc_a_at">Building Temporal Models for Gesture Recognition.</a><div class="gs_gray">R Bowden, M Sarhadi</div><div class="gs_gray">BMVC, 1-10<span class="gs_oph">, 2000</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18150789963879906682" class="gsc_a_ac gs_ibl">30</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2000</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:NJ774b8OgUMC" class="gsc_a_at">Texture-independent long-term tracking using virtual corners</a><div class="gs_gray">K Lebeda, S Hadfield, J Matas, R Bowden</div><div class="gs_gray">IEEE Transactions on Image Processing 25 (1), 359-371<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1667826410076160487" class="gsc_a_ac gs_ibl">29</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:W5xh706n7nkC" class="gsc_a_at">How much of driving is preattentive?</a><div class="gs_gray">N Pugeault, R Bowden</div><div class="gs_gray">IEEE Transactions on Vehicular Technology 64 (12), 5424-5438<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9540087913919941721" class="gsc_a_ac gs_ibl">29</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:XiVPGOgt02cC" class="gsc_a_at">Recent developments in automated lip-reading</a><div class="gs_gray">R Bowden, S Cox, R Harvey, Y Lan, EJ Ong, G Owen, BJ Theobald</div><div class="gs_gray">Optics and Photonics for Counterterrorism, Crime Fighting and Defence IX&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6658105713589362736" class="gsc_a_ac gs_ibl">29</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:yD5IFk8b50cC" class="gsc_a_at">Capturing the relative distribution of features for action recognition</a><div class="gs_gray">O Oshin, A Gilbert, R Bowden</div><div class="gs_gray">2011 IEEE International Conference on Automatic Face &amp; Gesture Recognition&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8014257017865390792" class="gsc_a_ac gs_ibl">29</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:ML0RJ9NH7IQC" class="gsc_a_at">Adaptive Visual System for Tracking Low Resolution Colour Targets</a><div class="gs_gray">R Bowden, P KaewTraKulPong</div><div class="gs_gray">Proceedings of the 12th British Machine Vision Conference (BMVC2001), 243-252<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4125313045923645663,3832996368045659467" class="gsc_a_ac gs_ibl">29</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="mvvgDvcAAAAJ:ML0RJ9NH7IQC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:08ZZubdj9fEC" class="gsc_a_at">The dicta-sign wiki: Enabling web communication for the deaf</a><div class="gs_gray">E Efthimiou, SE Fotinea, T Hanke, J Glauert, R Bowden, A Braffort, ...</div><div class="gs_gray">International Conference on Computers for Handicapped Persons, 205-212<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12335907603145583893" class="gsc_a_ac gs_ibl">28</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:TQgYirikUcIC" class="gsc_a_at">Action recognition using randomised ferns</a><div class="gs_gray">O Oshin, A Gilbert, J Illingworth, R Bowden</div><div class="gs_gray">2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV&nbsp;…<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7122709403086277234" class="gsc_a_ac gs_ibl">28</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:Zph67rFs4hoC" class="gsc_a_at">Robust lip-tracking using rigid flocks of selected linear predictors</a><div class="gs_gray">EJ Ong, R Bowden</div><div class="gs_gray">8th IEEE Int. Conf. on Automatic Face and Gesture Recognition<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4349305385532084076" class="gsc_a_ac gs_ibl">28</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:KlAtU1dfN6UC" class="gsc_a_at">Cluster based nonlinear principle component analysis</a><div class="gs_gray">R Bowden, TA Mitchell, M Sarhadi</div><div class="gs_gray">Electronics letters 33 (22), 1858-1859<span class="gs_oph">, 1997</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1119563363308846746" class="gsc_a_ac gs_ibl">28</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">1997</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:q3oQSFYPqjQC" class="gsc_a_at">May the force be with you: Force-aligned signwriting for automatic subunit annotation of corpora</a><div class="gs_gray">O Koller, H Ney, R Bowden</div><div class="gs_gray">2013 10th IEEE International Conference and Workshops on Automatic Face and&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9664456060034126077" class="gsc_a_ac gs_ibl">27</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:_kc_bZDykSQC" class="gsc_a_at">Sign language recognition using boosted volumetric features</a><div class="gs_gray">H Cooper, R Bowden</div><div class="gs_gray">Proceedings of the IAPR Conference on Machine Vision Applications, 359-362<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3520598620024438875" class="gsc_a_ac gs_ibl">27</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:P7Ujq4OLJYoC" class="gsc_a_at">Multi-channel transformers for multi-articulatory sign language translation</a><div class="gs_gray">NC Camgoz, O Koller, S Hadfield, R Bowden</div><div class="gs_gray">European Conference on Computer Vision, 301-319<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12181271767361023357" class="gsc_a_ac gs_ibl">26</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:vDijr-p_gm4C" class="gsc_a_at">Automatic alignment of hamnosys subunits for continuous sign language recognition</a><div class="gs_gray">O Koller, R Bowden, H Ney</div><div class="gs_gray">LREC 2016 Proceedings, 121-128<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4825209871142007171" class="gsc_a_ac gs_ibl">25</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:9ZlFYXVOiuMC" class="gsc_a_at">Learning pre-attentive driving behaviour from holistic visual features</a><div class="gs_gray">N Pugeault, R Bowden</div><div class="gs_gray">European Conference on Computer Vision, 154-167<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=843773156819639337" class="gsc_a_ac gs_ibl">24</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:bEWYMUwI8FkC" class="gsc_a_at">Sign language recognition using linguistically derived sub-units</a><div class="gs_gray">H Cooper, R Bowden</div><div class="gs_gray">Proceedings of 4th workshop on the representation and processing of sign&nbsp;…<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14609991220556713948" class="gsc_a_ac gs_ibl">24</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:M3ejUd6NZC8C" class="gsc_a_at">Linear predictors for fast simultaneous modeling and tracking</a><div class="gs_gray">L Ellis, N Dowson, J Matas, R Bowden</div><div class="gs_gray">2007 IEEE 11th International Conference on Computer Vision, 1-8<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13387296625876783080" class="gsc_a_ac gs_ibl">24</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:SdhP9T11ey4C" class="gsc_a_at">Read my lips: Continuous signer independent weakly supervised viseme recognition</a><div class="gs_gray">O Koller, H Ney, R Bowden</div><div class="gs_gray">European Conference on Computer Vision, 281-296<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13176683832967636506" class="gsc_a_ac gs_ibl">23</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:i2xiXl-TujoC" class="gsc_a_at">Sedar-semantic detection and ranging: Humans can localise without lidar, can robots?</a><div class="gs_gray">O Mendez, S Hadfield, N Pugeault, R Bowden</div><div class="gs_gray">2018 IEEE International Conference on Robotics and Automation (ICRA), 6053-6060<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3087395421319526972" class="gsc_a_ac gs_ibl">22</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:N5tVd3kTz84C" class="gsc_a_at">2D or not 2D: Bridging the gap between tracking and structure from motion</a><div class="gs_gray">K Lebeda, S Hadfield, R Bowden</div><div class="gs_gray">Asian Conference on Computer Vision, 642-658<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=536887428970724287" class="gsc_a_ac gs_ibl">22</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=mvvgDvcAAAAJ:O3NaXMp0MMsC" class="gsc_a_at">Guided optimisation through classification and regression for hand pose estimation</a><div class="gs_gray">P Krejov, A Gilbert, R Bowden</div><div class="gs_gray">Computer Vision and Image Understanding 155, 124-138<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17628798985994635694" class="gsc_a_ac gs_ibl">21</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:LjlpjdlvIbIC" class="gsc_a_at">Natural action recognition using invariant 3D motion encoding</a><div class="gs_gray">S Hadfield, K Lebeda, R Bowden</div><div class="gs_gray">European Conference on Computer Vision, 758-771<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=631356999399107210" class="gsc_a_ac gs_ibl">21</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:4TOpqqG69KYC" class="gsc_a_at">N-tier Simultaneous Modelling and Tracking for Arbitrary Warps.</a><div class="gs_gray">NDH Dowson, R Bowden</div><div class="gs_gray">BMVC 6, 569-578<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6797291418907520789" class="gsc_a_ac gs_ibl">21</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:35N4QoGY0k4C" class="gsc_a_at">Search-by-example in multilingual sign language databases</a><div class="gs_gray">R Elliott, H Cooper, EJ Ong, J Glauert, R Bowden, F Lefebvre-Albaret</div><div class="gs_gray">2nd Intl. Workshop on Sign Language Translation and Avatar Technology (SLTAT)<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14148143695790989473" class="gsc_a_ac gs_ibl">20</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:7PzlFSSx8tAC" class="gsc_a_at">Feature selection of facial displays for detection of non verbal communication in natural conversation</a><div class="gs_gray">T Sheerman-Chase, EJ Ong, R Bowden</div><div class="gs_gray">2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV&nbsp;…<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7832864193622121052" class="gsc_a_ac gs_ibl">20</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:yMeIxYmEMEAC" class="gsc_a_at">Progressive transformers for end-to-end sign language production</a><div class="gs_gray">B Saunders, NC Camgoz, R Bowden</div><div class="gs_gray">European Conference on Computer Vision, 687-705<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=636627572859576137" class="gsc_a_ac gs_ibl">19</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:4hFrxpcac9AC" class="gsc_a_at">Next-best stereo: extending next best view optimisation for collaborative sensors</a><div class="gs_gray">O Mendez Maldonado, S Hadfield, N Pugeault, R Bowden</div><div class="gs_gray">Proceedings of BMVC 2016<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2808832109092916473" class="gsc_a_ac gs_ibl">18</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="mvvgDvcAAAAJ:4hFrxpcac9AC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:blknAaTinKkC" class="gsc_a_at">Generalised pose estimation using depth</a><div class="gs_gray">S Hadfield, R Bowden</div><div class="gs_gray">European Conference on Computer Vision, 312-325<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18154444794987979830" class="gsc_a_ac gs_ibl">18</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:OU6Ihb5iCvQC" class="gsc_a_at">Learning temporal signatures for lip reading</a><div class="gs_gray">EJ Ong, R Bowden</div><div class="gs_gray">2011 IEEE International Conference on Computer Vision Workshops (ICCV&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2358790534706504595" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:kNdYIx-mwKoC" class="gsc_a_at">Jeremiah: the face of computer vision</a><div class="gs_gray">R Bowden, P Kaewtrakulpong, M Lewin</div><div class="gs_gray">Proceedings of the 2nd international symposium on Smart graphics, 124-128<span class="gs_oph">, 2002</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13979624344256928640" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2002</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:HtEfBTGE9r8C" class="gsc_a_at">Hollywood 3d: What are the best 3d features for action recognition?</a><div class="gs_gray">S Hadfield, K Lebeda, R Bowden</div><div class="gs_gray">International Journal of Computer Vision 121 (1), 95-110<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4307632588489964939" class="gsc_a_ac gs_ibl">16</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:tuHXwOkdijsC" class="gsc_a_at">Taking the scenic route to 3d: Optimising reconstruction from moving cameras</a><div class="gs_gray">O Mendez, S Hadfield, N Pugeault, R Bowden</div><div class="gs_gray">Proceedings of the IEEE International Conference on Computer Vision, 4677-4685<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9406684276576403894" class="gsc_a_ac gs_ibl">16</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:tkaPQYYpVKoC" class="gsc_a_at">Capturing relative motion and finding modes for action recognition in the wild</a><div class="gs_gray">O Oshin, A Gilbert, R Bowden</div><div class="gs_gray">Computer Vision and Image Understanding 125, 155-171<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18421517832980171190,11725195740461746345" class="gsc_a_ac gs_ibl">16</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:mVmsd5A6BfQC" class="gsc_a_at">Image template matching using mutual information and NP-Windows</a><div class="gs_gray">NDH Dowson, R Bowden, T Kadir</div><div class="gs_gray">18th International Conference on Pattern Recognition (ICPR'06) 2, 1186-1191<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14365951277984730131" class="gsc_a_ac gs_ibl">16</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:8AbLer7MMksC" class="gsc_a_at">Tracking the untrackable: How to track when your object is featureless</a><div class="gs_gray">K Lebeda, J Matas, R Bowden</div><div class="gs_gray">Asian Conference on Computer Vision, 347-359<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15781505850289087711" class="gsc_a_ac gs_ibl">15</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:Ehil0879vHcC" class="gsc_a_at">CCLXXV.—The constitution of soap solutions: migration data for potassium oleate and potassium laurate</a><div class="gs_gray">JW McBain, RC Bowden</div><div class="gs_gray">Journal of the Chemical Society, Transactions 123, 2417-2430<span class="gs_oph">, 1923</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10931584249731181500" class="gsc_a_ac gs_ibl">15</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">1923</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:l7t_Zn2s7bgC" class="gsc_a_at">Data fusion in ubiquitous networked robot systems for urban services</a><div class="gs_gray">L Merino, A Gilbert, J Capitán, R Bowden, J Illingworth, A Ollero</div><div class="gs_gray">annals of telecommunications-annales des télécommunications 67 (7), 355-375<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14315049489723629219" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:-f6ydRqryjwC" class="gsc_a_at">Multi person tracking within crowded scenes</a><div class="gs_gray">A Gilbert, R Bowden</div><div class="gs_gray">Workshop on Human Motion, 166-179<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16300197498734980118" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:hMod-77fHWUC" class="gsc_a_at">Driving me around the bend: Learning to drive from visual gist</a><div class="gs_gray">N Pugeault, R Bowden</div><div class="gs_gray">2011 IEEE International Conference on Computer Vision Workshops (ICCV&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=605593300664416097,12224274463941237122" class="gsc_a_ac gs_ibl">13</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:3htObqc8RwsC" class="gsc_a_at">Defeat-Net: general monocular depth via simultaneous unsupervised representation learning</a><div class="gs_gray">J Spencer, R Bowden, S Hadfield</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10482583096470600686" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:UxriW0iASnsC" class="gsc_a_at">Static Pose Estimation from Depth Images using Random Regression Forests and Hough Voting.</a><div class="gs_gray">B Holt, R Bowden</div><div class="gs_gray">VISAPP (1), 557-564<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5751711899335909075" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:zA6iFVUQeVQC" class="gsc_a_at">Cultural factors in the regression of non-verbal communication perception</a><div class="gs_gray">T Sheerman-Chase, EJ Ong, R Bowden</div><div class="gs_gray">2011 IEEE International Conference on Computer Vision Workshops (ICCV&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6724647436253234718" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:QIV2ME_5wuYC" class="gsc_a_at">Automatic facial expression recognition using boosted discriminatory classifiers</a><div class="gs_gray">S Moore, R Bowden</div><div class="gs_gray">International Workshop on Analysis and Modeling of Faces and Gestures, 71-83<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6061480057241960809" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:ZeXyd9-uunAC" class="gsc_a_at">Incremental Modelling of the Posterior Distribution of Objects for Inter and Intra Camera Tracking.</a><div class="gs_gray">A Gilbert, R Bowden</div><div class="gs_gray">BMVC<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10968422219442257543" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:YOwf2qJgpHMC" class="gsc_a_at">Metric mixtures for mutual information (M/sup 3/I) tracking</a><div class="gs_gray">N Dowson, R Bowden</div><div class="gs_gray">Proceedings of the 17th International Conference on Pattern Recognition&nbsp;…<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15135859326738668675" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:LhH-TYMQEocC" class="gsc_a_at">Adversarial training for multi-channel sign language production</a><div class="gs_gray">B Saunders, NC Camgoz, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:2008.12405<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9867859535958106890" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:S16KYo8Pm5AC" class="gsc_a_at">HARD-PnP: PnP optimization using a hybrid approximate representation</a><div class="gs_gray">S Hadfield, K Lebeda, R Bowden</div><div class="gs_gray">IEEE transactions on pattern analysis and machine intelligence 41 (3), 768-774<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=827425361801364253" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:uLbwQdceFCQC" class="gsc_a_at">Exploring causal relationships in visual object tracking</a><div class="gs_gray">K Lebeda, S Hadfield, R Bowden</div><div class="gs_gray">Proceedings of the IEEE International Conference on Computer Vision, 3065-3073<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13792926635731353289" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:fQNAKQ3IYiAC" class="gsc_a_at">Autonomous navigation and sign detector learning</a><div class="gs_gray">L Ellis, N Pugeault, K Öfjäll, J Hedborg, R Bowden, M Felsberg</div><div class="gs_gray">2013 IEEE Workshop on Robot Vision (WORV), 144-151<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=590655648697626717" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:dfsIfKJdRG4C" class="gsc_a_at">Sign language recognition: working with Limited Corpora</a><div class="gs_gray">H Cooper, R Bowden</div><div class="gs_gray">International Conference on Universal Access in Human-Computer Interaction&nbsp;…<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7421668056131971307" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:LO7wyVUgiFcC" class="gsc_a_at">Safe deep neural network-driven autonomous vehicles using software safety cages</a><div class="gs_gray">S Kuutti, R Bowden, H Joshi, R de Temple, S Fallah</div><div class="gs_gray">International Conference on Intelligent Data Engineering and Automated&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2675763918129994380" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:4fGpz3EwCPoC" class="gsc_a_at">End-to-end reinforcement learning for autonomous longitudinal control using advantage actor critic with temporal context</a><div class="gs_gray">S Kuutti, R Bowden, H Joshi, R de Temple, S Fallah</div><div class="gs_gray">2019 IEEE Intelligent Transportation Systems Conference (ITSC), 2456-2462<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10398640131437500147" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:bz8QjSJIRt4C" class="gsc_a_at">Deep learning for autonomous vehicle control: Algorithms, state-of-the-art, and future prospects</a><div class="gs_gray">S Kuutti, S Fallah, R Bowden, P Barber</div><div class="gs_gray">Synthesis Lectures on Advances in Automotive Technology 3 (4), 1-80<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9378812845237393878" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:_Ybze24A_UAC" class="gsc_a_at">Exploiting high level scene cues in stereo reconstruction</a><div class="gs_gray">S Hadfield, R Bowden</div><div class="gs_gray">Proceedings of the IEEE International Conference on Computer Vision, 783-791<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=924967012361300357" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:BqipwSGYUEgC" class="gsc_a_at">igroup: Weakly supervised image and video grouping</a><div class="gs_gray">A Gilbert, R Bowden</div><div class="gs_gray">2011 International Conference on Computer Vision, 2166-2173<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3940805489192247646" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:ZHo1McVdvXMC" class="gsc_a_at">Facial expression recognition using spatiotemporal boosted discriminatory classifiers</a><div class="gs_gray">S Moore, EJ Ong, R Bowden</div><div class="gs_gray">International Conference Image Analysis and Recognition, 405-414<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3970912095434461904" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:HoB7MX3m0LUC" class="gsc_a_at">Multi-view pose and facial expression recognition</a><div class="gs_gray">S Moore, R Bowden</div><div class="gs_gray">Proc. BMVC 2<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2418073801408062055" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:hFOr9nPyWt4C" class="gsc_a_at">Real-time motion control using pose space probability density estimation</a><div class="gs_gray">D Okwechime, EJ Ong, R Bowden</div><div class="gs_gray">2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV&nbsp;…<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17970071113536821938" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:ODE9OILHJdcC" class="gsc_a_at">Training adversarial agents to exploit weaknesses in deep control policies</a><div class="gs_gray">S Kuutti, S Fallah, R Bowden</div><div class="gs_gray">2020 IEEE International Conference on Robotics and Automation (ICRA), 108-114<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13433301663756807900" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:kRWSkSYxWN8C" class="gsc_a_at">A picture is worth a thousand tags: automatic web based image tag expansion</a><div class="gs_gray">A Gilbert, R Bowden</div><div class="gs_gray">Asian Conference on Computer Vision, 447-460<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13738105077496742157" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:JV2RwH3_ST0C" class="gsc_a_at">Online learning and partitioning of linear displacement predictors for tracking</a><div class="gs_gray">L Ellis, J Matas, R Bowden</div><div class="gs_gray">Proceedings of the British Machine Vision Conference, 33-42<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16771282636486297308" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:qUcmZB5y_30C" class="gsc_a_at">Efficient texture analysis for industrial inspection</a><div class="gs_gray">TA Mitchell, R Bowden, M Sarhadi</div><div class="gs_gray">International Journal of Production Research 38 (4), 967-984<span class="gs_oph">, 2000</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13689364133455376730" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2000</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:IWHjjKOFINEC" class="gsc_a_at">Real time hand tracking and gesture recognition as a 3D input device for graphical applications</a><div class="gs_gray">R Bowden, T Heap, D Hogg</div><div class="gs_gray">Progress in Gestural Interaction, 117-129<span class="gs_oph">, 1997</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7742956801745641137" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">1997</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:OcBU2YAGkTUC" class="gsc_a_at">NestedVAE: Isolating common factors via weak supervision</a><div class="gs_gray">MJ Vowels, NC Camgoz, R Bowden</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15969164858113045026" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:_axFR9aDTf0C" class="gsc_a_at">Hmm-based approaches to model multichannel information in sign language inspired from articulatory features-based speech processing</a><div class="gs_gray">S Tornay, M Razavi, NC Camgoz, R Bowden, MM Doss</div><div class="gs_gray">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9472508047019807692" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:0izLItjtcgwC" class="gsc_a_at">Image and video mining through online learning</a><div class="gs_gray">A Gilbert, R Bowden</div><div class="gs_gray">Computer Vision and Image Understanding 158, 72-84<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2505405320465161845" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:PELIpwtuRlgC" class="gsc_a_at">A multitouchless interface: expanding user interaction</a><div class="gs_gray">P Krejov, A Gilbert, R Bowden</div><div class="gs_gray">IEEE computer graphics and applications 34 (3), 40-48<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15877174445134823246" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:eq2jaN3J8jMC" class="gsc_a_at">Scene flow estimation using intelligent cost functions</a><div class="gs_gray">S Hadfield, R Bowden</div><div class="gs_gray">Proceedings of the British Conference on Machine Vision (BMVC)<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17976918068605029279" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:maZDTaKrznsC" class="gsc_a_at">Accurate fusion of robot, camera and wireless sensors for surveillance applications</a><div class="gs_gray">A Gilbert, J Illingworth, R Bowden, J Capitan, L Merino</div><div class="gs_gray">2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV&nbsp;…<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7529450868847632717" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:TFP_iSt0sucC" class="gsc_a_at">Probabilistic learning of salient patterns across spatially separated, uncalibrated views</a><div class="gs_gray">P KaewTraKulPong, R Bowden</div><div class="gs_gray">IET Digital Library<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16236120954463810363" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:dhFuZR0502QC" class="gsc_a_at">Virtual data gloves: Interacting with virtual environments through computer vision</a><div class="gs_gray">R Bowden, T Heap, C Hart</div><div class="gs_gray">Proc. 3rd UK VR-Sig Conference, DeMontfort University, Leicester, UK<span class="gs_oph">, 1996</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7763590023123541554" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">1996</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:a9-T7VOCCH8C" class="gsc_a_at">Stereo reconstruction using top-down cues</a><div class="gs_gray">S Hadfield, K Lebeda, R Bowden</div><div class="gs_gray">Computer Vision and Image Understanding 157, 206-222<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4473685314371497027" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:VOx2b1Wkg3QC" class="gsc_a_at">Non-linear predictors for facial feature tracking across pose and expression</a><div class="gs_gray">T Sheerman-Chase, EJ Ong, R Bowden</div><div class="gs_gray">2013 10th IEEE International Conference and Workshops on Automatic Face and&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4663302532147229873" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:2P1L_qKh6hAC" class="gsc_a_at">Evaluating dimensionality reduction techniques for visual category recognition using renyi entropy</a><div class="gs_gray">A Gupta, R Bowden</div><div class="gs_gray">2011 19th European Signal Processing Conference, 913-917<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=514749090089339983" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:70eg2SAEIzsC" class="gsc_a_at">Online learning of robust facial feature trackers</a><div class="gs_gray">T Sheerman-Chase, EJ Ong, R Bowden</div><div class="gs_gray">2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV&nbsp;…<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14513226544412452369" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:iH-uZ7U-co4C" class="gsc_a_at">A generative model for motion synthesis and blending using probability density estimation</a><div class="gs_gray">D Okwechime, R Bowden</div><div class="gs_gray">International Conference on Articulated Motion and Deformable Objects, 218-227<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14110179772074208334" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:RHpTSmoSYBkC" class="gsc_a_at">Real-time Upper Body 3D Pose Estimation from a Single Uncalibrated Camera.</a><div class="gs_gray">AS Micilotta, EJ Ong, R Bowden</div><div class="gs_gray">Eurographics (Short Presentations), 41-44<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3097817237099987985" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:ZzlSgRqYykMC" class="gsc_a_at">Targeted VAE: Structured inference and targeted learning for causal parameter estimation</a><div class="gs_gray">MJ Vowels, NC Camgoz, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:2009.13472<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6013951784872991510" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:OP4eGU-M3BUC" class="gsc_a_at">SignSynth: Data-Driven Sign Language Video Generation</a><div class="gs_gray">S Stoll, S Hadfield, R Bowden</div><div class="gs_gray">European Conference on Computer Vision, 353-370<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15001424132293961143" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:fFSKOagxvKUC" class="gsc_a_at">Same features, different day: Weakly supervised feature learning for seasonal invariance</a><div class="gs_gray">J Spencer, R Bowden, S Hadfield</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13048297637119443031" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:GtLg2Ama23sC" class="gsc_a_at">Weakly-supervised 3d pose estimation from a single image using multi-view consistency</a><div class="gs_gray">G Rochette, C Russell, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:1909.06119<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14788290658540979284" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:lmc2jWPfTJgC" class="gsc_a_at">Particle filter based probabilistic forced alignment for continuous gesture recognition</a><div class="gs_gray">N Cihan Camgoz, S Hadfield, R Bowden</div><div class="gs_gray">Proceedings of the IEEE International Conference on Computer Vision&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16088503969314610153" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:LPZeul_q3PIC" class="gsc_a_at">Is automated conversion of video to text a reality?</a><div class="gs_gray">R Bowden, SJ Cox, RW Harvey, Y Lan, EJ Ong, G Owen, BJ Theobald</div><div class="gs_gray">Optics and Photonics for Counterterrorism, Crime Fighting, and Defence VIII&nbsp;…<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3548646493081048622" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:738O_yMBCRsC" class="gsc_a_at">Go with the flow: Hand trajectories in 3D via clustered scene flow</a><div class="gs_gray">S Hadfield, R Bowden</div><div class="gs_gray">International Conference Image Analysis and Recognition, 285-295<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1377741787864205319" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:ubry08Y2EpUC" class="gsc_a_at">Sign Language Recognition, Chapter in Visual Analysis of Humans: Looking at People</a><div class="gs_gray">H Cooper, B Holt, R Bowden</div><div class="gs_gray">Springer<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15302919949662597097" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:_Qo2XoVZTnwC" class="gsc_a_at">Tracking objects across uncalibrated arbitrary topology camera networks</a><div class="gs_gray">R Bowden, A Gilbert, P KaewTraKulPong</div><div class="gs_gray">Intelligent Distributed Video Surveillance Systems 5, 157<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15739602193808722327" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:NaGl4SEjCO4C" class="gsc_a_at">Induced decision fusion in automated sign language interpretation: Using ica to isolate the underlying components of sign</a><div class="gs_gray">D Windridge, R Bowden</div><div class="gs_gray">International Workshop on Multiple Classifier Systems, 303-313<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9371099163272580747" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:Ak0FvsSvgGUC" class="gsc_a_at">D'ya like DAGs? A Survey on Structure Learning and Causal Discovery</a><div class="gs_gray">MJ Vowels, NC Camgoz, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:2103.02582<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13055251723643847167" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:fbc8zXXH2BUC" class="gsc_a_at">Everybody sign now: Translating spoken language to photo realistic sign language video</a><div class="gs_gray">B Saunders, NC Camgoz, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:2011.09846<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5048272709706586422" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:umqufdRvDiIC" class="gsc_a_at">ExTOL: Automatic recognition of British Sign Language using the BSL Corpus</a><div class="gs_gray">K Cormier, N Fox, B Woll, A Zisserman, NC Camgöz, R Bowden</div><div class="gs_gray">Proceedings of 6th Workshop on Sign Language Translation and Avatar&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4524925460817929605" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:hkOj_22Ku90C" class="gsc_a_at">Data mining for action recognition</a><div class="gs_gray">A Gilbert, R Bowden</div><div class="gs_gray">Asian Conference on Computer Vision, 290-303<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4323286321955575725" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:9vf0nzSNQJEC" class="gsc_a_at">Weakly supervised automatic transcription of mouthings for gloss-based sign language corpora</a><div class="gs_gray">O Koller, H Ney</div><div class="gs_gray">LREC 2014-NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9797666105614283176" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:mvPsJ3kp5DgC" class="gsc_a_at">Accurate static pose estimation combining direct regression and geodesic extrema</a><div class="gs_gray">B Holt, EJ Ong, R Bowden</div><div class="gs_gray">2013 10th IEEE International Conference and Workshops on Automatic Face and&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16506096009561414109" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:sSrBHYA8nusC" class="gsc_a_at">Mimic: Multimodal interactive motion controller</a><div class="gs_gray">D Okwechime, EJ Ong, R Bowden</div><div class="gs_gray">ieee transactions on multimedia 13 (2), 255-265<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8326044568500342158" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:SeFeTyx0c_EC" class="gsc_a_at">Social interactive human video synthesis</a><div class="gs_gray">D Okwechime, EJ Ong, A Gilbert, R Bowden</div><div class="gs_gray">Asian Conference on Computer Vision, 256-270<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=639933758492886059" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:2VqYfGB8ITEC" class="gsc_a_at">Interaction, reaction and performance</a><div class="gs_gray">R Bowden, S Broadhurst</div><div class="gs_gray">Brunel University<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15518768004906077736" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:XvxMoLDsR5gC" class="gsc_a_at">Gated variational autoencoders: Incorporating weak supervision to encourage disentanglement</a><div class="gs_gray">MJ Vowels, NC Camgoz, R Bowden</div><div class="gs_gray">2020 15th IEEE International Conference on Automatic Face and Gesture&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13829953935462256235" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:9pM33mqn1YgC" class="gsc_a_at">A robust extrinsic calibration framework for vehicles with unscaled sensors</a><div class="gs_gray">C Walters, O Mendez, S Hadfield, R Bowden</div><div class="gs_gray">2019 IEEE/RSJ International Conference on Intelligent Robots and Systems&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12610835776169049293" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:Fu2w8maKXqMC" class="gsc_a_at">Dense rigid reconstruction from unstructured discontinuous video</a><div class="gs_gray">K Lebeda, S Hadfield, R Bowden</div><div class="gs_gray">Proceedings of the IEEE International Conference on Computer Vision&nbsp;…<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=673827947303576949" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:4OULZ7Gr8RgC" class="gsc_a_at">Visualisation and prediction of conversation interest through mined social signals</a><div class="gs_gray">D Okwechime, EJ Ong, A Gilbert, R Bowden</div><div class="gs_gray">2011 IEEE International Conference on Automatic Face &amp; Gesture Recognition&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7256426660339721768" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:NXb4pA-qfm4C" class="gsc_a_at">Affordance mining: Forming perception through action</a><div class="gs_gray">L Ellis, M Felsberg, R Bowden</div><div class="gs_gray">Asian Conference on Computer Vision, 525-538<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3726088307449621455" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:6ZxmRoH8BuwC" class="gsc_a_at">Large lexicon detection of sign language. ICCV</a><div class="gs_gray">H Cooper, R Bowden</div><div class="gs_gray">Workshop Human Comp. Inter<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9725039608858937284" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:YFjsv_pBGBYC" class="gsc_a_at">Hidden Markov chain estimation and parameterisation via ICA-based feature-selection</a><div class="gs_gray">D Windridge, R Bowden</div><div class="gs_gray">Pattern analysis and applications 8 (1), 115-124<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3351306317129248146" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:2tRrZ1ZAMYUC" class="gsc_a_at">Continuous 3D Multi-Channel Sign Language Production via Progressive Transformers and Mixture Density Networks</a><div class="gs_gray">B Saunders, NC Camgoz, R Bowden</div><div class="gs_gray">International Journal of Computer Vision, 1-23<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15598988787353081808" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:8d8msizDQcsC" class="gsc_a_at">SeDAR: Reading Floorplans Like a Human—Using Deep Learning to Enable Human-Inspired Localisation</a><div class="gs_gray">O Mendez, S Hadfield, N Pugeault, R Bowden</div><div class="gs_gray">International Journal of Computer Vision 128 (5), 1286-1310<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3477483447709700808" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:rmuvC79q63oC" class="gsc_a_at">Scale-Adaptive Neural Dense Features: Learning via Hierarchical Context Aggregation</a><div class="gs_gray">J Spencer, R Bowden, S Hadfield</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5547049271392391186" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:0KyAp5RtaNEC" class="gsc_a_at">Direct-from-Video: Unsupervised NRS<i>f</i>M</a><div class="gs_gray">K Lebeda, S Hadfield, R Bowden</div><div class="gs_gray">European Conference on Computer Vision, 578-594<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5671876453662285646" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:WqliGbK-hY8C" class="gsc_a_at">Friendly Faces: Weakly supervised character identification</a><div class="gs_gray">M Marter, S Hadfield, R Bowden</div><div class="gs_gray">International Workshop on Face and Facial Expression Recognition from Real&nbsp;…<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3696130100510321013" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:geHnlv5EZngC" class="gsc_a_at">Meeting in the Middle: A top-down and bottom-up approach to detect pedestrians</a><div class="gs_gray">A Shaukat, A Gilbert, D Windridge, R Bowden</div><div class="gs_gray">Proceedings of the 21st International Conference on Pattern Recognition&nbsp;…<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17768025698200508878" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:isC4tDSrTZIC" class="gsc_a_at">Learning Distance for Arbitrary Visual Features</a><div class="gs_gray">EJ Ong, R Bowden</div><div class="gs_gray">Proceedings of the British Machine Vision Conference 2, 749-758<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17553094920397256957" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:j3f4tGmQtD8C" class="gsc_a_at">Unsupervised symbol grounding and cognitive bootstrapping in cognitive vision</a><div class="gs_gray">R Bowden, L Ellis, J Kittler, M Shevchenko, D Windridge</div><div class="gs_gray">International Conference on Image Analysis and Processing, 27-36<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10953844239745671886" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:_5tno0g5mFcC" class="gsc_a_at">The human tracking project</a><div class="gs_gray">R Bowden</div><div class="gs_gray">Unpublished paper<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15369127211997243510" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:uJ-U7cs_P_0C" class="gsc_a_at">Automotive Prototyping Using Augmented Reality</a><div class="gs_gray">M Lewin, R Bowden, M Sarhadi</div><div class="gs_gray">Proceedings of the 7th VRSIG Conference, Strathclyde University, Sept 2000<span class="gs_oph">, 2000</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11013064232888515905,11397035534789656703" class="gsc_a_ac gs_ibl">3</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="mvvgDvcAAAAJ:uJ-U7cs_P_0C">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2000</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:NhqRSupF_l8C" class="gsc_a_at">Automated visual inspection of dry carbon-fibre reinforced composite preforms</a><div class="gs_gray">TA Mitchell, R Bowden, M Sarhadi</div><div class="gs_gray">Proceedings of the Institution of Mechanical Engineers, Part G: Journal of&nbsp;…<span class="gs_oph">, 1999</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13223842085288108120" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">1999</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:8xutWZnSdmoC" class="gsc_a_at">XXIII.—Studies of the constitution of soap in solution: the electrical conductivity of sodium stearate solutions</a><div class="gs_gray">RC Bowden</div><div class="gs_gray">Journal of the Chemical Society, Transactions 99, 191-195<span class="gs_oph">, 1911</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13359922856903702585" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">1911</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:CaZNVDsoPx4C" class="gsc_a_at">Content4All Open Research Sign Language Translation Datasets</a><div class="gs_gray">NC Camgoz, B Saunders, G Rochette, M Giovanelli, G Inches, ...</div><div class="gs_gray">arXiv preprint arXiv:2105.02351<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18237170937117636910" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:BwyfMAYsbu0C" class="gsc_a_at">TMAGIC: A model-free 3D tracker</a><div class="gs_gray">K Lebeda, S Hadfield, R Bowden</div><div class="gs_gray">IEEE Transactions on Image Processing 26 (9), 4378-4388<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9304449960033169622" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:kzcrU_BdoSEC" class="gsc_a_at">IVACS-Interactive Visual Analytics for Cyber Security</a><div class="gs_gray">J Elder, EJ Ong, R Bowden</div><div class="gs_gray">Proceedings of the Institute of Electrical and Electronics Engineers Vision&nbsp;…<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16432946661452231861" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:XiSMed-E-HIC" class="gsc_a_at">Fuzzy encoding for image classification using Gustafson-Kessel algorithm</a><div class="gs_gray">A Gupta, R Bowden</div><div class="gs_gray">2012 19th IEEE International Conference on Image Processing, 3137-3140<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10789355688216591789" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:Y5dfb0dijaUC" class="gsc_a_at">UNITY IN DIVERSITY: DISCOVERING TOPICS FROM WORDS Information Theoretic Co-clustering for Visual Categorization</a><div class="gs_gray">A Gupta, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10643230889138319374,2482790740225032087" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:1sJd4Hv_s6UC" class="gsc_a_at">Give me a sign: A person independent interactive sign dictionary</a><div class="gs_gray">H Cooper, EJ Ong, R Bowden</div><div class="gs_gray">University of Surrey, Guildford, UK, Tech. Rep. VSSP-TR-1/2011<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6264224877268845404" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:pyW8ca7W8N0C" class="gsc_a_at">Push and Pull: Iterative grouping of media</a><div class="gs_gray">A Gilbert, R Bowden</div><div class="gs_gray">BMVC 2011-Proceedings of the British Machine Vision Conference 2011, 66.1-66.12<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10923403718879110716" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:F1b5ZUV5XREC" class="gsc_a_at">Action Recognition using Randomised Ferns, ICC V 2009</a><div class="gs_gray">O Oshin, A Gilbert, J Illingworth, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9462801925426675761" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:r0BpntZqJG4C" class="gsc_a_at">Learning responses to visual stimuli: A generic approach</a><div class="gs_gray">L Ellis, R Bowden</div><div class="gs_gray">International Conference on Computer Vision Systems: Proceedings (2007)<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12076265967672485774" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:DUooU5lO8OsC" class="gsc_a_at">Interaction</a><div class="gs_gray">R Bowden, S Broadhurst</div><div class="gs_gray">Reaction and Performance URL: http://people. brunel. ac. uk/~ pfstssb<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9523190940850721681" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:U4n9YNQMCAIC" class="gsc_a_at">AnonySIGN: Novel Human Appearance Synthesis for Sign Language Video Anonymisation</a><div class="gs_gray">B Saunders, NC Camgoz, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:2107.10685<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=235967974295284693" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:uDGL6kOW6j0C" class="gsc_a_at">SeeHear: Signer diarisation and a new dataset</a><div class="gs_gray">S Albanie, G Varol, L Momeni, T Afouras, A Brown, C Zhang, E Coto, ...</div><div class="gs_gray">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9288036977072952188" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:4X0JR2_MtJMC" class="gsc_a_at">Enabling spatio-temporal aggregation in Birds-Eye-View Vehicle Estimation</a><div class="gs_gray">A Saha, O Mendez, C Russell, R Bowden</div><div class="gs_gray">Proceedings of the International Conference on Robotics and Automation (ICRA)<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18284526016190394696" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:Aul-kAQHnToC" class="gsc_a_at">A phonology-based approach for isolated sign production assessment in sign language</a><div class="gs_gray">S Tornay, NC Camgoz, R Bowden, M Magimai Doss</div><div class="gs_gray">Companion Publication of the 2020 International Conference on Multimodal&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11664572514491715750" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:otzGkya1bYkC" class="gsc_a_at">Signer diarisation in the wild</a><div class="gs_gray">S Albanie, G Varol, L Momeni, T Afouras, ABCZE Coto, NCCB Saunders, ...</div><div class="gs_gray">International Journal of Computer Vision 128 (2), 420-437<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16471295001092565952" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:FAceZFleit8C" class="gsc_a_at">SeDAR: Reading floorplans like a human</a><div class="gs_gray">O Mendez, S Hadfield, N Pugeault, R Bowden</div><div class="gs_gray">Int. J. Comput. Vis<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1710447228139583566" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:PVjk1bu6vJQC" class="gsc_a_at">The Thermal Infrared Visual Object Tracking VOT-TIR2016 Challenge Result</a><div class="gs_gray">K Lebeda, SJ Hadfield, R Bowden</div><div class="gs_gray">Proceedings, European Conference on Computer Vision (ECCV) workshops<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13558813503032890299" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:ye4kPcJQO24C" class="gsc_a_at">Guest Editorial: Tracking, Detection and Segmentation</a><div class="gs_gray">R Bowden, J Collomosse, K Mikolajczyk</div><div class="gs_gray">International Journal of Computer Vision 110 (1), 1-1<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15853523654050535162" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:eJXPG6dFmWUC" class="gsc_a_at">Improving recognition and identification of facial areas involved in Non-Verbal Communication by feature selection</a><div class="gs_gray">T Sheerman-Chase, EJ Ong, N Pugeault, R Bowden</div><div class="gs_gray">2013 10th IEEE International Conference and Workshops on Automatic Face and&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15067127652276299210" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:g5m5HwL7SMYC" class="gsc_a_at">Learning to Recognise Spatio-Temporal Interest Points</a><div class="gs_gray">OT Oshin, A Gilbert, J Illingworth, R Bowden</div><div class="gs_gray">Machine Learning for Human Motion Analysis: Theory and Practice, 14-30<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9817866481044065575" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:GnPB-g6toBAC" class="gsc_a_at">Problem solving through imitation</a><div class="gs_gray">EJ Ong, L Ellis, R Bowden</div><div class="gs_gray">Image and Vision Computing 27 (11), 1715-1728<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5071007932296184370" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:ns9cj8rnVeAC" class="gsc_a_at">Learning multi-kernel distance functions using relative comparisons</a><div class="gs_gray">EJ Ong, R Bowden</div><div class="gs_gray">Pattern recognition 38 (12), 2653-2657<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8281573437459223545" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:RGFaLdJalmkC" class="gsc_a_at">A generalised exemplar approach to modeling perception action coupling</a><div class="gs_gray">L Ellis, R Bowden</div><div class="gs_gray">Tenth IEEE International Conference on Computer Vision Workshops (ICCVW'05&nbsp;…<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9320998303578402041" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:j8SEvjWlNXcC" class="gsc_a_at">BMVC 2005</a><div class="gs_gray">A Fitzgibbon, J Ferryman, R Bowden, D Alexander, J Gilby, M Mirmehdi, ...</div><div class="gs_gray">The Newsletter of the British Machine Vision Association and Volume 14 (2)<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9277217007938407182" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:epqYDVWIO7EC" class="gsc_a_at">Applying Augmented Reality to Virtual Product Prototyping</a><div class="gs_gray">M Lewin, R Bowden, M Sarhadi</div><div class="gs_gray">CfP: FIRST FRENCH-BRITISH INTERNATIONAL WORKSHOP ON VIRTUAL REALITY, 59-68<span class="gs_oph">, 2000</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10275427661707102202" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2000</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:DJbcl8HfkQkC" class="gsc_a_at">Non-linear Point Distribution Models</a><div class="gs_gray">R Bowden</div><div class="gs_gray">The University of Edinburgh<span class="gs_oph">, 1998</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8510653041920458361" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">1998</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:cK4Rrx0J3m0C" class="gsc_a_at">Improving Robot Localisation by Ignoring Visual Distraction</a><div class="gs_gray">O Mendez, M Vowels, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:2107.11857<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:kVjdVfd2voEC" class="gsc_a_at">Mixed SIGNals: Sign Language Production via a Mixture of Motion Primitives</a><div class="gs_gray">B Saunders, NC Camgoz, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:2107.11317<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:7Hz3ACDFbsoC" class="gsc_a_at">Looking for the Signs: Identifying Isolated Sign Instances in Continuous Video Footage</a><div class="gs_gray">T Jiang, NC Camgoz, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:2108.04229<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:43bX7VzcjpAC" class="gsc_a_at">Adversarial Mixture Density Networks: Learning to Drive Safely from Collision Data</a><div class="gs_gray">S Kuutti, S Fallah, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:2107.04485<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:zCSUwVk65WsC" class="gsc_a_at">ARC: Adversarially Robust Control Policies for Autonomous Vehicles</a><div class="gs_gray">S Kuutti, S Fallah, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:2107.04487<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:NyGDZy8z5eUC" class="gsc_a_at">Markov Localisation using Heatmap Regression and Deep Convolutional Odometry</a><div class="gs_gray">O Mendez, S Hadfield, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:2106.00371<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:wMgC3FpKEyYC" class="gsc_a_at">Content4All Open Research Sign Language Translation Datasets</a><div class="gs_gray">N Cihan Camgoz, B Saunders, G Rochette, M Giovanelli, G Inches, ...</div><div class="gs_gray">arXiv e-prints, arXiv: 2105.02351<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:6yz0xqPARnAC" class="gsc_a_at">There and Back Again: Self-supervised Multispectral Correspondence Estimation</a><div class="gs_gray">C Walters, O Mendez, M Johnson, R Bowden</div><div class="gs_gray">arXiv preprint arXiv:2103.10768<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:48xauSegjOkC" class="gsc_a_at">Hand Gesture Recognition Using OpenCV</a><div class="gs_gray">N Roy, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:QD3KBmkZPeQC" class="gsc_a_at">Evaluating the Immediate Applicability of Pose Estimation for Sign Language Recognition</a><div class="gs_gray">A Moryossef, I Tsochantaridis, J Dinn, NC Camgoz, R Bowden, T Jiang, ...</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:jL-93Qbq4QoC" class="gsc_a_at">Skeletor: Skeletal Transformers for Robust Body-Pose Estimation</a><div class="gs_gray">T Jiang, NC Camgoz, R Bowden</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:4xDN1ZYqzskC" class="gsc_a_at">Shadow-Mapping for Unsupervised Neural Causal Discovery</a><div class="gs_gray">MJ Vowels, NC Camgoz, R Bowden</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:sJsF-0ZLhtgC" class="gsc_a_at">VDSM: Unsupervised Video Disentanglement with State-Space Modeling and Deep Mixtures of Experts</a><div class="gs_gray">MJ Vowels, NC Camgoz, R Bowden</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:AHdEip9mkN0C" class="gsc_a_at">Weakly supervised reinforcement learning for autonomous highway driving via virtual safety cages</a><div class="gs_gray">S Kuutti, R Bowden, S Fallah</div><div class="gs_gray">Sensors 21 (6), 2032<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:5MTHONV0fEkC" class="gsc_a_at">2020 Index IEEE Transactions on Pattern Analysis and Machine Intelligence Vol. 42</a><div class="gs_gray">A Aberdam, J Achterhold, JK Adams, E Adeli, S Agaian, K Aizawa, ...</div><div class="gs_gray">IEEE Transactions on Pattern Analysis and Machine Intelligence 43 (1)<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:GFxP56DSvIMC" class="gsc_a_at">Multi-channel Transformers for Multi-articulatory Sign Language Translation</a><div class="gs_gray">N Cihan Camgoz, O Koller, S Hadfield, R Bowden</div><div class="gs_gray">arXiv e-prints, arXiv: 2009.00299<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:_OXeSy2IsFwC" class="gsc_a_at">SLRTP 2020: The Sign Language Recognition, Translation &amp; Production Workshop</a><div class="gs_gray">NC Camgöz, G Varol, S Albanie, N Fox, R Bowden, A Zisserman, ...</div><div class="gs_gray">European Conference on Computer Vision, 179-185<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:HeT0ZceujKMC" class="gsc_a_at">Extrinsic sensor calibration systems and methods</a><div class="gs_gray">C Walters, R Bowden, OM Maldonado, S Hadfield</div><div class="gs_gray">US Patent App. 16/676,186<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:KbBQZpvPDL4C" class="gsc_a_at">Sign Language Transformers: Joint End-to-end Sign Language Recognition and Translation</a><div class="gs_gray">N Cihan Camgoz, O Koller, S Hadfield, R Bowden</div><div class="gs_gray">arXiv e-prints, arXiv: 2003.13830<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:lvd772isFD0C" class="gsc_a_at">Towards large vocabulary continuous sign language recognition: from artificial to real-life tasks</a><div class="gs_gray">OTA Koller, H Ney, R Bowden</div><div class="gs_gray">Fachgruppe Informatik<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:_FM0Bhl9EiAC" class="gsc_a_at">Auto-Perceptive Reinforcement Learning (APRiL)</a><div class="gs_gray">R Allday, S Hadfield, R Bowden</div><div class="gs_gray">Proceedings of the 2019 IEEE/RSJ International Conference on Intelligent&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:XoXfffV-tXoC" class="gsc_a_at">Localisation via Deep Imagination: learn the features not the map</a><div class="gs_gray">J Spencer, O Mendez, R Bowden, S Hadfield</div><div class="gs_gray">Proceedings of the European Conference on Computer Vision (ECCV) Workshops, 0-0<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:ClCfbGk0d_YC" class="gsc_a_at">Taking the Scenic Route to 3D: Optimising Reconstruction from Moving Cameras</a><div class="gs_gray">O Mendez Maldonado, S Hadfield, N Pugeault, R Bowden</div><div class="gs_gray">ICCV 2017 Proceedings<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:tYavs44e6CUC" class="gsc_a_at">From Vision to Grasping: Adapting Visual Networks</a><div class="gs_gray">R Allday, S Hadfield, R Bowden</div><div class="gs_gray">Annual Conference Towards Autonomous Robotic Systems, 484-494<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:4MWp96NkSFoC" class="gsc_a_at">Appreciation to IJCV Reviewers</a><div class="gs_gray">H Aanæs, H Ackermann, A Agrawal, I Akhter, K Alahari, P Aljabar, ...</div><div class="gs_gray">Int J Comput Vis 116, 109-114<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:tzM49s52ZIMC" class="gsc_a_at">Learning multi-class discriminative patterns using episode-trees</a><div class="gs_gray">EJ Ong, N Pugeault, A Gilbert, R Bowden</div><div class="gs_gray">IARIA<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:TIZ-Mc8IlK0C" class="gsc_a_at">The evolution of Computer Vision</a><div class="gs_gray">R Bowden</div><div class="gs_gray">PERCEPTION 44, 360-361<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:_Re3VWB3Y0AC" class="gsc_a_at">Appreciation to IJCV Reviewers</a><div class="gs_gray">H Aanæs, S Achar, A Adams, L Agapito, A Agathos, K Alahari, A Alahi, ...</div><div class="gs_gray">Int J Comput Vis 111, 249-254<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:7T2F9Uy0os0C" class="gsc_a_at">Geometric Mining: Scaling Geometric Hashing to Large Datasets</a><div class="gs_gray">A Gilbert, R Bowden</div><div class="gs_gray">Proceedings of the IEEE International Conference on Computer Vision&nbsp;…<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:PR6Y55bgFSsC" class="gsc_a_at">2014 Index IEEE Transactions on Pattern Analysis and Machine Intelligence Vol. 36</a><div class="gs_gray">R Abiantun, N Ahuja, A Aissani, K Ait-Mohand, K Aizawa, Z Akata, ...</div><div class="gs_gray">IEEE Transactions on Pattern Analysis and Machine Intelligence 37 (1), 209<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:sNmaIFBj_lkC" class="gsc_a_at">Seeing and understanding people: Richard Bowden</a><div class="gs_gray">R Bowden</div><div class="gs_gray">Computational Vision and Medical Image Processing IV, 27-34<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:anf4URPfarAC" class="gsc_a_at">Seeing and understanding people</a><div class="gs_gray">R Bowden</div><div class="gs_gray">Computational Vision and Medical Image Processing IV: VIPIMAGE 2013, 9<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:4vMrXwiscB8C" class="gsc_a_at">The Visual Object Tracking VOT2013 challenge results</a><div class="gs_gray"></div><div class="gs_gray">VOT2013 Challenge workshop, In Proc. IEEE International Conference on&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:WJVC3Jt7v1AC" class="gsc_a_at">Hollywood 3D: Recognizing Actions in 3D Natural Scenes</a><div class="gs_gray">SHR Bowden</div><div class="gs_gray">CVPR<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:uWiczbcajpAC" class="gsc_a_at">Recent developments in automated lip-reading</a><div class="gs_gray">S Cox, R Harvey, Y Lan, R Bowden, EJ Ong, G Owen, B Theobald</div><div class="gs_gray">SPIE Security and Defence<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:1qzjygNMrQYC" class="gsc_a_at">Efficient Estimation of Human Upper Body Pose in Static Depth Images</a><div class="gs_gray">B Holt, R Bowden</div><div class="gs_gray">Computer Vision, Imaging and Computer Graphics. Theory and Application, 399-410<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:D_sINldO8mEC" class="gsc_a_at">Appreciation to IJCV Reviewers</a><div class="gs_gray">H Aanæs, J Ackermann, Y Adato, L Agapito, A Agarwala, J Aggarwal, ...</div><div class="gs_gray">Int J Comput Vis 101, 1-5<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:dshw04ExmUIC" class="gsc_a_at">There is more than one way to get out of a car: Automatic Mode Finding for Action Recognition in the Wild</a><div class="gs_gray">O Oshin, A Gilbert, R Bowden</div><div class="gs_gray">Iberian Conference on Pattern Recognition and Image Analysis, 41-48<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:dBIO0h50nwkC" class="gsc_a_at">Pose_Holt11</a><div class="gs_gray">B Holt</div><div class="gs_gray">University of Surrey<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:hCrLmN-GePgC" class="gsc_a_at">Decentralized sensor fusion for ubiquitous networking robotics in urban areas</a><div class="gs_gray">J Andrade-Cetto, M Barbosa, R Bowden, J Capitan, A Corominas, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:gsN89kCJA0AC" class="gsc_a_at">Learning Driving Behaviour Using Holistic Image Descriptors</a><div class="gs_gray">N Pugeault, R Bowden</div><div class="gs_gray">4th International Conference on Cognitive Systems, CogSys 2010<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:URolC5Kub84C" class="gsc_a_at">Universal Access in Human-Computer Interaction. Addressing Diversity</a><div class="gs_gray">E Efthimiou, SE Fotinea, C Vogler, T Hanke, J Glauert, R Bowden, ...</div><div class="gs_gray">Lecture Notes in Computer Science, 21-30<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:rO6llkc54NcC" class="gsc_a_at">Third Year Project</a><div class="gs_gray">M Nicholson, P Helland, E Cornish, A Aichi, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:abG-DnoFyZgC" class="gsc_a_at">Learning wormholes for sparsely labelled clustering</a><div class="gs_gray">EJ Ong, R Bowden</div><div class="gs_gray">18th International Conference on Pattern Recognition (ICPR'06) 1, 916-919<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:D03iK_w7-QYC" class="gsc_a_at">Poster Session II-Tracking and Motion-Tracking Objects Across Cameras by Incrementally Learning Inter-camera Colour Calibration and Patterns of Activity</a><div class="gs_gray">A Gilbert, R Bowden</div><div class="gs_gray">Lecture Notes in Computer Science 3952, 125-136<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:f2IySw72cVMC" class="gsc_a_at">Intelligent Distributed Surveillance Systems-Towards automated wide area visual surveillance: Tracking objects between spatially-separated, uncalibrated views</a><div class="gs_gray">R Bowden, P KaewTraKulPong</div><div class="gs_gray">IEE Proceedings-Vision Image and Signal Processing 152 (2), 213-223<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:KxtntwgDAa4C" class="gsc_a_at">Progress in sign and gesture recognition</a><div class="gs_gray">R Bowden</div><div class="gs_gray">International Conference on Articulated Motion and Deformable Objects, 13-13<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:xtRiw3GOFMkC" class="gsc_a_at">A general strategy for hidden markov chain parameterisation in composite feature-spaces</a><div class="gs_gray">D Windridge, R Bowden, J Kittler</div><div class="gs_gray">Joint IAPR International Workshops on Statistical Techniques in Pattern&nbsp;…<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:5icHVeHT4IsC" class="gsc_a_at">the Underlying Components of Sign</a><div class="gs_gray">D Windridge, R Bowden</div><div class="gs_gray">Multiple Classifier Systems:... International Workshop, MCS... Proceedings, 303<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:J-pR_7NvFogC" class="gsc_a_at">Probabilistic models in computer vision</a><div class="gs_gray">R Bowden</div><div class="gs_gray">IMAGE AND VISION COMPUTING 21 (10), 841-841<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:mNrWkgRL2YcC" class="gsc_a_at">William Ernest Bowden· Elisabeth Jean McQueen Lloyd· Peter Roberts· David Robertson Smith· John William Woolley</a><div class="gs_gray">D Bowden, R Bowden</div><div class="gs_gray">BMJ: British Medical Journal 322 (7283), 435<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:1lhNe0rCu4AC" class="gsc_a_at">Real Time Hand Tracking and Gesture Recognition as a 3D Input Device for</a><div class="gs_gray">R Bowden, T Heap, D Hogg</div><div class="gs_gray">Progress in Gestural Interaction: Proceedings of Gesture Workshop’96, March&nbsp;…<span class="gs_oph">, 1997</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">1997</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:EkHepimYqZsC" class="gsc_a_at">VRSIG'97, Proceedings of the 4th UK Virtual Reality Special Interest Group Conference</a><div class="gs_gray">R Bowden</div><div class="gs_gray">UK-VRSIG<span class="gs_oph">, 1997</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">1997</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:LdasjJ6CEcoC" class="gsc_a_at">Multi-Camera Sensor Fusion for Visual Odometry using Deep Uncertainty Estimation</a><div class="gs_gray">N Kaygusuz, O Mendez, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:v1_lew4L6wgC" class="gsc_a_at">MDN-VO: Estimating Visual Odometry with Confidence</a><div class="gs_gray">N Kaygusuz, O Mendez, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:BzfGm06jWhQC" class="gsc_a_at">Targeted VAE: Variational and Targeted Learning for Causal Inference</a><div class="gs_gray">M VOWELS, NC CAMGOZ, R BOWDEN</div><div class="gs_gray">IEEE International Conference on Smart Data Services<span class="gs_oph">, 0</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:jgBuDB5drN8C" class="gsc_a_at">Fast Realistic Multi-Action Recognition using Mined Dense Spatio-temporal</a><div class="gs_gray">A Gilbert, J Illingworth, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:ALROH1vI_8AC" class="gsc_a_at">Online Learning of Robust Facial Feature Trackers</a><div class="gs_gray">R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:lgwcVrK6X84C" class="gsc_a_at">VDSM: Unsupervised Video Disentanglement with State-Space Modeling and Deep Mixtures of Experts (Supplementary Material)</a><div class="gs_gray">MJ Vowels, NC Camgoz, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:buQ7SEKw-1sC" class="gsc_a_at">Markov Localisation using Heatmap Regression and Deep Convolutional Odometry</a><div class="gs_gray">OAM MALDONADO, SJ HADFIELD, R BOWDEN</div><div class="gs_gray">2021 International Conference on Robotics and Automation (ICRA 2021)<span class="gs_oph">, 0</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:Bg7qf7VwUHIC" class="gsc_a_at">A Cascaded Deep Convolutional Network for Vehicle Logo Recognition From Frontal and Rear Images of</a><div class="gs_gray">A Eskandarian, C Wu, C Sun, S Kuutti, R Bowden, Y Jin, P Barber, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:BJbdYPG6LGMC" class="gsc_a_at">Binefa, Xavier 93, 606 Bortolato, Blaž 495 Bourbakis, Nikolaos 667</a><div class="gs_gray">L Akarun, P Albert, L Alharbawee, MR Ali, M Alves Diniz, T Amorese, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:vDZJ-YLwNdEC" class="gsc_a_at">Area Chairs</a><div class="gs_gray">L Akarun, O Aran, S Berretti, R Bowden, A Caplier, H Dibeklioglu, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:artPoR2Yc-kC" class="gsc_a_at">Wen-Sheng Chu, Google, USA Enric Corona, IRI, Spain Nicholas Cummins, University of Augsburg, Germany Adam Czajka, University of Notre Dame, USA Naser Damer, Fraunhofer IGD&nbsp;…</a><div class="gs_gray">A Agarwal, S Akbarian, G Anbarjafari, O Aran, A Asgarian, V Athitsos, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:tH6gc1N1XXoC" class="gsc_a_at">Pilot 1 demostrator architecture, integration plan and evaluation methodologies</a><div class="gs_gray">P Panuccio, SB HFC, WP HHI, R Bowden, T Mallikarachchi, ML VRT, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:gKiMpY-AVTkC" class="gsc_a_at">Initial Reference System Architecture</a><div class="gs_gray">P Panuccio, WP HHI, R Bowden, T Mallikarachchi, ML VRT, R Ribback, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:gVv57TyPmFsC" class="gsc_a_at">Final Reference System Architecture</a><div class="gs_gray">MG FIN, R Bowden, JF FIN, C Galkandage, GM FIN, AO HFC, WP HHI, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:nVrZBo8bIpAC" class="gsc_a_at">Multi-channel Transformers for Multi-articulatory Sign Language Translation: Supplementary Material</a><div class="gs_gray">NC Camgoz, O Koller, S Hadfield, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:u-coK7KVo8oC" class="gsc_a_at">SignSynth: Data-Driven Sign Language Video Generation</a><div class="gs_gray">R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:yqoGN6RLRZoC" class="gsc_a_at">NestedVAE: Supplementary Material</a><div class="gs_gray">MJ Vowels, NC Camgoz, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:IRz6iEL74y4C" class="gsc_a_at">Data mining for Action Recognition</a><div class="gs_gray">AGR Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:kh2fBNsKQNwC" class="gsc_a_at">Access to the Document</a><div class="gs_gray">L Ellis, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:86PQX7AUzd4C" class="gsc_a_at">Metric Mixtures for Mutual Information (Х 3 С) Tracking</a><div class="gs_gray">N Dowson, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:FPJr55Dyh1AC" class="gsc_a_at">SurfCut: Surfaces of Minimal Paths from Topological Structures</a><div class="gs_gray">M Algarni, G Sundaramoorthi, Z Bylinskii, T Judd, A Oliva, A Torralba, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:-_dYPAW6P2MC" class="gsc_a_at">3DCars</a><div class="gs_gray">K Lebeda, SJ Hadfield, R Bowden</div><div class="gs_gray">IEEE<span class="gs_oph">, 0</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:2KloaMYe4IUC" class="gsc_a_at">FLO</a><div class="gs_gray">K Lebeda, J Matas, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:1yQoGdGgb4wC" class="gsc_a_at">IEEE Computer Society Publishing Services Staff</a><div class="gs_gray">C Bishop, A Blake, D Fleet, Z Ghahramani, E Grimson, D Koller, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:VL0QpB8kHFEC" class="gsc_a_at">Jacobian of Point Coordinates wrt Parameters of General Calibrated Projective Camera</a><div class="gs_gray">K Lebeda, S Hadfield, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:AXPGKjj_ei8C" class="gsc_a_at">Track and area chairs</a><div class="gs_gray">R Bowden, SB Kang, L Quan, R Ambasamudram, LIU Michael Felsberg, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:P5F9QuxV20EC" class="gsc_a_at">Auditory-Visual Speech Processing (AVSP) 2009</a><div class="gs_gray">L Wang, W Han, X Qian, F Soong</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:CHSYGLWDkRkC" class="gsc_a_at">3rd IEEE on-line learning for computer vision workshop</a><div class="gs_gray">B Babenko, MH Yang, S Belongie, R Pelossof, M Jones, I Vovsha, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:a0OBvERweLwC" class="gsc_a_at">Metric Mixtures for Mutual Information Tracking v1. 0</a><div class="gs_gray">N Dowson, R Bowden</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:cFHS6HbyZ2cC" class="gsc_a_at">1st IEEE workshop on video-oriented object and event classification</a><div class="gs_gray">L Ballan, M Bertini, A Del Bimbo, L Seidenari, G Serra, P Matikainen, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=mvvgDvcAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=mvvgDvcAAAAJ:3s1wT3WcHBgC" class="gsc_a_at">IEEE international workshop on human-computer interaction (HCI'09)</a><div class="gs_gray">D Kelly, JR Delannoy, J Mc Donald, C Markham, T Sheerman-Chase, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr></tbody></table><div id="gsc_a_sp" class=""></div><div id="gsc_a_err" class="gs_alrt">The system can't perform the operation now. Try again later.</div></div><div id="gsc_lwp"><span id="gsc_a_nn">Articles 1–304</span><div id="gsc_bpf"><button type="button" id="gsc_bpf_more" class="gs_btnPD gs_in_ib gs_btn_flat gs_btn_lrge gs_btn_lsu" disabled=""><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl">Show more</span></span></button></div></div></form></div></div></div></div><div id="gs_ftr_sp" role="presentation"></div><div id="gs_ftr" role="contentinfo"><div id="gs_ftr_rt"><a href="/intl/en/scholar/about.html">Help</a><a href="//www.google.com/intl/en/policies/privacy/">Privacy</a><a href="//www.google.com/intl/en/policies/terms/">Terms</a></div></div></div></body></html>