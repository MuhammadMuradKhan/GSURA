<html class="gs_el_sm gs_pfcs"><head><title>‪Wenwu Wang‬ - ‪Google Scholar‬</title><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><meta name="referrer" content="origin-when-cross-origin"><meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=2"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="https://scholar.google.co.uk/citations?user=JQFnV5IAAAAJ&amp;hl=en"><meta name="description" content="‪Professor, University of Surrey (CVSSP), UK‬ - ‪‪Cited by 4,553‬‬ - ‪signal processing‬ - ‪machine learning‬ - ‪audio/speech/audio-visual‬ - ‪information fusion‬"><meta property="og:description" content="‪Professor, University of Surrey (CVSSP), UK‬ - ‪‪Cited by 4,553‬‬ - ‪signal processing‬ - ‪machine learning‬ - ‪audio/speech/audio-visual‬ - ‪information fusion‬"><meta property="og:title" content="Wenwu Wang"><meta property="og:image" content="https://scholar.googleusercontent.com/citations?view_op=medium_photo&amp;user=JQFnV5IAAAAJ&amp;citpid=6"><meta property="og:type" content="website"><meta name="twitter:card" content="summary"><style>html,body,form,table,div,h1,h2,h3,h4,h5,h6,img,ol,ul,li,button{margin:0;padding:0;border:0;}table{border-collapse:collapse;border-width:0;empty-cells:show;}html,body{height:100%}#gs_top{position:relative;box-sizing:border-box;min-height:100%;min-width:964px;-webkit-tap-highlight-color:rgba(0,0,0,0);}#gs_top>*:not(#x){-webkit-tap-highlight-color:rgba(204,204,204,.5);}.gs_el_ph #gs_top,.gs_el_ta #gs_top{min-width:320px;}#gs_top.gs_nscl{position:fixed;width:100%;}body,td,input,button{font-size:13px;font-family:Arial,sans-serif;line-height:1.24;}body{background:#fff;color:#222;-webkit-text-size-adjust:100%;-moz-text-size-adjust:none;}.gs_gray{color:#777777}.gs_red{color:#dd4b39}.gs_grn{color:#006621}.gs_lil{font-size:11px}.gs_med{font-size:16px}.gs_hlt{font-weight:bold;}a:link{color:#1a0dab;text-decoration:none}a:visited{color:#660099;text-decoration:none}a:hover,a:hover .gs_lbl{text-decoration:underline}a:active,a:active .gs_lbl,a .gs_lbl:active{color:#d14836}.gs_el_tc a:hover,.gs_el_tc a:hover .gs_lbl{text-decoration:none}.gs_pfcs a:focus,.gs_pfcs button:focus,.gs_pfcs input:focus,.gs_pfcs label:focus{outline:none}.gs_a,.gs_a a:link,.gs_a a:visited{color:#006621}.gs_a a:active{color:#d14836}a.gs_fl:link,.gs_fl a:link{color:#1a0dab}a.gs_fl:visited,.gs_fl a:visited{color:#660099}a.gs_fl:active,.gs_fl a:active{color:#d14836}.gs_fl{color:#777777}.gs_ctc,.gs_ctu{vertical-align:middle;font-size:11px;font-weight:bold}.gs_ctc{color:#1a0dab}.gs_ctg,.gs_ctg2{font-size:13px;font-weight:bold}.gs_ctg{color:#1a0dab}a.gs_pda,.gs_pda a{padding:7px 0 5px 0}.gs_alrt{background:#f9edbe;border:1px solid #f0c36d;padding:0 16px;text-align:center;box-shadow:0 2px 4px rgba(0,0,0,.2);border-radius:2px;}.gs_spc{display:inline-block;width:12px}.gs_br{width:0;font-size:0}.gs_ibl{display:inline-block;}.gs_scl:after{content:"";display:table;clear:both;}.gs_ind{padding-left:8px;text-indent:-8px}.gs_ico,.gs_icm{display:inline-block;background:no-repeat url(/intl/en/scholar/images/1x/sprite_20161020.png);background-position:-23px -161px;background-size:169px;width:21px;height:21px;}@media(-webkit-min-device-pixel-ratio:1.5),(min-resolution:144dpi){.gs_ico,.gs_icm{background-image:url(/intl/en/scholar/images/2x/sprite_20161020.png);}}.gs_el_ta .gs_nta,.gs_ota,.gs_el_ph .gs_nph,.gs_oph{display:none}.gs_el_ta .gs_ota,.gs_el_ph .gs_oph{display:inline}.gs_el_ta div.gs_ota,.gs_el_ph div.gs_oph{display:block}.gs_sth_g{visibility:hidden;max-height:0;}.gs_sth_vis .gs_sth_g{max-height:1000px;}.gs_sth_vis .gs_sth_b{position:fixed;top:0;}@keyframes gs_anm_spin{0%{transform:rotate(0deg);}100%{transform:rotate(360deg);}}.gs_rimg{display:block;background-color:#e5e5e5;border-radius:50%;overflow:hidden;position:relative;z-index:1;}.gs_rimg>img{position:absolute;margin:auto;left:0;top:0;bottom:0;right:0;}.gs_in_txtw{display:inline-block;vertical-align:middle;}.gs_in_txtb{display:block;}.gs_in_txt{color:#000;background-color:#fff;font-size:16px;box-sizing:border-box;height:29px;line-height:23px;border:1px solid #d9d9d9;border-top-color:#c0c0c0;padding:3px 6px 1px 8px;border-radius:1px;outline:none;-webkit-appearance:none;-moz-appearance:none;}.gs_el_tc .gs_in_txt{font-size:18px;}.gs_in_txtb .gs_in_txt{width:100%;}.gs_in_txt:hover{border-color:#b9b9b9;border-top-color:#a0a0a0;box-shadow:inset 0 1px 2px rgba(0,0,0,.1);}.gs_in_txte .gs_in_txt{border-color:#dd4b39;}.gs_in_txt:focus{border-color:#4d90fe;box-shadow:inset 0 1px 2px rgba(0,0,0,.3);}.gs_in_txt:disabled{color:#b8b8b8;border-color:#f1f1f1;box-shadow:none;}.gs_in_txtm .gs_in_txt{font-size:13px;height:24px;line-height:16px;padding:3px 6px;}.gs_el_tc .gs_in_txtm .gs_in_txt{height:29px;line-height:21px;}.gs_in_txts{font-size:13px;line-height:18px;color:#666;}.gs_in_txte .gs_in_txts{color:#dd4b39;}button{position:relative;z-index:1;box-sizing:border-box;font-size:13px;cursor:pointer;height:29px;line-height:normal;min-width:72px;padding:0 8px;color:#444;border:1px solid rgba(0,0,0,.1);border-radius:3px;text-align:center;background-color:#f5f5f5;-webkit-user-select:none;user-select:none;}button.gs_btn_rnd{border-radius:14px;padding:0 12px;}button.gs_btn_rnd.gs_btn_rndci{padding-left:4px;}button.gs_btn_lrge{height:41px;min-width:82px;padding:0 9px;}button.gs_btn_lrge.gs_btn_rnd{border-radius:20px;padding:0 16px;}button.gs_btn_lrge.gs_btn_rnd.gs_btn_rndci{padding-left:10px;}button.gs_btn_cir{border-radius:14.5px;min-width:29px;}button.gs_btn_lrge.gs_btn_cir{border-radius:20.5px;min-width:41px;}button.gs_btn_mini{padding:0;border:0;}.gs_el_ph button.gs_btn_mph,.gs_el_ta button.gs_btn_mta{height:41px;}button .gs_wr{position:relative;display:inline-block;width:100%;height:100%;}button .gs_wr:before{content:"";width:0;height:100%;}button .gs_wr:before,button .gs_ico,button .gs_rdt,button .gs_lbl,button .gs_icm{display:inline-block;vertical-align:middle;}button .gs_wr{font-size:13px;text-transform:none;}.gs_btn_lrge .gs_wr{font-size:15px;}.gs_btn_lsb .gs_wr{font-size:11px;font-weight:bold;}.gs_btn_lsu .gs_wr{font-size:11px;text-transform:uppercase;}.gs_btn_lrge.gs_btn_lsb .gs_wr,.gs_btn_lrge.gs_btn_lsu .gs_wr{font-size:13px;}.gs_btn_half,.gs_el_ta .gs_btn_hta,.gs_el_ph .gs_btn_hph{min-width:36px;}.gs_btn_lrge.gs_btn_half,.gs_el_ta .gs_btn_lrge.gs_btn_hta,.gs_el_ph .gs_btn_lrge.gs_btn_hph,.gs_el_ta .gs_btn_mta,.gs_el_ph .gs_btn_mph{min-width:41px;}.gs_btn_slt{border-radius:3px 0 0 3px;}.gs_btn_srt{margin-left:-1px;border-radius:0 3px 3px 0;}.gs_btn_smd{margin-left:-1px;border-radius:0;}button:hover{z-index:2;color:#222;border-color:rgba(0,0,0,.2);background-color:#f8f8f8;}button.gs_sel{background-color:#dcdcdc;}button:active{z-index:2;background-color:#f1f1f1;}button:focus{z-index:2;}button::-moz-focus-inner{padding:0;border:0}button:-moz-focusring{outline:1px dotted ButtonText}.gs_pfcs button:-moz-focusring{outline:none}a.gs_in_ib{position:relative;display:inline-block;line-height:16px;padding:6px 0 7px 0;-webkit-user-select:none;user-select:none;}a.gs_btn_lrge{height:40px;padding:0;}a.gs_in_ib .gs_lbl{display:inline-block;padding-left:21px;color:#222;}a.gs_in_ib .gs_lbl:not(:empty){padding-left:29px;}button.gs_in_ib .gs_lbl:not(:empty){padding-left:4px;}a.gs_in_ib:active .gs_lbl,a.gs_in_ib .gs_lbl:active,a.gs_in_ib :active~.gs_lbl{color:#d14836;}.gs_el_ta .gs_btn_hta .gs_lbl,.gs_el_ph .gs_btn_hph .gs_lbl,.gs_el_ta .gs_btn_mta .gs_lbl,.gs_el_ph .gs_btn_mph .gs_lbl,.gs_el_ta .gs_btn_cta .gs_lbl,.gs_el_ph .gs_btn_cph .gs_lbl{display:none;}a.gs_in_ib .gs_ico{position:absolute;top:3px;left:0;}.gs_in_ib.gs_md_li .gs_ico{left:14px;}.gs_el_tc .gs_in_ib.gs_md_li .gs_ico{top:11px;}.gs_in_ib.gs_md_li.gs_md_lix .gs_ico{top:10px;left:16px;}a.gs_btn_lrge .gs_ico{top:50%;left:50%;margin:-10.5px 0 0 -10.5px;}.gs_in_ib .gs_ico{opacity:.55;}.gs_in_ib:hover .gs_ico{opacity:.72;}.gs_in_ib:active .gs_ico,.gs_in_ib .gs_ico:active,.gs_in_ib :active~.gs_ico{opacity:1;}.gs_in_ib:disabled .gs_ico,.gs_in_ib.gs_dis .gs_ico{opacity:.28;}.gs_in_ib.gs_btn_act .gs_ico,.gs_in_ib.gs_btn_cre .gs_ico{opacity:1;}.gs_btn_act:disabled .gs_ico,.gs_btn_cre:disabled .gs_ico{opacity:.72;}.gs_rdt{position:relative;width:0;height:21px;}.gs_rdt:before{content:"";position:absolute;top:2px;right:1px;width:5px;height:5px;border-radius:50%;background-color:#dd4b39;}button.gs_btn_flat{border-color:transparent;background-color:transparent;}button.gs_btn_flat:hover{background-color:rgba(0,0,0,.05);}button.gs_btn_flat:active{background-color:rgba(0,0,0,.1);}button.gs_btn_flat.gs_btn_flact{color:#1a0dab;}button.gs_btn_act{color:#fff;-webkit-font-smoothing:antialiased;background-color:#4d90fe;}button.gs_btn_act:hover{color:#fff;background-color:#3983fe;}button.gs_btn_act.gs_sel{background-color:#2f6bcc;}button.gs_btn_act:active{background-color:#357ae8;}button.gs_btn_cre{color:#fff;-webkit-font-smoothing:antialiased;background-color:#d14836;}button.gs_btn_cre:hover{color:#fff;background-color:#c53727;}button.gs_btn_cre.gs_sel{background-color:#992b1e;}html:not(.gs_pfcs) .gs_btn_act:focus:not(:active){box-shadow:inset 0 0 0 1px rgba(255,255,255,.5);}button.gs_btn_cre:active{background-color:#b0281a;}button:disabled,button:disabled:hover,button:disabled:active{cursor:default;color:#b8b8b8;border-color:rgba(0,0,0,.05);background-color:transparent;z-index:0;}button.gs_btn_flat:disabled{color:#b8b8b8;border-color:transparent;}button.gs_btn_act:disabled{color:#fff;background-color:#a6c8ff;}button.gs_btn_cre:disabled{color:#fff;background-color:#e8a49b;}a.gs_in_ib.gs_dis{cursor:default;pointer-events:none}a.gs_in_ib.gs_dis .gs_lbl{color:#b8b8b8;text-decoration:none}.gs_ttp{position:absolute;top:100%;right:50%;z-index:10;pointer-events:none;visibility:hidden;opacity:0;transition:visibility 0s .13s,opacity .13s ease-out;}button:hover .gs_ttp,button:focus .gs_ttp,a:hover .gs_ttp,a:focus .gs_ttp{transition:visibility 0s .3s,opacity .13s ease-in .3s;visibility:visible;opacity:1;}.gs_md_tb.gs_sel .gs_ttp{transition:none;visibility:hidden;}button.gs_btn_lrge.gs_btn_cir .gs_ttp{top:75%;}.gs_ttp .gs_aro,.gs_ttp .gs_aru{position:absolute;top:-2px;right:-5px;width:0;height:0;line-height:0;font-size:0;border:5px solid transparent;border-top:none;border-bottom-color:#595959;z-index:1;}.gs_ttp .gs_aro{top:-3px;right:-6px;border-width:6px;border-top:none;border-bottom-color:white;}.gs_ttp .gs_txt{display:block;position:relative;top:2px;right:-50%;padding:4px 6px;background:#595959;color:white;font-size:11px;font-weight:bold;line-height:normal;white-space:nowrap;border:1px solid white;border-radius:3px;box-shadow:inset 0 1px 4px rgba(0,0,0,.2);}.gs_press,.gs_in_se,.gs_tan{touch-action:none;}.gs_in_se .gs_lbl:not(:empty){padding-right:14px;}.gs_in_se .gs_icm{position:absolute;top:50%;margin-top:-5.5px;right:0;width:7px;height:11px;background-position:-21px -88px;opacity:.55;}.gs_in_se:hover .gs_icm{opacity:.72;}.gs_in_se:active .gs_icm{opacity:1;}.gs_in_se:disabled .gs_icm{opacity:.28;}.gs_el_ta .gs_btn_hta .gs_icm,.gs_el_ph .gs_btn_hph .gs_icm,.gs_el_ta .gs_btn_mta .gs_icm,.gs_el_ph .gs_btn_mph .gs_icm,.gs_el_ta .gs_btn_cta .gs_icm,.gs_el_ph .gs_btn_cph .gs_icm{display:none;}.gs_btn_mnu .gs_icm{margin-top:-3.5px;height:7px;background-position:0 -110px;}.gs_in_se.gs_btn_act .gs_icm,.gs_in_se.gs_btn_cre .gs_icm{margin-top:-3.5px;height:7px;background-position:-42px -44px;opacity:1;}.gs_btn_act:disabled .gs_icm,.gs_btn_cre:disabled .gs_icm{opacity:.72;}button.gs_btnG .gs_ico{width:21px;height:21px;background-position:-92px -253px;}button .gs_bs{position:absolute;top:50%;left:50%;margin-top:-10px;margin-left:-10px;box-sizing:border-box;width:20px;height:20px;border-radius:50%;border:2px solid #eee;border-top-color:#4d90fe;visibility:hidden;animation:gs_anm_spin .8s linear infinite;}button.gs_bsp .gs_bs{visibility:visible;transition:visibility 0s .4s;}.gs_md_d{text-transform:none;white-space:nowrap;position:absolute;top:0;left:0;border:1px solid #ccc;border-color:rgba(0,0,0,.2);background:#fff;box-shadow:0 2px 4px rgba(0,0,0,.2);z-index:1100;text-align:left;visibility:hidden;max-height:0;margin-top:-1000px;opacity:0;transition:opacity .13s,visibility 0s .13s,max-height 0s .13s,margin-top 0s .13s;}.gs_md_d.gs_vis{visibility:visible;max-height:10000px;margin-top:0;opacity:1;transition:all 0s;}.gs_el_tc .gs_md_d{transform-origin:100% 0;transform:scale(1,0);transition:opacity .218s ease-out,transform 0s .218s,visibility 0s .218s,max-height 0s .218s,margin-top 0s .218s;}.gs_el_ios .gs_md_d{-webkit-backface-visibility:hidden;}.gs_el_tc .gs_md_d.gs_ttzi{transform-origin:50% 50%;transform:scale(0,0);}.gs_el_tc .gs_md_d.gs_ttzr{transform:scale(0,0);}.gs_el_tc .gs_md_d.gs_vis{transform:scale(1,1);transition:transform .218s ease-out;}.gs_md_r{position:relative;display:inline-block;}.gs_md_rmb>.gs_md_d{top:29px}.gs_md_rmbl>.gs_md_d{top:41px}.gs_md_ul{list-style-type:none;word-wrap:break-word;display:inline-block;vertical-align:top;}.gs_md_ul.gs_md_ul_tb{display:block;}.gs_md_li,.gs_in_cb.gs_md_li,.gs_md_li:link,.gs_md_li:visited{display:block;padding:6px 44px 6px 16px;font-size:13px;line-height:16px;color:#222;cursor:pointer;text-decoration:none;position:relative;z-index:0;}a.gs_md_li:hover .gs_lbl,a.gs_md_li:active .gs_lbl{text-decoration:none}.gs_el_tc .gs_md_li{padding-top:14px;padding-bottom:10px;}.gs_md_li.gs_md_lix{font-size:16px;line-height:20px;padding:12px 16px 8px 16px;}.gs_md_li:before{content:"";background-color:#f1f1f1;position:absolute;left:0;right:0;top:0;bottom:0;opacity:0;transition:opacity .13s;z-index:-1;}.gs_md_li:hover:before,.gs_md_li:focus:before{opacity:1;transition:all 0s;}a.gs_in_ib.gs_md_li .gs_lbl{color:#222}a.gs_in_ib.gs_md_li.gs_in_gray .gs_lbl{color:#444}.gs_md_li:active:before{background-color:#ddd}.gs_md_li.gs_sel,a.gs_in_ib.gs_md_li.gs_sel .gs_lbl{color:#d14836}.gs_md_d:focus,.gs_md_li:focus{outline:none}a.gs_md_lix .gs_lbl,a.gs_md_lix .gs_lbl:not(:empty){padding:0 0 0 40px;}a.gs_in_cb:link,a.gs_in_cb:visited,a.gs_in_cb:active,a.gs_in_cb:hover{cursor:pointer;color:#222;text-decoration:none;}.gs_in_cb,.gs_in_ra{position:relative;line-height:16px;display:inline-block;-webkit-user-select:none;user-select:none;}.gs_in_cb.gs_md_li{padding:6px 44px 6px 16px;}.gs_in_cb input,.gs_in_ra input{position:absolute;top:1px;left:1px;width:15px;height:15px;margin:0;padding:0;opacity:0;z-index:2;}.gs_in_ra input{top:0;left:0}.gs_el_tc .gs_in_cb input{top:9px}.gs_el_tc .gs_in_ra input{top:8px}.gs_in_cb.gs_in_cbj input{top:15px;left:15px}.gs_in_cb label,.gs_in_cb .gs_lbl,.gs_in_ra label{display:inline-block;padding-left:21px;min-height:16px;}.gs_in_cb label:empty:before,.gs_in_cb .gs_lbl:empty:before,.gs_in_ra label:empty:before{content:"\200b";}.gs_el_tc .gs_in_cb label,.gs_el_tc .gs_in_cb .gs_lbl,.gs_el_tc .gs_in_ra label{padding-top:8px;padding-bottom:5px;}.gs_in_cb.gs_in_cbj label,.gs_in_cb.gs_in_cbj .gs_lbl{padding:13px 0 12px 41px;}.gs_in_cbb,.gs_in_cbb label,.gs_in_cbb .gs_lbl{display:block;}.gs_in_cb .gs_cbx,.gs_in_ra .gs_cbx{position:absolute}.gs_in_cb .gs_cbx{top:2px;left:2px;width:11px;height:11px;border:1px solid #c6c6c6;border-radius:1px;}.gs_md_li .gs_cbx{top:8px;left:18px}.gs_el_tc .gs_in_cb .gs_cbx{top:10px}.gs_el_tc .gs_md_li .gs_cbx{top:16px}.gs_in_cb.gs_in_cbj .gs_cbx{top:15px;left:15px}.gs_el_tc .gs_in_ra .gs_cbx{top:8px}.gs_in_ra .gs_cbx{top:0;left:0;border:1px solid #c6c6c6;width:13px;height:13px;border-radius:7px;}.gs_in_cb:hover .gs_cbx,.gs_in_ra:hover .gs_cbx{border-color:#666;box-shadow:inset 0 1px 1px rgba(0,0,0,.1);}button.gs_in_cb:hover .gs_cbx{border-color:#c6c6c6;}.gs_in_cb :focus~label,.gs_in_ra :focus~label{outline:1px dotted #222;outline:auto -webkit-focus-ring-color;}.gs_pfcs .gs_in_cb :focus~label,.gs_pfcs .gs_in_ra :focus~label{outline:none;}.gs_in_cb:active .gs_cbx,.gs_in_ra:active .gs_cbx,.gs_in_cb .gs_cbx:active,.gs_in_ra .gs_cbx:active,.gs_in_cb :active~.gs_cbx,.gs_in_ra :active~.gs_cbx{border-color:#666;background-color:#ebebeb;}button.gs_in_cb:active .gs_cbx{border-color:#a6a6a6;}.gs_in_cb :disabled~.gs_cbx,.gs_in_ra :disabled~.gs_cbx,button.gs_in_cb:disabled .gs_cbx{border-color:#f1f1f1;box-shadow:none;}.gs_in_cb :disabled~label,.gs_in_ra :disabled~label{color:#b8b8b8;}.gs_in_cb.gs_err .gs_cbx{border-color:#eda29b;}.gs_in_cb .gs_chk,.gs_in_ra .gs_chk{position:absolute;z-index:1;top:-3px;left:-2px;width:21px;height:21px;}.gs_md_li .gs_chk{top:3px;left:14px}.gs_el_tc .gs_in_cb .gs_chk{top:5px}.gs_el_tc .gs_md_li .gs_chk{top:11px}.gs_in_cb.gs_in_cbj .gs_chk{top:10px;left:11px}.gs_in_ra .gs_chk{top:4px;left:4px;width:7px;height:7px;border-radius:4px;}.gs_el_tc .gs_in_ra .gs_chk{top:12px}.gs_in_cb input:checked~.gs_chk,.gs_in_cb.gs_sel .gs_chk{background:no-repeat url(/intl/en/scholar/images/1x/sprite_20161020.png) -69px -67px;opacity:.62;}.gs_in_ra input:checked~.gs_chk{background-color:#666}.gs_in_cb.gs_par .gs_chk{background:no-repeat url(/intl/en/scholar/images/1x/sprite_20161020.png) -21px -44px;opacity:.55;}@media(-webkit-min-device-pixel-ratio:1.5),(min-resolution:144dpi){.gs_in_cb input:checked~.gs_chk,.gs_in_cb.gs_sel .gs_chk,.gs_in_cb.gs_par .gs_chk{background-image:url(/intl/en/scholar/images/2x/sprite_20161020.png);background-size:169px;}}.gs_in_cb input:checked:disabled~.gs_chk{opacity:.22}.gs_in_ra input:checked:disabled~.gs_chk{background-color:#f1f1f1}.gs_ico_x{background-position:-113px -22px;opacity:.55;}.gs_ico_x:hover{opacity:.72;}.gs_ico_x:active{opacity:1;}.gs_ico_X{background-position:-71px 0;opacity:.55;}.gs_ico_X:hover{opacity:.72;}.gs_ico_X:active{opacity:1;}.gs_el_tc .gs_ico_Xt{background-origin:content-box;background-clip:content-box;padding:10px 6px 10px 14px;}.gs_ico_P{background-position:0 0;opacity:.55;}.gs_ico_P:hover{opacity:.72;}.gs_ico_P:active{opacity:1;}.gs_btnP .gs_ico{background-position:-21px 0;}.gs_btnC .gs_ico{background-position:0 -66px;}.gs_btnL .gs_ico{background-position:-92px -44px;}.gs_ico_LB{background-position:-50px -44px;height:16px;}.gs_btnJ .gs_ico{background-position:-92px -22px;}.gs_btnM .gs_ico{background-position:-92px 0;}.gs_btnMW .gs_ico{background-position:-21px -22px;}.gs_btnSB .gs_ico{background-position:0 -44px;}.gs_btnTSB .gs_ico{background-position:-115px -253px;}.gs_btnPL .gs_ico{background-position:-148px -66px;}.gs_btnPR .gs_ico{background-position:-21px -66px;}.gs_btnPLW .gs_ico{background-position:-0 -230px;}.gs_btnPRW .gs_ico{background-position:-23px -230px;}.gs_btnZI .gs_ico{background-position:-148px -22px;}.gs_btnZO .gs_ico{background-position:-127px -44px;}.gs_btnDE .gs_ico{background-position:-134px 0;}.gs_btnFI .gs_ico{background-position:-50px -66px;}.gs_btnAD .gs_ico{background-position:-141px -88px;opacity:.55;}.gs_btnAD:hover .gs_ico{opacity:.72;}.gs_btnAD:active .gs_ico,.gs_btnAD .gs_ico:active,.gs_btnAD :active~.gs_ico{opacity:1;}.gs_btnBA .gs_ico{background-position:-50px -22px;}.gs_btnADD .gs_ico{background-position:-92px -66px;}.gs_btnMRG .gs_ico{background-position:-113px 0;}.gs_btnLBL .gs_ico{background-position:0 -161px;}.gs_btnCNCL .gs_ico{background-position:-71px 0;}.gs_btnDWL .gs_ico{background-position:-28px -88px;}.gs_btnMNU .gs_ico{background-position:0 -88px;}.gs_btnMNT .gs_ico{background-position:-46px -161px;}.gs_btnALT .gs_ico{background-position:-92px -161px;}.gs_btnART .gs_ico{background-position:-115px -161px;}.gs_btnGSL .gs_ico{background-position:-69px -161px;}.gs_btnCLS .gs_ico{background-position:-138px -161px;}.gs_btnXBLU .gs_ico{background-position:-138px -253px;}.gs_btnSSB .gs_ico{background-position:0 -276px;}.gs_btnSSW .gs_ico{background-position:-23px -276px;}.gs_btnFLT .gs_ico{background-position:0 -184px;}.gs_btnXT .gs_ico{background-position:-46px -184px;}.gs_btnPD .gs_ico{background-position:-69px -184px;}.gs_btnPU .gs_ico {background-position:-92px -276px;}.gs_btnCP .gs_ico{background-position:-92px -184px;}.gs_btnTP .gs_ico{background-position:-138px -184px;}.gs_btnML .gs_ico{background-position:-115px -276px;}.gs_btnCHK .gs_ico{background-position:-71px -66px;}.gs_btnDNB .gs_ico{background-position:-115px -230px;}.gs_btnDNW .gs_ico{background-position:0 -207px;}.gs_btnACA .gs_ico{background-position:-23px -207px;}.gs_btnAPT .gs_ico{background-position:-46px -207px;}.gs_btnAPTW .gs_ico{background-position:-92px -230px;}.gs_btnAFL .gs_ico{background-position:-69px -207px;}.gs_btnAN .gs_ico{background-position:-46px -276px;}.gs_btnAI .gs_ico{background-position:-69px -276px;}.gs_btnPBL .gs_ico{background-position:-92px -207px;}.gs_btnUCT .gs_ico{background-position:-115px -207px;}.gs_btnVRF .gs_ico{background-position:-138px -207px;}.gs_btnLSI .gs_ico{background-position:-46px -230px;}.gs_btnLSG .gs_ico{background-position:-69px -230px;}.gs_btnMOR .gs_ico{background-position:-23px -253px;}.gs_btnADV .gs_ico{background-position:-46px -253px;}.gs_btnPRO .gs_ico{background-position:-69px -253px;}.gs_ico_star{background-position:-71px -44px;width:13px;height:13px;}.gs_btnPLSW .gs_ico{background-position:-138px -230px;}.gs_btnPDF .gs_ico{background-position:0 -253px;}.gs_btnS .gs_ico{background-position:-138px -276px;}.gs_btnUNS .gs_ico{background-position:0 -299px;}.gs_btnMORR .gs_ico{background-position:-23px -299px;}.gs_btnTW .gs_ico{background-position:-46px -299px;}.gs_btnIN .gs_ico{background-position:-69px -299px;}.gs_btnFB .gs_ico{background-position:-92px -299px;}#gs_hdr_drs,#gs_hdr_drw{position:fixed;top:0;left:0;width:100%;height:100%;z-index:1200;visibility:hidden;}#gs_hdr_drs{opacity:0;background-color:#fff;transition:opacity .15s,visibility 0s .15s;}.gs_el_ta #gs_hdr_drs,.gs_el_ph #gs_hdr_drs{background-color:#666;}#gs_hdr_drs.gs_vis{visibility:visible;opacity:.5;transition:opacity .15s,visibility 0s;}.gs_el_tc #gs_hdr_drs{transition:opacity .218s,visibility 0s .218s;}.gs_el_tc #gs_hdr_drs.gs_vis{transition:opacity .218s,visibility 0s;}#gs_hdr_drw{overflow:auto;width:228px;background-color:#fff;box-shadow:2px 2px 4px rgba(0,0,0,.15);outline:none;transform:translate(-100%,0);transition:transform .15s ease-in-out,visibility 0s .15s;}#gs_hdr_drw.gs_vis{visibility:visible;transform:translate(0,0);transition:transform .15s ease-in-out,visibility 0s;}.gs_el_tc #gs_hdr_drw{transition:transform .3s cubic-bezier(.4,0,.6,1),visibility 0s .3s;}.gs_el_tc #gs_hdr_drw.gs_vis{transition:transform .225s cubic-bezier(0,0,.2,1),visibility 0s;}#gs_hdr_drw.gs_abt,.gs_el_tc #gs_hdr_drw.gs_abt{transition:none;}#gs_hdr_drw_in{position:relative;box-sizing:border-box;min-height:100%;padding:0 0 8px 0;}.gs_el_ta #gs_hdr_drw_in,.gs_el_ph #gs_hdr_drw_in{padding:0 0 65px 0;}#gs_hdr_drw_top{position:relative;height:63px;border-bottom:1px solid #e5e5e5;margin-bottom:8px;}.gs_el_ta #gs_hdr_drw_top,.gs_el_ph #gs_hdr_drw_top{height:57px;}#gs_hdr_drw_mnu,#gs_hdr_drw_lgo{position:absolute;top:0;height:100%;}#gs_hdr_drw_mnu{left:0;width:55px;}#gs_hdr_drw_lgo{left:56px;}.gs_hdr_drw_sec:before{display:block;content:" ";height:0;border-bottom:1px solid #e5e5e5;margin:8px 0;}.gs_hdr_drw_sec:first-child:before{display:none;}#gs_hdr_drw_bot{display:none;}.gs_el_ta #gs_hdr_drw_bot,.gs_el_ph #gs_hdr_drw_bot{display:block;position:absolute;left:0;bottom:0;width:100%;height:65px;}#gs_hdr_drw_bot .gs_md_li:before{opacity:0;}#gs_hdr_drw_bot .gs_hdr_pp{display:block;position:absolute;bottom:14px;left:15px;pointer-events:none;}#gs_hdr_drw_bot .gs_lbl{display:block;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;}#gs_hdr{position:relative;height:63px;background-color:#f5f5f5;border-bottom:1px solid #e5e5e5;display:flex;}.gs_el_ta #gs_hdr,.gs_el_ph #gs_hdr{height:57px;}#gs_hdr_mnu,#gs_hdr_bck,#gs_hdr_lgo,#gs_hdr_lgt,#gs_hdr_md,#gs_hdr_sre,#gs_hdr_act{display:inline-block;vertical-align:top;position:relative;height:100%;flex:0 0 auto;}#gs_hdr_md{flex:1 1 auto;}#gs_hdr .gs_hdr_mbo,#gs_hdr .gs_hdr_mbo,.gs_el_ta #gs_hdr .gs_hdr_dso,.gs_el_ph #gs_hdr .gs_hdr_dso{display:none;}.gs_el_ta #gs_hdr .gs_hdr_mbo,.gs_el_ph #gs_hdr .gs_hdr_mbo{display:inline-block;}#gs_hdr_mnu,#gs_hdr_bck,#gs_hdr_sre{width:55px;margin-right:1px;}#gs_hdr_lgo,#gs_hdr_drw_lgo{width:149px;background:no-repeat url('/intl/en/scholar/images/1x/scholar_logo_24dp.png') 0% 50%;background-size:149px;}@media(-webkit-min-device-pixel-ratio:1.5),(min-resolution:144dpi){#gs_hdr_lgo,#gs_hdr_drw_lgo{background-image:url('/intl/en/scholar/images/2x/scholar_logo_24dp.png');}}#gs_hdr_lgo{margin-right:31px;}.gs_el_ph #gs_hdr_lgo{margin-right:0;}#gs_hdr_lgt{min-width:164px;margin-right:16px;}#gs_hdr_lgt:empty{display:none;}#gs_hdr_md{margin-right:16px;min-width:1px;}#gs_hdr_lgt,#gs_hdr_md h1{padding:19px 0 0 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;font-size:20px;line-height:25px;font-weight:normal;color:#666;max-width:100%;text-align:left;}.gs_el_ta #gs_hdr_md h1,.gs_el_ph #gs_hdr_md h1{padding:16px 0 0 0;}#gs_hdr_srch{padding:14px 0 0 0;max-width:600px;}.gs_el_ta #gs_hdr_srch,.gs_el_ph #gs_hdr_srch{padding:10px 0 0 0;max-width:none;}#gs_hdr_frm{position:relative;padding-right:39px;}#gs_hdr_tsi{height:38px;border-radius:2px 0 0 2px;}#gs_hdr_tsi::-ms-clear{display:none;}#gs_hdr_tsc{display:none;position:absolute;top:3px;right:41px;width:21px;height:21px;padding:6px 10px 7px 10px;}.gs_in_acw[dir="rtl"]~#gs_hdr_tsc{right:auto;left:1px;}#gs_hdr_tsb{position:absolute;top:0;right:0;width:40px;height:38px;border-radius:0 2px 2px 0;}#gs_hdr_frm_ac{top:37px;right:40px;}.gs_el_ph #gs_hdr_frm_ac{right:0;}.gs_el_ph .gs_hdr_ifc #gs_hdr_mnu,.gs_el_ph .gs_hdr_ifc #gs_hdr_bck,.gs_hdr_src #gs_hdr_srch,.gs_hdr_src #gs_hdr_lgt,.gs_hdr_srx #gs_hdr_sre,.gs_hdr_srx #gs_hdr_md h1,.gs_hdr_srx #gs_hdr_md h1.gs_hdr_mbo,.gs_hdr_srx #gs_hdr_md h1.gs_hdr_dso,.gs_el_ta .gs_hdr_srx #gs_hdr_lgo,.gs_el_ph .gs_hdr_srx #gs_hdr_lgo,.gs_el_ph .gs_hdr_srx #gs_hdr_mnu,.gs_el_ph .gs_hdr_srx #gs_hdr_bck{display:none;}.gs_el_ph .gs_hdr_ifc #gs_hdr_md,.gs_el_ph .gs_hdr_srx #gs_hdr_md{margin-left:16px;}.gs_el_tc .gs_hdr_tsc #gs_hdr_tsi[dir="ltr"]{padding-right:41px;}.gs_el_tc .gs_hdr_tsc #gs_hdr_tsi[dir="rtl"]{padding-left:41px;}.gs_el_tc .gs_hdr_tsc .gs_in_acw~#gs_hdr_tsc{display:block;}#gs_hdr_act{min-width:64px;max-width:200px;text-align:right;float:right;}.gs_el_ta #gs_hdr_act,.gs_el_ph #gs_hdr_act{display:none;}#gs_hdr_act_i,#gs_hdr_act_s{display:inline-block;padding:23px 24px 23px 16px;max-width:100%;box-sizing:border-box;font-size:13px;line-height:17px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;color:#444;}#gs_hdr_act_s{text-transform:uppercase;}.gs_el_sm #gs_hdr_act_i,.gs_el_sm #gs_hdr_act_s{padding:23px 16px;}.gs_el_ta #gs_hdr_act_i,.gs_el_ta #gs_hdr_act_s,.gs_el_ph #gs_hdr_act_i,.gs_el_ph #gs_hdr_act_s{padding:20px 16px;}#gs_hdr_act_i:active,#gs_hdr_act_s:active{color:#d14836;}#gs_hdr_act_i,.gs_el_sm #gs_hdr_act_i{padding-top:15px;padding-bottom:16px;}.gs_el_ta #gs_hdr_act_i,.gs_el_ph #gs_hdr_act_i{padding-top:12px;padding-bottom:13px;}#gs_hdr_act_i .gs_hdr_pp{vertical-align:top;}#gs_hdr_act_d{top:63px;left:auto;right:24px;min-width:288px;max-width:400px;}.gs_el_sm #gs_hdr_act_d{right:16px;}.gs_el_ta #gs_hdr_act_d{top:57px;}.gs_el_ph #gs_hdr_act_d{top:57px;min-width:280px;max-width:280px;max-width:90vw;}/* Account dialog body. */#gs_hdr_act_aw,#gs_hdr_act_ap,.gs_hdr_act_am,#gs_hdr_act_ab{display:block;padding:10px 20px;word-wrap:break-word;white-space:normal;}#gs_hdr_act_aw{background-color:#fef9db;font-size:11px;}#gs_hdr_act_ap,.gs_hdr_act_am{border-bottom:1px solid #ccc;}#gs_hdr_act_ap{padding:20px;}.gs_el_ph #gs_hdr_act_ap{padding:10px;}#gs_hdr_act_apb{margin-top:12px;}#gs_hdr_act_aa:link,#gs_hdr_act_aa:visited{float:right;margin-left:8px;color:#1a0dab;}#gs_hdr_act_aa:active{color:#d14836}.gs_hdr_act_am:link,.gs_hdr_act_am:visited{color:#222;text-decoration:none;background:#fbfbfb;}.gs_hdr_act_am:hover,.gs_hdr_act_am:focus{background:#f1f1f1;}.gs_hdr_act_am:active{background:#eee;}#gs_hdr_act_ab{background:#fbfbfb;padding:10px 0;display:table;width:100%;white-space:nowrap;}#gs_hdr_act_aba,#gs_hdr_act_abs{display:table-cell;padding:0 20px;}#gs_hdr_act_abs{text-align:right;}.gs_el_ph #gs_hdr_act_aba,.gs_el_ph #gs_hdr_act_abs{display:block;padding:10px;text-align:center;}.gs_el_ph #gs_hdr_act_aba button,.gs_el_ph #gs_hdr_act_abs button{width:100%;}#gs_hdr_act_a1,#gs_hdr_act_a2{position:absolute;top:-9px;right:7.5px;width:0;height:0;z-index:1;border:8.5px solid transparent;border-top:none;border-bottom-color:#333;border-bottom-color:rgba(0,0,0,.2);}#gs_hdr_act_a2{top:-8px;border-bottom-color:#fff;}.gs_hdr_act_mw #gs_hdr_act_a2{border-bottom-color:#fef9db;}.gs_hdr_pp{border-radius:50%;overflow:hidden;}#gs_hdr_act_ap .gs_hdr_pp,.gs_hdr_act_am .gs_hdr_pp{float:left;}#gs_hdr_act_ap .gs_hdr_pm{margin-left:116px;}.gs_hdr_act_am .gs_hdr_pm{margin:6px 0 0 58px;}#gs_ab{position:relative;height:41px;border-bottom:1px solid #e5e5e5;display:flex;white-space:nowrap;background-color:#fff;z-index:1000;}.gs_el_ta #gs_ab.gs_nta,.gs_el_ph #gs_ab.gs_nph{display:none;}#gs_ab_g{height:42px;}.gs_sth_vis #gs_ab{position:fixed;}#gs_ab_ico,#gs_ab_ttl,#gs_ab_md,#gs_ab_btns{display:inline-block;vertical-align:top;position:relative;height:100%;flex:0 0 auto;}.gs_el_ph #gs_ab_md{display:block;}#gs_ab_ico{width:55px;margin-right:1px;}#gs_ab_ico .gs_ico{position:absolute;top:50%;left:50%;margin:-10.5px 0 0 -10.5px;}#gs_ab_ttl{min-width:172px;padding-right:8px;}.gs_el_sm #gs_ab_ttl{min-width:68px;}.gs_el_ta #gs_ab_ttl,.gs_el_ph #gs_ab_ttl{min-width:0;}#gs_ab_ttl,#gs_ab_ttll{font-size:18px;color:#666;text-transform:none;}.gs_el_sm #gs_ab_ttl,.gs_el_sm #gs_ab_ttll{font-size:16px;}#gs_ab_ttll{overflow:hidden;text-overflow:ellipsis;max-width:200px;}#gs_ab_md{flex:1 0 auto;}.gs_ab_st #gs_ab_md{flex:1 1 auto;font-size:13px;line-height:17px;padding:0 8px;color:#999;overflow:hidden;text-overflow:ellipsis;}.gs_el_ph .gs_ab_st #gs_ab_md{visibility:hidden;padding:0;}#gs_ab_btns{margin-right:8px;}.gs_el_sm #gs_ab_btns{margin-right:0;}.gs_el_ta #gs_ab_btns,.gs_el_ph #gs_ab_btns{margin-right:4px;}#gs_ab_ttl:before,#gs_ab_md:before,#gs_ab_btns:before{content:"";display:inline-block;width:0;height:100%;vertical-align:middle;}#gs_ab_md>button,#gs_ab_btns>button,#gs_ab_md>.gs_in_ib,#gs_ab_btns>.gs_in_ib,#gs_ab_md>.gs_md_r,#gs_ab_btns>.gs_md_r,#gs_ab .gs_ab_mdw,#gs_ab .gs_ab_btw{margin:0 8px;vertical-align:middle;}#gs_ab .gs_ab_mdw,.gs_ab_btw{display:inline-block;margin:0;}#gs_ab_btns>.gs_in_ib{margin:0 16px 0 8px;}#gs_ab .gs_ab_btw{margin:0 12px 0 16px;}.gs_el_ta .gs_ab_sel #gs_ab_ico,.gs_el_ph .gs_ab_sel #gs_ab_ico,.gs_el_ta .gs_ab_sel #gs_ab_ttl,.gs_el_ph .gs_ab_sel #gs_ab_ttl,.gs_el_ta .gs_ab_sel #gs_ab_btns,.gs_el_ph .gs_ab_sel #gs_ab_btns{display:none;}#gs_bdy{display:table;table-layout:fixed;width:100%;}#gs_bdy_sb{vertical-align:top;width:228px;word-wrap:break-word;display:none;}.gs_el_sm #gs_bdy_sb{}.gs_el_ta #gs_bdy_sb,.gs_el_ph #gs_bdy_sb{}.gs_bdy_sb_sec{margin:0 40px 0 56px;}.gs_bdy_sb_sec:before{display:block;content:" ";height:0;margin:13px 0;border-top:1px solid #eee;}.gs_bdy_sb_sec:first-child:before{margin:21px 0 0 0;border:none;}#gs_bdy_sb ul{list-style-type:none;}.gs_bdy_sb_sec a:link,.gs_bdy_sb_sec a:visited{color:#222;}.gs_bdy_sb_sec a:active{color:#d14836;}.gs_bdy_sb_sel a:link,.gs_bdy_sb_sel a:visited{color:#d14836;text-decoration:none;}.gs_el_tc .gs_bdy_sb_sec li.gs_ind,.gs_el_tc .gs_bdy_sb_sec li.gs_ind a{padding-top:8px;padding-bottom:5px;}.gs_el_tc .gs_bdy_sb_sec:first-child li.gs_ind:first-child{margin-top:-8px;}#gs_bdy_sb .gs_ind,#gs_bdy_sb .gs_inw{margin-bottom:4px;}.gs_el_tc #gs_bdy_sb .gs_ind,.gs_el_tc #gs_bdy_sb .gs_inw{margin-bottom:0;}#gs_bdy_ccl{display:table-cell;vertical-align:top;padding:0 24px 0 16px;}.gs_el_sm #gs_bdy_ccl{padding:0 16px;}.gs_el_ta #gs_bdy_ccl,.gs_el_ph #gs_bdy_ccl{padding:0 16px;}.gs_el_ph #gs_bdy_ccl{padding:0;}#gs_ftr_sp{height:62px;}.gs_el_sm #gs_ftr_sp{height:57px;}#gs_ftr{position:absolute;bottom:0;left:0;width:100%;white-space:nowrap;border-top:1px solid #e4e4e4;background-color:#f2f2f2;display:flex;}#gs_ftr_rt{box-sizing:border-box;max-width:100%;overflow-x:auto;margin-left:auto;padding:0 12px;}.gs_el_sm #gs_ftr_rt{padding:0 8px;}.gs_el_ph #gs_ftr_rt:after{content:" ";position:absolute;top:0;right:0;width:16px;height:100%;background-image:linear-gradient(to right,rgba(242,242,242,0),rgba(242,242,242,1) 80%);}#gs_ftr_rt a{display:inline-block;line-height:16px;padding:12px;white-space:nowrap;}.gs_el_sm #gs_ftr_rt a{padding:12px 8px;}#gs_ftr_rt a:link,#gs_ftr_rt a:visited{color:#666}#gs_ftr_rt a:active{color:#d14836}#gsc_a_t{width:100%;table-layout:fixed;}#gsc_a_tr0,#gsc_a_trh{box-sizing:border-box;}#gsc_a_tr0 th.gsc_a_x,#gsc_a_tr0 th.gsc_a_t,#gsc_a_tr0 th.gsc_a_c,#gsc_a_tr0 th.gsc_a_y{height:0;}#gsc_a_trh{z-index:700;background-color:#f5f5f5;height:42px;}.gs_el_ta #gsc_a_trh,.gs_el_ph #gsc_a_trh,.gs_el_ta #gsc_a_t td,.gs_el_ph #gsc_a_t td{background-color:#fff;border-bottom:1px solid #e5e5e5;}#gsc_a_t th.gsc_a_x,#gsc_a_t th.gsc_a_t,#gsc_a_t th.gsc_a_c,#gsc_a_t th.gsc_a_y{box-sizing:border-box;text-transform:uppercase;vertical-align:middle;padding-top:0;padding-bottom:0;}#gsc_x_all{z-index:1;}.gsc_a_x,.gsc_a_t,.gsc_a_c,.gsc_a_y,.gsc_a_e{font-weight:normal;padding:16px 16px 0 16px;vertical-align:top;text-align:right;}.gsc_a_c{padding:16px 8px 0 8px;}.gs_el_sm .gsc_a_x,.gs_el_sm .gsc_a_t,.gs_el_sm .gsc_a_c{padding:12px 8px 0 8px;}.gs_el_ta .gsc_a_x,.gs_el_ta .gsc_a_t,.gs_el_ta .gsc_a_c,.gs_el_ph .gsc_a_x,.gs_el_ph .gsc_a_t,.gs_el_ph .gsc_a_c{padding:12px 8px;}.gs_el_sm .gsc_a_y{padding:12px 8px 0 8px;}.gs_el_ta .gsc_a_y{padding-bottom:12px;}.gsc_a_x{width:41px;padding:4px 0 0 0;}.gs_el_sm .gsc_a_x{padding:0;}.gsc_a_t{text-align:left;}.gs_el_ph .gsc_a_t{padding-left:16px;}#gsc_a_ta{display:inline-block;vertical-align:middle;margin-right:16px;}.gs_el_ph #gsc_a_ta{display:none}.gs_el_ph .gsc_a_c{padding-right:16px;}th.gsc_a_c{width:64px;white-space:nowrap;}.gsc_art_sel #gsc_a_ta,.gsc_art_sel #gsc_a_ca,.gsc_art_sel .gsc_a_h{display:none;}.gsc_a_ac,.gsc_a_hc{margin-top:3px;}th.gsc_a_y{width:88px;white-space:nowrap;}.gs_el_sm th.gsc_a_y{width:58px;}.gs_el_ph th.gsc_a_y,.gs_el_ph td.gsc_a_y{width:0;padding:0;}.gs_el_ph .gsc_a_h{display:none}@media print{#gs_top th.gsc_a_y{width:58pt;}#gs_top #gsc_a_tr0{display:none}#gs_top #gsc_a_trh{position:static}}.gsc_a_e{padding:16px;text-align:center;}.gsc_a_a{padding:8px 0}.gsc_a_at{padding:8px 0;font-size:16px}a.gsc_a_acm{text-decoration:line-through;}a.gsc_a_acm:hover,a.gs_a_acm:active{text-decoration:underline;}.gsc_a_m{position:absolute;}.gs_el_ph .gsc_a_m{display:block;position:static;}.gsc_a_am{font-size:24px;position:absolute;top:-18px;left:-2px;padding:8px 12px 4px 8px;}.gs_el_ph .gsc_a_am{display:inline-block;position:static;padding:6px 16px;margin-bottom:-6px;}#gsc_a_sp{visibility:hidden;}#gsc_a_sp.gs_vis{visibility:visible;padding:16px 0;height:25px;border-bottom:1px solid #ccc;}#gsc_a_sp:after{display:block;height:100%;content:" ";background:url('/intl/en/scholar/images/spinner.gif') no-repeat 50% 50%;opacity:0;}#gsc_a_sp.gs_vis:after{opacity:1;transition:opacity 0s .4s;}#gsc_a_err{display:none;padding:28px 0;}#gsc_a_err.gs_vis{display:block;}#gsc_md_iad{width:800px;max-width:94%;}.gs_el_ph #gsc_md_iad{width:100%;max-width:100%;}#gsc_md_iad .gs_md_prg{min-height:400px;}.gs_el_ph #gsc_iads_res .gs_md_prg{margin:0 16px;}#gsc_iad_tart,.gsc_iad_tsel.gsc_iad_tart #gsc_iad_tart,.gsc_iad_tart #gsc_iad_tgrp,.gsc_iad_tsel #gsc_iad_tgrp,#gsc_iad_tsel,#gsc_napb_hdr #gsc_iad_tart,#gsc_napb_hdr #gsc_iad_tgrp{display:none;}#gsc_iad_tgrp,.gsc_iad_tart #gsc_iad_tart,.gsc_iad_tsel #gsc_iad_tsel,#gsc_napb_hdr #gsc_iad_tsel{display:inline-block;}#gsc_iad_t:not(.gsc_iad_tsel) #gsc_iad_tsel{pointer-events:none;color:#b5b5b5;}.gs_el_ph #gsc_napb #gsc_iads_frm{margin:0 16px;}#gsc_iads_res{position:relative;margin:8px 0 16px 0;min-height:80px;border-bottom:1px solid #e5e5e5;}.gs_el_ph #gsc_md_iad #gsc_iads_res{margin:8px -16px 16px -16px;}.gs_el_ph #gsc_napb #gsc_iads_pp{margin-right:16px;}#gsc_iadb_hdr{display:table;table-layout:fixed;width:100%;}#gsc_iadb_hdr_cb,#gsc_iadb_hdr_instr{display:table-cell;vertical-align:middle;height:41px;}#gsc_iadb_hdr_cb{width:41px;}#gsc_iadb_hdr_cb:empty{width:0;}.gs_el_ph #gsc_iadb_hdr_cb:empty{width:16px;}#gsc_iadb_hdr_instr{font-size:16px;}.gs_el_ph #gsc_iadb_hdr_instr{padding-right:16px;}.gsc_oic{position:relative;}.gsc_oic_cb{font-weight:normal;border-top:1px solid #e5e5e5;border-bottom:1px solid #e5e5e5;background-color:#fcfcfc;padding-right:16px;}.gsc_oict{display:block;overflow:hidden;}.gsc_oict_name{display:block;font-size:16px;line-height:20px;word-wrap:break-word;}.gsc_oict_inf{display:block;float:right;margin-left:16px;white-space:nowrap;}.gsc_oict_all,.gsc_oict_prf{font-size:13px;text-transform:uppercase;line-height:20px;}.gsc_oict_all[data-a]{color:#1a0dab;cursor:pointer;}.gsc_oict_all[data-a]:hover{text-decoration:underline;}.gsc_oict_all[data-a]:active{color:#d14836;}.gsc_oict_prf{padding-left:8px;margin-left:8px;border-left:1px solid #e0e0e0;}.gsc_oict_prf:empty{display:none;}.gs_el_ph .gsc_oict_all,.gs_el_ph .gsc_oict_prf{float:right;clear:both;margin:0;padding:0;border:none;}.gs_el_ph .gsc_oict_prf{margin-top:2px;}.gsc_oic_res{margin:8px 0 12px 41px;}.gs_el_ph .gsc_oic_res{margin-right:16px;}.gsc_oic_res h4{font-size:13px;font-weight:normal;}.gsc_oic_dis .gsc_oic_name,.gsc_oic_dis .gsc_oic_all,.gsc_oic_dis .gsc_oic_prf{color:#777;}.gsc_oic_dis .gsc_oict_all[data-a]{color:#1a0dab;opacity:.66;}.gsc_oic_dis .gsc_oic_res{opacity:.5;}.gsc_iadb_art{border-top:1px solid #e5e5e5;overflow:hidden;}.gsc_iadb_art_cb{float:left;}.gsc_iadb_art_added{float:right;margin:12px;font-size:11px;text-transform:uppercase;color:#777;}.gs_el_ph .gsc_iadb_art_added{display:block;float:none;text-align:right;margin:8px 16px;}.gsc_iadb_art_added:empty{display:none;}.gsc_iadb_art_body{margin:12px 0 12px 41px;}.gs_el_ph .gsc_iadb_art_body{margin:12px 16px 12px 41px;}.gsc_iadb_art_body h3{font-size:13px;font-weight:normal;}.gsc_iadb_art_dis .gsc_iadb_art_body{opacity:.5;}#gsc_md_mopt,#gsc_md_cbyd,#gsc_md_cbym{width:600px;}.gs_el_ta #gsc_md_mopt,.gs_el_ta #gsc_md_cbyd,.gs_el_ta #gsc_md_cbym{width:500px;}.gs_el_ph #gsc_md_mopt,.gs_el_ph #gsc_md_cbyd,.gs_el_ph #gsc_md_cbym{width:100%;}.gsc_mob_art{vertical-align:top;padding:8px 0;}.gs_el_tc .gsc_mob_art>.gs_in_ra{margin-top:-8px;}.gsc_mob_cby{vertical-align:top;text-align:right;padding:8px 12px;position:relative;}.gsc_mob_ttl,.gsc_mob_pub{display:block;}.gsc_mob_pub{color:#666;}.gsc_mob_cbym{text-decoration:line-through}.gsc_mob_cbm{font-size:24px;position:absolute;padding:4px 0 0 4px;line-height:16px;}.gs_fsvg line{stroke:#222222}a:link .gs_fsvg{fill:#1a0dab;}a:link .gs_fsvg line{stroke:#1a0dab;}a:visited .gs_fsvg{fill:#660099;}a:visited .gs_fsvg line{stroke:#660099;}a:active .gs_fsvg{fill:#d14836;}a:active .gs_fsvg line{stroke:#d14836;}a .gs_fsvg{border-bottom:1px solid transparent;}a:hover .gs_fsvg,a:focus .gs_fsvg{border-bottom-color:inherit;}.gs_fsml{font-size:13px}.gs_fscp{font-variant:small-caps}.gsh_clim{display:table-row}.gsh_clil,.gsh_clic{display:table-cell;padding-bottom:8px}.gsh_clil{padding-right:8px;}.gsh_lla{list-style-type:lower-alpha}.gsh_lua{list-style-type:upper-alpha}.gsh_llr{list-style-type:lower-roman}.gsh_lur{list-style-type:upper-roman}.gsh_l>li{margin-left:32px;}.gsh_h3{font-size:inherit;font-weight:normal}.gsh_h3,.gsh_csp{margin:16px 0}.gsh_h3+.gsh_csp{margin-top:-8px}.gsh_ovln{text-decoration:overline}.gsh_small .gsh_l .gsh_csp{margin:8px 0}.gsh_small .gsh_csp:first-child,.gsh_small .gsh_h3:first-child{margin-top:0}.gsh_small .gsh_csp:last-child{margin-bottom:0}.gsh_dspfr{text-align:center}.gsh_dspfr svg{margin:8px 0}.gs_pp_tn,.gs_el_ta .gs_pp_mo_tn,.gs_el_ph .gs_pp_mo_tn{width:32px;height:32px;}.gs_pp_sm,.gs_el_ta .gs_pp_mo_sm,.gs_el_ph .gs_pp_mo_sm{width:56px;height:56px;}.gs_pp_nm,.gs_el_ta .gs_pp_mo_nm,.gs_el_ph .gs_pp_mo_nm{width:128px;height:128px;}.gs_ai_pho{float:left;}.gs_ai_t{margin-left:72px;}.gs_ai_pho_pst+.gs_ai_t{margin-left:48px;}.gs_ai_t.gs_ai_pss{margin-left:64px;}.gs_ai_pho_pst+.gs_ai_t.gs_ai_pss{margin-left:40px;}.gs_ai_name{font-size:17px;font-weight:normal;margin-bottom:4px;}.gs_ai_name a{padding:6px 0 4px 0;}.gs_ai_name.gs_ai_name_nlsb{font-size:15px;}.gs_ai_name.gs_ai_name_nlsb a:link,.gs_ai_name.gs_ai_name_nlsb a:visited{padding:7px 0 5px 0; color:#222;}.gs_ai_name.gs_ai_name_nlsb a:active{color:#d14836;}.gs_ai_int{margin-top:5px;}.gs_ai_eml:empty,.gs_ai_int:empty,.gs_ai_cby:empty{display:none;}.gs_ai_one_int{vertical-align:top;font-size:13px;margin-right:8px;white-space:nowrap;display:inline-block;max-width:200px;text-overflow:ellipsis;overflow:hidden;}.gs_el_tc a.gs_ai_one_int{padding:8px 0 5px 0;}.gs_el_ph .gs_ai_eml,.gs_el_ph .gs_ai_cby{margin-top:8px;}.gs_ai_ilnl .gs_ai_int,.gs_ai_ilnl .gs_ai_cby{margin-top:8px;color:#666;}.gs_ai.gs_ai_chpr{position:relative;}.gs_ai_chpr .gs_ai_t{margin-right:276px;}.gs_el_sm .gs_ai_chpr .gs_ai_t{margin-right:156px;}.gs_el_ph .gs_ai_chpr .gs_ai_t{margin-right:0;}.gs_ai_chpr .gs_ai_cby{position:absolute;top:4px;right:0;text-align:right;}.gs_el_sm .gs_ai_chpr .gs_ai_cby,.gs_el_ta .gs_ai_chpr .gs_ai_cby{width:132px;word-wrap:break-word;}.gs_el_ph .gs_ai_chpr .gs_ai_cby{text-align:left;position:static;width:auto;}#gsc_bdy{position:relative;max-width:1200px;margin:0 auto;}.gs_el_ph #gsc_bdy,.gs_el_ta #gsc_bdy{display:flex;flex-flow:column;}.gsc_lcl{position:relative;margin:0 350px 0 0;order:3;}.gs_el_sm .gsc_lcl{margin-right:334px;}.gs_el_ta .gsc_lcl,.gs_el_ph .gsc_lcl{margin:0;}#gsc_prf_t_wrp{position:relative;order:2;overflow:hidden;}.gs_el_tc #gsc_prf_t_wrp:after{display:block;content:"";position:absolute;z-index:100;top:0;right:0;width:12px;height:100%;background-image:linear-gradient(to right,rgba(247,247,247,0),rgba(247,247,247,1) 80%);}#gsc_prf_t{width:100%;background-color:#f5f5f5;display:none;white-space:nowrap;overflow-x:auto;padding:0 4px;}.gs_el_ta #gsc_prf_t,.gs_el_ph #gsc_prf_t{display:block;}#gsc_prf_t:after{content:"\00A0";padding:0 4px;}.gsc_prf_tab,.gsc_prf_tab:link{font-size:13px;text-transform:uppercase;padding:13px 12px;display:inline-block;color:#666;cursor:pointer;}.gsc_prf_tab:hover{color:#000;text-decoration:none}.gsc_prf_tab:active{color:#4d90fe;}.gsc_prf_tab[aria-selected="true"]{border-bottom:2px solid #4d90fe;color:#0461f9;cursor:default;}.gs_el_ta #gsc_art,.gs_el_ph #gsc_art,.gs_el_ta #gsc_rsb_cit,.gs_el_ph #gsc_rsb_cit,.gs_el_ta #gsc_rsb_mnd,.gs_el_ph #gsc_rsb_mnd,.gs_el_ta #gsc_rsb_awd,.gs_el_ph #gsc_rsb_awd,.gs_el_ta #gsc_rsb_co,.gs_el_ph #gsc_rsb_co{display:none;}#gsc_bdy[data-tab="gsc_prf_t-art"] #gsc_art,#gsc_bdy[data-tab="gsc_prf_t-cit"] #gsc_rsb_cit,#gsc_bdy[data-tab="gsc_prf_t-mnd"] #gsc_rsb_mnd,#gsc_bdy[data-tab="gsc_prf_t-awd"] #gsc_rsb_awd,#gsc_bdy[data-tab="gsc_prf_t-ath"] #gsc_rsb_co{display:block;}.gsc_rsb{float:right;width:317px;order:4;border-left:1px solid #eee;margin-top:32px;}.gs_el_sm .gsc_rsb{margin-top:16px;}.gs_el_ph .gsc_rsb,.gs_el_ta .gsc_rsb{float:none;width:auto;border:none;margin:0;}.gsc_rsb_s{margin:0 0 48px 16px;position:relative;}.gs_el_sm .gsc_rsb_s{margin:0 0 32px 16px;}.gs_el_ph .gsc_rsb_s,.gs_el_ta .gsc_rsb_s{margin:0;}.gsc_rsb_s:last-child{margin-bottom:0;}.gsc_rsb_header{padding:8px 8px 12px 8px;border-bottom:1px solid #e5e5e5;font-weight:normal;font-size:15px;}.gs_el_sm .gsc_rsb_header{padding:4px 8px 9px 8px;}.gs_el_ph .gsc_rsb_header,.gs_el_ta .gsc_rsb_header{display:none;}.gsc_rsb_action{position:absolute;top:-3px;right:-2px;}.gs_el_sm .gsc_rsb_action{top:-8px;}.gsc_rsb_tap{display:block;position:absolute;right:2px;top:12px;opacity:.5;z-index:1;}.gs_el_ta .gsc_rsb_tap,.gs_el_ph .gsc_rsb_tap{top:24px;right:10px;}.gsc_rsb_hm{border-bottom:1px solid #e5e5e5;padding:3px 6px;}#gsc_rsb_gpl{display:block;margin-top:3px;padding:6px 16px;line-height:15px;color:#0461f9;border:1px solid #4d90fe;border-radius:2px;text-align:center;text-transform:uppercase;}.gs_el_sm #gsc_rsb_gpl{margin-top:0;}.gs_el_ta #gsc_rsb_gpl,.gs_el_ph #gsc_rsb_gpl{display:none;}#gsc_rsb_st{width:100%;}.gsc_rsb_std{text-align:right;padding-right:8px;}.gs_el_ta .gsc_rsb_std,.gs_el_ph .gsc_rsb_std{padding-right:16px;}.gsc_rsb_sc1{text-align:left;padding:2px 8px;}.gs_el_sm .gsc_rsb_sc1{padding:0 8px;}.gs_el_ta .gsc_rsb_sc1,.gs_el_ph .gsc_rsb_sc1{padding:4px 16px;}.gsc_rsb_sth{font-weight:normal;padding:8px 8px 8px 0;border-bottom:1px solid #e5e5e5;text-align:right;}.gs_el_sm .gsc_rsb_sth{padding:4px 8px 4px 0;}.gs_el_ta .gsc_rsb_sth,.gs_el_ph .gsc_rsb_sth{padding:16px 16px 16px 0;}#gsc_rsb_st tbody:before,#gsc_rsb_st tbody:after{content:'';display:block;height:8px;}.gs_el_sm #gsc_rsb_st tbody:before,.gs_el_sm #gsc_rsb_st tbody:after{height:4px;}.gs_el_ph #gsc_hist_opn,.gs_el_ta #gsc_hist_opn{display:none;}.gsc_rsb_f{max-width:118px;word-wrap:break-word;white-space:normal;}.gs_el_ta .gsc_rsb_f{max-width:none;}.gsc_rsb_f:link,.gsc_rsb_f:visited{color:#222;}.gsc_rsb_m_na{color:#dd4b39;}.gsc_rsb_m_a{color:#006621;float:right;position:relative;}.gsc_rsb_m_bar{width:100%;height:4px;margin:8px 0 8px 0;background:#006621;}.gsc_rsb_m_bar_na{background:#dd4b39;width:100%;height:100%;z-index:1;}.gsc_rsb_m{padding:8px;}.gs_el_ta .gsc_rsb_m,.gs_el_ph .gsc_rsb_m{padding:8px 16px;}.gsc_rsb_m_desc{padding-top:16px;color:#777;}.gsc_rsb_m_s{font-size:24px;position:absolute;line-height:0.3;}#gsc_lwp_mndt_lnk{text-transform:uppercase;margin-left:16px;margin-right:-9px;text-align:right;font-size:13px;padding:12px 9px;border-radius:3px;}#gsc_lwp_mndt_lnk:hover,#gsc_lwp_mndt_lnk:active,#gsc_lwp_mndt_lnk:visited{text-decoration:none;color:#1a0dab;}#gsc_lwp_mndt_lnk:hover{background-color:rgba(0,0,0,.05);}#gsc_lwp_mndt_lnk:active{background-color:rgba(0,0,0,.1);}.gsc_rsb_m_title{padding-bottom:12px;}.gsc_rsb_m_header{display:flex;align-items:flex-end;justify-content:space-between;padding:0 8px;}.gs_el_sm .gsc_rsb_m_header{padding:0 8px;}.gsc_rsb_hmv{text-align:center;padding-top:16px;}.gsc_rsb_a{list-style:none;}.gsc_rsb_a>li{position:relative;}.gs_el_ta .gsc_rsb_a>li,.gs_el_ph .gsc_rsb_a>li{border-bottom:1px solid #e5e5e5;}.gsc_rsb_a>li:first-child{margin-top:8px;}.gsc_rsb_a_pht{float:left;width:32px;height:32px;}.gsc_rsb_a_desc{margin:0 33px 0 48px;min-height:32px;display:block;}.gs_el_ph .gsc_rsb_a_desc,.gs_el_ta .gsc_rsb_a_desc{margin:0 33px 0 64px;min-height:56px;}.gsc_rsb_a_desc a{color:#222;}.gsc_rsb_a_ext{display:block;color:#777;font-size:13px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;}.gs_el_ph .gsc_rsb_a_ext,.gs_el_ta .gsc_rsb_a_ext{white-space:normal;}.gsc_rsb_a_ext2{display:none;}.gs_el_ph .gsc_rsb_a_ext2,.gs_el_ta .gsc_rsb_a_ext2{display:block;}.gsc_rsb_aa{display:block;padding:8px;line-height:normal;cursor:pointer;}.gs_el_ph .gsc_rsb_aa,.gs_el_ta .gsc_rsb_aa{font-size:17px;padding:12px 16px;}.gsc_rsb_aa:hover,.gsc_rsb_aa:active{text-decoration:none;background:#f1f1f1;}.gsc_rsb_aa a:hover{text-decoration:none;}#gsc_prf_w{order:1;padding:32px 0;overflow:hidden;}.gs_el_sm #gsc_prf_w{padding:16px 0;}#gsc_prf_pu{float:left;width:128px;height:128px;text-align:center;}.gs_el_ph #gsc_prf_pu{float:none;width:100%;margin:0 0 8px 0;}#gsc_prf_pua{line-height:0;width:128px;height:128px;}.gs_el_ph #gsc_prf_pua{margin:0 auto;}#gsc_prf_pufi{width:0;height:0;overflow:hidden;}.gsc_prf_pufo #gsc_prf_pufi{width:auto;height:auto;overflow:visible;position:relative;z-index:10;}.gsc_prf_pufo #gsc_prf_pufi2{display:inline-block;background:#fcfcfc;padding:8px 8px 8px 0;}.gsc_prf_puic{position:absolute;bottom:0;width:100%;padding:8px 0;background-color:#000;opacity:.6;}.gsc_prf_pel{cursor:pointer;}#gsc_prf_i{margin:0 16px 0 160px;}.gs_el_sm #gsc_prf_i{margin:0 16px 0 144px;}.gs_el_ph #gsc_prf_i{margin:0 16px;text-align:center;}#gsc_prf_btne{vertical-align:top;margin:-9px 4px;}.gs_el_ph #gsc_prf_btne{position:absolute;top:60px;right:8px;margin:0;}#gsc_prf_btnf{float:right;margin:3px 0 16px 16px;}.gs_el_sm #gsc_prf_btnf{margin-top:0;}.gs_el_ph #gsc_prf_btnf{float:none;margin:0;position:absolute;top:8px;right:8px;border-radius:50%;}#gsc_prf_btnf .gs_lbl{padding:0 4px;}#gsc_prf_in{font-size:24px;line-height:24px;padding:3px 0 12px 0;word-wrap:break-word;}.gs_el_sm #gsc_prf_in{font-size:22px;padding:3px 0 8px 0;}.gs_el_ph #gsc_prf_in{font-size:20px;padding:0 0 2px 0;}.gsc_prf_il{font-size:15px;line-height:18px;padding:1px 0;}.gs_el_ph .gsc_prf_il{font-size:13px;line-height:16px;}.gsc_prf_ila:link,.gsc_prf_ila:visited{text-decoration:underline;color:#222;}#gsc_prf_int{margin-top:5px;}#gsc_prf_int:empty{display:none;}.gsc_prf_inta{margin-right:16px;white-space:nowrap;max-width:200px;text-overflow:ellipsis;overflow:hidden;vertical-align:top;}.gsc_prf_inta:last-child{margin:0}.gs_el_tc .gsc_prf_ila,.gs_el_tc .gsc_prf_inta{padding:8px 0 5px 0;}.gsc_md_pro_tt,.gsc_md_pro_ch #gsc_md_pro_lgtm,#gsc_md_pro_save{display:none;}.gsc_md_pro_ed #gsc_md_pro_ted,.gsc_md_pro_aa #gsc_md_pro_taa,.gsc_md_pro_ra #gsc_md_pro_tra,.gsc_md_pro_an #gsc_md_pro_tan,.gsc_md_pro_ai #gsc_md_pro_tai,.gsc_md_pro_ch #gsc_md_pro_save{display:inline-block;}.gsc_md_pro_el{color:#777;}.gsc_md_pro_ev{padding:4px 0 16px 0;}#gsc_dd_add-d,#gsc_dd_exp-d,#gsc_dd_sort-d,#gsc_dd_mor-d{top:42px;}#gsc_dd_add-d,#gsc_dd_mor-d,#gsc_dd_sort-d{white-space:normal;word-wrap:break-word;width:208px;width:-webkit-max-content;width:max-content;min-width:100px;max-width:208px;}.gs_el_ph #gsc_dd_add-d{left:-9px;}.gs_el_ph #gsc_dd_exp-d{left:auto;right:12px;}.gs_el_ph #gsc_dd_mor-d{left:-58px;}.gs_el_ph #gsc_dd_sort-d{left:10px;}.gs_el_ph #gsc_dd_sort-r{margin-left:-10px;}.gsc_dd_sec,#gsc_dd_exp-d{padding:8px 0;}.gs_el_tc .gsc_dd_sec,.gs_el_tc #gsc_dd_exp-d{padding:4px 0 8px 0;}.gsc_dd_sep{border-top:1px solid #ebebeb;}#gsc_dd_mor-s .gsc_dd_mor-sel,#gsc_dd_sort-s .gsc_dd_sort-sel{color:#dd4b39;}#gsc_dd_mor-p{padding:14px 44px 14px 16px;color:#777;}.gs_el_tc #gsc_dd_mor-p{padding:18px 44px 18px 16px;}.gsc_art_sel #gsc_dd_add-r,.gsc_art_sel #gsc_dd_mor-r,#gsc_btn_mer,#gsc_btn_del,#gsc_dd_exp-r{display:none;}#gsc_dd_mor-r,.gsc_art_sel #gsc_btn_mer,.gsc_art_sel #gsc_btn_del,.gsc_art_sel #gsc_dd_exp-r{display:inline-block;}html:not(.gs_el_ph) #gsc_dd_sort-r{display:none;}#gsc_lwp{margin:24px 0;text-align:center;}.gs_el_sm #gsc_lwp{margin:16px 0;}#gsc_bpf{display:inline-block;verticle-align:middle;}#gsc_a_nn{display:inline-block;vertical-align:middle;padding-right:16px;font-size:13px;}.gs_el_ph #gsc_a_nn{display:none;}@media print{#gs_top #gs_md_s,#gs_top #gs_md_w,#gs_top #gs_hdr,#gs_top #gs_hdr_drs,#gs_top #gs_hdr_drw,#gs_top #gs_ftr,#gs_top #gsc_nag,#gs_top #gsc_prf_nbar_btns,#gs_top #gsc_prf_btne,#gs_top #gsc_prf_btnf,#gs_top #gsc_prf_ivh,#gs_top #gsc_prf_puf,#gs_top #gsc_rsb_co,#gs_top #gsc_bdy #gsc_rsb_co,#gs_top .gsc_g_hist_wrp,#gs_top #gsc_prf_t_wrp,#gs_top .gsc_rsb_header,#gs_top .gsc_a_tb,#gs_top .gsc_a_x,#gs_top #gsc_lwp,#gs_top .gsc_prf_puic,#gs_top #gsc_dd_add-r,#gs_top #gsc_dd_mor-r,#gs_top #gsc_dd_sort-r{display:none;}#gs_top,#gs_top #gsc_bdy,#gs_top #gsc_prf_w,#gs_top #gsc_prf,#gs_top #gsc_prf_pu,#gs_top #gsc_prf_pua,#gs_top #gsc_prf_i,#gs_top .gsc_rsb_s,#gs_top .gsc_lcl,#gs_top .gsc_rsb,#gs_top #gsc_a_tw,#gs_top #gsc_a_t,#gs_top .gsc_prf_il,#gs_top .gsc_prf_ila,#gs_top .gsc_prf_inta,#gs_top #gsc_rsb_st{background:none;border:none;padding:0;margin:0;height:auto;width:auto;min-width:0;max-width:none;float:none;display:block;position:static;color:black;font-weight:normal;font-size:12pt;text-decoration:none;}#gs_top .gsc_a_ac,#gs_top .gsc_a_a,#gs_top #gsc_a_ca,#gs_top .gsc_a_at,#gs_top .gsc_rsb_sc1,#gs_top .gsc_rsb_sth,#gs_top .gsc_rsb_std,#gs_top #gsc_bdy .gsc_a_x,#gs_top #gsc_bdy .gsc_a_t,#gs_top #gsc_bdy .gsc_a_c,#gs_top #gsc_bdy .gsc_a_y,#gs_top #gsc_a_trh,#gs_top .gsc_a_m,#gs_top .gsc_a_am{color:black;font-weight:normal;font-size:12pt;padding:0;margin:0;background:none;border:none;}#gs_top #gsc_a_trh,#gs_top #gsc_a_trh th{height:0;}#gs_top #gsc_a_ta,#gs_top #gsc_a_ca,#gs_top #gsc_a_ha,#gs_top .gsc_a_a{font-size:11pt;}#gs_top .gsc_a_ac{font-size:10pt}#gs_top #gsc_prf_pu{width:80pt;height:auto;float:left;margin:0 7pt 7pt 0;}#gs_top #gsc_prf_pua{left:auto;transform:none;border-radius:0;}#gs_top #gsc_prf_pua>img{position:static;}#gs_top #gsc_prf_i{margin:0 7pt 7pt 87pt;text-align:left;}#gs_top #gsc_prf_in{font-size:18pt;line-height:18pt;padding:0 0 4pt 0;}#gs_top .gsc_prf_il{padding:2pt 0;}#gs_top #gsc_prf_w{float:left;width:64%;}#gs_top .gsc_rsb{float:right;width:35%;}#gs_top #gsc_art{clear:both;}#gs_top #gsc_rsb_st{display:table;width:100%;max-width:none;margin-top:3pt;}#gs_top .gsc_rsb_sc1,#gs_top .gsc_rsb_sth,#gs_top .gsc_rsb_std{font-size:10pt;}#gs_top th.gsc_rsb_sc1,#gs_top .gsc_rsb_sth{border-bottom:1pt solid #ccc;}#gs_top .gsc_rsb_f{max-width:60pt;}#gs_top .gsc_rsb_sth{padding-left:14pt;}#gs_top #gsc_bdy .gsc_a_x,#gs_top #gsc_bdy .gsc_a_t,#gs_top #gsc_bdy .gsc_a_c,#gs_top #gsc_bdy .gsc_a_y,#gs_top #gsc_a_trh{padding:6pt 0;}#gs_top #gsc_a_trh{border-bottom:1pt solid #ccc;}#gs_top #gsc_a_ca{display:block;width:auto;}#gs_top #gsc_a_ta{display:inline-block;vertical-align:middle;margin-right:12pt;}#gs_top .gsc_a_h{display:inline;font-size:10pt;}#gs_top .gsc_a_at{color:#008;}#gs_top .gsc_a_m,#gs_top .gsc_a_am{display:inline;position:absolute;}#gs_top .gsc_a_am{padding: 11pt 0 0 8pt;}#gs_top .gsc_a_t .gs_gray{color:black;font-size:10pt;}}.gsc_lwpds_frm{position:relative;height:29px;}.gsc_lwpds_tsiw{position:absolute;top:0;left:0;right:38px;}.gsc_lwpds_tsiw input{border-radius:3px 0 0 3px;}.gsc_lwpds_tsbw{position:absolute;top:0;right:0;}.gsc_lwpds_tsbw button{border-radius:0 3px 3px 0;}.gsc_pgn{text-align:right;font-weight:bold;line-height:29px;}.gsc_pgn_ppn{margin:0 8px;}.gsc_ccb_ck{padding:11px 10px 9px 10px;}.gsc_ccb_svg{stroke:#666;stroke-width:2px;fill:#fff;width:21px;height:21px;vertical-align:top;}.gsc_ccb_lim .gsc_ccb_svg,.gsc_ccb_dis .gsc_ccb_svg{fill:#e2e2e2;stroke:#fff;}.gsc_ccb_lim .gsc_ccb_svg>circle,.gsc_ccb_dis .gsc_ccb_svg>circle{stroke:#e2e2e2;}.gsc_ccb_on .gsc_ccb_svg{fill:#4d90fe;stroke:#fff;}.gsc_ccb_on .gsc_ccb_svg>circle{stroke:#4d90fe;}.gsc_ccb_del:active .gsc_ccb_svg>circle,.gsc_ccb_add:active .gsc_ccb_svg>circle{fill:#2f6de1;}#gsc_md_cod{width:800px;max-width:94%;}.gs_el_ph #gsc_md_cod{width:100%;max-width:100%;}#gsc_md_cod .gs_md_prg{min-height:400px;}.gsc_codb_instr{font-size:16px;margin:1em 0;}#gsc_cods_res{position:relative;margin-bottom:24px;min-height:80px;border-bottom:1px solid #e5e5e5;}.gs_el_ph #gsc_cods_res{margin-bottom:16px;}.gsc_cods_hide,.gsc_cod_sugg #gsc_cod_tedit,.gsc_cod_sugg #gsc_cods_frm,.gsc_cod_sugg #gsc_cods_pp,.gsc_cod_lc #gsc_cod_tadd,.gsc_cod_changed #gsc_cod_tedit,.gsc_cod_changed #gsc_cod_tadd,.gsc_cod_lim #gsc_cod_tedit,.gsc_cod_lim #gsc_cod_tadd{display:none;}#gsc_cods_frm{margin:0 0 24px 0;}.gs_el_ph #gsc_cods_frm{margin:0 0 16px 0;}.gsc_ucoar{padding:24px 0;border-bottom:1px solid #eee;}.gs_el_ph .gsc_ucoar{padding:16px 0px;}.gsc_ucoar:first-child{padding-top:0;}.gsc_ucoar:last-child{border-bottom:none;}.gsc_ucoar_cb{float:right;margin-top:-8px;}#gsc_cod_trev{display:none;color:#666;pointer-events:none;}.gsc_cod_changed #gsc_cod_trev,.gsc_cod_lim #gsc_cod_trev{display:inline-block;}.gsc_cod_changed #gsc_cod_trev{color:#1a0dab;pointer-events:auto;}.gsc_fol_cr{margin:0 0 8px 0;}.gs_el_tc .gsc_fol_cr{margin:0;}.gs_el_tc .gsc_fol_cr:first-child{margin-top:-8px;}#gsc_fol_ml{display:block;color:#777;padding:12px 0 4px 0;}</style><script>!function(GSP){/*

 Copyright The Closure Library Authors.
 SPDX-License-Identifier: Apache-2.0
*/
var aa="function"==typeof Object.create?Object.create:function(a){var b=function(){};b.prototype=a;return new b},ba;if("function"==typeof Object.setPrototypeOf)ba=Object.setPrototypeOf;else{var da;a:{var ea={a:!0},fa={};try{fa.__proto__=ea;da=fa.a;break a}catch(a){}da=!1}ba=da?function(a,b){a.__proto__=b;if(a.__proto__!==b)throw new TypeError(a+" is not extensible");return a}:null}
var ha=ba,ia=function(a,b){a.prototype=aa(b.prototype);a.prototype.constructor=a;if(ha)ha(a,b);else for(var c in b)if("prototype"!=c)if(Object.defineProperties){var d=Object.getOwnPropertyDescriptor(b,c);d&&Object.defineProperty(a,c,d)}else a[c]=b[c];a.na=b.prototype},ja=function(){},ka=function(a,b){var c=Array.prototype.slice.call(arguments,1);return function(){var d=c.slice();d.push.apply(d,arguments);return a.apply(this,d)}};var g=function(){this.o=this.o;this.F=this.F};g.prototype.o=!1;g.prototype.isDisposed=function(){return this.o};g.prototype.T=function(){this.o||(this.o=!0,this.H())};g.prototype.H=function(){if(this.F)for(;this.F.length;)this.F.shift()()};function la(a){var b=[],c=0,d;for(d in a)b[c++]=d;return b};function l(a,b){a.classList.add(b)}function n(a,b){a.classList.remove(b)}function p(a,b){return a.classList?a.classList.contains(b):!1}function q(a,b,c){c=void 0!==c?c:!p(a,b);(c?l:n)(a,b)};function r(a){return 0<=(navigator.userAgent||"").indexOf(a)}var ma=r("iPhone")||r("iPad")||r("iPod"),na=r("iPhone")||r("Android")&&r("Mobile");function oa(){if(void 0===b){var a=window.screen;a={width:window.innerWidth,height:window.innerHeight,ma:a.width,la:a.height}}else a=b;var b=a;a=b.width;var c=b.height,d=b.ma;b=b.la;var e=4;if(600>a||48E4>d*b||na)e=1;else if(982>a)e=2;else if(1136>a||590>c)e=3;return e}var pa,qa=/[?&]tc=([01])/.exec(location.search||"");
pa=qa?0<+qa[1]:r("Android")?!0:window.matchMedia&&window.matchMedia("(pointer)").matches?window.matchMedia("(pointer:coarse)").matches:!r("Firefox")||r("Mobile")||r("Tablet")?ma||"ontouchstart"in window||0<(navigator.msMaxTouchPoints||0):!1;function ra(){if(void 0==sa){sa=!1;try{var a=Object.defineProperty({},"passive",{get:function(){sa=!0}});window.addEventListener("testPassive",ja,a);window.removeEventListener("testPassive",ja,a)}catch(b){}}return sa}var sa;var ta=function(a){this.Y=a},ua=new ta("INPUT"),va=new ta("TABLE");function t(a){return document.getElementById(a)}function x(a){return a.id||(a.id="gs_id"+wa++)}function xa(a){a=(void 0===a?null:a)||document.body;return"rtl"==(a?window.getComputedStyle(a,null):null).direction}
function ya(a){var b=[];a=a.elements;for(var c=a.length,d=0;d<c;d++){var e=a[d],f=encodeURIComponent(e.name||""),h=e.type;!f||e.disabled||!("checkbox"!=h&&"radio"!=h||e.checked)||b.push(f+"="+encodeURIComponent(e.value||""))}return b.join("&")}function za(a,b){var c=a.elements[b];c||(c=document.createElement(ua.Y),c.type="hidden",c.name=b,a.appendChild(c));return c}function Aa(a){t("gsc_md_cbyd_c").href=a&&a.match(Ba)?a:"javascript:void(0)"}function Ca(a){a.match(Ba)&&(window.location.href=a)}
var wa=100,Da=/\S+/g,Ba=/^(?:https?:|[^:/?#]*(?:[/?#]|$))/i,Ea=/^(?:#|\/[a-z0-9_-]*(?:[?].*)?$)/i;function y(a){return a.hasOwnProperty("gs_uid")?a.gs_uid:a.gs_uid=++Fa}var Fa=0;var z=function(){this.i=[];this.A={};this.O=this.v=0};z.prototype.add=function(a){var b=y(a);this.A[b]||(this.i.push(a),this.A[b]=this.i.length,++this.v)};z.prototype.remove=function(a){a=y(a);var b=this.A[a];b&&(this.i[b-1]=null,delete this.A[a],2*--this.v<this.i.length&&!this.O&&Ga(this))};z.prototype.notify=function(a){var b=this.i;try{++this.O;for(var c=0;c<b.length;c++){var d=b[c];d&&d.apply(null,arguments)}}finally{!--this.O&&2*this.v<b.length&&Ga(this)}};
var Ga=function(a){var b=a.i,c=b.length;a=a.A;for(var d=0,e=0;e<c;e++){var f=b[e];f&&(b[d]=f,a[y(f)]=++d)}b.length=d};function B(a,b,c,d,e){Ha(a,b,c,void 0===d?!1:d,void 0===e?!1:e,Ia)}function C(a,b,c,d){Ha(a,b,c,void 0===d?!1:d,!1,Ja)}function Ka(a,b,c,d){function e(h){C(f,a,e,c);b(h)}var f=document;c=void 0===c?!1:c;B(f,a,e,c,void 0===d?!1:d)}function D(a){La?La.add(a):a()}var Ma=window.requestAnimationFrame?function(a){window.requestAnimationFrame(a)}:function(a){setTimeout(a,33)};function Na(a){a.stopPropagation();a.preventDefault()}
function Oa(a){return(a.ctrlKey?1:0)|(a.altKey?2:0)|(a.metaKey?4:0)|(a.shiftKey?8:0)}function Ia(a,b,c,d,e){var f=a.addEventListener;e=e&&ra();f.call(a,b,c,e?{passive:e,capture:d}:d)}function Ja(a,b,c,d){a.removeEventListener(b,c,d)}function Ha(a,b,c,d,e,f){if("string"===typeof b)f(a,b,c,d,e);else for(var h=b.length,k=0;k<h;k++)f(a,b[k],c,d,e)}function Pa(){La.notify();La=null}function Qa(){"complete"==document.readyState&&(C(document,"readystatechange",Qa),Pa())}
var La,Ra=!!document.attachEvent,Sa=document.readyState;if(Ra?"complete"!=Sa:"loading"==Sa)La=new z,Ra?B(document,"readystatechange",Qa):Ka("DOMContentLoaded",Pa);function Ta(){Ka(["mousedown","touchstart"],function(){q(document.documentElement,"gs_pfcs",!0);B(document,"keydown",Ua,!0)},!0,!0)}function Ua(a){9==a.keyCode&&(q(document.documentElement,"gs_pfcs",!1),C(document,"keydown",Ua,!0),Ta())}Ta();function Va(a,b,c,d,e){var f=t(a);Wa(f,function(){l(f,"gs_vis");b&&b()},function(){n(f,"gs_vis");c&&c()},d,e)}function Wa(a,b,c,d,e){var f=x(a);if(!E[f]){var h=document.activeElement;Xa(Ya(a),!0);b&&b();G.push(function(k){delete E[f];try{k||(e||h).focus()}catch(m){}c&&c()});E[f]=G.length;h&&a.contains(h)||setTimeout(function(){var k=d,m=k&&"text"==k.type;if(!k||m&&pa)k=a;try{k.focus(),m&&(k.value=k.value)}catch(w){}},0)}}function H(a){Xa((E[a]||1E6)-1,!1)}
function Za(a){a=void 0===a?!1:a;G.pop()(a)}function Xa(a,b){for(b=void 0===b?!1:b;G.length>a;)Za(b||G.length>a+1)}function Ya(a){for(var b=0;a&&!(b=E[a.id]||0);)a=a.parentNode;return b}var G=[],E={};B(document,"click",function(a){var b=G.length;b&&!Oa(a)&&b>Ya(a.target)&&Za(!0)});B(document,"keydown",function(a){27==a.keyCode&&!Oa(a)&&G.length&&Za()});
B(document,"focus",function(a){var b=G.length;if(b)for(var c=Ya(a.target);c<b;){var d="",e;for(e in E)if(E[e]==b){d=e;break}a:{d=(t(d).getAttribute("data-wfc")||"").match(Da)||[];for(var f=0;f<d.length;f++){var h=t(d[f]);if(h&&h.offsetWidth){d=h;break a}}d=void 0}if(d){Na(a);d.focus();break}else Za(!0),--b}},!0);var $a={},ab={},bb;try{bb=window.sessionStorage}catch(a){};function J(a){return"object"==typeof a?a:null}function cb(a,b){b=db(b);a=eb(a);a=fb(a)||"#";gb=J(b);hb?window.history.pushState(b,"",a):window.location.assign(a)}function ib(a,b){b=db(b);a=eb(a);a=fb(a)||"#";gb=J(b);hb?window.history.replaceState(b,"",a):window.location.replace(a)}function fb(a){var b=[],c;for(c in a)b.push(encodeURIComponent(c)+"="+encodeURIComponent(a[c]));return(a=b.sort().join("&"))?"#"+a:""}
function jb(a){var b={};a=a.split("&");for(var c=0;c<a.length;c++){var d=a[c],e=d.indexOf("=");if(e+1){var f=d.substr(0,e);d=d.substr(e+1)}else f=d,d="";f&&(b[decodeURIComponent(f)]=decodeURIComponent(d))}return b}function kb(a){var b=a.indexOf("#")+1;return jb(b?a.substr(b):"")}function lb(a){var b=a.indexOf("?")+1;a=b?a.substr(b):"";b=a.indexOf("#");return jb(b+1?a.substr(0,b):a)}function mb(a,b){for(var c in b){var d=b[c];void 0!==d?a[c]=d:delete a[c]}}
function eb(a){var b=kb(window.location.hash);mb(b,a);return b}function db(a){var b=gb||J(window.history.state),c={},d;for(d in b)c[d]=b[d];mb(c,a);return c}function nb(){setTimeout(function(){if(!ob){var a=window.history.state;ob=!0;gb=J(a);rb.notify()}sb=!1},0)}var rb=new z,gb,ob=!1,sb=!0,hb="pushState"in window.history,tb;
if("undefined"==typeof GSP)tb=!1;else{var ub=.001*Date.now(),vb=GSP.eventId,wb=!1,K,xb=bb;if(!("nh"in $a)){var yb=xb&&xb.getItem("nh"),zb;if(yb)try{zb=JSON.parse(yb)}catch(a){}ab.nh=zb}K=ab.nh;K instanceof Array||(K=[]);for(var Ab=K.length,Bb=0,Cb=0;Cb<Ab;Cb++){var Db=K[Cb];if(Db instanceof Array&&2==Db.length){var Eb=Db[1]==vb;wb=wb||Eb;10>=Ab-Cb&&+Db[0]>ub-86400&&!Eb&&(K[Bb++]=Db)}}K.length=Bb;K.push([ub,vb]);var Fb=K,Gb=bb;ab.nh=Fb;try{Gb&&Gb.setItem("nh",JSON.stringify(Fb))}catch(a){}tb=wb}
var Hb=tb;"onpageshow"in window?B(window,"pageshow",nb):D(nb);B(window,hb?"popstate":"hashchange",function(a){"loading"!=document.readyState&&(a=a.state,ob=!0,gb=J(a),rb.notify())});function Ib(){Jb&&(C(t("gs_alrt_l"),"click",Jb),Jb=void 0)}function Kb(){var a=Lb();l(a,"gs_anm");l(a,"gs_vis");B(document,"click",Mb);clearTimeout(Nb);Nb=setTimeout(Mb,4E3);++Ob;setTimeout(Pb,0)}function Mb(){Ob||(C(document,"click",Mb),clearTimeout(Nb),Nb=void 0,Ib(),n(Lb(),"gs_vis"))}function Lb(){return t("gs_alrt")}function Pb(){Ob=0}var Nb,Ob=0,Jb;D(function(){var a=t("gs_alrt_m");a&&(a.innerHTML&&!Hb&&Kb(),B(window,"pagehide",function(){Ob=0;Mb();n(Lb(),"gs_anm")}))});function Qb(a,b,c){var d=new XMLHttpRequest;d.onreadystatechange=function(){if(4==d.readyState){var e=d.status,f=d.responseText,h=d.responseURL,k=window.location,m=k.protocol;k="//"+k.host+"/";h&&h.indexOf(m+k)&&h.indexOf("https:"+k)&&(e=0,f="");c(e,f)}};d.open(b?"POST":"GET",a,!0);d.setRequestHeader("X-Requested-With","XHR");b&&d.setRequestHeader("Content-Type","application/x-www-form-urlencoded");b?d.send(b):d.send();return d}function Rb(a){a&&(a.onreadystatechange=ja,a.abort())};var Sb=function(a,b,c){this.type=a;this.currentTarget=this.target=b;this.g=void 0===c?null:c;this.P=!1};Sb.prototype.stopPropagation=function(){this.g&&this.g.stopPropagation();this.P=!0};var L=function(a){a.g&&Na(a.g);a.P=!0};var M=function(a,b){this.R=a;this.ka=b},Tb=function(a,b,c){this.R=a;this.types=b;this.listener=c};function Ub(a,b){var c=b.length;if(c){var d=y(a),e=Vb[d];if(!e){e=Vb[d]=[];d=Wb(b[0].R);for(var f in d){var h=Xb[f];h||(h=Xb[f]=Object.create(null));for(var k in d[f]){var m=h[k];m||(m=h[k]=[]);m.push(a)}}Yb(a,e,b[0],Zb);for(f=1;f<c;f++)Yb(a,e,b[f],$b)}}}function O(a,b,c){ac(new Sb(a,b,void 0===c?null:c))}
function P(a,b,c){var d=bc;"string"===typeof b&&(cc[0]=b,b=cc);var e=b.length;a=Wb(a);for(var f in a)for(var h in a[f])for(var k=0;k<e;k++)d(f,h,b[k],c)}function Wb(a){"string"===typeof a&&(dc[0]=a,a=dc);for(var b=a.length,c=Object.create(null),d=0;d<b;d++){var e=a[d],f=e.charAt(0),h=e.substr(1);if("#"!=f&&"."!=f||!h)throw Error("bad selector: "+e);(e=c[f])||(e=c[f]=Object.create(null));e[h]=!0}return c}
function bc(a,b,c,d){var e=ec[c];e||("touchstart"!=c&&"mouseover"!=c&&"mouseout"!=c&&B(document,c,fc,"focus"==c||"blur"==c),e=ec[c]=Object.create(null));(c=e[a])||(c=e[a]=Object.create(null));(a=c[b])||(a=c[b]=new z);a.add(d)}function fc(a){var b=a.target;b&&3==b.nodeType&&(b=b.parentNode);ac(new Sb(a.type,b,a))}
function ac(a){for(var b=a.target;b&&b!=document&&!b.disabled&&!p(b,"gs_dis");){a.currentTarget=b;var c=b.id;if(c&&!gc("#",c,a))break;c=b.classList||[];for(var d=c.length,e=0;e<d;e++)if(!gc(".",c[e],a))return;b=b.parentNode}}function gc(a,b,c){var d=ec[c.type];(b=(a=d&&d[a])&&a[b])&&b.notify(c);return!c.P}function Yb(a,b,c,d){var e=c.R;c=c.ka;for(var f in c){var h=ka(d,a,c[f]);P(e,f,h);b.push(new Tb(e,f,h))}}function Zb(a,b,c){var d=c.currentTarget;a=hc(a,d)||a;a=ic(a,d);b.call(a,c)}
function $b(a,b,c){a:{for(var d=c.currentTarget;d&&d!=document;){var e=hc(a,d);if(e){a=ic(e,d);break a}d=d.parentNode}a=void 0}a&&b.call(a,c)}function ic(a,b){var c=jc(b),d=kc[c];d||(d=kc[c]=[]);for(var e=d.length,f=0;f<e;f++){var h=d[f];if(h instanceof a)return h}b=new a(b);d.push(b);a=y(a);(d=lc[a])||(d=lc[a]=[]);d.push(c);return b}function hc(a,b){var c,d=b.id;d&&(c=mc(a,c,"#",d));b=b.classList||[];d=b.length;for(var e=0;e<d;e++)c=mc(a,c,".",b[e]);return c}
function mc(a,b,c,d){c=(d=(c=Xb[c])&&c[d])?d.length:0;for(var e=0;e<c;e++){var f=d[e];!(f===a||f.prototype instanceof a)||b&&!(f===b||f.prototype instanceof b)||(b=f)}return b}function jc(a){var b=a.getAttribute("data-duid");b||a.setAttribute("data-duid",b=""+nc++);return b}var ec=Object.create(null),dc=[""],cc=[""],Xb=Object.create(null),Vb=Object.create(null),lc=Object.create(null),kc=Object.create(null),nc=100;window.gs_evt_dsp=fc;function oc(){var a=".gs_md_li";if("string"===typeof a){var b=a.charAt(0),c=a.slice(1);if("#"==b)a=function(d){return d.id==c&&0<d.offsetWidth};else if("."==b)a=function(d){return p(d,c)&&0<d.offsetWidth};else throw Error("bad selector: "+a);}return a}function pc(a,b){return a&&((void 0===b?0:b)?a.lastElementChild:a.firstElementChild)}function qc(a,b){return a&&((void 0===b?0:b)?a.previousElementSibling:a.nextElementSibling)}function rc(a,b,c){c=void 0===c?!1:c;return sc(a,b,oc(),c,!1)}
function sc(a,b,c,d,e){for(var f;b&&a;){if(c(b)){if(e)return b}else for(f=pc(b,d);f;f=qc(f,d))if(e=sc(f,f,c,d,!0))return e;for(e=!0;;){if(b==a)return null;f=b.parentNode;if(b=qc(b,d))break;b=f}}return null};function tc(a){return!!p(a,"gs_sel")+2*!!p(a,"gs_par")}function uc(a){return+a.getAttribute("data-s")}function vc(a,b,c){c=void 0===c?!1:c;q(a,"gs_sel",1==b);q(a,"gs_par",2==b);a.setAttribute("aria-checked",wc[b]);c||a.setAttribute("data-s",""+b)}var wc=["false","true","mixed"];var Q=function(){this.j=Object.create(null);this.l=0};Q.prototype.clear=function(){this.j=Object.create(null);this.l=0};Q.prototype.has=function(a){return a in this.j};Q.prototype.get=function(a){return this.j[a]};Q.prototype.set=function(a,b){this.has(a)||this.l++;this.j[a]=b};Q.prototype.delete=function(a){this.has(a)&&(delete this.j[a],this.l--)};var xc=function(a){var b=window,c=this;this.i=new z;this.V=0;this.S=[b,a,function(){c.V++||Ma(d)},!1];var d=function(){c.V=0;c.i.notify()}};xc.prototype.addListener=function(a){this.i.v||B.apply(null,this.S);this.i.add(a)};xc.prototype.removeListener=function(a){this.i.remove(a);this.i.v||C.apply(null,this.S)};var yc=new xc("scroll"),zc=new xc("resize");var Ac=new z;function Bc(){var a=document.documentElement,b=oa();b={gs_el_ph:1==b,gs_el_ta:2==b,gs_el_sm:4!=b,gs_el_tc:pa||1==b};var c;for(c in b){var d=b[c];if(p(a,c)!=d){var e=!0;q(a,c,d)}}e&&Ac.notify()}q(document.documentElement,"gs_el_ios",ma);Bc();zc.addListener(Bc);B(window,["pageshow","load"],Bc);function R(a,b,c,d){function e(){var u=ca&&p(h,"gs_el_ph");q(F,"gs_vis",!u);h.style.overflowY=Yd&&!u?"scroll":""}function f(){var u=h.clientHeight,I=+A.getAttribute("data-h");I||(w.style.maxHeight="none",I=m.offsetHeight);I=Math.max((u-I)/2,10);u=Math.max(u-48-2*I,10);var Jc=ca&&p(h,"gs_el_ph");m.style.top=Jc?"auto":I+"px";w.style.maxHeight=Jc?"none":u+"px";Cc(w)}b=void 0===b?"":b;c=void 0===c?"":c;d=void 0===d?"":d;var h=document.documentElement,k=t("gs_top"),m=t(a),w=t(a+"-bdy"),v=t(m.getAttribute("data-cid")||
m.id+"-bdy")||m,F=t(m.getAttribute("data-shd")||"gs_md_s"),A=Dc(m),ca=!!A&&p(A,"gs_md_wmw"),N=window.pageYOffset,Yd=k.scrollHeight>h.clientHeight,pb=!!E[a],qb=pb?"":S,Lc=b&&"#"!=b[0]&&!d,$d=a==S&&b==Ec&&c==T;Fc=b;Lc?(pb?q(v,"gs_md_ldg",!0):Gc(m,v,'<div class="gs_md_prg">'+t("gs_md_ldg").innerHTML+"</div>"),O("gs-md-ldin",v)):(d&&Gc(m,v,d),O("gs-md-lded",v));qb&&(++Hc,H(qb),--Hc);S=a;Ec=b;T=c;Ic=d;$d||Hc||(Kc+=1,(qb?ib:cb)(Mc(),Nc()));pb||Wa(m,function(){A&&l(A,"gs_vis");l(m,"gs_vis");q(m,"gs_abt",
sb);Oc(a);Ac.add(e);e();A&&w&&(f(),zc.addListener(f));l(k,"gs_nscl");k.style.top=-N+"px"},function(){Ac.remove(e);zc.removeListener(f);A&&n(A,"gs_vis");n(m,"gs_vis");n(m,"gs_abt");n(F,"gs_vis");h.style.overflowY="";n(k,"gs_nscl");k.style.top="auto";Rb(U);U=null;window.scrollTo(0,N);S=Ec=T=Ic="";var u=Kc;Kc=0;Hc||(0<u?window.history.go(-u):ib(Mc(),Nc()))},Pc(m),Qc(m));Lc&&(Rb(U),U=null,U=Qb(b,c,function(u,I){U=null;u=200==u;Gc(m,v,u?I:Rc());u&&a==S&&b==Ec&&c==T&&(Ic=I,ib(Mc(),Nc()));O("gs-md-lded",
v)}))}function Dc(a){a=a.parentNode;return p(a,"gs_md_wnw")?a:null}function Pc(a){return(a=a.getAttribute("data-ifc"))?t(a):null}function Qc(a){return(a=a.getAttribute("data-cfc"))?t(a):null}
function Gc(a,b,c){q(b,"gs_md_ldg",!1);for(var d=b.querySelectorAll("[data-duid]"),e=d.length,f={},h=0;h<e;h++){for(var k=jc(d[h]),m=kc[k],w=m?m.length:0,v=0;v<w;v++){var F=m[v],A=y(F.constructor),ca=f[A];ca||(ca=f[A]={});ca[k]=!0;F&&"function"==typeof F.T&&F.T()}delete kc[k]}for(var N in f){N=+N;d=f[N];h=(e=lc[N])?e.length:0;for(m=k=0;m<h;m++)w=e[m],w in d||(e[k++]=w);k?e.length=k:delete lc[N]}b.innerHTML=c;Oc(a.id);Rb(U);U=null}
function Oc(a){if(a=document.querySelector("#"+a+">.gs_md_bdy"))a.scrollTop=a.scrollLeft=0,Cc(a)}function Cc(a){var b=a.style,c="padding"+(xa(a)?"Left":"Right");b[c]="";var d=a.offsetWidth-a.clientWidth;2<d&&(a=parseInt(window.getComputedStyle(a,null)[c],10)||0,b[c]=Math.max(a-d,0)+"px")}function Rc(){return'<div class="gs_md_prg"><div class="gs_alrt">'+t("gs_md_err").innerHTML+"</div></div>"}function Mc(){return{d:S||void 0,u:Ec||void 0,p:T?"1":void 0}}function Nc(){return{n:Kc,p:T,h:Ic}}
var U=null,Fc="",S="",Ec="",T="",Ic="",Kc=0,Hc=0;rb.add(function(){var a=kb(window.location.hash),b=a.d||"",c=b?t(b):null;++Hc;if(c){c=a.u||"";a=0<+a.p;var d=gb||J(window.history.state)||{},e=+d.n||0,f=""+(d.p||"");d=""+(d.h||"");c.match(Ea)||(c="");a!=!!f?R(b,"","",Rc()):b==S&&c==Ec&&f==T&&d==Ic||R(b,c,f,d);Kc=e}else S&&H(S);--Hc});var Sc=function(a){g.call(this);this.D=a;this.K=Object.create(null);this.C=null;a=a.querySelectorAll(".gs_in_txtw>input[type=text]");for(var b=a.length;b--;){var c=a[b],d=c.parentNode.querySelector(".gs_in_txts");c=c.name;d&&c&&(this.K[c]=d.innerHTML)}};ia(Sc,g);Sc.prototype.H=function(){Rb(this.C);this.D=this.C=null;g.prototype.H.call(this)};
Sc.prototype.ga=function(a){var b=this;L(a);if((a=this.D)&&!this.C){var c="json=&"+ya(a);Tc(this,!0);this.C=Qb(a.action,c,function(d,e){b.C=null;Tc(b,!1);var f=b.D,h=f.getAttribute("data-alrt");if(h=h?t(h):null)h.innerHTML="";try{var k=200==d&&JSON.parse(e)}catch(A){}k&&"object"==typeof k||(Uc(h,t("gs_md_err").innerHTML),k={});if(d=k.L)Ca(""+d);else{(d=k.M)&&Uc(h,d);d=1E6;if(h&&h.innerHTML){var m=h;d=h.getBoundingClientRect().top}f=f.elements;k=k.E;"object"==typeof k||(k=Object.create(null));for(var w in b.K){h=
f[w];e=void 0;var v=""+(k[w]||""),F=h.parentNode.querySelector(".gs_in_txts");q(h.parentNode,"gs_in_txte",!!v);F&&(F.innerHTML=v||b.K[w]||"");v&&(e=h.getBoundingClientRect().top)<d&&(m=h,d=e)}m&&m.scrollIntoView&&(0>d||d+20>window.innerHeight)&&m.scrollIntoView()}})}};
var Tc=function(a,b){a=a.D;var c=a.getAttribute("data-bsel");a=c?document.querySelectorAll(c):a.querySelectorAll("button");for(c=a.length;c--;){var d=a[c];d.disabled=b;q(d,"gs_bsp",b)}},Uc=function(a,b){if(a)a.innerHTML=b;else{var c=void 0===c?"":c;var d=void 0===d?"":d;var e=void 0===e?[]:e;t("gs_alrt_m").innerHTML=b;Lb().action=d.match(Ba)?d:"";a=t("gs_alrt_l");a.textContent=c;c=t("gs_alrt_h");c.innerHTML="";for(var f in e)b=document.createElement("input"),b.type="hidden",b.name=f,b.value=e[f],
c.appendChild(b);Ib();q(a,"gs_fm_s",!0);Kb()}};Ub(Sc,[new M(".gs_ajax_frm",{submit:Sc.prototype.ga})]);var Vc=[[1,0,1],[2,0,1]];P(".gs_cb_gen","click",function(a){var b=a.currentTarget,c=tc(b),d=2==+b.getAttribute("data-s");vc(b,Vc[+d][c],!0);O("gs-change",b,a.g)});P(".gs_cb_gen",["keydown","keyup"],function(a){var b=a.currentTarget,c=a.g.keyCode;"BUTTON"!=b.tagName||13!=c&&32!=c||(L(a),"keydown"==a.type&&b.click())});P([".gs_cb_gen",".gs_md_li"],"keydown",function(a){var b=a.currentTarget,c=b.tagName,d=a.g.keyCode;"BUTTON"!=c&&(32==d||13==d&&"A"!=c)&&(L(a),b.click())});var Wc=["click","contextmenu","mouseup"].concat(navigator.sendBeacon?[]:["mousedown","touchstart"]),Xc="",Yc=null;function Zc(){Yc=null}function $c(a){navigator.sendBeacon?navigator.sendBeacon(a):Yc&&a==Yc.src||((Yc=new Image).src=a,setTimeout(Zc,1E3))}function ad(){var a=lb(document.location.href).hl||"";a="/scholar_bfnav?url="+encodeURIComponent(document.location.href)+"&hl="+encodeURIComponent(a)+"&ei="+GSP.eventId;$c(a)}D(function(){Xc=Hb?"&bn=1":"";Hb&&ad()});
B(window,"pageshow",function(a){a.persisted&&(Xc="&bn=1",ad())});
B(document,Wc,function(a){if(!("click"==a.type&&a.button||"mouseup"==a.type&&1!=a.button)){var b,c;a:{for(a=a.target;a;){var d=a.nodeName;if("A"==d)break a;if("SPAN"==d||"B"==d||"I"==d||"EM"==d||"IMG"==d)a=a.parentNode;else break}a=null}a&&(b=a.getAttribute("href"))&&(c=a.getAttribute("data-clk"))&&(b="/scholar_url?url="+encodeURIComponent(b)+"&"+c+"&ws="+window.innerWidth+"x"+window.innerHeight+"&at=",c=encodeURIComponent,a=(a=a.getAttribute("data-clk-atid"))&&t(a),b=b+c(a&&a.innerText||"")+Xc,$c(b))}},
!1,!0);P(".gs_fm_s","click",function(a){a=a.currentTarget.getAttribute("data-fm")||"";(a=t(a))&&a.submit()});var V=function(a){this.m=x(a.querySelector(".gs_md_d"));this.G=x(a.querySelector(".gs_md_tb"))};V.prototype.I=function(a){var b=t(this.m);return void 0!==a?rc(b,b,a):null};V.prototype.open=function(a){a=this.I(a);if(p(t(this.G),"gs_sel"))try{a&&a.focus()}catch(c){}else{var b=t(this.G);Va(this.m,function(){l(b,"gs_sel")},function(){n(b,"gs_sel")},a,b)}};V.prototype.close=function(){H(this.m)};V.prototype.Z=function(a){L(a);p(t(this.G),"gs_sel")?this.close():this.open("keydown"==a.g.type?!1:void 0)};
V.prototype.U=function(a){var b=a.g.keyCode;if(38==b||40==b)L(a),this.open(38==b)};V.prototype.aa=function(a){a.target.id==this.m&&this.U(a)};Ub(V,[new M(".gs_md_rmb",{}),new M(".gs_md_tb",{"gs-press":V.prototype.Z,keydown:V.prototype.U}),new M(".gs_md_d",{keydown:V.prototype.aa})]);var W=function(a){V.call(this,a);this.ia=x(a.querySelector(".gs_md_in"));this.ja=x(a.querySelector(".gs_md_tb .gs_lbl"))};ia(W,V);W.prototype.I=function(){return t(this.m).querySelector(".gs_md_li[aria-selected]")};W.prototype.ba=function(a){bd(this,a)};W.prototype.J=function(a){var b=a.g.keyCode;13!=b&&32!=b||bd(this,a)};
var bd=function(a,b){var c=b.currentTarget,d=t(a.ia),e=a.I();c!=e&&(d.value=c.getAttribute("data-v"),t(a.ja).innerHTML=c.innerHTML,e&&cd(e,!1),cd(c,!0));L(b);a.close();O("gs-change",d,b.g)},cd=function(a,b){q(a,"gs_sel",b);b?a.setAttribute("aria-selected","true"):a.removeAttribute("aria-selected")};Ub(W,[new M(".gs_md_ris",{}),new M(".gs_md_li",{click:W.prototype.ba,keydown:W.prototype.J})]);P("#gs_lp","click",function(a){L(a);R("gs_lp_d")});P("#gs_lp_cur","click",function(a){L(a);H("gs_lp_d")});var dd=function(a){this.W=x(a)};dd.prototype.J=function(a){var b=a.currentTarget,c=a.g.keyCode;if(38==c||40==c){var d=t(this.W);d=rc(d,b,38==c)||rc(d,d,38==c)}else if(37==c||39==c)a:{c=!!(37==c^xa(b.parentNode));d=b.parentNode;var e=d.children,f=e.length;if(d.id!=this.W){for(;e[--f]!=b;);d=qc(d,c)||pc(d.parentNode,c);e=d.children;if(f=Math.min(f+1,e.length))if(d=e[f-1],p(d,"gs_md_li")&&d.offsetLeft!=b.offsetLeft)break a}d=void 0}d&&(L(a),d.focus())};
Ub(dd,[new M(".gs_md_ulr",{}),new M(".gs_md_li",{keydown:dd.prototype.J})]);P("#gs_hdr_mnu","click",function(a){L(a);R("gs_hdr_drw")});P("#gs_hdr_drw_mnu","click",function(a){L(a);H("gs_hdr_drw")});P("#gs_hdr_act_i","click",function(a){L(a);1==oa()?Ca(document.querySelector("#gs_hdr_drw_bot>a").href):Va("gs_hdr_act_d")});P("#gs_hdr_drw","keydown",function(a){var b=a.g.keyCode;if(38==b||40==b){var c=a.currentTarget;if(b=rc(c,c,38==b))L(a),b.focus()}});
P("#gs_hdr_tsi",["focus","blur"],function(a){function b(){var h=d.getBoundingClientRect().top-10;10<Math.abs(h)&&window.scrollBy(0,h);clearTimeout(e);c()}function c(){C(window,f,b)}var d=a.target;a="focus"==a.type;q(t("gs_hdr"),"gs_hdr_ifc",a);if(a&&pa&&!(749<window.innerHeight)){var e=setTimeout(c,1E3),f=["scroll","resize"];B(window,f,b)}});P("#gs_hdr_tsi",["input","gs-change"],function(a){q(t("gs_hdr_frm"),"gs_hdr_tsc",!!a.currentTarget.value)});
P("#gs_hdr_tsc","mousedown",function(a){L(a);var b=t("gs_hdr_tsi");b.value="";b.focus();O("input",b,a.g)});P("#gs_hdr_sre","click",function(a){L(a);var b=t("gs_hdr");Va("gs_hdr_frm",function(){n(b,"gs_hdr_src");l(b,"gs_hdr_srx")},function(){l(b,"gs_hdr_src");n(b,"gs_hdr_srx")},t("gs_hdr_tsi"))});P(".gs_md_x","click",function(a){(a=a.currentTarget.getAttribute("data-mdx"))&&H(a)});var X=function(){},ed,fd;X.prototype.$=function(a){a.g.button||(L(a),gd(a))};X.prototype.ca=function(a){hd(a)&&(L(a),gd(a))};X.prototype.da=function(a){hd(a)&&L(a)};X.prototype.ea=function(a){if(!a.g.button){L(a);var b=a.g;b&&(id=b.clientX||0,jd=b.clientY||0,B(document,kd,ld,!0),clearTimeout(ed),ed=setTimeout(md,2E3));gd(a)}};X.prototype.ha=function(a){L(a);if(nd){var b=a.g;if(b=(b=b&&b.touches)&&1==b.length&&b[0])od=b.clientX,pd=b.clientY,B(document,qd,rd,!0),clearTimeout(fd),fd=setTimeout(sd,2E3)}gd(a)};
var hd=function(a){a=a.g.keyCode;return 32==a||13==a},gd=function(a){O("gs-press",a.currentTarget,a.g)},md=function(){C(document,kd,ld,!0);clearTimeout(ed);ed=void 0},ld=function(a){"mousedown"!=a.type&&10>Math.abs(a.clientX-id)&&10>Math.abs(a.clientY-jd)?(Na(a),"click"==a.type&&md()):md()},sd=function(){C(document,qd,rd,!0);clearTimeout(fd);fd=void 0},rd=function(a){"touchstart"!=a.type&&10>Math.abs(a.clientX-od)&&10>Math.abs(a.clientY-pd)?(Na(a),"click"==a.type&&sd()):sd()},id=0,jd=0,kd=["mousedown",
"mouseup","click"],nd=r("Android")&&!r("Chrome"),od=0,pd=0,qd=["touchstart","mousedown","mouseup","click"];Ub(X,[new M(".gs_press",{click:X.prototype.$,keydown:X.prototype.ca,keyup:X.prototype.da,mousedown:X.prototype.ea,touchstart:X.prototype.ha})]);function td(){var a=0>ud.getBoundingClientRect().top;vd!=a&&(vd=a,q(wd,"gs_sth_vis",a),a?xd():(yd.style.left="",yd.style.width="",zd()))}function xd(){if(vd){var a=ud.getBoundingClientRect();yd.style.left=a.left+"px";yd.style.width=a.width+"px";zd()}}function zd(){O("gs-sth-change",t("gs_sth"))}var wd,ud,yd,vd=!1;D(function(){if(wd=t("gs_sth"))ud=wd.querySelector(".gs_sth_g"),yd=wd.querySelector(".gs_sth_b"),yc.addListener(td),zc.addListener(xd),td()});function Ad(){var a=t("gsc_rsb_co");if(a){a=a.querySelectorAll("img.gs_pp_df");for(var b=0;b<a.length;b++){var c=a[b];c.getAttribute("data-srcset")&&(c.setAttribute("srcset",c.getAttribute("data-srcset")),c.removeAttribute("data-srcset"));c.getAttribute("data-src")&&(c.setAttribute("src",c.getAttribute("data-src")),c.removeAttribute("data-src"))}}};var Bd=/\S+@\S+\.\S+/;function Cd(a){return p(a,"gsc_ccb_dis")||p(a,"gsc_ccb_lim")}function Dd(){for(var a=0>=Ed(),b=t("gsc_cods_res").querySelectorAll(".gsc_ccb_add"),c=b.length;c--;){var d=b[c];p(d,"gsc_ccb_on")||q(d,"gsc_ccb_lim",a)}};var Fd=function(a){this.X=a};Fd.prototype.fa=function(a){L(a);a=a.currentTarget.getAttribute("data-a");this.X.setAttribute("data-a",a||"");O("gsc-navigate",this.X)};var Gd=[new M(".gsc_pgn",{}),new M([".gsc_pgn_ppr",".gsc_pgn_pnx"],{click:Fd.prototype.fa})];function Hd(a,b){b=void 0===b?"":b;var c=t("gsc_md_cod");a+=fb({t:Id});R(c.id,a,"",b)}function Jd(a){if(Id!=a){var b=t("gsc_md_cod");n(b,Id);l(b,a);Id=a}}function Kd(){var a=kb(Fc).t;"gsc_cod_sugg"!=a&&"gsc_cod_lc"!=a||Jd(a)}function Ld(){var a=Md();a=a?a.value:"";var b=(t("gsc_cods_urls").getAttribute("data-sa")||"").replace(Nd,"$1"+encodeURIComponent(a));a=a?b:t("gsc_cods_urls").getAttribute("data-lc")||"";Hd(a)}
function Od(a){var b=t("gsc_cods_frm");if(b){b=b.elements;var c=b[1];b[0].disabled=c.disabled=a;q(c,"gs_bsp",a)}a=a?null:t("gsc_codb_data");if(c=t("gsc_cods_pp")){var d=a&&a.getAttribute("data-prev");b=a&&a.getAttribute("data-next");var e=a&&a.getAttribute("data-start"),f=a&&a.getAttribute("data-end");c.querySelector(".gsc_pgn_ppn").textContent=e&&f?e+" - "+f:"";e=c.querySelector(".gsc_pgn_ppr");e.disabled=!d;e.setAttribute("data-a",d||"");c=c.querySelector(".gsc_pgn_pnx");c.disabled=!b;c.setAttribute("data-a",
b||"")}a&&(Pd=+a.getAttribute("data-max")||0,za(t("gsc_cods_save"),"xsrf").value=a.getAttribute("data-xsrf")||"")}function Qd(){var a=0<Y.l||0<Z.l,b=Ed(),c=0>=b;t("gsc_cod_done").disabled=!a||0>b;q(t("gsc_cod_t"),"gsc_cod_changed",a);a=t("gsc_cod_trev");a.textContent=a.getAttribute(c?"data-lim":"data-txt")||"";q(t("gsc_cod_t"),"gsc_cod_lim",c)}function Ed(){return Pd-Y.l+("gsc_cod_sugg"==Id?0:Z.l)}function Md(){return t("gsc_cods_tsi")}
function Rd(a){for(var b="",c=la(a.j),d=c.length;d--;)b+=a.get(c[d]);return b}var Id="gsc_cod_lc",Pd=0,Nd=/([?&]mauthors=)([^&]*)/,Y=new Q,Z=new Q;function Sd(a){q(t("gsc_a_sp"),"gs_vis",0==a);q(t("gsc_a_err"),"gs_vis",2==a)}function Td(){return document.querySelectorAll("#gsc_a_t input[type=checkbox]")}function Ud(){O("gsc-works-change",t("gsc_a_t"))}function Vd(){var a=t("gsc_x_all");if(a){var b=document.querySelectorAll("#gsc_a_t input[type=checkbox]:checked");var c=b.length;var d=Td().length;c=c?c==d?1:2:0;vc(a,c);2==c&&(Wd=b)}Ud()}var Wd=[];var Xd="",Zd=0,ae=0;function be(a){for(var b=[!1,!1,!1],c=0;c<b.length;c++){var d=t(ce[c]);d&&(b[c]=!!a(d))}return b}function de(){var a=t("gsc_fol_m");if(a){var b=t("gsc_fol_b");if(!(a=!Bd.test(a.value))){a:{a=be(tc);for(var c=be(uc),d=0;d<a.length;d++)if(a[d]!=c[d]){a=!0;break a}a=!1}a=!a}b.disabled=a}}var ce=["gsc_fol_a","gsc_fol_c","gsc_fol_r"],ee=["follow_articles_btn","follow_citations_btn","follow_related_btn"];function fe(){p(document.documentElement,"gs_el_ph")||p(document.documentElement,"gs_el_ta")||Ad()};function ge(a){if(a){a.id&&a.removeAttribute("id");for(var b=0;b<a.children.length;b++)ge(a.children[b])}};function he(){var a=t("gsc_prf_pufii");if(r("MSIE ")){var b=t("gsc_prf_puf");Va("gsc_prf_pufi",function(){l(b,"gsc_prf_pufo")},function(){n(b,"gsc_prf_pufo")},a)}else a.click()};function ie(){var a=document.querySelectorAll(".gsc_prf_pnl"),b=document.documentElement;b=p(b,"gs_el_ph")||p(b,"gs_el_ta");for(var c=0;c<a.length;c++)a[c].setAttribute("role",b?"tabpanel":"region")};var je=kb(window.location.hash),ke=je.u||"";"gs_md_cita-d"==je.d&&ke.match(Ea)&&0<=ke.indexOf("view_citation")&&Ca(ke);P("#gsc_md_cod","gs-md-ldin",function(){Kd();Od(!0)});P("#gsc_md_cod","gs-md-lded",function(){Kd();Od(!1);for(var a=t("gsc_cods_res").querySelectorAll(".gsc_ccb_ck"),b=a.length;b--;){var c=a[b];if(!Cd(c)){var d=c.getAttribute("data-authorid")||"";d=(p(c,"gsc_ccb_add")?Y:Z).has(d);q(c,"gsc_ccb_on",d)}}Dd();Qd();a=lb(Fc);(b=Md())&&(b.value=a.mauthors||"")});
P("#gsc_cods_frm","gsc-lwpds-submit",Ld);P("#gsc_cods_pp","gsc-navigate",function(a){(a=a.currentTarget.getAttribute("data-a"))&&Hd(a)});
P([".gsc_ccb_add",".gsc_ccb_del"],"click",function(a){a=a.currentTarget;if(!Cd(a)){var b=!p(a,"gsc_ccb_on");q(a,"gsc_ccb_on",b);var c=p(a,"gsc_ccb_add")?".gsc_ccb_del":".gsc_ccb_add",d=a.parentNode;(c=d&&d.querySelector(c))&&n(c,"gsc_ccb_on");c=a.getAttribute("data-authorid")||"";Y.delete(c);Z.delete(c);b&&(p(a,"gsc_ccb_add")?Y:Z).set(c,t("gsc_ucoar-"+c).outerHTML);Dd();Qd()}});
P("#gsc_cod_trev","click",function(){var a=t("gsc_cods_res").cloneNode(!0),b=a.querySelector("#gsc_codb_content");b||(b=document.createElement("div"),b.id="gsc_codb_content",a.appendChild(b));var c=Rd(Y)+Rd(Z);b.innerHTML=c;(b=Md())&&(b.value="");Hd("",a.innerHTML)});P("#gsc_cod_done","click",function(){var a=t("gsc_cods_save");za(a,"colleague_add").value=la(Y.j).join(",");za(a,"colleague_del").value=la(Z.j).join(",");a.submit()});
P(["#gsc_coauth_opn",".gsc_rsb_btne",".gsc_rsb_btnv"],"click",function(){Jd("gsc_cod_lc");Pd=0;Y.clear();Z.clear();var a=Md();a&&(a.value="");Ld()});P(".gsc_rsb_aa",["click","keydown"],function(a){if("keydown"!=a.type||a.g&&!Oa(a.g)&&13==a.g.keyCode)a.g&&Na(a.g),(a=(a=a.currentTarget.querySelector("a"))?a.getAttribute("href"):"")&&Ca(a)});P("#gsc_prf_t-ath","click",function(){Ad()});D(function(){Ac.add(fe);fe()});P(".gsc_lwpds_frm","submit",function(a){L(a);O("gsc-lwpds-submit",a.target)});
var le=window.location.href.split("#")[0];Xd=le.replace(/([?&])(cstart|pagesize)=[^&]*/g,"$1");Zd=Math.max(+le.replace(/.*[?&]cstart=([^&]*).*/,"$1")||0,0);ae=+le.replace(/.*[?&]pagesize=([^&]*).*/,"$1")||0;ae=Math.max(Math.min(ae,100),20);
P("#gsc_bpf_more","click",function(a){var b=a.currentTarget,c=ae,d=100>c?100-c:100;a=(Xd+"&cstart="+(Zd+c)+"&pagesize="+d).replace(/([?&])&+/g,"$1");Sd(0);b.disabled=!0;Qb(a,"json=1",function(e,f){b.disabled=!1;try{var h=200==e&&JSON.parse(f)}catch(m){}if(h&&"object"==typeof h){ae=c+=d;Sd(1);e=t("gsc_a_b");f=document.createElement(va.Y);f.innerHTML=""+h.B;f=Array.prototype.slice.call(f.rows);for(var k=0;k<f.length;k++)e.appendChild(f[k]);Vd();if(e=t("gsc_a_nn"))f=e.innerHTML.replace(/[0-9]+$/,""+
t("gsc_a_b").rows.length),e.innerHTML=f;b.disabled=!h.N}else Sd(2)})});P(["#gsc_fol_a","#gsc_fol_c","#gsc_fol_r"],"gs-change",de);P("#gsc_fol_m","input",de);P("#gsc_fol_f","submit",function(a){a.g&&a.g.preventDefault();a=t("gsc_fol_f");var b=t("gsc_fol_inp");b.innerHTML="";for(var c=be(tc),d=be(uc),e=0;e<c.length;e++)if(c[e]!=d[e]){var f=ee[e],h=document.createElement("input");h.type="hidden";h.name=c[e]?f:"un"+f;b.appendChild(h)}O("gsc-fol-submit",a)});P("#gsc_fol_f","gsc-fol-submit",function(a){a.currentTarget.submit()});
P("#gsc_md_hist","gs-md-lded",function(){var a=t("gsc_md_hist_c");if(!a.innerHTML){var b=document.getElementsByClassName("gsc_g_hist_wrp");1==b.length&&(a.appendChild(b[0].cloneNode(!0)),ge(a.lastChild))}});P(["#gsc_hist_opn",".gsc_md_hist_b"],"click",function(){var a=document.documentElement;!t("gsc_hist_opn")||p(a,"gs_el_ph")||p(a,"gs_el_ta")||R("gsc_md_hist")});
P("#gsc_lwp_mndt_lnk","click",function(a){var b=a.currentTarget.getAttribute("href")+"&tzom="+(new Date).getTimezoneOffset();window.location.assign(b);a.g.preventDefault()});P("#gsc_prf_btne","click",function(){var a=t("gsc_md_pro-d");a.setAttribute("data-ifc","");R(a.id,fb({t:"gsc_md_pro_ed"}))});P("#gsc_prf_btnf","click",function(){R("gsc_md_fol")});P("#gsc_md_fol_pub","click",function(){t("gsc_fol_mpf").submit()});P("#gsc_prf_iv_tg","click",function(){q(t("gsc_prf_w"),"gsc_prf_why")});
P(".gsc_prf_pel",["click","keydown"],function(a){("keydown"!=a.type||13==a.g.keyCode&&a.g&&!Oa(a.g))&&he()});P("#gsc_prf_pufii","change",function(){t("gsc_prf_puf").submit()});P(".gsc_prf_tab","click",function(a){var b=t("gsc_bdy");b.setAttribute("data-tab",a.currentTarget.id);b=b.querySelectorAll(".gsc_prf_tab");for(var c=0;c<b.length;c++){var d=b[c];d.setAttribute("aria-selected",""+(d==a.currentTarget))}});D(function(){Ac.add(ie);ie()});
P("#gsc_md_cbyd","gs-md-ldin",function(){var a=t("gsc_md_cbyd_merge");a&&(a.disabled=!0);Aa("")});P("#gsc_md_cbyd","gs-md-lded",function(){var a=t("gsc_md_cbyd_f"),b=t("gsc_md_cbyd_merge"),c=Fc,d=lb(c).s||"";c=kb(c).c||"";a.elements.s.value=d;Aa(c);b&&a.elements.choose&&(b.disabled=!1,b.getBoundingClientRect().bottom<window.innerHeight&&b.focus())});
P("#gsc_md_cbym",["gs-md-ldin","gs-md-lded"],function(){var a=lb(Fc).s||"",b=t("gsc_md_cbym_e");b&&a&&0>a.indexOf("&")&&b.setAttribute("data-href",(b.getAttribute("data-href")||"").replace(/(&citation_for_view=)[^&]*/,"$1"+a))});P("#gsc_md_cbym_e","click",function(a){a=a.currentTarget.getAttribute("data-href")||"";R("gs_md_cita-d",a)});Ub(Fd,Gd);D(function(){return setTimeout(Vd,0)});P(".gsc_a_x","change",Vd);
P("#gsc_x_all","gs-change",function(a){a=tc(a.currentTarget);for(var b=2==a?Wd:Td(),c=b.length;c--;)b[c].checked=0!=a;Ud()});P(".gsc_a_acm","click",function(a){L(a);var b=a.currentTarget;a=b.href;var c=b.getAttribute("data-eid")||"";b=b.getAttribute("data-eud")||"";a=t("gsc_md_cbyd_f").action+"&update_op=merge_options&s="+(b+","+c)+fb({c:a});R("gsc_md_cbyd",a)});
P(".gsc_a_am","click",function(a){a=a.currentTarget.getAttribute("data-eid")||"";a=(t("gsc_md_cbym_l").getAttribute("data-act")||"")+"&update_op=merge_options&s="+a;R("gsc_md_cbym",a)});P("#gs_sth","gs-sth-change",function(a){var b=t("gsc_a_tr0"),c=t("gsc_a_trh"),d=b.querySelector(".gsc_a_t"),e=c.querySelector(".gsc_a_t");p(a.currentTarget,"gs_sth_vis")?(e.style.width=d.offsetWidth+"px",b.style.height=c.offsetHeight+"px"):e.style.width=b.style.height="auto"});
P("#gs_md_cita-b-save","click",function(){var a=t("gsc_ecd_form");za(a,"continue").value=window.location.pathname+window.location.search;O("submit",a)});P(".gsc_ecd_form_tsel","click",function(a){var b=t("gsc_ecd_table"),c=za(t("gsc_ecd_form"),"articletype");a=a.currentTarget;c.value=a.getAttribute("data-type")||"";b.className=a.getAttribute("data-class")||"";b=document.querySelectorAll("#gsc_ecd_citation_type button");for(c=b.length;c--;)q(b[c],"gs_sel",b[c]==a)});
}({"customAC":2,"eventId":"lrc0Ye6rDYqrmwHK3IKACA"});</script></head><body><div id="gs_top" onclick=""><style>#gs_md_s,.gs_md_wnw{z-index:1200;position:fixed;top:0;left:0;width:100%;height:100%;visibility:hidden;}#gs_md_s{background-color:#fff;opacity:.5;}.gs_el_ta #gs_md_s,.gs_el_ph #gs_md_s{background-color:#666;}.gs_md_wnw{transition:all 0s .218s;}#gs_md_s.gs_vis,.gs_md_wnw.gs_vis{visibility:visible;transition:all 0s;}.gs_md_wnw>.gs_md_d{position:relative;margin:0 auto;width:464px;box-shadow:2px 2px 8px rgba(0,0,0,.2);white-space:normal;}.gs_el_ta .gs_md_wnw>.gs_md_d,.gs_el_ph .gs_md_wnw>.gs_md_d{box-shadow:2px 2px 8px rgba(0,0,0,.65);}.gs_el_ph .gs_md_wnw>.gs_md_d{width:80%;max-width:440px;}.gs_el_ph .gs_md_wmw>.gs_md_d{width:100%;height:100%;max-width:none;border:none;box-shadow:none;transform:translate(0,100%);transform:translate(0,100vh);transition:transform .27s cubic-bezier(.4,0,.6,1),opacity 0s .27s,visibility 0s .27s,max-height 0s .27s;}.gs_el_ph .gs_md_wmw>.gs_md_d.gs_vis{transform:translate(0,0);transition:transform .3s cubic-bezier(0,0,.2,1);}.gs_md_wmw>.gs_md_d.gs_abt,.gs_el_ph .gs_md_wmw>.gs_md_d.gs_abt{transition:none;}.gs_md_hdr{display:flex;align-items:center;height:47px;border-bottom:1px solid #e0e0e0;border-bottom-color:rgba(0,0,0,.12);background-color:#f5f5f5;}.gs_md_hdr>a,.gs_md_hdr>a.gs_btn_lrge{flex:0 0 auto;width:41px;height:47px;}.gs_el_ph .gs_md_hdr>a{margin:0 2px 0 0;}.gs_el_ph a.gs_md_hdr_c{margin:0 0 0 2px;}.gs_md_hdr_b{margin:0 41px 0 16px;}.gs_el_ph .gs_md_hdr_b{margin:0 16px;}.gs_md_hdr_t:empty~.gs_md_hdr_b{margin-left:0;}.gs_md_hdr_b:empty{width:41px;margin:0;}.gs_el_ph .gs_md_hdr_b:empty{margin-right:2px;}.gs_md_hdr_b:empty:not(:last-child){display:none;}.gs_md_hdr_b>button{min-width:51px;height:33px;}.gs_md_hdr_t{flex:1 1 auto;font-size:18px;font-weight:normal;color:#666;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;text-align:center;}.gs_md_bdy{overflow-y:auto;box-sizing:border-box;padding:24px 41px 0 41px;}.gs_md_bdy:after{display:block;content:"";clear:both;padding-bottom:24px;}.gs_el_ph .gs_md_bdy{padding:16px 16px 0 16px;}.gs_el_ph .gs_md_bdy:after{padding-bottom:16px;}.gs_el_ph .gs_md_wmw .gs_md_bdy{position:absolute;width:100%;top:48px;bottom:0;}.gs_md_lbl{display:block;font-size:16px;margin:0 0 16px 0;word-wrap:break-word;}.gs_md_btns{margin:24px 0 0 0;white-space:nowrap;}.gs_el_ph .gs_md_btns{margin:16px 0 0 0;}.gs_md_btns button{margin-right:16px;}.gs_md_btns button:last-child{margin-right:0;}.gs_md_prg{margin:24px 0;text-align:center;}.gs_md_prg .gs_alrt{padding:4px 16px;}.gs_md_ldg:before{content:"";position:absolute;top:0;left:0;bottom:0;right:0;background-color:#fff;opacity:.5;z-index:100;}</style><div id="gs_md_ldg" style="display:none">Loading...</div><div id="gs_md_err" style="display:none">The system can't perform the operation now. Try again later.</div><div id="gs_md_s"></div><div data-h="0" class="gs_md_wnw"><div id="gsc_md_hist" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gsc_md_hist-t" data-wfc="gsc_md_hist-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_hist-x" role="button" aria-label="Cancel" data-mdx="gsc_md_hist" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_hist-t" class="gs_md_hdr_t">Citations per year</h2><div class="gs_md_hdr_b"></div></div><div id="gsc_md_hist-bdy" class="gs_md_bdy"><style>#gsc_md_hist{width:80%;max-width:386px;}#gsc_md_hist_c{position:relative;width:100%;}</style><div id="gsc_md_hist_c"></div></div></div></div><div data-h="600" class="gs_md_wnw gs_md_wmw"><div id="gsc_md_cbyd" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gsc_md_cbyd-t" data-cid="gsc_md_cbyd_l" data-wfc="gsc_md_cbyd-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_cbyd-x" role="button" aria-label="Cancel" data-mdx="gsc_md_cbyd" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_cbyd-t" class="gs_md_hdr_t">Duplicate citations</h2><div class="gs_md_hdr_b"></div></div><div id="gsc_md_cbyd-bdy" class="gs_md_bdy"><form id="gsc_md_cbyd_f" action="/citations?hl=en&amp;user=JQFnV5IAAAAJ&amp;view_op=list_works" method="post"><input type="hidden" name="s" value=""><div class="gs_md_lbl">The following articles are merged in Scholar. Their <a id="gsc_md_cbyd_c" href="javascript:void(0)">combined citations</a> are counted only for the first article.</div><div id="gsc_md_cbyd_l"></div></form></div></div></div><div data-h="600" class="gs_md_wnw gs_md_wmw"><div id="gsc_md_cbym" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gsc_md_cbym-t" data-cid="gsc_md_cbym_l" data-wfc="gsc_md_cbym-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_cbym-x" role="button" aria-label="Cancel" data-mdx="gsc_md_cbym" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_cbym-t" class="gs_md_hdr_t">Merged citations</h2><div class="gs_md_hdr_b"></div></div><div id="gsc_md_cbym-bdy" class="gs_md_bdy"><div class="gs_md_lbl">This "Cited by" count includes citations to the following articles in Scholar. The ones marked <span id="gsc_md_cbym_s">*</span> may be different from the article in the profile.</div><div id="gsc_md_cbym_l" data-act="/citations?hl=en&amp;user=JQFnV5IAAAAJ&amp;view_op=list_works"></div></div></div></div><div data-h="900" class="gs_md_wnw gs_md_wmw"><div id="gsc_md_cod" class="gs_md_d gs_ttzi gsc_cod_lc" role="dialog" tabindex="-1" aria-labelledby="gsc_md_cod-t" data-cid="gsc_cods_res" data-wfc="gsc_md_cod-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_cod-x" role="button" aria-label="Cancel" data-mdx="gsc_md_cod" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_cod-t" class="gs_md_hdr_t"><span id="gsc_cod_t"><span id="gsc_cod_tadd">Add co-authors</span><span id="gsc_cod_tedit">Co-authors</span><a id="gsc_cod_trev" href="javascript:void(0)" data-txt="Review" data-lim="Limit reached"></a></span></h2><div class="gs_md_hdr_b"><button type="button" id="gsc_cod_done" aria-label="Add co-authors" disabled="" class="gs_btnDNW gs_in_ib gs_btn_act gs_btn_half gs_btn_lsb"><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl"></span></span></button></div></div><div id="gsc_md_cod-bdy" class="gs_md_bdy"><div id="gsc_cods_urls" class="gsc_cods_hide" data-ls="" data-lc="/citations?view_op=list_colleagues&amp;hl=en&amp;json=&amp;user=JQFnV5IAAAAJ" data-sa=""></div><form id="gsc_cods_save" action="" method="POST"><input type="hidden" name="colleague_add"><input type="hidden" name="colleague_del"></form><div id="gsc_cods_res"></div></div></div></div><div data-h="800" class="gs_md_wnw gs_md_wmw"><div id="gs_md_cita-d" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gs_md_cita-d-t" data-cid="gs_md_cita-l" data-wfc="gs_md_cita-d-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gs_md_cita-d-x" role="button" aria-label="Cancel" data-mdx="gs_md_cita-d" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gs_md_cita-d-t" class="gs_md_hdr_t"></h2><div class="gs_md_hdr_b"><button type="button" id="gs_md_cita-b-save" aria-label="Save" class="gs_btnDNW gs_in_ib gs_btn_act gs_btn_half gs_btn_lsb"><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl"></span></span></button></div></div><div id="gs_md_cita-d-bdy" class="gs_md_bdy"><style>#gs_md_cita-d{width:90%;max-width:1000px;}.gs_el_ph #gs_md_cita-d{width:100%;max-width:none;}#gs_md_cita-d .gs_md_prg{min-height:600px;}</style><div id="gs_md_cita-l" aria-live="assertive"></div></div></div></div><div data-h="0" class="gs_md_wnw gs_md_wmw"><div id="gsc_md_fol" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gsc_md_fol-t" data-wfc="gsc_md_fol-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_fol-x" role="button" aria-label="Cancel" data-mdx="gsc_md_fol" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_fol-t" class="gs_md_hdr_t">Follow this author</h2><div class="gs_md_hdr_b"></div></div><div id="gsc_md_fol-bdy" class="gs_md_bdy"><form method="post" id="gsc_fol_f" action="/citations?hl=en&amp;user=JQFnV5IAAAAJ&amp;view_op=list_works"><input type="hidden" name="xsrf" value="AMD79ooAAAAAYTYJFqx5FH4_74ojlFtjwrFpjOFUFeYQ"><input type="hidden" name="user" value="JQFnV5IAAAAJ"><div id="gsc_fol_inp"></div><div id="gsc_fol_cb"><div class="gsc_fol_cr"><a href="javascript:void(0)" id="gsc_fol_a" role="checkbox" aria-checked="false" data-s="0" class="gs_cb_gen gs_in_cb"><span class="gs_lbl">New articles by this author</span><span class="gs_chk"></span><span class="gs_cbx"></span></a></div><div class="gsc_fol_cr"><a href="javascript:void(0)" id="gsc_fol_c" role="checkbox" aria-checked="false" data-s="0" class="gs_cb_gen gs_in_cb"><span class="gs_lbl">New citations to this author</span><span class="gs_chk"></span><span class="gs_cbx"></span></a></div><div class="gsc_fol_cr"><a href="javascript:void(0)" id="gsc_fol_r" role="checkbox" aria-checked="false" data-s="0" class="gs_cb_gen gs_in_cb"><span class="gs_lbl">New articles related to this author's research</span><span class="gs_chk"></span><span class="gs_cbx"></span></a></div></div><div id="gsc_fol_email"><label id="gsc_fol_ml" for="gsc_fol_m">Email address for updates</label><div class="gs_in_txtw gs_in_txtb"><input type="text" class="gs_in_txt" name="email_for_op" value="" id="gsc_fol_m" maxlength="100" autocapitalize="off" autocorrect="off"></div></div><div class="gs_md_btns"><button type="submit" id="gsc_fol_b" disabled="" class=" gs_btn_act gs_btn_lrge gs_btn_lsu"><span class="gs_wr"><span class="gs_lbl">Done</span></span></button></div></form></div></div></div><!--[if lte IE 9]><div class="gs_alrt" style="padding:16px"><div>Sorry, some features may not work in this version of Internet Explorer.</div><div>Please use <a href="//www.google.com/chrome/">Google Chrome</a> or <a href="//www.mozilla.com/firefox/">Mozilla Firefox</a> for the best experience.</div></div><![endif]--><div id="gs_hdr_drs"></div><div id="gs_hdr_drw" class="gs_md_ulr" role="dialog" tabindex="-1" data-shd="gs_hdr_drs" data-wfc="gs_hdr_drw_mnu" data-cfc="gs_hdr_mnu"><div id="gs_hdr_drw_in"><div id="gs_hdr_drw_top"><a href="javascript:void(0)" id="gs_hdr_drw_mnu" role="button" aria-controls="gs_hdr_drw" aria-label="Options" class="gs_btnMNT gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><a id="gs_hdr_drw_lgo" href="/schhp?hl=en" aria-label="Homepage"></a></div><div><div class="gs_hdr_drw_sec"><a href="/citations?hl=en" role="menuitem" class="gs_btnPRO gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">My profile</span></a><a href="/scholar?scilib=1&amp;hl=en" role="menuitem" class="gs_btnL gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">My library</span></a><a href="/citations?view_op=metrics_intro&amp;hl=en" role="menuitem" class="gs_btnJ gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">Metrics</span></a><a href="/scholar_alerts?view_op=list_alerts&amp;hl=en" role="menuitem" class="gs_btnM gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">Alerts</span></a></div><div class="gs_hdr_drw_sec"><a href="/scholar_settings?hl=en" role="menuitem" class="gs_btnP gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">Settings</span></a></div></div><div id="gs_hdr_drw_bot" class="gs_hdr_drw_sec"><a href="https://accounts.google.com/Login?hl=en&amp;continue=https://scholar.google.com/schhp%3Fhl%3Den" class=" gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">Sign in</span></a></div></div></div><div id="gs_hdr" role="banner" class="gs_hdr_src"><a href="javascript:void(0)" id="gs_hdr_mnu" role="button" aria-controls="gs_hdr_drw" class="gs_btnMNT gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><a id="gs_hdr_lgo" class="" href="/schhp?hl=en" aria-label="Homepage"></a><div id="gs_hdr_md"><div id="gs_hdr_srch"><form id="gs_hdr_frm" action="/citations"><input type="hidden" name="view_op" value="search_authors"><input type="hidden" name="hl" value="en"><div class="gs_in_txtw gs_in_txtb"><input type="text" class="gs_in_txt" name="mauthors" value="" id="gs_hdr_tsi" placeholder="Search profiles" size="50" maxlength="2048" autocapitalize="off" aria-label="Search"></div><span id="gs_hdr_tsc"><span class="gs_ico gs_ico_X"></span></span><button type="submit" id="gs_hdr_tsb" name="btnG" aria-label="Search" class="gs_btnG gs_in_ib gs_btn_act gs_btn_half gs_btn_lsb"><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl"></span></span></button></form></div></div><a href="javascript:void(0)" id="gs_hdr_sre" role="button" aria-controls="gs_hdr_frm" aria-label="Search" class="gs_btnTSB gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><div id="gs_hdr_act"><a id="gs_hdr_act_s" href="https://accounts.google.com/Login?hl=en&amp;continue=https://scholar.google.com/schhp%3Fhl%3Den">Sign in</a></div></div><style>#gs_alrt{position:fixed;bottom:48px;left:16px;max-width:384px;z-index:1250;display:flex;justify-content:space-between;align-items:center;font-size:13px;line-height:16px;color:#e2e2e2;background:#333;text-align:left;border-radius:3px;box-shadow:0 3px 5px -1px rgba(0,0,0,.2),0 6px 10px 0 rgba(0,0,0,.14),0 1px 18px 0 rgba(0,0,0,.12);visibility:hidden;transform-origin:center;transform:scale(0.8,0.8) translate(0,100%);}.gs_el_ph #gs_alrt{bottom:0;left:0;width:100%;max-width:none;border-radius:0;box-shadow:none;transform:scale(1,1) translate(0,100%);}#gs_alrt.gs_vis{visibility:visible;transform:scale(1,1) translate(0,0);}#gs_alrt.gs_anm{transition:transform .067s cubic-bezier(.4,0,1,1),visibility 0s .067s;}#gs_alrt.gs_vis.gs_anm{transition:transform .067s cubic-bezier(0,0,.2,1);}.gs_el_ph #gs_alrt.gs_anm{transition:transform .084s cubic-bezier(.4,0,1,1),visibility 0s .084s;}.gs_el_ph #gs_alrt.gs_vis.gs_anm{transition:transform .1s cubic-bezier(0,0,.2,1);}#gs_alrt_m{display:block;padding:16px;}#gs_alrt_l{display:block;padding:8px;margin:0 8px 0 -8px;border-radius:3px;color:#fcc934;text-transform:uppercase;text-decoration:none;}#gs_alrt_l:hover{background-color:rgba(255,255,255,.05)}#gs_alrt_l:active{background-color:rgba(255,255,255,.1)}#gs_alrt_l:empty{display:none}#gs_alrt_m a{padding:8px 0;color:#e2e2e2;text-decoration:underline;}#gs_alrt_m a:active{color:#f6aea9}</style><form action="" method="post" id="gs_alrt"><span id="gs_alrt_m"></span><span id="gs_alrt_h"></span><a id="gs_alrt_l" href="javascript:void(0)" class="gs_fm_s" data-fm="gs_alrt"></a></form><div id="gs_bdy"><div id="gs_bdy_sb" role="navigation"><div id="gs_bdy_sb_in"></div></div><div id="gs_bdy_ccl" role="main"><div id="gsc_bdy" class="gs_scl" data-tab="gsc_prf_t-art"><div class="gsc_rsb" role="navigation"><a id="gsc_rsb_gpl" class="gsc_rsb_s" href="/citations?hl=en">Get my own profile</a><div class="gsc_rsb_s gsc_prf_pnl" id="gsc_rsb_cit" role="region" aria-labelledby="gsc_prf_t-cit"><h3 class="gsc_rsb_header"><span class="gsc_rsb_title">Cited by</span><button type="button" id="gsc_hist_opn" class=" gs_btn_flat gs_btn_flact gs_btn_lrge gs_btn_half gs_btn_lsu gsc_rsb_action"><span class="gs_wr"><span class="gs_lbl">View all</span></span></button></h3><table id="gsc_rsb_st"><thead><tr><th class="gsc_rsb_sth"></th><th class="gsc_rsb_sth">All</th><th class="gsc_rsb_sth">Since 2016</th></tr></thead><tbody><tr><td class="gsc_rsb_sc1"><a href="javascript:void(0)" class="gsc_rsb_f gs_ibl" title="This is the number of citations to all publications. The second column has the &quot;recent&quot; version of this metric which is the number of new citations in the last 5 years to all publications.">Citations</a></td><td class="gsc_rsb_std">4553</td><td class="gsc_rsb_std">3313</td></tr><tr><td class="gsc_rsb_sc1"><a href="javascript:void(0)" class="gsc_rsb_f gs_ibl" title="h-index is the largest number h such that h publications have at least h citations. The second column has the &quot;recent&quot; version of this metric which is the largest number h such that h publications have at least h new citations in the last 5 years.">h-index</a></td><td class="gsc_rsb_std">38</td><td class="gsc_rsb_std">30</td></tr><tr><td class="gsc_rsb_sc1"><a href="javascript:void(0)" class="gsc_rsb_f gs_ibl" title="i10-index is the number of publications with at least 10 citations. The second column has the &quot;recent&quot; version of this metric which is the number of publications that have received at least 10 new citations in the last 5 years.">i10-index</a></td><td class="gsc_rsb_std">115</td><td class="gsc_rsb_std">85</td></tr></tbody></table><style>.gsc_g_t{position:absolute;bottom:0;color:#777;font-size:11px;}.gsc_g_a{position:absolute;bottom:13px;width:15px;background:#777;}.gsc_g_a:hover,.gsc_g_a:focus,.gsc_g_a:active{text-decoration:none;cursor:default;}.gsc_g_al{position:absolute;bottom:15px;left:7px;color:#222;background:white;font-size:11px;padding:1px;border:1px solid #777;border-radius:1px;visibility:hidden;opacity:0;transition:opacity .218s,visibility 0s .218s;}.gsc_g_a:hover .gsc_g_al,.gsc_g_a:focus .gsc_g_al,.gsc_g_a:active .gsc_g_al{visibility:visible;opacity:1;transition:all 0s;}#gsc_md_hist{max-width:642px;}.gsc_md_hist_w{position:relative;overflow:hidden;margin-right:43px;}.gs_md_bdy .gsc_md_hist_w,.gs_el_ph .gsc_md_hist_w,.gs_el_ta .gsc_md_hist_w{overflow-x:auto;padding-bottom:16px;}.gsc_md_hist_b{position:relative;height:174px;width:100%;}.gsc_md_hist_b .gsc_g_a{bottom:auto;}.gsc_md_hist_b .gsc_g_t{bottom:auto;top:161px;}.gsc_md_hist_b:after{position:absolute;right:600px;content:"\00A0";}.gsc_g_hist_x{position:relative;margin-right:45px;}.gsc_g_hist_xl{position:absolute;right:8px;width:35px;}.gs_el_ta .gsc_g_hist_xl,.gs_el_ph .gsc_g_hist_xl{right:16px;}.gsc_g_hist_wrp{padding-top:32px;position:relative;}.gs_el_ta .gsc_g_hist_wrp,.gs_el_ph .gsc_g_hist_wrp{padding-right:8px;}.gs_md_bdy .gsc_g_hist_wrp{border-top:0;}.gs_el_tc .gs_md_bdy .gsc_g_hist_wrp:after,.gs_el_tc.gs_el_ph .gsc_g_hist_wrp:after,.gs_el_tc.gs_el_ta .gsc_g_hist_wrp:after{display:block;content:"";position:absolute;z-index:100;top:0;left:0;width:20px;height:100%;background-image:linear-gradient(to left,rgba(255,255,255,0),rgba(255,255,255,1) 80%);}.gsc_g_x,.gsc_g_xt{position:absolute;left:0;border-bottom:1px solid #eee;width:100%;text-align:right;}.gsc_g_x{border-bottom:1px solid #eee;}.gsc_g_xtl{position:absolute;color:#777;}.gsc_g_gtr{position:absolute;}.gsc_g_a:last-child .gsc_g_al{right:0;left:auto;}</style><div class="gsc_g_hist_wrp" dir="rtl"><div class="gsc_g_hist_x"><div class="gsc_g_x" style="top:160px;"></div><div class="gsc_g_xt" style="top:0px;"></div><div class="gsc_g_xt" style="top:80px;"></div><div class="gsc_g_xt" style="top:120px;"></div><div class="gsc_g_xt" style="top:40px;"></div></div><div class="gsc_g_hist_xl"><div class="gsc_g_xtl" style="top:153px;">0</div><div class="gsc_g_xtl" style="top:-7px;">860</div><div class="gsc_g_xtl" style="top:73px;">430</div><div class="gsc_g_xtl" style="top:113px;">215</div><div class="gsc_g_xtl" style="top:33px;">645</div></div><div class="gsc_md_hist_w"><div class="gsc_md_hist_b"><span class="gsc_g_t" style="right:547px">2004</span><span class="gsc_g_t" style="right:515px">2005</span><span class="gsc_g_t" style="right:483px">2006</span><span class="gsc_g_t" style="right:451px">2007</span><span class="gsc_g_t" style="right:419px">2008</span><span class="gsc_g_t" style="right:387px">2009</span><span class="gsc_g_t" style="right:355px">2010</span><span class="gsc_g_t" style="right:323px">2011</span><span class="gsc_g_t" style="right:291px">2012</span><span class="gsc_g_t" style="right:259px">2013</span><span class="gsc_g_t" style="right:227px">2014</span><span class="gsc_g_t" style="right:195px">2015</span><span class="gsc_g_t" style="right:163px">2016</span><span class="gsc_g_t" style="right:131px">2017</span><span class="gsc_g_t" style="right:99px">2018</span><span class="gsc_g_t" style="right:67px">2019</span><span class="gsc_g_t" style="right:35px">2020</span><span class="gsc_g_t" style="right:3px">2021</span><a href="javascript:void(0)" class="gsc_g_a" style="right:552px;top:157px;height:3px;z-index:18"><span class="gsc_g_al">20</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:520px;top:153px;height:7px;z-index:17"><span class="gsc_g_al">40</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:488px;top:153px;height:7px;z-index:16"><span class="gsc_g_al">39</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:456px;top:149px;height:11px;z-index:15"><span class="gsc_g_al">63</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:424px;top:148px;height:12px;z-index:14"><span class="gsc_g_al">67</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:392px;top:148px;height:12px;z-index:13"><span class="gsc_g_al">69</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:360px;top:147px;height:13px;z-index:12"><span class="gsc_g_al">75</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:328px;top:137px;height:23px;z-index:11"><span class="gsc_g_al">124</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:296px;top:136px;height:24px;z-index:10"><span class="gsc_g_al">130</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:264px;top:129px;height:31px;z-index:9"><span class="gsc_g_al">167</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:232px;top:128px;height:32px;z-index:8"><span class="gsc_g_al">177</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:200px;top:121px;height:39px;z-index:7"><span class="gsc_g_al">213</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:168px;top:114px;height:46px;z-index:6"><span class="gsc_g_al">252</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:136px;top:98px;height:62px;z-index:5"><span class="gsc_g_al">337</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:104px;top:63px;height:97px;z-index:4"><span class="gsc_g_al">524</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:72px;top:24px;height:136px;z-index:3"><span class="gsc_g_al">732</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:40px;top:3px;height:157px;z-index:2"><span class="gsc_g_al">846</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:8px;top:46px;height:114px;z-index:1"><span class="gsc_g_al">616</span></a></div></div></div></div><div class="gsc_rsb_s gsc_prf_pnl" id="gsc_rsb_mnd" role="region" aria-labelledby="gsc_prf_t-mnd"><div class="gsc_rsb_header gsc_rsb_m_header"><div class="gsc_rsb_m_title">Public access</div><a href="/citations?view_op=list_mandates&amp;hl=en&amp;user=JQFnV5IAAAAJ" id="gsc_lwp_mndt_lnk">View all</a></div><div class="gsc_rsb_hm gs_ota gs_oph"><button type="button" onclick="window.location='/citations?view_op\x3dlist_mandates\x26hl\x3den\x26user\x3dJQFnV5IAAAAJ'" class=" gs_btn_flat gs_btn_flact gs_btn_lrge gs_btn_half gs_btn_lsu"><span class="gs_wr"><span class="gs_lbl">View all</span></span></button></div><div class="gsc_rsb_m"><div class="gsc_rsb_m_a"><span>117 articles</span></div><div class="gsc_rsb_m_na"><div>5 articles</div></div><div class="gsc_rsb_m_bar"><div class="gsc_rsb_m_bar_na" style="width:4%"></div></div><div class="gsc_rsb_m_a"><span>available</span></div><div class="gsc_rsb_m_na"><span>not available</span></div><div class="gsc_rsb_m_desc">Based on funding mandates</div></div></div><div class="gsc_rsb_s gsc_prf_pnl" id="gsc_rsb_co" role="region" aria-labelledby="gsc_prf_t-ath"><h3 class="gsc_rsb_header"><span class="gsc_rsb_title">Co-authors</span><button type="button" id="gsc_coauth_opn" class=" gs_btn_flat gs_btn_flact gs_btn_lrge gs_btn_half gs_btn_lsu gsc_rsb_action"><span class="gs_wr"><span class="gs_lbl">View all</span></span></button></h3><ul class="gsc_rsb_a"><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-28TCymYAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-28TCymYAAAAJ-img,.gs_el_ph #gsc_rsb-28TCymYAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-28TCymYAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Mark D. Plumbley" sizes="(max-width:981px) 56px,32px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=28TCymYAAAAJ&amp;citpid=4" id="gsc_rsb-28TCymYAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=28TCymYAAAAJ&amp;citpid=4 32w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=28TCymYAAAAJ&amp;citpid=4 56w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=28TCymYAAAAJ&amp;citpid=4 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=28TCymYAAAAJ&amp;hl=en">Mark D. Plumbley</a><span class="gsc_rsb_a_ext">Centre for Vision, Speech and Signal Processing (CVSSP), University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-UeOcj28AAAAJ-img{width:23px;height:32px;}.gs_el_ta #gsc_rsb-UeOcj28AAAAJ-img,.gs_el_ph #gsc_rsb-UeOcj28AAAAJ-img{width:40px;height:56px;}</style><span id="gsc_rsb-UeOcj28AAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Jonathon A Chambers" sizes="(max-width:981px) 40px,23px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=UeOcj28AAAAJ&amp;citpid=7" id="gsc_rsb-UeOcj28AAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=UeOcj28AAAAJ&amp;citpid=7 23w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=UeOcj28AAAAJ&amp;citpid=7 40w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=UeOcj28AAAAJ&amp;citpid=7 92w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=UeOcj28AAAAJ&amp;hl=en">Jonathon A Chambers</a><span class="gsc_rsb_a_ext">Emeritus Professor, University of Leicester; Int. Hon. Dean, Harbin Eng. Univ.</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at le.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-B6O3SycAAAAJ-img{width:26px;height:32px;}.gs_el_ta #gsc_rsb-B6O3SycAAAAJ-img,.gs_el_ph #gsc_rsb-B6O3SycAAAAJ-img{width:45px;height:56px;}</style><span id="gsc_rsb-B6O3SycAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Qiuqiang Kong" sizes="(max-width:981px) 45px,26px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=B6O3SycAAAAJ&amp;citpid=1" id="gsc_rsb-B6O3SycAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=B6O3SycAAAAJ&amp;citpid=1 26w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=B6O3SycAAAAJ&amp;citpid=1 45w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=B6O3SycAAAAJ&amp;citpid=1 102w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=B6O3SycAAAAJ&amp;hl=en">Qiuqiang Kong</a><span class="gsc_rsb_a_ext">PhD student, CVSSP, University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-nCmKPM4AAAAJ-img{width:28px;height:32px;}.gs_el_ta #gsc_rsb-nCmKPM4AAAAJ-img,.gs_el_ph #gsc_rsb-nCmKPM4AAAAJ-img{width:48px;height:56px;}</style><span id="gsc_rsb-nCmKPM4AAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Yong Xu" sizes="(max-width:981px) 48px,28px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=nCmKPM4AAAAJ&amp;citpid=5" id="gsc_rsb-nCmKPM4AAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=nCmKPM4AAAAJ&amp;citpid=5 28w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=nCmKPM4AAAAJ&amp;citpid=5 48w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=nCmKPM4AAAAJ&amp;citpid=5 111w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=nCmKPM4AAAAJ&amp;hl=en">Yong Xu</a><span class="gsc_rsb_a_ext">Principal Researcher, Tencent America, Bellevue, USA</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at tencent.com</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-vgue80YAAAAJ-img{width:26px;height:32px;}.gs_el_ta #gsc_rsb-vgue80YAAAAJ-img,.gs_el_ph #gsc_rsb-vgue80YAAAAJ-img{width:46px;height:56px;}</style><span id="gsc_rsb-vgue80YAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Philip J.B. Jackson" sizes="(max-width:981px) 46px,26px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=vgue80YAAAAJ&amp;citpid=2" id="gsc_rsb-vgue80YAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=vgue80YAAAAJ&amp;citpid=2 26w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=vgue80YAAAAJ&amp;citpid=2 46w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=vgue80YAAAAJ&amp;citpid=2 106w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=vgue80YAAAAJ&amp;hl=en">Philip J.B. Jackson</a><span class="gsc_rsb_a_ext">Reader, Univ. of Surrey (CVSSP), UK</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-3MdEZ-AAAAAJ-img{width:32px;height:27px;}.gs_el_ta #gsc_rsb-3MdEZ-AAAAAJ-img,.gs_el_ph #gsc_rsb-3MdEZ-AAAAAJ-img{width:56px;height:47px;}</style><span id="gsc_rsb-3MdEZ-AAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Syed Mohsen Naqvi" sizes="(max-width:981px) 56px,32px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=3MdEZ-AAAAAJ&amp;citpid=4" id="gsc_rsb-3MdEZ-AAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=3MdEZ-AAAAAJ&amp;citpid=4 32w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=3MdEZ-AAAAAJ&amp;citpid=4 56w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=3MdEZ-AAAAAJ&amp;citpid=4 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=3MdEZ-AAAAAJ&amp;hl=en">Syed Mohsen Naqvi</a><span class="gsc_rsb_a_ext">School of Engineering, Newcastle University, United Kingdom</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at newcastle.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-0vksjrEAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-0vksjrEAAAAJ-img,.gs_el_ph #gsc_rsb-0vksjrEAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-0vksjrEAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Qingju LIU" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-0vksjrEAAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=0vksjrEAAAAJ&amp;hl=en">Qingju LIU</a><span class="gsc_rsb_a_ext">Research Fellow, University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-zUaubUQAAAAJ-img{width:25px;height:32px;}.gs_el_ta #gsc_rsb-zUaubUQAAAAJ-img,.gs_el_ph #gsc_rsb-zUaubUQAAAAJ-img{width:44px;height:56px;}</style><span id="gsc_rsb-zUaubUQAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Saeid Sanei" sizes="(max-width:981px) 44px,25px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=zUaubUQAAAAJ&amp;citpid=3" id="gsc_rsb-zUaubUQAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=zUaubUQAAAAJ&amp;citpid=3 25w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=zUaubUQAAAAJ&amp;citpid=3 44w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=zUaubUQAAAAJ&amp;citpid=3 99w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=zUaubUQAAAAJ&amp;hl=en">Saeid Sanei</a><span class="gsc_rsb_a_ext">NTU</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at ntu.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-9RQZKQMAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-9RQZKQMAAAAJ-img,.gs_el_ph #gsc_rsb-9RQZKQMAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-9RQZKQMAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Mark Barnard" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-9RQZKQMAAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=9RQZKQMAAAAJ&amp;hl=en">Mark Barnard</a><span class="gsc_rsb_a_ext">Research Fellow, CVSSP, University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-Vtc4nscAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-Vtc4nscAAAAJ-img,.gs_el_ph #gsc_rsb-Vtc4nscAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-Vtc4nscAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Turab Iqbal" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-Vtc4nscAAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=Vtc4nscAAAAJ&amp;hl=en">Turab Iqbal</a><span class="gsc_rsb_a_ext">Centre for Vision, Speech and Signal Processing (CVSSP), University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-pk-yb_kAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-pk-yb_kAAAAJ-img,.gs_el_ph #gsc_rsb-pk-yb_kAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-pk-yb_kAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Josef Kittler" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-pk-yb_kAAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=pk-yb_kAAAAJ&amp;hl=en">Josef Kittler</a><span class="gsc_rsb_a_ext">University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-J9edRm4AAAAJ-img{width:21px;height:32px;}.gs_el_ta #gsc_rsb-J9edRm4AAAAJ-img,.gs_el_ph #gsc_rsb-J9edRm4AAAAJ-img{width:37px;height:56px;}</style><span id="gsc_rsb-J9edRm4AAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Yin Cao" sizes="(max-width:981px) 37px,21px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=J9edRm4AAAAJ&amp;citpid=1" id="gsc_rsb-J9edRm4AAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=J9edRm4AAAAJ&amp;citpid=1 21w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=J9edRm4AAAAJ&amp;citpid=1 37w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=J9edRm4AAAAJ&amp;citpid=1 85w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=J9edRm4AAAAJ&amp;hl=en">Yin Cao</a><span class="gsc_rsb_a_ext">University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-k75IPyEAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-k75IPyEAAAAJ-img,.gs_el_ph #gsc_rsb-k75IPyEAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-k75IPyEAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Wei Dai" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-k75IPyEAAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=k75IPyEAAAAJ&amp;hl=en">Wei Dai</a><span class="gsc_rsb_a_ext">Imperial College London</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at imperial.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-ryLVnDwAAAAJ-img{width:22px;height:32px;}.gs_el_ta #gsc_rsb-ryLVnDwAAAAJ-img,.gs_el_ph #gsc_rsb-ryLVnDwAAAAJ-img{width:39px;height:56px;}</style><span id="gsc_rsb-ryLVnDwAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Volkan KILIC" sizes="(max-width:981px) 39px,22px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=ryLVnDwAAAAJ&amp;citpid=5" id="gsc_rsb-ryLVnDwAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=ryLVnDwAAAAJ&amp;citpid=5 22w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=ryLVnDwAAAAJ&amp;citpid=5 39w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=ryLVnDwAAAAJ&amp;citpid=5 90w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=ryLVnDwAAAAJ&amp;hl=en">Volkan KILIC</a><span class="gsc_rsb_a_ext">University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-sfyr7zMAAAAJ-img{width:27px;height:32px;}.gs_el_ta #gsc_rsb-sfyr7zMAAAAJ-img,.gs_el_ph #gsc_rsb-sfyr7zMAAAAJ-img{width:48px;height:56px;}</style><span id="gsc_rsb-sfyr7zMAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Yuexian Zou" sizes="(max-width:981px) 48px,27px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=sfyr7zMAAAAJ&amp;citpid=2" id="gsc_rsb-sfyr7zMAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=sfyr7zMAAAAJ&amp;citpid=2 27w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=sfyr7zMAAAAJ&amp;citpid=2 48w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=sfyr7zMAAAAJ&amp;citpid=2 109w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=sfyr7zMAAAAJ&amp;hl=en">Yuexian Zou</a><span class="gsc_rsb_a_ext">Peking University Shenzhen Graduate School</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at pkusz.edu.cn</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-wf60G1sAAAAJ-img{width:27px;height:32px;}.gs_el_ta #gsc_rsb-wf60G1sAAAAJ-img,.gs_el_ph #gsc_rsb-wf60G1sAAAAJ-img{width:48px;height:56px;}</style><span id="gsc_rsb-wf60G1sAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Jian Guan" sizes="(max-width:981px) 48px,27px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=wf60G1sAAAAJ&amp;citpid=4" id="gsc_rsb-wf60G1sAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=wf60G1sAAAAJ&amp;citpid=4 27w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=wf60G1sAAAAJ&amp;citpid=4 48w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=wf60G1sAAAAJ&amp;citpid=4 109w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=wf60G1sAAAAJ&amp;hl=en">Jian Guan</a><span class="gsc_rsb_a_ext">Group of Intelligent Signal Processing, CCST, Harbin Engineering University</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at hrbeu.edu.cn</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-g9L-JiEAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-g9L-JiEAAAAJ-img,.gs_el_ph #gsc_rsb-g9L-JiEAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-g9L-JiEAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Tao Xu" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-g9L-JiEAAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=g9L-JiEAAAAJ&amp;hl=en">Tao Xu</a><span class="gsc_rsb_a_ext">Centre for Vision, Speech and Signal Processing, University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-OT2FXYkAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-OT2FXYkAAAAJ-img,.gs_el_ph #gsc_rsb-OT2FXYkAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-OT2FXYkAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Qiang Huang" sizes="(max-width:981px) 56px,32px" src="/citations/images/avatar_scholar_56.png" id="gsc_rsb-OT2FXYkAAAAJ-img" class="gs_pp_df" srcset="/citations/images/avatar_scholar_32.png 32w,/citations/images/avatar_scholar_56.png 56w,/citations/images/avatar_scholar_128.png 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=OT2FXYkAAAAJ&amp;hl=en">Qiang Huang</a><span class="gsc_rsb_a_ext">Lecturer, School of Computing and Engineering, University of West London</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at sheffield.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-oC54ovYAAAAJ-img{width:23px;height:32px;}.gs_el_ta #gsc_rsb-oC54ovYAAAAJ-img,.gs_el_ph #gsc_rsb-oC54ovYAAAAJ-img{width:41px;height:56px;}</style><span id="gsc_rsb-oC54ovYAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Yang Liu" sizes="(max-width:981px) 41px,23px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=oC54ovYAAAAJ&amp;citpid=3" id="gsc_rsb-oC54ovYAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=oC54ovYAAAAJ&amp;citpid=3 23w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=oC54ovYAAAAJ&amp;citpid=3 41w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=oC54ovYAAAAJ&amp;citpid=3 93w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=oC54ovYAAAAJ&amp;hl=en">Yang Liu</a><span class="gsc_rsb_a_ext">Zoom</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at microsoft.com</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li><li><div class="gsc_rsb_aa" tabindex="0"><style>#gsc_rsb-vTIYTNQAAAAJ-img{width:32px;height:32px;}.gs_el_ta #gsc_rsb-vTIYTNQAAAAJ-img,.gs_el_ph #gsc_rsb-vTIYTNQAAAAJ-img{width:56px;height:56px;}</style><span id="gsc_rsb-vTIYTNQAAAAJ" class="gs_rimg gs_pp_tn gs_pp_mo_sm gsc_rsb_a_pht"><img alt="Adrian Hilton" sizes="(max-width:981px) 56px,32px" src="https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=vTIYTNQAAAAJ&amp;citpid=6" id="gsc_rsb-vTIYTNQAAAAJ-img" class="gs_pp_df" srcset="https://scholar.googleusercontent.com/citations?view_op=tiny_photo&amp;user=vTIYTNQAAAAJ&amp;citpid=6 32w,https://scholar.googleusercontent.com/citations?view_op=small_photo&amp;user=vTIYTNQAAAAJ&amp;citpid=6 56w,https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=vTIYTNQAAAAJ&amp;citpid=6 128w"></span><span class="gsc_rsb_a_desc"><a tabindex="-1" href="/citations?user=vTIYTNQAAAAJ&amp;hl=en">Adrian Hilton</a><span class="gsc_rsb_a_ext">Professor of Computer Vision &amp; Graphics,  University of Surrey</span><span class="gsc_rsb_a_ext gsc_rsb_a_ext2">Verified email at surrey.ac.uk</span><span class="gsc_rsb_tap"><span class="gs_btnPR"><span class="gs_ico"></span></span></span></span></div></li></ul><div class="gsc_rsb_hmv gs_ota gs_oph"><button type="button" class=" gs_btn_flat gs_btn_flact gs_btn_lrge gs_btn_lsu gsc_rsb_btnv"><span class="gs_wr"><span class="gs_lbl">View all</span></span></button></div></div></div><div class="gsc_lcl" role="main" id="gsc_prf_w"><div id="gsc_prf"><button type="button" id="gsc_prf_btnf" class="gs_btnMW gs_in_ib gs_btn_act gs_btn_lsu gs_btn_mph"><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl">Follow</span></span></button><div id="gsc_prf_pu"><div id="gsc_prf_pua" class="gs_rimg"><style>#gsc_prf_pup-img{width:101px;height:128px;}@media print{#gs_top #gsc_prf_pup-img{width:63pt;height:80pt;}}</style><img alt="Wenwu Wang" sizes="print 63px,101px" src="https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=JQFnV5IAAAAJ&amp;citpid=6" id="gsc_prf_pup-img" srcset="https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=JQFnV5IAAAAJ&amp;citpid=6 101w,https://scholar.googleusercontent.com/citations?view_op=medium_photo&amp;user=JQFnV5IAAAAJ&amp;citpid=6 202w"></div></div><div id="gsc_prf_i"><div id="gsc_prf_in">Wenwu Wang</div><div class="gsc_prf_il">Professor, <a href="/citations?view_op=view_org&amp;hl=en&amp;org=5559442388202218053" class="gsc_prf_ila">University of Surrey</a> (CVSSP), UK</div><div class="gsc_prf_il" id="gsc_prf_ivh">Verified email at surrey.ac.uk - <a href="http://personal.ee.surrey.ac.uk/Personal/W.Wang/" rel="nofollow" class="gsc_prf_ila">Homepage</a></div><div class="gsc_prf_il" id="gsc_prf_int"><a href="/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:signal_processing" class="gsc_prf_inta gs_ibl">signal processing</a><a href="/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:machine_learning" class="gsc_prf_inta gs_ibl">machine learning</a><a href="/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:audio_speech_audio_visual" class="gsc_prf_inta gs_ibl">audio/speech/audio-visual</a><a href="/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:information_fusion" class="gsc_prf_inta gs_ibl">information fusion</a></div></div></div></div><div id="gsc_prf_t_wrp" role="navigation"><div id="gsc_prf_t" role="tablist"><a id="gsc_prf_t-art" class="gsc_prf_tab" href="javascript:void(0)" role="tab" aria-controls="gsc_art" aria-selected="true">Articles</a><a id="gsc_prf_t-cit" class="gsc_prf_tab" href="javascript:void(0)" role="tab" aria-controls="gsc_rsb_cit">Cited by</a><a id="gsc_prf_t-mnd" class="gsc_prf_tab" href="javascript:void(0)" role="tab" aria-controls="gsc_rsb_mnd">Public access</a><a id="gsc_prf_t-ath" class="gsc_prf_tab" href="javascript:void(0)" role="tab" aria-controls="gsc_rsb_co">Co-authors</a></div></div><div class="gsc_lcl gsc_prf_pnl" id="gsc_art" role="region" aria-labelledby="gsc_prf_t-art"><form method="post" action="/citations?hl=en&amp;user=JQFnV5IAAAAJ&amp;view_op=list_works"><input type="hidden" name="xsrf" value="AMD79ooAAAAAYTYJFqx5FH4_74ojlFtjwrFpjOFUFeYQ"><div id="gsc_a_tw"><table id="gsc_a_t"><thead><tr id="gsc_a_tr0" aria-hidden="true"><th class="gsc_a_t"></th><th class="gsc_a_c"></th><th class="gsc_a_y"></th></tr><tr id="gsc_a_trh"><th class="gsc_a_t" scope="col"><span id="gsc_a_ta"><a href="/citations?hl=en&amp;user=JQFnV5IAAAAJ&amp;view_op=list_works&amp;sortby=title" class="gsc_a_a">Title</a></span><div id="gsc_dd_sort-r" class="gs_md_r gs_md_rmb gs_md_rmbl"><button type="button" id="gsc_dd_sort-b" aria-controls="gsc_dd_sort-d" aria-haspopup="true" ontouchstart="gs_evt_dsp(event)" class=" gs_in_se gs_btn_mnu gs_btn_flat gs_btn_lrge gs_btn_half gs_btn_lsu gs_press gs_md_tb"><span class="gs_wr"><span class="gs_lbl">Sort</span><span class="gs_icm"></span></span></button><div id="gsc_dd_sort-d" class="gs_md_d gs_md_ulr" role="menu" tabindex="-1"><div id="gsc_dd_sort-s" class="gs_oph gsc_dd_sec gsc_dd_sep"><a role="menuitem" href="/citations?hl=en&amp;user=JQFnV5IAAAAJ&amp;view_op=list_works" tabindex="-1" class="gs_md_li gsc_dd_sort-sel">Sort by citations</a><a role="menuitem" href="/citations?hl=en&amp;user=JQFnV5IAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" tabindex="-1" class="gs_md_li">Sort by year</a><a role="menuitem" href="/citations?hl=en&amp;user=JQFnV5IAAAAJ&amp;view_op=list_works&amp;sortby=title" tabindex="-1" class="gs_md_li">Sort by title</a></div></div></div></th><th class="gsc_a_c" scope="col" dir="rtl"><span id="gsc_a_ca"><div class="gs_nph">Cited by</div><div class="gs_oph">Cited by</div></span></th><th class="gsc_a_y" scope="col"><span class="gsc_a_h" id="gsc_a_ha"><a href="/citations?hl=en&amp;user=JQFnV5IAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" class="gsc_a_a">Year</a></span></th></tr></thead><tbody id="gsc_a_b"><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:oursBaop5wYC" class="gsc_a_at">Large-scale weakly supervised audio classification using gated convolutional neural network</a><div class="gs_gray">Y Xu, Q Kong, W Wang, MD Plumbley</div><div class="gs_gray">2018 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5884218640549640327" class="gsc_a_ac gs_ibl">177</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:9ZlFYXVOiuMC" class="gsc_a_at">Simultaneous Codeword Optimization (SimCO) for Dictionary Update and Learning</a><div class="gs_gray">W Dai, T Xu, W Wang</div><div class="gs_gray">IEEE Transactions on Signal Processing 60 (12), 6340-6353<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14158417386224970677" class="gsc_a_ac gs_ibl">129</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:BPS1z4jHU5cC" class="gsc_a_at">Panns: Large-scale pretrained audio neural networks for audio pattern recognition</a><div class="gs_gray">Q Kong, Y Cao, T Iqbal, Y Wang, W Wang, MD Plumbley</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech, and Language Processing 28, 2880-2894<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9554371435468861681" class="gsc_a_ac gs_ibl">122</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:u5HHmVD_uO8C" class="gsc_a_at">Penalty function-based joint diagonalization approach for convolutive blind separation of nonstationary sources</a><div class="gs_gray">W Wang, S Sanei, JA Chambers</div><div class="gs_gray">IEEE Transactions on Signal Processing 53 (5), 1654-1669<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2482681450270868377" class="gsc_a_ac gs_ibl">94</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:rqnDXT1GswoC" class="gsc_a_at">Blind source separation: Advances in theory, algorithms and applications</a><div class="gs_gray">GR Naik, W Wang</div><div class="gs_gray">Springer<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15328517054211846319" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="JQFnV5IAAAAJ:rqnDXT1GswoC" data-eud="JQFnV5IAAAAJ:PQEM9vzQD9gC">85</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:PQEM9vzQD9gC" class="gsc_a_at">Blind source separation</a><div class="gs_gray">GR Naik, W Wang</div><div class="gs_gray">Berlin: Springer 10, 978-3<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15328517054211846319" class="gsc_a_ac gs_ibl">85</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:W7OEmFMy1HYC" class="gsc_a_at">Note onset detection via nonnegative factorization of magnitude spectrum</a><div class="gs_gray">W Wang, Y Luo, JA Chambers, S Sanei</div><div class="gs_gray">EURASIP Journal on Advances in Signal Processing 2008 (19)<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5116686972482387287,11620190192978378856" class="gsc_a_ac gs_ibl">85</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="JQFnV5IAAAAJ:W7OEmFMy1HYC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:gV6rEsy15s0C" class="gsc_a_at">Audio set classification with attention model: A probabilistic perspective</a><div class="gs_gray">Q Kong, Y Xu, W Wang, MD Plumbley</div><div class="gs_gray">2018 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14763329651806150067" class="gsc_a_ac gs_ibl">84</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:xGWFX6Gbr9MC" class="gsc_a_at">Heterogeneous feature selection with multi-modal deep neural networks and sparse group lasso</a><div class="gs_gray">L Zhao, Q Hu, W Wang</div><div class="gs_gray">IEEE Transactions on Multimedia 17 (11), 1936-1948<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5770708357294717828" class="gsc_a_ac gs_ibl">78</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:v_tt_AnqfNMC" class="gsc_a_at">Convolutional gated recurrent neural network incorporating spatial features for audio tagging</a><div class="gs_gray">Y Xu, Q Kong, Q Huang, W Wang, MD Plumbley</div><div class="gs_gray">2017 International Joint Conference on Neural Networks (IJCNN), 3461-3466<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6718675045285906002" class="gsc_a_ac gs_ibl">77</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:u-x6o8ySG0sC" class="gsc_a_at">Video assisted speech source separation</a><div class="gs_gray">W Wang, D Cosker, Y Hicks, S Sanei, J Chambers</div><div class="gs_gray">Acoustics, Speech, and Signal Processing, 2005. Proceedings.(ICASSP'05&nbsp;…<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14982832701320862822" class="gsc_a_ac gs_ibl">77</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:GYcXSSpN504C" class="gsc_a_at">Unsupervised feature learning based on deep models for environmental audio tagging</a><div class="gs_gray">Y Xu, Q Huang, W Wang, P Foster, S Sigtia, PJB Jackson, MD Plumbley</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech, and Language Processing 25 (6), 1230&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14752659927723962208" class="gsc_a_ac gs_ibl">74</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:lK9BDNCuzFgC" class="gsc_a_at">Audio assisted robust visual tracking with adaptive particle filtering</a><div class="gs_gray">V Kılıç, M Barnard, W Wang, J Kittler</div><div class="gs_gray">IEEE Transactions on Multimedia 17 (2), 186-200<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13488001543978177663" class="gsc_a_ac gs_ibl">74</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:d1gkVwhDpl0C" class="gsc_a_at">Variable step-size sign natural gradient algorithm for sequential blind source separation</a><div class="gs_gray">L Yuan, W Wang, JA Chambers</div><div class="gs_gray">IEEE Signal Processing Letters 12 (8), 589-592<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1578444629845229435" class="gsc_a_ac gs_ibl">73</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:ufrVoPGSRksC" class="gsc_a_at">A multiplicative algorithm for convolutive non-negative matrix factorization based on squared Euclidean distance</a><div class="gs_gray">W Wang, A Cichocki, JA Chambers</div><div class="gs_gray">Signal Processing, IEEE Transactions on 57 (7), 2858-2864<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14794711463772299145" class="gsc_a_ac gs_ibl">72</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:8uzoZH4hB9AC" class="gsc_a_at">Sound Event Detection and Time–Frequency Segmentation from Weakly Labelled Data</a><div class="gs_gray">Q Kong, Y Xu, I Sobieraj, W Wang, MD Plumbley</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP) 27 (4&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14809952285431992104" class="gsc_a_ac gs_ibl">71</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:3lUAU8Oskd0C" class="gsc_a_at">Deep neural network baseline for DCASE challenge 2016</a><div class="gs_gray">Q Kong, I Sobieraj, W Wang, MD Plumbley</div><div class="gs_gray">Proceedings of DCASE 2016<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9126832055753471262" class="gsc_a_ac gs_ibl">71</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:wSy_KLzO7YEC" class="gsc_a_at">Tensor dictionary learning with sparse tucker decomposition</a><div class="gs_gray">S Zubair, W Wang</div><div class="gs_gray">2013 18th International Conference on Digital Signal Processing (DSP), 1-6<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15409867488332000520" class="gsc_a_ac gs_ibl">68</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:sfnaS5RM6jYC" class="gsc_a_at">Audiovisual speech source separation: An overview of key methodologies</a><div class="gs_gray">B Rivet, W Wang, SM Naqvi, JA Chambers</div><div class="gs_gray">IEEE Signal Processing Magazine 31 (3), 125-134<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5772641327347355053" class="gsc_a_ac gs_ibl">67</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;citation_for_view=JQFnV5IAAAAJ:i91s68tWr-MC" class="gsc_a_at">Cross-task learning for audio tagging, sound event detection and spatial localization: DCASE 2019 baseline systems</a><div class="gs_gray">Q Kong, Y Cao, T Iqbal, Y Xu, W Wang, MD Plumbley</div><div class="gs_gray">arXiv preprint arXiv:1904.03476<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14149199278275690462" class="gsc_a_ac gs_ibl">54</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:XAp-VaTZjjwC" class="gsc_a_at">Attention and Localization based on a Deep Convolutional Recurrent Model for Weakly Supervised Audio Tagging</a><div class="gs_gray">Y Xu, Q Kong, Q Huang, W Wang, MD Plumbley</div><div class="gs_gray">arXiv preprint arXiv:1703.06052<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3833600658102524830" class="gsc_a_ac gs_ibl">52</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:lYAcb2jw7qUC" class="gsc_a_at">Dictionary learning based sparse coefficients for audio classification with max and average pooling</a><div class="gs_gray">S Zubair, F Yan, W Wang</div><div class="gs_gray">Digital Signal Processing 23 (3), 960-970<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13725882578536484837" class="gsc_a_ac gs_ibl">51</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:3A3nxV7CjKIC" class="gsc_a_at">A joint detection-classification model for audio tagging of weakly labelled data</a><div class="gs_gray">Q Kong, Y Xu, W Wang, MD Plumbley</div><div class="gs_gray">Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15067074143065910173" class="gsc_a_ac gs_ibl">49</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:WF5omc3nYNoC" class="gsc_a_at">A compressed sensing approach for underdetermined blind audio source separation with sparse representation</a><div class="gs_gray">T Xu, W Wang</div><div class="gs_gray">2009 IEEE/SP 15th Workshop on Statistical Signal Processing, 493-496<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3777489386711487236" class="gsc_a_ac gs_ibl">49</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:LWqeokA2EBkC" class="gsc_a_at">Weakly Labelled AudioSet Tagging With Attention Neural Networks</a><div class="gs_gray">Q Kong, C Yu, Y Xu, T Iqbal, W Wang, MD Plumbley</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech, and Language Processing 27 (11&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16181447850812716944" class="gsc_a_ac gs_ibl">48</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:Gb6Hms-Uo9kC" class="gsc_a_at">Polyphonic Sound Event Detection and Localization using a Two-Stage Strategy</a><div class="gs_gray">Y Cao, Q Kong, T Iqbal, F An, W Wang, MD Plumbley</div><div class="gs_gray">arXiv preprint arXiv:1905.00268<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16243552768554090849" class="gsc_a_ac gs_ibl">47</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:2osOgNQ5qMEC" class="gsc_a_at">Sequential blind source separation based exclusively on second-order statistics developed for a class of periodic signals</a><div class="gs_gray">MG Jafari, W Wang, JA Chambers, T Hoya, A Cichocki</div><div class="gs_gray">IEEE Transactions on Signal Processing 54 (3), 1028-1040<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8451094831610125995" class="gsc_a_ac gs_ibl">46</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:Se3iqnhoufwC" class="gsc_a_at">A multistage approach to blind separation of convolutive speech mixtures</a><div class="gs_gray">T Jan, W Wang, DL Wang</div><div class="gs_gray">Speech Communication 53 (4), 524-539<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9277462405243605372" class="gsc_a_ac gs_ibl">45</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:5LPo_wSKItgC" class="gsc_a_at">A multistage approach to blind separation of convolutive speech mixtures</a><div class="gs_gray">T Jan, W Wang, DL Wang</div><div class="gs_gray">Speech Communication 53 (4), 524-539<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9277462405243605372" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="JQFnV5IAAAAJ:5LPo_wSKItgC" data-eud="JQFnV5IAAAAJ:Se3iqnhoufwC">45</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:9yKSN-GCB0IC" class="gsc_a_at">A novel hybrid approach to the permutation problem of frequency domain blind source separation</a><div class="gs_gray">W Wang, JA Chambers, S Sanei</div><div class="gs_gray">International Conference on Independent Component Analysis and Signal&nbsp;…<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12737819893152873840" class="gsc_a_ac gs_ibl">45</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:IjCSPb-OGe4C" class="gsc_a_at">Exploitation of source nonstationarity in underdetermined blind source separation with advanced clustering techniques</a><div class="gs_gray">Y Luo, W Wang, JA Chambers, S Lambotharan, I Proudler</div><div class="gs_gray">IEEE Transactions on Signal Processing 54 (6), 2198-2212<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13923840402563768739" class="gsc_a_ac gs_ibl">44</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:UeHWp8X0CEIC" class="gsc_a_at">Removal of eye blinking artifact from the electro-encephalogram, incorporating a new constrained blind source separation algorithm</a><div class="gs_gray">L Shoker, S Sanei, W Wang, JA Chambers</div><div class="gs_gray">Medical and Biological Engineering and Computing 43 (2), 290-295<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7484713814077304188" class="gsc_a_ac gs_ibl">44</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:wGzT3bKASkAC" class="gsc_a_at">DCASE 2018 challenge surrey cross-task convolutional neural network baseline</a><div class="gs_gray">Q Kong, T Iqbal, Y Xu, W Wang, MD Plumbley</div><div class="gs_gray">arXiv preprint arXiv:1808.00773<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10030635746648879515" class="gsc_a_ac gs_ibl">43</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:K4-iKlO5MD4C" class="gsc_a_at">DCASE 2018 Challenge Surrey Cross-task convolutional neural network baseline</a><div class="gs_gray">Q Kong, T Iqbal, Y Xu, W Wang, MD Plumbley</div><div class="gs_gray">DCASE2018 Workshop<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10030635746648879515" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="JQFnV5IAAAAJ:K4-iKlO5MD4C" data-eud="JQFnV5IAAAAJ:wGzT3bKASkAC">43</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:1r-w4gtu6w8C" class="gsc_a_at">Joint mixing vector and binaural model based stereo source separation</a><div class="gs_gray">A Alinaghi, PJB Jackson, Q Liu, W Wang</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech, and Language Processing 22 (9), 1434&nbsp;…<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8470632480455357484" class="gsc_a_ac gs_ibl">41</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:h168fVGZblEC" class="gsc_a_at">Acoustic Reflector Localization: Novel Image Source Reversion and Direct Localization Methods</a><div class="gs_gray">L Remaggi, PJB Jackson, P Coleman, W Wang, L Remaggi, PJB Jackson, ...</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP) 25 (2&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12799605904109690239" class="gsc_a_ac gs_ibl">40</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:kUhpeDhEZMUC" class="gsc_a_at">Localization based stereo speech source separation using probabilistic time-frequency masking and deep neural networks</a><div class="gs_gray">Y Yu, W Wang, P Han</div><div class="gs_gray">EURASIP Journal on Audio, Speech, and Music Processing 2016 (1), 1-18<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10542918790172977293" class="gsc_a_ac gs_ibl">40</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:fPk4N6BV_jEC" class="gsc_a_at">Multimodal (audio–visual) source separation exploiting multi-speaker tracking, robust beamforming and time–frequency masking</a><div class="gs_gray">SM Naqvi, W Wang, MS Khan, M Barnard, JA Chambers</div><div class="gs_gray">IET signal processing 6 (5), 466-477<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5178767331953801950" class="gsc_a_ac gs_ibl">40</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:TGkaJS32XoUC" class="gsc_a_at">Social Force Model-Based MCMC-OCSVM Particle PHD Filter for Multiple Human Tracking</a><div class="gs_gray">P Feng, W Wang, S Dlay, SM Naqvi, J Chambers</div><div class="gs_gray">IEEE Transactions on Multimedia 19 (4), 725-739<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1051741728719875217" class="gsc_a_ac gs_ibl">38</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:pyW8ca7W8N0C" class="gsc_a_at">Preface of Machine Audition: Principles, Algorithms and Systems</a><div class="gs_gray">W Wang</div><div class="gs_gray">Information Science Reference<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6279200043421493384" class="gsc_a_ac gs_ibl">38</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="JQFnV5IAAAAJ:pyW8ca7W8N0C">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:oqD4_j7ulsYC" class="gsc_a_at">Machine Audition: Principles, Algorithms and Systems: Principles, Algorithms and Systems</a><div class="gs_gray">W Wang</div><div class="gs_gray">IGI Global<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6279200043421493384" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="JQFnV5IAAAAJ:oqD4_j7ulsYC" data-eud="JQFnV5IAAAAJ:pyW8ca7W8N0C">38</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:LkGwnXOMwfcC" class="gsc_a_at">A new variable step-size LMS algorithm with robustness to nonstationary noise</a><div class="gs_gray">Y Zhang, JA Chambers, W Wang, P Kendrick, TJ Cox</div><div class="gs_gray">2007 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8263127918015370297" class="gsc_a_ac gs_ibl">38</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:ZeXyd9-uunAC" class="gsc_a_at">多媒体定时器的定制和使用方法</a><div class="gs_gray">王文武， 王诚， 郝燕玲， 周建新</div><div class="gs_gray">计算机应用 20 (3), 39-42<span class="gs_oph">, 2000</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16498674880789497742" class="gsc_a_ac gs_ibl">38</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2000</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:KTwcwpFFj4wC" class="gsc_a_at">Analysis SimCO algorithms for sparse analysis model based dictionary learning</a><div class="gs_gray">J Dong, W Wang, W Dai, MD Plumbley, ZF Han, J Chambers</div><div class="gs_gray">IEEE Transactions on Signal Processing 64 (2), 417-431<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11926892681187958555" class="gsc_a_ac gs_ibl">37</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:qsWQJNntlusC" class="gsc_a_at">Momentum fractional LMS for power signal parameter estimation</a><div class="gs_gray">S Zubair, NI Chaudhary, ZA Khan, W Wang</div><div class="gs_gray">Signal Processing 142, 441-449<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15462704133516373039" class="gsc_a_ac gs_ibl">36</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:qPeb-qHga9sC" class="gsc_a_at">Mean-shift and sparse sampling-based SMC-PHD filtering for audio informed visual speaker tracking</a><div class="gs_gray">V Kılıç, M Barnard, W Wang, A Hilton, J Kittler</div><div class="gs_gray">IEEE Transactions on Multimedia 18 (12), 2417-2431<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16615722694892641965" class="gsc_a_ac gs_ibl">35</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:Ic1VZgkJnDsC" class="gsc_a_at">Source separation of convolutive and noisy mixtures using audio-visual dictionary learning and probabilistic time-frequency masking</a><div class="gs_gray">Q Liu, W Wang, PJB Jackson, M Barnard, J Kittler, J Chambers</div><div class="gs_gray">IEEE Transactions on Signal Processing 61 (22), 5520-5535<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11900007666671350604" class="gsc_a_ac gs_ibl">33</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:nqdriD65xNoC" class="gsc_a_at">Sparse coding with adaptive dictionary learning for underdetermined blind speech separation</a><div class="gs_gray">T Xu, W Wang, W Dai</div><div class="gs_gray">Speech Communication 55 (3), 432-450<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14912554904384818010" class="gsc_a_ac gs_ibl">32</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:X4-KO54GjGYC" class="gsc_a_at">A perceptually-weighted deep neural network for monaural speech enhancement in various background noise conditions</a><div class="gs_gray">Q Liu, W Wang, PJB Jackson, Y Tang</div><div class="gs_gray">2017 25th European Signal Processing Conference (EUSIPCO), 1270-1274<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5697792485319847863" class="gsc_a_ac gs_ibl">31</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:M_lZXyI38BkC" class="gsc_a_at">Particle Flow SMC-PHD Filter for Audio-Visual Multi-speaker Tracking</a><div class="gs_gray">Y Liu, W Wang, J Chambers, V Kilic, A Hilton</div><div class="gs_gray">International Conference on Latent Variable Analysis and Signal Separation&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1109338506022966046" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="JQFnV5IAAAAJ:M_lZXyI38BkC" data-eud="JQFnV5IAAAAJ:RXiHnyRawswC">31</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:RXiHnyRawswC" class="gsc_a_at">Particle ow SMC-PHD lter for audio-visual multi-speaker tracking</a><div class="gs_gray">Y Liu, W Wang, J Chambers, V Kilic, A Hilton</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1109338506022966046" class="gsc_a_ac gs_ibl">31</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="JQFnV5IAAAAJ:RXiHnyRawswC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:37UQlXuwjP4C" class="gsc_a_at">Robust multi-speaker tracking via dictionary learning and identity modeling</a><div class="gs_gray">M Barnard, P Koniusz, W Wang, J Kittler, SM Naqvi, J Chambers</div><div class="gs_gray">IEEE Transactions on Multimedia 16 (3), 864-880<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12473488061842549608" class="gsc_a_ac gs_ibl">31</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:BOlwja0KXvYC" class="gsc_a_at">Video-aided model-based source separation in real reverberant rooms</a><div class="gs_gray">MS Khan, SM Naqvi, W Wang, J Chambers</div><div class="gs_gray">IEEE Transactions on Audio, Speech, and Language Processing 21 (9), 1900-1912<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14711946838544212977" class="gsc_a_ac gs_ibl">31</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:Cvh0bltMcLgC" class="gsc_a_at">IENet: Interacting embranchment one stage anchor free detector for orientation aerial object detection</a><div class="gs_gray">Y Lin, P Feng, J Guan, W Wang, J Chambers</div><div class="gs_gray">arXiv preprint arXiv:1912.00969<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15229508077011814511" class="gsc_a_ac gs_ibl">29</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:WzTVkKNmPSkC" class="gsc_a_at">Sparse analysis model based multiplicative noise removal with enhanced regularization</a><div class="gs_gray">J Dong, Z Han, Y Zhao, W Wang, A Prochazka, J Chambers</div><div class="gs_gray">Signal Processing 137, 160-176<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17652700112784263725" class="gsc_a_ac gs_ibl">29</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:0ngZmJvimKcC" class="gsc_a_at">Surrey-cvssp system for DCASE2017 challenge task4</a><div class="gs_gray">Y Xu, Q Kong, W Wang, MD Plumbley</div><div class="gs_gray">arXiv preprint arXiv:1709.00551<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17315132948634632699" class="gsc_a_ac gs_ibl">28</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:mVmsd5A6BfQC" class="gsc_a_at">A visual voice activity detection method with adaboosting</a><div class="gs_gray">Q Liu, W Wang, P Jackson</div><div class="gs_gray">Sensor Signal Processing for Defence (SSPD 2011), 1-5<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1737003048525772207" class="gsc_a_ac gs_ibl">28</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:17ZO-CJnx_8C" class="gsc_a_at">Capsule routing for sound event detection</a><div class="gs_gray">T Iqbal, Y Xu, Q Kong, W Wang</div><div class="gs_gray">2018 26th European Signal Processing Conference (EUSIPCO), 2255-2259<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14137573692044627244" class="gsc_a_ac gs_ibl">27</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:rbGdIwl2e6cC" class="gsc_a_at">Particle flow for sequential monte carlo implementation of probability hypothesis density</a><div class="gs_gray">Y Liu, W Wang, Y Zhao</div><div class="gs_gray">2017 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10046541109855703157" class="gsc_a_ac gs_ibl">27</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:dAp6zn-oMfAC" class="gsc_a_at">Spatial and coherence cues based time-frequency masking for binaural reverberant speech separation</a><div class="gs_gray">A Alinaghi, W Wang, PJB Jackson</div><div class="gs_gray">2013 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10868117258845758418" class="gsc_a_ac gs_ibl">27</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:IWHjjKOFINEC" class="gsc_a_at">课表编排专家系统</a><div class="gs_gray">周建新， 王科俊</div><div class="gs_gray">计算机应用 20 (5), 76-78<span class="gs_oph">, 2000</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7820987833138937238" class="gsc_a_ac gs_ibl">27</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2000</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:eFf2swCANGcC" class="gsc_a_at">Intensity Particle Flow SMC-PHD Filter For Audio Speaker Tracking</a><div class="gs_gray">Y Liu, W Wang, V Kilic</div><div class="gs_gray">arXiv preprint arXiv:1812.01570<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2205501711167231877" class="gsc_a_ac gs_ibl">26</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:7Frjd3zlGBUC" class="gsc_a_at">Reverberant speech separation with probabilistic time–frequency masking for B-format recordings</a><div class="gs_gray">X Chen, W Wang, Y Wang, X Zhong, A Alinaghi</div><div class="gs_gray">Speech Communication 68, 41-54<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2908191734845284036" class="gsc_a_ac gs_ibl">26</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:3BvdIg-l-ZAC" class="gsc_a_at">Audio–Visual Particle Flow SMC-PHD Filtering for Multi-Speaker Tracking</a><div class="gs_gray">Y Liu, V Kılıç, J Guan, W Wang</div><div class="gs_gray">IEEE Transactions on Multimedia 22 (4), 934-948<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=644159338058985420" class="gsc_a_ac gs_ibl">25</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:blknAaTinKkC" class="gsc_a_at">Integrating binaural cues and blind source separation method for separating reverberant speech mixtures</a><div class="gs_gray">A Alinaghi, W Wang, PJB Jackson</div><div class="gs_gray">2011 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8359317476018868515" class="gsc_a_ac gs_ibl">25</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:zYLM7Y9cAGgC" class="gsc_a_at">Advances in nonnegative matrix and tensor factorization</a><div class="gs_gray">A Cichocki, M Mørup, P Smaragdis, W Wang, R Zdunek</div><div class="gs_gray">Computational intelligence and neuroscience 2008<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8449348142059517282" class="gsc_a_ac gs_ibl">25</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:qjMakFHDy7sC" class="gsc_a_at">A joint diagonalization method for convolutive blind separation of nonstationary sources in the frequency domain</a><div class="gs_gray">W Wang, JA Chambers, S Sanei</div><div class="gs_gray">Proc. ICA, 939-944<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2796834885007533418" class="gsc_a_ac gs_ibl">25</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:d4tt_xEv1X8C" class="gsc_a_at">Non-zero diffusion particle flow SMC-PHD filter for audio-visual multi-speaker tracking</a><div class="gs_gray">Y Liu, A Hilton, J Chambers, Y Zhao, W Wang</div><div class="gs_gray">2018 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12683000098104957410" class="gsc_a_ac gs_ibl">24</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:xyvS_IvSCKsC" class="gsc_a_at">Hierarchical learning for DNN-based acoustic scene classification</a><div class="gs_gray">Y Xu, Q Huang, W Wang, MD Plumbley</div><div class="gs_gray">arXiv preprint arXiv:1607.03682<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16044408344346812426" class="gsc_a_ac gs_ibl">24</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:PVqtIyvKoSUC" class="gsc_a_at">Audio Commons: bringing Creative Commons audio content to the creative industries</a><div class="gs_gray">F Font, T Brookes, G Fazekas, M Guerber, A La Burthe, D Plans, ...</div><div class="gs_gray">Audio Engineering Society Conference: 61st International Conference: Audio&nbsp;…<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17526069105755869184" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="JQFnV5IAAAAJ:PVqtIyvKoSUC" data-eud="JQFnV5IAAAAJ:vVJNg6_NJEsC">24</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:vVJNg6_NJEsC" class="gsc_a_at">Audio Commons: bringing Creative Commons audio content to the creative industries</a><div class="gs_gray">F Font, T Brookes, G Fazekas, M Guerber, A La Burthe, D Plans, ...</div><div class="gs_gray">Audio Engineering Society Conference: 61st International Conference: Audio&nbsp;…<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17526069105755869184" class="gsc_a_ac gs_ibl">24</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:sgsej9ZJWHMC" class="gsc_a_at">A joint separation-classification model for sound event detection of weakly labelled data</a><div class="gs_gray">Q Kong, Y Xu, W Wang, MD Plumbley</div><div class="gs_gray">2018 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12577398696634415721" class="gsc_a_ac gs_ibl">23</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:_tF6a-HnqWAC" class="gsc_a_at">Analysis SimCO: A new algorithm for analysis dictionary learning</a><div class="gs_gray">J Dong, W Wang, W Dai</div><div class="gs_gray">2014 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17142653670425411989" class="gsc_a_ac gs_ibl">23</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:Y0pCki6q_DkC" class="gsc_a_at">Squared Euclidean distance based convolutive non-negative matrix factorization with multiplicative learning rules for audio pattern separation</a><div class="gs_gray">W Wang</div><div class="gs_gray">2007 IEEE International Symposium on Signal Processing and Information&nbsp;…<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7962439197135358561" class="gsc_a_ac gs_ibl">23</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:MGPUR4WVBMEC" class="gsc_a_at">Sound event detection of weakly labelled data with CNN-transformer and automatic threshold optimization</a><div class="gs_gray">Q Kong, Y Xu, W Wang, MD Plumbley</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech, and Language Processing 28, 2450-2460<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7942313280009886396" class="gsc_a_ac gs_ibl">22</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:C-Rn0OCouf8C" class="gsc_a_at">Labelled non-zero particle flow for SMC-PHD filtering</a><div class="gs_gray">Y Liu, Q Hu, Y Zou, W Wang</div><div class="gs_gray">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11066839614935446184" class="gsc_a_ac gs_ibl">22</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:YsMSGLbcyi4C" class="gsc_a_at">Blind separation of convolutive mixtures of cyclostationary signals</a><div class="gs_gray">W Wang, MG Jafari, S Sanei, JA Chambers</div><div class="gs_gray">International Journal of Adaptive Control and Signal Processing 18 (3), 279-298<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16832010060887545484" class="gsc_a_ac gs_ibl">22</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:adHtZc2wMuEC" class="gsc_a_at">Two-stage sound event localization and detection using intensity vector and generalized cross-correlation</a><div class="gs_gray">Y Cao, T Iqbal, Q Kong, M Galindo, W Wang, MD Plumbley</div><div class="gs_gray">Tech. report of Detection and Classification of Acoustic Scenes and Events&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15556849447019087369" class="gsc_a_ac gs_ibl">21</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:ShjGdcaqzI0C" class="gsc_a_at">Sparse recovery and dictionary learning from nonlinear compressive measurements</a><div class="gs_gray">L Rencker, F Bach, W Wang, MD Plumbley</div><div class="gs_gray">IEEE Transactions on Signal Processing 67 (21), 5659-5670<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15945304734231987252" class="gsc_a_ac gs_ibl">20</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:DIubQTN3OvUC" class="gsc_a_at">Two-Stage Monaural Source Separation in Reverberant Room Environments Using Deep Neural Networks</a><div class="gs_gray">Y Sun, W Wang, J Chambers, SM Naqvi</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech, and Language Processing 27 (1), 125-139<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15655022167418095646" class="gsc_a_ac gs_ibl">19</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:60iIaj97TE0C" class="gsc_a_at">Fully DNN-based Multi-label regression for audio tagging</a><div class="gs_gray">Y Xu, Q Huang, W Wang, PJB Jackson, MD Plumbley</div><div class="gs_gray">arXiv preprint arXiv:1606.07695<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5357511615038785111" class="gsc_a_ac gs_ibl">19</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:Zph67rFs4hoC" class="gsc_a_at">A block-based compressed sensing method for underdetermined blind speech separation incorporating binary mask</a><div class="gs_gray">T Xu, W Wang</div><div class="gs_gray">2010 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1648879416635744570" class="gsc_a_ac gs_ibl">19</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:5nxA0vEk-isC" class="gsc_a_at">Convolutive non-negative sparse coding</a><div class="gs_gray">W Wang</div><div class="gs_gray">2008 IEEE International Joint Conference on Neural Networks (IEEE World&nbsp;…<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11895143510704381907" class="gsc_a_ac gs_ibl">19</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:ULOm3_A8WrAC" class="gsc_a_at">Use of bimodal coherence to resolve the permutation problem in convolutive BSS</a><div class="gs_gray">Q Liu, W Wang, P Jackson</div><div class="gs_gray">Signal Processing 92 (8), 1916-1927<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3843775435553437931" class="gsc_a_ac gs_ibl">18</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:CCeGMaHljPEC" class="gsc_a_at">Source separation with weakly labelled data: An approach to computational auditory scene analysis</a><div class="gs_gray">Q Kong, Y Wang, X Song, Y Cao, W Wang, MD Plumbley</div><div class="gs_gray">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9056981609032481449" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:NU-BerS4NX4C" class="gsc_a_at">Monaural Source Separation in Complex Domain with Long Short-Term Memory Neural Network</a><div class="gs_gray">Y Sun, Y Xian, W Wang, SM Naqvi</div><div class="gs_gray">IEEE Journal of Selected Topics in Signal Processing 13 (2), 359-369<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3155323477224246479" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:bXQfdp6S9ecC" class="gsc_a_at">Semisupervised Online Multikernel Similarity Learning for Image Retrieval</a><div class="gs_gray">J Liang, Q Hu, W Wang, Y Han</div><div class="gs_gray">IEEE Transactions on Multimedia 19 (5), 1077-1089<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1279934246035935220" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:aDl3D7KC1E4C" class="gsc_a_at">Adaptive retrodiction particle PHD filter for multiple human tracking</a><div class="gs_gray">P Feng, W Wang, SM Naqvi, J Chambers</div><div class="gs_gray">IEEE Signal Processing Letters 23 (11), 1592-1596<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13843145053038036538" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:pQTOvowfQioC" class="gsc_a_at">Audio constrained particle filter based visual tracking</a><div class="gs_gray">V Kılıç, M Barnard, W Wang, J Kittler</div><div class="gs_gray">2013 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14620340712754323888" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:8Xgff_V0N9gC" class="gsc_a_at">Audio analysis of statistically instantaneous signals with mixed Gaussian probability distributions</a><div class="gs_gray">GR Naik, W Wang</div><div class="gs_gray">International Journal of Electronics 99 (10), 1333-1350<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15360932154496245086" class="gsc_a_ac gs_ibl">16</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:BJtnxTr0fRcC" class="gsc_a_at">Efficient multi-modal geometric mean metric learning</a><div class="gs_gray">J Liang, Q Hu, P Zhu, W Wang</div><div class="gs_gray">Pattern Recognition 75, 188-198<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18406711255413118834" class="gsc_a_ac gs_ibl">15</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:AZju0d2GQJ0C" class="gsc_a_at">Subset pursuit for analysis dictionary learning</a><div class="gs_gray">Y Zhang, H Wang, T Yu, W Wang</div><div class="gs_gray">21st European Signal Processing Conference (EUSIPCO 2013), 1-5<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3448326877207329074" class="gsc_a_ac gs_ibl">15</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:3fE2CSJIrl8C" class="gsc_a_at">Methods for learning adaptive dictionary in underdetermined speech separation</a><div class="gs_gray">T Xu, W Wang</div><div class="gs_gray">2011 IEEE International Workshop on Machine Learning for Signal Processing, 1-6<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17632574477211236779" class="gsc_a_ac gs_ibl">15</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:0EnyYjriUFMC" class="gsc_a_at">Non-negative matrix factorization based on projected nonlinear conjugate gradient algorithm</a><div class="gs_gray">W Wang, X Zou</div><div class="gs_gray">ICA Research Network International Workshop (ICARN 2008), 5-8<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15122348421358465309" class="gsc_a_ac gs_ibl">15</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:eQOLeE2rZwMC" class="gsc_a_at">Non-negative matrix factorization for note onset detection of audio signals</a><div class="gs_gray">W Wang, Y Luo, JA Chambers, S Sanei</div><div class="gs_gray">2006 16th IEEE Signal Processing Society Workshop on Machine Learning for&nbsp;…<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18338975101574143947" class="gsc_a_ac gs_ibl">15</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:wkm4DBaukwsC" class="gsc_a_at">An Improved Event-Independent Network for Polyphonic Sound Event Localization and Detection</a><div class="gs_gray">Y Cao, T Iqbal, Q Kong, F An, W Wang, MD Plumbley</div><div class="gs_gray">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17091237164743527347,1999594629351665478" class="gsc_a_ac gs_ibl">14</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="JQFnV5IAAAAJ:wkm4DBaukwsC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:oAywNP-vUhwC" class="gsc_a_at">Environmental sound classification with parallel temporal-spectral attention</a><div class="gs_gray">H Wang, Y Zou, D Chong, W Wang</div><div class="gs_gray">Proceedings of INTERSPEECH 2020<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11645570926672524150" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:7VEv-pLvLSsC" class="gsc_a_at">Consistent dictionary learning for signal declipping</a><div class="gs_gray">L Rencker, F Bach, W Wang, MD Plumbley</div><div class="gs_gray">International Conference on Latent Variable Analysis and Signal Separation&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10411860622644209806" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:9shLKfS_uJEC" class="gsc_a_at">A 3D model for room boundary estimation</a><div class="gs_gray">L Remaggi, PJB Jackson, W Wang, JA Chambers</div><div class="gs_gray">Proc. of the IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3408909720525573607" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=JQFnV5IAAAAJ:JWITY9-sCbMC" class="gsc_a_at">Direction of arrival tracking of an underwater acoustic source using particle filtering: Real data experiments</a><div class="gs_gray">X Zhong, AB Premkumar, W Wang</div><div class="gs_gray">IEEE 2013 Tencon-Spring, 420-424<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=660550945980421150" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:5Ul4iDaHHb8C" class="gsc_a_at">Blind reverberation time estimation based on Laplace distribution</a><div class="gs_gray">T Jan, W Wang</div><div class="gs_gray">2012 Proceedings of the 20th European Signal Processing Conference (EUSIPCO&nbsp;…<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12717866464358048340" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Tyk-4Ss8FVUC" class="gsc_a_at">A coupled HMM for solving the permutation problem in frequency domain BSS</a><div class="gs_gray">S Sanei, W Wang, JA Chambers</div><div class="gs_gray">2004 IEEE International Conference on Acoustics, Speech, and Signal&nbsp;…<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=494610905794815461" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:mB3voiENLucC" class="gsc_a_at">潜艇应急操纵的建模与仿真 [J]</a><div class="gs_gray">王鹢， 王文武， 孙枫， 王国夫</div><div class="gs_gray">计算机仿真 20 (6), 1-3<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12826789501238151734" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:hHIA4WEVY-EC" class="gsc_a_at">Learning soft mask with DNN and DNN-SVM for multi-speaker DOA estimation using an acoustic vector sensor</a><div class="gs_gray">D Wang, Y Zou, W Wang</div><div class="gs_gray">Journal of the Franklin Institute 355 (4), 1692-1709<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9032258147273119676" class="gsc_a_ac gs_ibl">13</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:jlhcAiayVhoC" class="gsc_a_at">Interference reduction in reverberant speech separation with visual voice activity detection</a><div class="gs_gray">Q Liu, AJ Aubrey, W Wang</div><div class="gs_gray">IEEE Transactions on Multimedia 16 (6), 1610-1623<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12698965743004912684" class="gsc_a_ac gs_ibl">13</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:EUQCXRtRnyEC" class="gsc_a_at">Dictionary learning and update based on simultaneous codeword optimization (SIMCO)</a><div class="gs_gray">W Dai, T Xu, W Wang</div><div class="gs_gray">2012 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3250314192051379215" class="gsc_a_ac gs_ibl">13</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:_FxGoFyzp5QC" class="gsc_a_at">Blind separation of convolutive mixtures of cyclostationary sources using an extended natural gradient method</a><div class="gs_gray">W Wang, MG Jafari, S Sanei, JA Chambers</div><div class="gs_gray">Seventh International Symposium on Signal Processing and Its Applications&nbsp;…<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6813922275226605574" class="gsc_a_ac gs_ibl">13</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:4Yq6kJLCcecC" class="gsc_a_at">K-plane clustering algorithm for analysis dictionary learning</a><div class="gs_gray">Y Zhang, H Wang, W Wang, S Sanei</div><div class="gs_gray">2013 IEEE International Workshop on Machine Learning for Signal Processing&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1508896424409051118" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:ijdKiLOsEJMC" class="gsc_a_at">Acoustic source tracking in a reverberant environment using a pairwise synchronous microphone network</a><div class="gs_gray">X Zhong, A Mohammadi, W Wang, AB Premkumar, A Asif</div><div class="gs_gray">Proceedings of the 16th International Conference on Information Fusion, 953-960<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12050589180046878910" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:CRzUtm-VnGAC" class="gsc_a_at">A Skip Attention Mechanism for Monaural Singing Voice Separation</a><div class="gs_gray">W Yuan, S Wang, X Li, M Unoki, W Wang</div><div class="gs_gray">IEEE Signal Processing Letters 26 (10), 1481-1485<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2826113241589628784" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Nufq_to8ts0C" class="gsc_a_at">A Source Counting Method Using Acoustic Vector Sensor Based on Sparse Modeling of DOA Histogram</a><div class="gs_gray">Y Chen, W Wang, Z Wang, B Xia</div><div class="gs_gray">IEEE Signal Processing Letters 26 (1), 69-73<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6502656025157180791" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:w2UhwfzvF0QC" class="gsc_a_at">Multiple Speaker Tracking in Spatial Audio via PHD Filtering and Depth-Audio Fusion</a><div class="gs_gray">Q Liu, W Wang, T de Campos, P Jackson, A Hilton</div><div class="gs_gray">IEEE Transactions on Multimedia<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13514433127518248382" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:orDZ08hpP44C" class="gsc_a_at">Room boundary estimation from acoustic room impulse responses</a><div class="gs_gray">L Remaggi, PJB Jackson, P Coleman, W Wang</div><div class="gs_gray">2014 Sensor Signal Processing for Defence (SSPD), 1-5<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11918284032646010614" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:iyewoVqAXLQC" class="gsc_a_at">Acoustic vector sensor based reverberant speech separation with probabilistic time-frequency masking</a><div class="gs_gray">X Zhong, X Chen, W Wang, A Alinaghi, AB Premkumar</div><div class="gs_gray">21st European Signal Processing Conference (EUSIPCO 2013), 1-5<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17976940019559586482" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:hFOr9nPyWt4C" class="gsc_a_at">干扰力作用下潜艇近水面运动的仿真</a><div class="gs_gray">王文武， 孙枫</div><div class="gs_gray">系统仿真学报 15 (001), 84-87<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3225533609554742516" class="gsc_a_ac gs_ibl">11</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="JQFnV5IAAAAJ:hFOr9nPyWt4C">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Gpwnp1kGG20C" class="gsc_a_at">Low rank matrix completion using truncated nuclear norm and sparse regularizer</a><div class="gs_gray">J Dong, Z Xue, J Guan, ZF Han, W Wang</div><div class="gs_gray">Signal Processing: Image Communication 68, 76-87<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=704945973998108324" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:j5aT6aphRxQC" class="gsc_a_at">Iterative deep neural networks for speaker-independent binaural blind speech separation</a><div class="gs_gray">Q Liu, Y Xu, PJB Jackson, W Wang, P Coleman</div><div class="gs_gray">2018 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1314196527885627126" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:0sTkTiv_uMkC" class="gsc_a_at">Social force model aided robust particle PHD filter for multiple human tracking</a><div class="gs_gray">P Feng, W Wang, SM Naqvi, S Dlay, JA Chambers</div><div class="gs_gray">2016 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2357186387488536185" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:m4fbC6XIj1kC" class="gsc_a_at">Show-through removal for scanned images using non-linear NMF with adaptive smoothing</a><div class="gs_gray">Q Liu, W Wang</div><div class="gs_gray">2013 IEEE China Summit and International Conference on Signal and&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11649519137136600461" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:wyM6WWKXmoIC" class="gsc_a_at">MCMCPF Based Multiple Head Tracking in a Room Environment</a><div class="gs_gray">A UrRehman, SM Naqvi, R Phan, W Wang, J Chambers</div><div class="gs_gray">BMVC Computer Vision Workshop (BMVW’12), Guildford, UK<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9921751200833596991" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:SeFeTyx0c_EC" class="gsc_a_at">Audio classification based on sparse coefficients</a><div class="gs_gray">S Zubair, W Wang</div><div class="gs_gray">Sensor Signal Processing for Defence (SSPD 2011), 1-5<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3009682824925689191" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:gmHTDCtJMcoC" class="gsc_a_at">Enhanced time-frequency masking by using neural networks for monaural source separation in reverberant room environments</a><div class="gs_gray">Y Sun, W Wang, JA Chambers, SM Naqvi</div><div class="gs_gray">2018 26th European Signal Processing Conference (EUSIPCO), 1647-1651<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13595800958200748740" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:cSdaV2aYdYsC" class="gsc_a_at">Stacked convolutional neural networks for general-purpose audio tagging</a><div class="gs_gray">T Iqbal, Q Kong, M Plumbley, W Wang</div><div class="gs_gray">DCASE2018 Challenge<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=90959270077611508" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:i_7YvbSbtFEC" class="gsc_a_at">Binaural and log-power spectra features with deep neural networks for speech-noise separation</a><div class="gs_gray">A Zermini, Q Liu, Y Xu, MD Plumbley, D Betts, W Wang</div><div class="gs_gray">2017 IEEE 19th International Workshop on Multimedia Signal Processing (MMSP&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4702044084137676572" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:hNSvKAmkeYkC" class="gsc_a_at">Adaptive particle filtering approach to audio-visual tracking</a><div class="gs_gray">V Kılıç, M Barnard, W Wang, J Kittler</div><div class="gs_gray">Signal Processing Conference (EUSIPCO), 2013 Proceedings of the 21st&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14350956536553432196" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:pRWBApOjXDcC" class="gsc_a_at">Instantaneous Versus Convolutive Non-Negative Matrix Factorization: Models, Algorithms and Applications to Audio Pattern Separation</a><div class="gs_gray">W Wang</div><div class="gs_gray">Machine Audition: Principles, Algorithms and Systems, 353-370<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=642326423171945785" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="JQFnV5IAAAAJ:pRWBApOjXDcC" data-eud="JQFnV5IAAAAJ:_Qo2XoVZTnwC">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:_Qo2XoVZTnwC" class="gsc_a_at">Instantaneous vs. Convolutive Non-Negative Matrix Factorization</a><div class="gs_gray">W Wang</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=642326423171945785,14178276848489443953" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:roLk4NBRz8UC" class="gsc_a_at">Use of bimodal coherence to resolve spectral indeterminacy in convolutive BSS</a><div class="gs_gray">Q Liu, W Wang, P Jackson</div><div class="gs_gray">International Conference on Latent Variable Analysis and Signal Separation&nbsp;…<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14271507466986704688" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:EBV337fEn3EC" class="gsc_a_at">Instantaneous vs. convolutive non-negative matrix factorization: Models, algorithms and applications</a><div class="gs_gray">W Wang</div><div class="gs_gray">Machine Audition: Principles, Algorithms and Systems: Principles, Algorithms&nbsp;…<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=642326423171945785" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="JQFnV5IAAAAJ:EBV337fEn3EC" data-eud="JQFnV5IAAAAJ:_Qo2XoVZTnwC">9</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="JQFnV5IAAAAJ:EBV337fEn3EC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:4JMBOYKVnBMC" class="gsc_a_at">Simulation of Submarine Near-surface Motion Under Disturbance Force</a><div class="gs_gray">Y Wang, WW Wang, F Sun, GF Wang</div><div class="gs_gray">Journal of System Simulation 15 (1), 84-87<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17394058044730855731" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:QKtdBID3u5MC" class="gsc_a_at">Single-Channel Signal Separation and Deconvolution with Generative Adversarial Networks</a><div class="gs_gray">Q Kong, Y Xu, W Wang, PJB Jackson, MD Plumbley</div><div class="gs_gray">arXiv preprint arXiv:1906.07552<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17438958015224857706" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:kO05sadLmrgC" class="gsc_a_at">Generalisation in environmental sound classification: the ‘making sense of sounds’ data set and challenge</a><div class="gs_gray">C Kroos, O Bones, Y Cao, L Harris, PJB Jackson, WJ Davies, W Wang, ...</div><div class="gs_gray">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7732432770710102476" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:X5YyAB84Iw4C" class="gsc_a_at">Multi-source phase retrieval from multi-channel phaseless STFT measurements</a><div class="gs_gray">Y Guo, A Wang, W Wang</div><div class="gs_gray">Signal Processing 144, 36-40<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16354108900498831739" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:1EqfMoDn7-AC" class="gsc_a_at">General-purpose audio tagging from noisy labels using convolutional neural networks</a><div class="gs_gray">T Iqbal, Q Kong, MD Plumbley, W Wang</div><div class="gs_gray">Proceedings of the Detection and Classification of Acoustic Scenes and&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16660388754749711609" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:u3T1itk59dMC" class="gsc_a_at">Sparse <svg class="gs_fsvg" aria-label="\ell _{1}" width="15px" height="15px" style="vertical-align:-4px;"><g transform="matrix(0.01700, 0.00000, 0.00000, 0.01700, 0.00000, 11.98500)"><g><path transform="scale(0.48828, -0.48828)" d="M 49 152  Q 40 152 30 163  T 20 184  Q 20 201 190 356  Q 190 365 189 371  T 188 383  Q 188 471 202 562  T 240 745  T 302 935  T 377 1108  Q 443 1243 521 1343  T 694 1444  Q 759 1444 787 1399  T 815 1288  Q 815 913 317 406  Q 309 318 309 281  Q 309 25 426 25  Q 476 25 525 51  T 610 109  T 709 201  Q 713 205 721 205  Q 732 205 742 193  T 752 170  Q 752 163 743 156  Q 652 67 579 18  T 422 -31  Q 314 -31 261 62  T 195 283  Q 140 228 61 156  Q 59 152 49 152  Z M 334 504  Q 443 620 538 748  T 696 1017  T 760 1294  Q 760 1391 692 1391  Q 619 1391 543 1216  T 413 839  T 334 504  Z "></path><g transform="translate(416.67001, 150.00000)"><g><path transform="scale(0.34180, -0.34180)" d="M 233 0  V 82  Q 516 82 516 143  V 1202  Q 401 1147 219 1147  V 1229  Q 341 1229 447 1258  T 629 1360  H 666  Q 685 1355 690 1335  V 143  Q 690 82 973 82  V 0  H 233  Z "></path></g></g></g></g></svg>-Optimal Multiloudspeaker Panning and Its Relation to Vector Base Amplitude Panning</a><div class="gs_gray">A Franck, W Wang, FM Fazi</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech, and Language Processing 25 (5), 996-1010<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14235944827733577408" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Y9VhQm-5nPIC" class="gsc_a_at">A source separation evaluation method in object-based spatial audio</a><div class="gs_gray">Q Liu, W Wang, PJB Jackson, TJ Cox</div><div class="gs_gray">2015 23rd European Signal Processing Conference (EUSIPCO), 1088-1092<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8411165176282543508" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:WwIwg2wKZ0QC" class="gsc_a_at">An Analysis Dictionary Learning Algorithm under a Noisy Data Model with Orthogonality Constraint</a><div class="gs_gray">Y Zhang, T Yu, W Wang</div><div class="gs_gray">The Scientific World Journal 2014<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10607861108242605724" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:4TOpqqG69KYC" class="gsc_a_at">Multimodal blind source separation with a circular microphone array and robust beamforming</a><div class="gs_gray">SM Naqvi, MS Khan, Q Liu, W Wang, JA Chambers</div><div class="gs_gray">2011 19th European Signal Processing Conference, 1050-1054<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4454799845063006687" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:_mQi-xiA4oYC" class="gsc_a_at">Multi-channel Convolutional Neural Networks with Multi-level Feature Fusion for Environmental Sound Classification</a><div class="gs_gray">D Chong, Y Zou, W Wang</div><div class="gs_gray">International Conference on Multimedia Modeling, 157-168<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2527147567869015671" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:oYLFIHfuHKwC" class="gsc_a_at">Fast Iterative Shrinkage for Signal Declipping and Dequantization</a><div class="gs_gray">L Rencker, F Bach, W Wang, MD Plumbley</div><div class="gs_gray">Proceedings of iTWIST’18-International Traveling Workshop on Interactions&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11951872392074479899" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:as0KMg8qHbkC" class="gsc_a_at">Assessment of musical noise using localization of isolated peaks in time-frequency domain</a><div class="gs_gray">R Hamon, V Emiya, L Rencker, W Wang, M Plumbley</div><div class="gs_gray">2017 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10291501148170120276" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Vno172sVVMwC" class="gsc_a_at">Variational Bayesian PHD Filter with Deep Learning Network Updating for Multiple Human Tracking</a><div class="gs_gray">P Feng, W Wang, SM Naqvi, J Chambers</div><div class="gs_gray">2015 Sensor Signal Processing for Defence (SSPD), 1-5<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5982200061206483356" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:rOcdG6UcVlcC" class="gsc_a_at">Audio super-resolution using analysis dictionary learning</a><div class="gs_gray">J Dong, W Wang, J Chambers</div><div class="gs_gray">Digital Signal Processing (DSP), 2015 IEEE International Conference on, 604-608<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8121345755473168969" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:G36d5HCDkJYC" class="gsc_a_at">Audio-visual tracking of a variable number of speakers with a random finite set approach</a><div class="gs_gray">V Kılıç, X Zhong, M Barnard, W Wang, J Kittler</div><div class="gs_gray">17th International Conference on Information Fusion (FUSION), 1-7<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3607513052272487309" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="JQFnV5IAAAAJ:G36d5HCDkJYC" data-eud="JQFnV5IAAAAJ:N4u4nq0IxgcC">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:N4u4nq0IxgcC" class="gsc_a_at">Audio-visual tracking of a variable number of speakers with a random finite set approach</a><div class="gs_gray">V Kılıç, X Zhong, M Barnard, W Wang, J Kittler</div><div class="gs_gray">17th International Conference on Information Fusion (FUSION), 1-7<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3607513052272487309" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:kNdYIx-mwKoC" class="gsc_a_at">Audio-visual convolutive blind source separation</a><div class="gs_gray">Q Liu, W Wang, P Jackson</div><div class="gs_gray">Sensor Signal Processing for Defence (SSPD 2010), 1-5<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15926521905746180628" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:wLxue7F8ec0C" class="gsc_a_at">基于状态观测器的超混沌系统高精度同步方法</a><div class="gs_gray">张学义， 李殿璞， 陈实如， 王文武</div><div class="gs_gray">电路与系统学报 6 (4), 15-19<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11334937841013786821" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:q1zXlPLtbUIC" class="gsc_a_at">An RIP-Based Performance Guarantee of Covariance-Assisted Matching Pursuit</a><div class="gs_gray">J Wang, G Li, L Rencker, W Wang, Y Gu</div><div class="gs_gray">IEEE Signal Processing Letters 25 (6), 828-832<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11255558996353349762" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:yJjnfzR0HrkC" class="gsc_a_at">A non-intrusive method for estimating binaural speech intelligibility from noise-corrupted signals captured by a pair of microphones</a><div class="gs_gray">Y Tang, Q Liu, W Wang, TJ Cox</div><div class="gs_gray">Speech Communication 96, 116-128<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6816770433076814780" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:WWeOtg8bX_EC" class="gsc_a_at">A robust student's-t distribution PHD filter with OCSVM updating for multiple human tracking</a><div class="gs_gray">P Feng, M Yu, SM Naqvi, W Wang, JA Chambers</div><div class="gs_gray">2015 23rd European Signal Processing Conference (EUSIPCO), 2396-2400<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7743687373043086414" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:ji7lAbPyDbYC" class="gsc_a_at">Generalized generating function with tucker decomposition and alternating least squares for underdetermined blind identification</a><div class="gs_gray">F Gu, H Zhang, W Wang, D Zhu</div><div class="gs_gray">EURASIP Journal on Advances in Signal Processing 2013 (1), 1-9<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9300287670041883380" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:TQgYirikUcIC" class="gsc_a_at">太阳系天体视位置的长期计算法</a><div class="gs_gray">王文武， 孙枫</div><div class="gs_gray">哈尔滨工程大学学报 21 (005), 18-23<span class="gs_oph">, 2000</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15696418900819531037" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2000</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:1xBWf43XMUgC" class="gsc_a_at">SpecAugment++: A Hidden Space Data Augmentation Method for Acoustic Scene Classification</a><div class="gs_gray">H Wang, Y Zou, W Wang</div><div class="gs_gray">arXiv preprint arXiv:2103.16858<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13494838176994153973" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:mVC4hKzE2FoC" class="gsc_a_at">Modeling the Comb Filter Effect and Interaural Coherence for Binaural Source Separation</a><div class="gs_gray">L Remaggi, PJB Jackson, W Wang</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech, and Language Processing 27 (12&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2573468108860260416" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:4QKQTXcH0q8C" class="gsc_a_at">Acoustic Scene Generation with Conditional Samplernn</a><div class="gs_gray">Q Kong, Y Xu, T Iqbal, Y Cao, W Wang, MD Plumbley</div><div class="gs_gray">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9478393861233249693" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:3MwzVuqRcA0C" class="gsc_a_at">Randomly Sketched Sparse Subspace Clustering for Acoustic Scene Clustering</a><div class="gs_gray">S Li, W Wang</div><div class="gs_gray">2018 26th European Signal Processing Conference (EUSIPCO), 2489-2493<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3524340068443955544" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:DquSII9TDu4C" class="gsc_a_at">Manifold-based Visual Object Counting</a><div class="gs_gray">Y Wang, Y Zou, W Wang</div><div class="gs_gray">IEEE Transactions on Image Processing 27 (7), 3248-3263<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8906942566945167678" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Vztgr1qGG8IC" class="gsc_a_at">Synthesis of images by two-stage generative adversarial networks</a><div class="gs_gray">Q Huang, PJB Jackson, MD Plumbley, W Wang</div><div class="gs_gray">2018 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3045655719206170720" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:MDX3w3dAD3YC" class="gsc_a_at">Polynomial dictionary learning algorithms in sparse representations</a><div class="gs_gray">J Guan, X Wang, P Feng, J Dong, J Chambers, ZL Jiang, W Wang</div><div class="gs_gray">Signal Processing 142, 492-503<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1916440831172363375" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:4e5Qn2KL_jwC" class="gsc_a_at">An expectation-maximization algorithm for blind separation of noisy mixtures using Gaussian mixture model</a><div class="gs_gray">F Gu, H Zhang, W Wang, S Wang</div><div class="gs_gray">Circuits, Systems, and Signal Processing 36 (7), 2697-2726<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8101748401076697286" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:NtCmTCuxid4C" class="gsc_a_at">Higher-Order Circularity Based I/Q Imbalance Compensation in Direct-Conversion Receivers</a><div class="gs_gray">F Gu, S Wang, J Wei, W Wang</div><div class="gs_gray">2016 IEEE 84th Vehicular Technology Conference (VTC-Fall), 1-6<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4735154660492795960" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:E7VqQtBCVmcC" class="gsc_a_at">Identity association using PHD filters in multiple head tracking with depth sensors</a><div class="gs_gray">Q Liu, TE de Campos, W Wang, A Hilton</div><div class="gs_gray">2016 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=143585621186751704" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:PlWzFYVEG4EC" class="gsc_a_at">Localization based stereo speech separation using deep networks</a><div class="gs_gray">Y Yu, W Wang, J Luo, P Feng</div><div class="gs_gray">2015 IEEE International Conference on Digital Signal Processing (DSP), 153-157<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12291978125802307642" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:natZJ_-F0IUC" class="gsc_a_at">Person tracking using audio and depth cues</a><div class="gs_gray">Q Liu, T de Campos, W Wang, P Jackson, A Hilton</div><div class="gs_gray">Proceedings of the IEEE International Conference on Computer Vision&nbsp;…<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2053495244842098600" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:9DLIHnF0jcYC" class="gsc_a_at">PARAFAC-Based Blind Identification of Underdetermined Mixtures Using Gaussian Mixture Model</a><div class="gs_gray">F Gu, H Zhang, W Wang, D Zhu</div><div class="gs_gray">Circuits, Systems, and Signal Processing 33 (6), 1841-1857<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9813992003987255757" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:yY3RG6sOEgwC" class="gsc_a_at">Acoustic vector sensor based speech source separation with mixed Gaussian-Laplacian distributions</a><div class="gs_gray">X Chen, A Alinaghi, X Zhong, W Wang</div><div class="gs_gray">2013 18th International Conference on Digital Signal Processing (DSP), 1-5<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6254335732390306202" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:sJPMR1oEGYQC" class="gsc_a_at">Joint image separation and dictionary learning</a><div class="gs_gray">X Zhao, G Zhou, W Dai, T Xu, W Wang</div><div class="gs_gray">2013 18th International Conference on Digital Signal Processing (DSP), 1-6<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2898097693531676767" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:iH-uZ7U-co4C" class="gsc_a_at">Modeling and Simulation of Submarine Emergency Maneuver</a><div class="gs_gray">Y WANG, W WANG, F SUN, G WANG</div><div class="gs_gray">Computer, 06<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4139453556497785683" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:hC7cP41nSMkC" class="gsc_a_at">潜艇航行训练模拟器视景系统的设计与实现</a><div class="gs_gray">王地， 赵琳， 沈晓蓉， 王文武</div><div class="gs_gray">哈尔滨工程大学学报 22 (2)<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11185208224578864764" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:It0W0vAlS5QC" class="gsc_a_at">Optimal feasible step-size based working set selection for large scale SVMs training</a><div class="gs_gray">S Peng, Q Hu, J Dang, W Wang</div><div class="gs_gray">Neurocomputing 407, 366-375<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13550448698636734789" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:ufKn5pxu7C0C" class="gsc_a_at">Meta Metric Learning for Highly Imbalanced Aerial Scene Classification</a><div class="gs_gray">J Guan, J Liu, J Sun, P Feng, T Shuai, W Wang</div><div class="gs_gray">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15225975697286406324" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:I9gX6wnfuA8C" class="gsc_a_at">Short-term traffic flow prediction with wavelet and multi-dimensional taylor network model</a><div class="gs_gray">S Zhu, Y Zhao, Y Zhang, Q Li, W Wang, S Yang</div><div class="gs_gray">IEEE Transactions on Intelligent Transportation Systems 22 (5), 3203-3208<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=782332857093339739" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:htyGaKyDgHMC" class="gsc_a_at">Learning discriminative and robust time-frequency representations for environmental sound classification</a><div class="gs_gray">H Wang, Y Zou, D Chong, W Wang</div><div class="gs_gray">arXiv preprint arXiv:1912.06808<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15383971471115975154" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:B2rIPIGFPLEC" class="gsc_a_at">Speaker-discriminative embedding learning via affinity matrix for short utterance speaker verification</a><div class="gs_gray">J Peng, R Gu, Y Zou, W Wang</div><div class="gs_gray">2019 Asia-Pacific Signal and Information Processing Association Annual&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14701201952593460958" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Nnq8S6OXqDYC" class="gsc_a_at">Semantic Super-resolution for Extremely Low-resolution Vehicle License Plate</a><div class="gs_gray">Y Zou, Y Wang, W Guan, W Wang</div><div class="gs_gray">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16873033023352671023" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:S2WlVNSe3u4C" class="gsc_a_at">Predicting the perceived level of reverberation using machine learning</a><div class="gs_gray">S Safavi, A Pearce, W Wang, M Plumbley</div><div class="gs_gray">2018 52nd Asilomar Conference on Signals, Systems, and Computers, 27-30<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11539371934516809479" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:AFmTUeZ1pmEC" class="gsc_a_at">Error sensitivity analysis of Delta divergence-a novel measure for classifier incongruence detection</a><div class="gs_gray">J Kittler, C Zor, I Kaloskampis, Y Hicks, W Wang</div><div class="gs_gray">Pattern Recognition 77, 30-44<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18426097566280516085" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:CMvovTBb2okC" class="gsc_a_at">Bootstrap averaging for model-based source separation in reverberant conditions</a><div class="gs_gray">S Chandna, W Wang</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP) 26 (4&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13384854148632016038" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:idthP5jqfYAC" class="gsc_a_at">Sparse Blind Speech Deconvolution with Dynamic Range Regularization and Indicator Function</a><div class="gs_gray">J Guan, X Wang, W Wang, L Huang</div><div class="gs_gray">Circuits, Systems, and Signal Processing 36 (10), 4145-4160<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17672557130366633712" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:ifOnle78iJkC" class="gsc_a_at">A novel approach for detection of medial temporal discharges using blind source separation incorporating dictionary look up</a><div class="gs_gray">S Shapoori, S Sanei, W Wang</div><div class="gs_gray">2015 7th International IEEE/EMBS Conference on Neural Engineering (NER), 894-897<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9015721445890746305" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:ymY9cBF3mdcC" class="gsc_a_at">Fourth-order cumulant based sources number estimation from mixtures of unknown number of sources</a><div class="gs_gray">F Gu, W Li, W Wang</div><div class="gs_gray">2014 Sixth International Conference on Wireless Communications and Signal&nbsp;…<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17609600694813904281" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:n3vGvpFsckwC" class="gsc_a_at">Blind Source Separation Based on Dictionary Learning: A Singularity-Aware Approach</a><div class="gs_gray">X Zhao, G Zhou, W Dai, W Wang</div><div class="gs_gray">Blind Source Separation, 39-59<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16759602543339837225" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:i2xiXl-TujoC" class="gsc_a_at">Frequency dependent statistical model for the suppression of late reverberations</a><div class="gs_gray">T Jan, W Wang</div><div class="gs_gray">Sensor Signal Processing for Defence (SSPD 2012), 1-5<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9861193033313121241" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:ZHo1McVdvXMC" class="gsc_a_at">A dictionary learning approach to tracking</a><div class="gs_gray">M Barnard, W Wang, J Kittler, SM Naqvi, JA Chambers</div><div class="gs_gray">2012 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7370814577136381168" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:RGFaLdJalmkC" class="gsc_a_at">Blind source separation and visual voice activity detection for target speech extraction</a><div class="gs_gray">Q Liu, W Wang</div><div class="gs_gray">Awareness Science and Technology (iCAST), 2011 3rd International Conference&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1388262254083569284" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:RHpTSmoSYBkC" class="gsc_a_at">Cocktail Party Problem</a><div class="gs_gray">T Jan, W Wang</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10704020095239167688" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:hqOjcs7Dif8C" class="gsc_a_at">Bimodal coherence based scale ambiguity cancellation for target speech extraction and enhancement</a><div class="gs_gray">Q Liu, W Wang, PJB Jackson</div><div class="gs_gray">Proceedings of 11th Annual Conference of the International Speech&nbsp;…<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11822504481734767815" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:JV2RwH3_ST0C" class="gsc_a_at">A hybrid iterative algorithm for nonnegative matrix factorization</a><div class="gs_gray">ŞM Şoltuz, W Wang, PJB Jackson</div><div class="gs_gray">Statistical Signal Processing, 2009. SSP'09. IEEE/SP 15th Workshop on, 409-412<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5716417859488301945" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:qUcmZB5y_30C" class="gsc_a_at">基于虚拟现实的潜艇航行训练模拟器研究</a><div class="gs_gray">王文武</div><div class="gs_gray">哈尔滨工程大学博士学位论文 64, l<span class="gs_oph">, 2002</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12355927059723131011" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2002</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:HDshCWvjkbEC" class="gsc_a_at">基于 VR 的潜艇航行训练模拟器设计</a><div class="gs_gray">王文武， 赵琳</div><div class="gs_gray">系统仿真学报 13 (5), 599-601<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2097784288708246699" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:cF7EPgIk0B4C" class="gsc_a_at">An encoder-decoder based audio captioning system with transfer and reinforcement learning for DCASE challenge 2021 task 6</a><div class="gs_gray">X Mei, Q Huang, X Liu, G Chen, J Wu, Y Wu, J Zhao, S Li, T Ko, HL Tang, ...</div><div class="gs_gray">DCASE2021 Challenge, Tech. Rep<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7127319917847733044" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:zdX0sdgBH_kC" class="gsc_a_at">Weakly Labelled Audio Tagging Via Convolutional Networks with Spatial and Channel-Wise Attention</a><div class="gs_gray">S Hong, Y Zou, W Wang, M Cao</div><div class="gs_gray">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4414282388844652107" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:v_xunPV0uK0C" class="gsc_a_at">Adaptive Separation of Respiratory and Heartbeat Signals among Multiple People Based on Empirical Wavelet Transform Using UWB Radar</a><div class="gs_gray">M He, Y Nian, L Xu, L Qiao, W Wang</div><div class="gs_gray">Sensors 20 (17), 4913<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16770193734935359055" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:oldoQiaHq2UC" class="gsc_a_at">Enhanced Streaming Based Subspace Clustering Applied to Acoustic Scene Data Clustering</a><div class="gs_gray">S Li, Y Gu, Y Luo, J Chambers, W Wang</div><div class="gs_gray">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16393291797012830310" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:VnuxuLaQPLMC" class="gsc_a_at">Blind Multiple-Input Multiple-Output Image Phase Retrieval</a><div class="gs_gray">Y Guo, X Zhao, J Li, A Wang, W Wang</div><div class="gs_gray">IEEE Transactions on Industrial Electronics 67 (3), 2220-2230<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11599350014878698950" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:inmFHauC9wsC" class="gsc_a_at">LD-CNN: A Lightweight Dilated Convolutional Neural Network for Environmental Sound Classification</a><div class="gs_gray">X Zhang, Y Zou, W Wang</div><div class="gs_gray">2018 24th International Conference on Pattern Recognition (ICPR), 373-378<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13361711968075030054" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Tfl4UtY-dJUC" class="gsc_a_at">Improving reverberant speech separation with binaural cues using temporal context and convolutional neural networks</a><div class="gs_gray">A Zermini, Q Kong, Y Xu, MD Plumbley, W Wang</div><div class="gs_gray">International Conference on Latent Variable Analysis and Signal Separation&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17075937808889343687" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="JQFnV5IAAAAJ:Tfl4UtY-dJUC" data-eud="JQFnV5IAAAAJ:hfzGNhXhx5MC">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:hfzGNhXhx5MC" class="gsc_a_at">Improving reverberant speech separation with binaural cues using temporal context and convolutional neural networks</a><div class="gs_gray">A Zermini, Q Kong, Y Xu, MD Plumbley, W Wang</div><div class="gs_gray">International Conference on Latent Variable Analysis and Signal Separation&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17075937808889343687" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:cRMvf6lLvU8C" class="gsc_a_at">Intelligent signal processing mechanisms for nuanced anomaly detection in action audio-visual data streams</a><div class="gs_gray">J Kittler, I Kaloskampis, C Zor, Y Xu, Y Hicks, W Wang</div><div class="gs_gray">2018 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13558129681122510694" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:8VtEwCQfWZkC" class="gsc_a_at">A greedy algorithm with learned statistics for sparse signal reconstruction</a><div class="gs_gray">L Rencker, W Wang, MD Plumbley</div><div class="gs_gray">2017 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3748456524367620368" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:KI9T_ytC6pkC" class="gsc_a_at">Audio head pose estimation using the direct to reverberant speech ratio</a><div class="gs_gray">M Barnard, W Wang</div><div class="gs_gray">Speech Communication 85, 98-108<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9189441367033599613" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:4n0clTBhZ78C" class="gsc_a_at">Deep neural network based audio source separation</a><div class="gs_gray">A Zermini, Y Yu, Y Xu, M Plumbley, W Wang</div><div class="gs_gray">Proceedings of the 11th IMA International Conference on Mathematics in&nbsp;…<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10021828319011213414" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Ej9njvOgR2oC" class="gsc_a_at">Fully Deep Neural Networks Incorporating Unsupervised Feature Learning for Audio Tagging</a><div class="gs_gray">Y Xu, Q Huang, W Wang, P Foster, S Sigtia, PJB Jackson, MD Plumbley</div><div class="gs_gray">arXiv preprint arXiv:1607.03681<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18198190756072410389" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:aEW5N-EHWIMC" class="gsc_a_at">Removing speckle noise by analysis dictionary learning</a><div class="gs_gray">J Dong, W Wang, J Chambers</div><div class="gs_gray">2015 Sensor Signal Processing for Defence (SSPD), 1-5<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15637299874190807237" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:U0iAMwwPxtsC" class="gsc_a_at">A Polynomial Dictionary Learning Method for Acoustic Impulse Response Modeling</a><div class="gs_gray">J Guan, J Dong, X Wang, W Wang</div><div class="gs_gray">International Conference on Latent Variable Analysis and Signal Separation&nbsp;…<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14389675328877213793" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:YPNY0knpFBYC" class="gsc_a_at">Audio informed visual speaker tracking with SMC-PHD filter</a><div class="gs_gray">V Kılıç, M Barnard, W Wang, A Hilton, J Kittler</div><div class="gs_gray">2015 IEEE International Conference on Multimedia and Expo (ICME), 1-6<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6638978798005614421" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:g8uWPOAv7ggC" class="gsc_a_at">Adaptive Bayesian sparse representation for underwater acoustic signal de-noising</a><div class="gs_gray">M Barnard, W Wang</div><div class="gs_gray">Proc. 2nd IET International Conference on Intelligent Signal Processing ISP<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7852420537892547273" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:ndLnGcHYRF0C" class="gsc_a_at">Signal classification based on block-sparse tensor representation</a><div class="gs_gray">S Zubair, W Wang</div><div class="gs_gray">2014 19th International Conference on Digital Signal Processing, 361-365<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1206246286896501552" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:QsKbpXNoaWkC" class="gsc_a_at">Improving model-based convolutive blind source separation techniques via bootstrap</a><div class="gs_gray">S Chandna, W Wang</div><div class="gs_gray">2014 IEEE Workshop on Statistical Signal Processing (SSP), 424-427<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13702499373854241805" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Vr2j17o0sqMC" class="gsc_a_at">Frequency Domain Blind Source Separation Based on Independent Vector Analysis with a Multivariate Generalized Gaussian Source Prior</a><div class="gs_gray">Y Liang, SM Naqvi, W Wang, JA Chambers</div><div class="gs_gray">Blind Source Separation, 131-150<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4310435366807138848" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:eJXPG6dFmWUC" class="gsc_a_at">Joint blind dereverberation and separation of speech mixtures</a><div class="gs_gray">T Jan, W Wang</div><div class="gs_gray">2012 Proceedings of the 20th European Signal Processing Conference (EUSIPCO&nbsp;…<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3654478271971267683" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:5MTHONV0fEkC" class="gsc_a_at">Reverberant speech separation based on audio-visual dictionary learning and binaural cues</a><div class="gs_gray">Q Liu, W Wang, P Jackson, M Barnard</div><div class="gs_gray">2012 IEEE Statistical Signal Processing Workshop (SSP), 664-667<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13589830765390529278" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:naSTrk-c4S8C" class="gsc_a_at">Sparseness constrained tensor factorization algorithm for dictionary learning over high-dimensional space</a><div class="gs_gray">S Zubair, W Dai, W Wang</div><div class="gs_gray">IMA<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14576948968563546772" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:aqlVkmm33-oC" class="gsc_a_at">Empirical mode decomposition for joint denoising and dereverberation</a><div class="gs_gray">T Jan, W Wang</div><div class="gs_gray">2011 19th European Signal Processing Conference, 206-210<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6414292393462926757" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:bEWYMUwI8FkC" class="gsc_a_at">The Design of the Submarine Voyage Training Simulator Based on VR [J]</a><div class="gs_gray">W WANG, L ZHAO, Y HAO, S YANG</div><div class="gs_gray">Acta Simulata Systematica Sinica 5<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=736552104985450402" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:r0BpntZqJG4C" class="gsc_a_at">The design of Submarine Voyage Training Simulator Based on Virtual Reality [J]</a><div class="gs_gray">W Wenwu</div><div class="gs_gray">Journal of System Simulation 13, 599-602<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4897552569867590841" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:R3hNpaxXUhUC" class="gsc_a_at">利用硬盘特性对软件加密, 解密</a><div class="gs_gray">王文武， 郝燕玲</div><div class="gs_gray">应用科技 28 (011), 45-47<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2976097075206640451" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:DGzKIA18-3YC" class="gsc_a_at">Multi-Scale Residual Convolutional Encoder Decoder with Bidirectional Long Short-Term Memory for Single Channel Speech Enhancement</a><div class="gs_gray">Y Xian, Y Sun, W Wang, SM Naqvi</div><div class="gs_gray">2020 28th European Signal Processing Conference (EUSIPCO), 431-435<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=465810227860957173" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:8p8iYwVyaVcC" class="gsc_a_at">Joint Raindrop and Haze Removal From a Single Image</a><div class="gs_gray">Y Guo, J Chen, X Ren, A Wang, W Wang</div><div class="gs_gray">IEEE Transactions on Image Processing 29, 9508-9519<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12386198417127643695" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:GJVTs2krol4C" class="gsc_a_at">A Speech Synthesis Approach for High Quality Speech Separation and Generation</a><div class="gs_gray">Q Liu, PJB Jackson, W Wang</div><div class="gs_gray">IEEE Signal Processing Letters 26 (12), 1872-1876<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1897281043538759597" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:hKjooKYXoHIC" class="gsc_a_at">Proximal Deep Recurrent Neural Network for Monaural Singing Voice Separation</a><div class="gs_gray">W Yuan, S Wang, X Li, M Unoki, W Wang</div><div class="gs_gray">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12362074181020947927" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:BW2nPTmhBn4C" class="gsc_a_at">A Performance Evaluation of Several Deep Neural Networks for Reverberant Speech Separation</a><div class="gs_gray">Q Liu, W Wang, PJB Jackson, S Safavi</div><div class="gs_gray">2018 52nd Asilomar Conference on Signals, Systems, and Computers, 689-693<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9469525648085508957" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Nw_I7GeUguwC" class="gsc_a_at">Standard-independent I/Q imbalance estimation and compensation scheme inOFDM</a><div class="gs_gray">F Gu, S Wang, W Wang</div><div class="gs_gray">Frontiers of Information Technology &amp; Electronic Engineering 19 (3), 388-397<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10387388229084270265" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:sJK75vZXtG0C" class="gsc_a_at">Co-Prime Arrays with Reduced Sensors (CARS) for Direction-Of-Arrival Estimation</a><div class="gs_gray">M Chen, L Gan, W Wang</div><div class="gs_gray">2017 Sensor Signal Processing for Defence Conference (SSPD), 1-5<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16040614831101279540" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:uAPFzskPt0AC" class="gsc_a_at">Multivariate Iterative Hard Thresholding for sparse decomposition with flexible sparsity patterns</a><div class="gs_gray">L Rencker, W Wang, MD Plumbley</div><div class="gs_gray">2017 25th European Signal Processing Conference (EUSIPCO), 2156-2160<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17980084218618456622" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:ukw-9cB-YDkC" class="gsc_a_at">Wideband DoA estimation based on joint optimisation of array and spatial sparsity</a><div class="gs_gray">M Chen, W Wang, M Barnard, J Chambers</div><div class="gs_gray">2017 25th European Signal Processing Conference (EUSIPCO), 2106-2110<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5755717684123286488" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:RfUwGJFMQ-0C" class="gsc_a_at">Audio‐Visual Speaker Tracking</a><div class="gs_gray">V Kılıç, W Wang</div><div class="gs_gray">Motion Tracking and Gesture Recognition<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13278324461543741763" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:J3LtWjKFLicC" class="gsc_a_at">Joint array and spatial sparsity based optimisation for DoA estimation</a><div class="gs_gray">M Chen, M Barnard, W Wang</div><div class="gs_gray">2016 Sensor Signal Processing for Defence (SSPD), 1-5<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7508933536895348481" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:PuOEWVtPfzwC" class="gsc_a_at">Predicting binaural speech intelligibility from signals estimated by a blind source separation algorithm</a><div class="gs_gray">Q Liu, Y Tang, PJB Jackson, W Wang</div><div class="gs_gray">Proceedings of the Annual Conference of the International Speech&nbsp;…<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1271163557106186016" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:I858iXPj1OkC" class="gsc_a_at">A Local Discontinuity Based Approach for Monaural Singing Voice Separation from Accompanying Music with Multi-stage Non-negative Matrix Factorization</a><div class="gs_gray">H Deif, W Wang, L Gan, S Alhashmi</div><div class="gs_gray">2015 IEEE Global Conference on Signal and Information Processing (GlobalSIP&nbsp;…<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2727911424156582991" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:6ZzL7HXColQC" class="gsc_a_at">Separation of vocals from monaural music recordings using diagonal median filters and practical time-frequency parameters</a><div class="gs_gray">H Deif, D Fitzgerald, W Wang, L Gan</div><div class="gs_gray">2015 IEEE International Symposium on Signal Processing and Information&nbsp;…<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17846007015371341768" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:rLGzs9wiiwIC" class="gsc_a_at">Cosparsity-based Stagewise Matching Pursuit algorithm for reconstruction of the cosparse signals</a><div class="gs_gray">D Wu, Y Zhao, W Wang, Y Hao</div><div class="gs_gray">EURASIP Journal on Advances in Signal Processing 2015 (1), 1-11<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1929357709390500678" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:R22Rs3tN8aoC" class="gsc_a_at">A robust PHD filter with deep learning updating for multiple human tracking</a><div class="gs_gray">P Feng, W Wang, SM Naqvi, JA Chambers</div><div class="gs_gray">2015 IEEE International Conference on Digital Signal Processing (DSP), 1227-1231<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8737962107885067671" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:pYKElYtJMmwC" class="gsc_a_at">An analysis dictionary learning algorithm based on recursive least squares</a><div class="gs_gray">Y Zhang, H Wang, W Wang</div><div class="gs_gray">2014 12th International Conference on Signal Processing (ICSP), 831-835<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5293930614871420175" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:qmtmRrLr0tkC" class="gsc_a_at">Comparison between the Statistical cues in BSS techniques and Binaural cues in CASA approaches for reverberant speech separation</a><div class="gs_gray">A Alinaghi, PJB Jackson, W Wang</div><div class="gs_gray">Intelligent Signal Processing Conference 2013 (ISP 2013), IET, 1-4<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9414656260720365242" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:l6Q3WhenKVUC" class="gsc_a_at">Monaural Audio Separation Using Spectral Template and Isolated Note Information</a><div class="gs_gray">A Lal, W Wang</div><div class="gs_gray">Independent Component Analysis for Audio and Biosignal Applications<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2519335092324869908" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="JQFnV5IAAAAJ:l6Q3WhenKVUC" data-eud="JQFnV5IAAAAJ:Xl6nMSl579sC">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:M3NEmzRMIkIC" class="gsc_a_at">Simultaneous codeword optimization (SimCO) for dictionary learning</a><div class="gs_gray">W Dai, T Xu, W Wang</div><div class="gs_gray">2011 49th Annual Allerton Conference on Communication, Control, and&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6931998514414391404" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:_kc_bZDykSQC" class="gsc_a_at">Single channel music sound separation based on spectrogram decomposition and note classification</a><div class="gs_gray">W Wang, H Mustafa</div><div class="gs_gray">Exploring Music Contents, 84-101<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2726003037627246740" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:DQNrXyjhriIC" class="gsc_a_at">Single channel music sound separation based on spectrogram decomposition and note classification</a><div class="gs_gray">W Wang, H Mustafa</div><div class="gs_gray">International Symposium on Computer Music Modeling and Retrieval, 84-101<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2726003037627246740" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="JQFnV5IAAAAJ:DQNrXyjhriIC" data-eud="JQFnV5IAAAAJ:_kc_bZDykSQC">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:M3ejUd6NZC8C" class="gsc_a_at">Non-negative matrix factorization for face illumination analysis</a><div class="gs_gray">X Zou, W Wang, J Kittler</div><div class="gs_gray">Proc. ICA Research Network International Workshop, 52-55<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6949420868756134285" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:8k81kl-MbHgC" class="gsc_a_at">An effective method to improve convergence for sequential blind source separation</a><div class="gs_gray">L Yuan, E Sang, W Wang, JA Chambers</div><div class="gs_gray">International Conference on Natural Computation, 199-208<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17962379766100100487" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:QoJ_w57xiyAC" class="gsc_a_at">Penalty function approach for constrained convolutive blind source separation</a><div class="gs_gray">W Wang, JA Chambers, S Sanei</div><div class="gs_gray">International Conference on Independent Component Analysis and Signal&nbsp;…<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17805238629786344237" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:4DMP91E08xMC" class="gsc_a_at">Localization of P300 sources in schizophrenia patients using constrained BSS</a><div class="gs_gray">S Sanei, L Spyrou, W Wang, JA Chambers</div><div class="gs_gray">International Conference on Independent Component Analysis and Signal&nbsp;…<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6588570244861977562" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:j3f4tGmQtD8C" class="gsc_a_at">The Design and Implementation of Visual System of a Submarine Voyage Training Simulator</a><div class="gs_gray">W Yi, W Wenwu, Z Lin, S Xiaorong</div><div class="gs_gray">Proceeding of International Conference on Navigation, Guidance and Control 444<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4185196312161237799" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Xl6nMSl579sC" class="gsc_a_at">Monaural Audio Separation Using Spectral Template and Isolated Note Information</a><div class="gs_gray">A Lal, W Wang</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2519335092324869908" class="gsc_a_ac gs_ibl">2</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="JQFnV5IAAAAJ:Xl6nMSl579sC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:urP0JZOBBUsC" class="gsc_a_at">A Global-Local Attention Framework for Weakly Labelled Audio Tagging</a><div class="gs_gray">H Wang, Y Zou, W Wang</div><div class="gs_gray">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4244844470928610044" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:tgTmbKTkO1IC" class="gsc_a_at">An Audio-Based Deep Learning Framework ForBBC Television Programme Classification</a><div class="gs_gray">L Pham, C Baume, Q Kong, T Hussain, W Wang, M Plumbley</div><div class="gs_gray">arXiv preprint arXiv:2104.01161<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17564277198964921548" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:NXYAu82O0W8C" class="gsc_a_at">Adaptive Recursive Decentralized Cooperative Localization for Multirobot Systems With Time-Varying Measurement Accuracy</a><div class="gs_gray">Y Huang, C Xue, F Zhu, W Wang, Y Zhang, JA Chambers</div><div class="gs_gray">IEEE Transactions on Instrumentation and Measurement 70, 1-25<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17902481809671906516" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:eAUscmXIlQ8C" class="gsc_a_at">Multiple Acoustic Source Localization in Microphone Array Networks</a><div class="gs_gray">J Yang, X Zhong, W Chen, W Wang</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech, and Language Processing 29, 334-347<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3103142790666470298" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:iKswqCX-FLkC" class="gsc_a_at">Modeling Label Dependencies for Audio Tagging With Graph Convolutional Network</a><div class="gs_gray">H Wang, Y Zou, D Chong, W Wang</div><div class="gs_gray">IEEE Signal Processing Letters 27, 1560-1564<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13344530700897385368" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:yZoBfgUKqwcC" class="gsc_a_at">Association Loss for Visual Object Detection</a><div class="gs_gray">D Xu, J Guan, P Feng, W Wang</div><div class="gs_gray">IEEE Signal Processing Letters 27, 1435-1439<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5006891032334743545" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:NZNkWSpQBv0C" class="gsc_a_at">Robust PCA Using Nonconvex Rank Approximation and Sparse Regularizer</a><div class="gs_gray">J Dong, Z Xue, W Wang</div><div class="gs_gray">Circuits, Systems, and Signal Processing 39 (6), 3086-3104<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4869632527185654241" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:ujxm2eEBZHIC" class="gsc_a_at">Learning With Out-of-Distribution Data for Audio Classification</a><div class="gs_gray">T Iqbal, Y Cao, Q Kong, MD Plumbley, W Wang</div><div class="gs_gray">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12618779406888628312" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:j8pvxH-kN2QC" class="gsc_a_at">Gated Multi-Head Attention Pooling for Weakly Labelled Audio Tagging.</a><div class="gs_gray">S Hong, Y Zou, W Wang</div><div class="gs_gray">INTERSPEECH, 816-820<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8493239055166758206" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:u0Mu_IsstPMC" class="gsc_a_at">Monaural Speech Enhancement Based On Two Stage Long Short-Term Memory Networks</a><div class="gs_gray">Y Xian, Y Sun, W Wang, SM Naqvi</div><div class="gs_gray">2019 13th International Conference on Signal Processing and Communication&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5916619557791879471" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:NtGNdKbuCngC" class="gsc_a_at">Multiple Input Single Output Phase Retrieval</a><div class="gs_gray">Y Guo, T Wang, J Li, A Wang, W Wang</div><div class="gs_gray">Circuits, Systems, and Signal Processing 38 (8), 3818-3840<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8093114002218781419" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:vxA22ZmNLkoC" class="gsc_a_at">SVD-Based Channel Pruning for Convolutional Neural Network in Acoustic Scene Classification Model</a><div class="gs_gray">J Wang, S Li, W Wang</div><div class="gs_gray">2019 IEEE International Conference on Multimedia &amp; Expo Workshops (ICMEW&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6707303836565994450" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:rFyVMFCKTwsC" class="gsc_a_at">Predicting the perceived level of reverberation using features from nonlinear auditory model</a><div class="gs_gray">S Safavi, W Wang, M Plumbley, AJ Choobbasti, G Fazekas</div><div class="gs_gray">Proceedings of the 23rd FRUCT conference. Institute of Electrical and&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6145100841947408480" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:ojlX30-wUrgC" class="gsc_a_at">Cascade Deep Networks for Sparse Linear Inverse Problems</a><div class="gs_gray">H Zhang, H Shi, W Wang</div><div class="gs_gray">2018 24th International Conference on Pattern Recognition (ICPR), 812-817<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13988610914583950249" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:hefNtdE4IMkC" class="gsc_a_at">Bayesian inference for multi-line spectra in linear sensor array</a><div class="gs_gray">VH Tran, W Wang, Y Luo, J Chambers</div><div class="gs_gray">2018 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7695370787380868085" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:qCpRzq7zkD8C" class="gsc_a_at">Music Source Separation using Weakly Labelled Data</a><div class="gs_gray">Q Kong, Y Xu, W Wang, MD Plumbley</div><div class="gs_gray">Proc. International Society for Music Information Retrieval Conference&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16831208669124479306" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:VRfTbSk87rEC" class="gsc_a_at">Blind source separation of medial temporal discharges via partial dictionary learning</a><div class="gs_gray">S Shapoori, S Sanei, W Wang</div><div class="gs_gray">2015 IEEE 25th International workshop on machine learning for signal&nbsp;…<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8098162369516562371" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Kqc1aDSOPooC" class="gsc_a_at">Discriminativetensor dictionaries and sparsity for speaker identification</a><div class="gs_gray">S Zubair, W Wang, JA Chambers</div><div class="gs_gray">2014 4th Joint Workshop on Hands-free Speech Communication and Microphone&nbsp;…<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1722158047545843061" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:m92CDrhVnKEC" class="gsc_a_at">Audio-visual face detection for tracking in a meeting room environment</a><div class="gs_gray">M Barnard, W Wang, J Kittler, SM Naqvi, J Chambers</div><div class="gs_gray">Proceedings of the 16th International Conference on Information Fusion, 1222&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10608483899538549262" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Og1tA8FjbJAC" class="gsc_a_at">Underdetermined model-based blind source separation of reverberant speech mixtures using spatial cues in a variational bayesian framework</a><div class="gs_gray">V Popa, W Wang, A Alinaghi</div><div class="gs_gray">IET Digital Library<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17642973956179386360" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:2vr6o8x5NLkC" class="gsc_a_at">Fast dictionary learning algorithm via codeword clustering and hierarchical sparse coding</a><div class="gs_gray">T Xu, W Dai, W Wang</div><div class="gs_gray">Proc. 9th IMA Intl. Conf. on Math. in Signal Process<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5089918783844763944" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:qxL8FJ1GzNcC" class="gsc_a_at">Robust feature selection for scaling ambiguity reduction in audio-visual convolutive BSS</a><div class="gs_gray">Q Liu, SM Naqvi, W Wang, P Jackson, J Chambers</div><div class="gs_gray">2011 19th European Signal Processing Conference, 1060-1064<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6188530015843618594" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:b0M2c_1WBrUC" class="gsc_a_at">Machine Audition: Principles, Algorithms</a><div class="gs_gray">W Wang</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4818714411487894634" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:YOwf2qJgpHMC" class="gsc_a_at">Adaptive signal processing techniques for clutter removal in radar-based navigation systems</a><div class="gs_gray">Y Liang, W Wang, J Chambers</div><div class="gs_gray">2009 Conference Record of the Forty-Third Asilomar Conference on Signals&nbsp;…<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3034129889695106879" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:MXK_kJrjxJIC" class="gsc_a_at">Penalty function based joint diagonalization approach for convolutive constrained BSS of nonstationary signals</a><div class="gs_gray">W Wang, JA Chambers, S Sanei</div><div class="gs_gray">Proc. EUSIPCO<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16001668149101839980" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:c59VksA5Vz4C" class="gsc_a_at">利用状态观测器实现超混沌信号的高精度同步</a><div class="gs_gray">张学义， 陈实如， 王文武， 李殿璞</div><div class="gs_gray">哈尔滨工程大学学报 4, 008<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12278376405450646141" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:e5wmG9Sq2KIC" class="gsc_a_at">网络环境下军事信息对抗</a><div class="gs_gray">王文武， 刘承香</div><div class="gs_gray">舰船电子工程, 42-46<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6205201861074387574" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:jmjb1lOE9QIC" class="gsc_a_at">舰船电力系统生命力设计的探讨</a><div class="gs_gray">杨树国， 唐嘉亨， 郭镇明， 王文武， 李春霞</div><div class="gs_gray">船电技术 2, 000<span class="gs_oph">, 2000</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16919468398112385589" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2000</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:isC4tDSrTZIC" class="gsc_a_at">基于 ECDIS 系统的舰船天文导航系统的设计方案</a><div class="gs_gray">王文武， 郝燕玲</div><div class="gs_gray">中国航海, 71-77<span class="gs_oph">, 2000</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=34191655874542893" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2000</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:TFP_iSt0sucC" class="gsc_a_at">恒星视位置的长期计算法</a><div class="gs_gray">王文武， 王辉， 孙枫</div><div class="gs_gray">哈尔滨工程大学学报 19 (6), 35-41<span class="gs_oph">, 1998</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12514234563791255903" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">1998</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:HKviVsUxM5wC" class="gsc_a_at">Conditional Sound Generation Using Neural Discrete Time-Frequency Representation Learning</a><div class="gs_gray">X Liu, T Iqbal, J Zhao, Q Huang, MD Plumbley, W Wang</div><div class="gs_gray">arXiv preprint arXiv:2107.09998<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:VjBpw8Hezy4C" class="gsc_a_at">CL4AC: A Contrastive Loss for Audio Captioning</a><div class="gs_gray">X Liu, Q Huang, X Mei, T Ko, HL Tang, MD Plumbley, W Wang</div><div class="gs_gray">arXiv preprint arXiv:2107.09990<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:rpSJNIKeXWsC" class="gsc_a_at">Audio Captioning Transformer</a><div class="gs_gray">X Mei, X Liu, Q Huang, MD Plumbley, W Wang</div><div class="gs_gray">arXiv preprint arXiv:2107.09817<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:nOiSByfp82kC" class="gsc_a_at">Weighted Magnitude-Phase Loss for Speech Dereverberation</a><div class="gs_gray">J Zhang, MD Plumbley, W Wang</div><div class="gs_gray">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:4oJvMfeQlr8C" class="gsc_a_at">Dimension Selected Subspace Clustering</a><div class="gs_gray">S Li, Y Luo, J Chambers, W Wang</div><div class="gs_gray">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:_9Xh93LWpsYC" class="gsc_a_at">Enhancing Audio Augmentation Methods with Consistency Learning</a><div class="gs_gray">T Iqbal, K Helwani, A Krishnaswamy, W Wang</div><div class="gs_gray">ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:u_mOZUIutIEC" class="gsc_a_at">Convolutional fusion network for monaural speech enhancement</a><div class="gs_gray">Y Xian, Y Sun, W Wang, SM Naqvi</div><div class="gs_gray">Neural Networks<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:GtqhT-R7ZnwC" class="gsc_a_at">Indoor Multi-Speaker Localization Based on Bayesian Nonparametrics in the Circular Harmonic Domain</a><div class="gs_gray">K SongGong, H Chen, W Wang</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech, and Language Processing 29, 1864-1880<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:nU66GSXDKhoC" class="gsc_a_at">Time-domain Speech Enhancement with Generative Adversarial Learning</a><div class="gs_gray">F Xiao, J Guan, Q Kong, W Wang</div><div class="gs_gray">arXiv preprint arXiv:2103.16149<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:xa5BkEQK8BgC" class="gsc_a_at">Multiscale Deep Neural Network With Two-Stage Loss for SAR Target Recognition With Small Training Set</a><div class="gs_gray">J Guan, J Liu, P Feng, W Wang</div><div class="gs_gray">IEEE Geoscience and Remote Sensing Letters<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:ZysSsiWj_g4C" class="gsc_a_at">Adaptive Recursive Decentralized Cooperative Localization for Multi-Robot Systems</a><div class="gs_gray">J Chambers, Y Huang, C Xue, F Zhu, W Wang, Y Zhang</div><div class="gs_gray">University of Leicester<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:xii_ZKWM4-0C" class="gsc_a_at">Evolving Multi-Resolution Pooling CNN for Monaural Singing Voice Separation</a><div class="gs_gray">W Yuan, B Dong, S Wang, M Unoki, W Wang</div><div class="gs_gray">IEEE/ACM Transactions on Audio, Speech, and Language Processing<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:vD2iS2Kej30C" class="gsc_a_at">Sparse Analysis Model Based Dictionary Learning for Signal Declipping</a><div class="gs_gray">B Li, L Rencker, J Dong, Y Luo, MD Plumbley, W Wang</div><div class="gs_gray">IEEE Journal of Selected Topics in Signal Processing 15 (1), 25-36<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:J4E9jCG1tHUC" class="gsc_a_at">Crossfire Conditional Generative Adversarial Networks for Singing Voice Extraction}}</a><div class="gs_gray">W Yuan, S Wang, X Li, M Unoki, W Wang</div><div class="gs_gray">Proc. Interspeech 2021, 3041-3045<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:XtJa11BXPS4C" class="gsc_a_at">A Multi-Scale Feature Recalibration Network for End-to-End Single Channel Speech Enhancement</a><div class="gs_gray">Y Xian, Y Sun, W Wang, SM Naqvi</div><div class="gs_gray">IEEE Journal of Selected Topics in Signal Processing 15 (1), 143-155<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:q0uBw5dMOAkC" class="gsc_a_at">Dataset for Sparse, l1-Optimal Multi-Loudspeaker Panning and its Relation to Vector Base Amplitude Panning</a><div class="gs_gray">A Franck, W Wang, F Fazi</div><div class="gs_gray">University of Surrey<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:cdwqcPQS8ssC" class="gsc_a_at">A Covert Ultrasonic Phone-to-Phone Communication Scheme</a><div class="gs_gray">L Shi, L Yu, K Huang, X Zhu, Z Wang, X Li, W Wang, X Wang</div><div class="gs_gray">International Conference on Collaborative Computing: Networking&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:SWgZeABleR0C" class="gsc_a_at">Open-Window: A Sound Event Data Set For Window State Detection And Recognition</a><div class="gs_gray">S Safavi, T Iqbal, W Wang, P Coleman, MD Plumbley</div><div class="gs_gray">Proc. 5th International Workshop on Detection and Classification of Acoustic&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:IT1MJ6E3JesC" class="gsc_a_at">An Analytical Solution to Jacobsen Estimator for Windowed Signals</a><div class="gs_gray">T Murakami, W Wang</div><div class="gs_gray">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:WMtz-WDmgKQC" class="gsc_a_at">Single-Channel Speech Enhancement with Sequentially Trained DNN System</a><div class="gs_gray">Y Sun, Y Xian, W Wang, SM Naqvi</div><div class="gs_gray">2019 13th International Conference on Signal Processing and Communication&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:HqhvjgTjE9cC" class="gsc_a_at">A Method for Content-Based Image Retrieval with a Two-Stage Feature Matching</a><div class="gs_gray">J Huang, S Yang, W Wang</div><div class="gs_gray">2019 Tenth International Conference on Intelligent Control and Information&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:GiYFt9mpioMC" class="gsc_a_at">Two Stage Audio-Video Speech Separation using Multimodal Convolutional Neural Networks</a><div class="gs_gray">Y Xian, Y Sun, W Wang, SM Naqvi</div><div class="gs_gray">2019 Sensor Signal Processing for Defence Conference (SSPD), 1-5<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:AFXcoJnoRH0C" class="gsc_a_at">A New Sparse Linear Array With Three-Level Nested Structure</a><div class="gs_gray">M Chen, L Gan, W Wang</div><div class="gs_gray">2019 Sensor Signal Processing for Defence Conference (SSPD), 1-5<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:N6_Y7JlWxwsC" class="gsc_a_at">Background adaptation for improved listening experience in broadcasting</a><div class="gs_gray">Y Tang, TJ Cox, BM Fazenda, Q Liu, W Wang</div><div class="gs_gray">ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:M0j1y4EgrScC" class="gsc_a_at">Weakly labelled AudioSet Classification with Attention Neural Networks</a><div class="gs_gray">Q Kong, C Yu, T Iqbal, Y Xu, W Wang, MD Plumbley</div><div class="gs_gray">arXiv preprint arXiv:1903.00765<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:WIXB4To3Tx4C" class="gsc_a_at">Background Adaptation for Improved Listening Experience in Broadcasting</a><div class="gs_gray">Q Liu, W Wang, BM Fazenda, TJ Cox, Y Tang</div><div class="gs_gray">Proceedings of ICASSP 2019<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:9LpHyFPp1DQC" class="gsc_a_at">Spatially Regularized Low Rank Tensor Optimization for Visual Data Completion</a><div class="gs_gray">J Gao, H Shi, W Wang</div><div class="gs_gray">2018 25th IEEE International Conference on Image Processing (ICIP), 1822-1826<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:cB__R-XWw9UC" class="gsc_a_at">Bayesian inference for PCA and MUSIC algorithms with unknown number of sources</a><div class="gs_gray">VH Tran, W Wang</div><div class="gs_gray">arXiv preprint arXiv:1809.10168<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:c1AJUTjuCtUC" class="gsc_a_at">Approximate message passing for underdetermined audio source separation</a><div class="gs_gray">T Iqbal, W Wang</div><div class="gs_gray">​ IET 3rd International Conference on​​ Intelligent Signal Processing (ISP&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:nWoA1JPTheMC" class="gsc_a_at">Joint <svg class="gs_fsvg" aria-label="L1-L2" width="61px" height="12px" style="vertical-align:-1px;"><g transform="matrix(0.01700, 0.00000, 0.00000, 0.01700, 0.00000, 11.61100)"><path transform="scale(0.48828, -0.48828)" d="M 96 0  Q 76 0 76 27  Q 77 32 80 44  T 88 64  T 102 72  Q 227 72 276 86  Q 303 95 315 141  L 596 1266  Q 600 1286 600 1294  Q 600 1316 575 1319  Q 537 1327 428 1327  Q 408 1327 408 1354  Q 415 1380 419 1389  T 442 1399  H 1047  Q 1065 1399 1065 1372  Q 1062 1351 1058 1339  T 1038 1327  Q 887 1327 836 1317  Q 786 1308 774 1257  L 494 133  Q 485 108 485 88  Q 485 72 555 72  H 745  Q 906 72 1006 136  T 1154 280  T 1234 447  T 1282 537  H 1300  Q 1321 537 1321 510  L 1139 14  Q 1136 0 1120 0  H 96  Z "></path><path transform="matrix(0.48828, 0.00000, 0.00000, -0.48828, 680.56000, 0.00000)" d="M 190 0  V 72  Q 446 72 446 137  V 1212  Q 340 1161 178 1161  V 1233  Q 429 1233 557 1364  H 586  Q 593 1364 599 1358  T 606 1346  V 137  Q 606 72 862 72  V 0  H 190  Z "></path><path transform="matrix(0.48828, 0.00000, 0.00000, -0.48828, 1402.78296, 0.00000)" d="M 209 471  Q 192 471 181 484  T 170 512  Q 170 527 181 540  T 209 553  H 1384  Q 1400 553 1410 540  T 1421 512  Q 1421 497 1410 484  T 1384 471  H 209  Z "></path><path transform="matrix(0.48828, 0.00000, 0.00000, -0.48828, 2402.78589, 0.00000)" d="M 96 0  Q 76 0 76 27  Q 77 32 80 44  T 88 64  T 102 72  Q 227 72 276 86  Q 303 95 315 141  L 596 1266  Q 600 1286 600 1294  Q 600 1316 575 1319  Q 537 1327 428 1327  Q 408 1327 408 1354  Q 415 1380 419 1389  T 442 1399  H 1047  Q 1065 1399 1065 1372  Q 1062 1351 1058 1339  T 1038 1327  Q 887 1327 836 1317  Q 786 1308 774 1257  L 494 133  Q 485 108 485 88  Q 485 72 555 72  H 745  Q 906 72 1006 136  T 1154 280  T 1234 447  T 1282 537  H 1300  Q 1321 537 1321 510  L 1139 14  Q 1136 0 1120 0  H 96  Z "></path><path transform="matrix(0.48828, 0.00000, 0.00000, -0.48828, 3083.34595, 0.00000)" d="M 102 0  V 55  Q 102 60 106 66  L 424 418  Q 496 496 541 549  T 630 671  T 699 811  T 725 963  Q 725 1047 694 1123  T 601 1246  T 453 1292  Q 364 1292 293 1238  T 193 1100  Q 201 1102 215 1102  Q 261 1102 293 1071  T 326 991  Q 326 944 293 911  T 215 879  Q 167 879 134 912  T 102 991  Q 102 1068 131 1135  T 214 1255  T 337 1336  T 483 1364  Q 600 1364 701 1314  T 861 1174  T 920 963  Q 920 874 881 794  T 781 648  T 625 500  T 500 389  L 268 166  H 465  Q 610 166 707 168  T 811 176  Q 835 202 860 365  H 920  L 862 0  H 102  Z "></path></g></svg> Regularisation for Blind Speech Deconvolution</a><div class="gs_gray">J Guan, X Wang, Z Xie, S Qi, W Wang</div><div class="gs_gray">Pacific Rim Conference on Multimedia, 834-843<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:Oo1CbQkBAzEC" class="gsc_a_at">Blind Speech Deconvolution via Pretrained Polynomial Dictionary and Sparse Representation</a><div class="gs_gray">J Guan, X Wang, S Qi, J Dong, W Wang</div><div class="gs_gray">Pacific Rim Conference on Multimedia, 411-420<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:SpPTWFSNUtQC" class="gsc_a_at">Audio source separation with deep neural networks using the dropout algorithm</a><div class="gs_gray">A Zermini, W Wang, Q Kong, Y Xu, M Plumbley</div><div class="gs_gray">Signal Processing with Adaptive Sparse Structured Representations (SPARS&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:txeM2kYbVNMC" class="gsc_a_at">Matrix of Polynomials Model based Polynomial Dictionary Learning Method for Acoustic Impulse Response Modeling</a><div class="gs_gray">J Guan, X Wang, P Feng, J Dong, W Wang</div><div class="gs_gray">arXiv preprint arXiv:1705.08660<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:vnF2_uLGgtgC" class="gsc_a_at">Fast tagging of natural sounds using marginal co-regularization</a><div class="gs_gray">Q Huang, Y Xu, PJB Jackson, W Wang, MD Plumbley</div><div class="gs_gray">2017 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:wBLCggQE-ToC" class="gsc_a_at">Signal Processing, Psychoacoustic Engineering and Digital Worlds: Interdisciplinary Audio Research at the University of Surrey</a><div class="gs_gray">P Jackson, MD Plumbley, W Wang, T Brookes, P Coleman, R Mason, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:g_UdREhPGEoC" class="gsc_a_at">Analysis dictionary learning based on max transvection function</a><div class="gs_gray">H Wang, W Fang, W Wang, Y Zhang, S Sanei</div><div class="gs_gray">2016 IEEE International Conference on Signal and Image Processing (ICSIP&nbsp;…<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:eH23hyXCXa4C" class="gsc_a_at">A Promising Technique for Blind Identification: The Generic Statistics</a><div class="gs_gray">F Gu, H Zhang, W Wang, C Xiong</div><div class="gs_gray">Circuits, Systems, and Signal Processing 35 (7), 2544-2562<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:oTdOBqtIf_kC" class="gsc_a_at">A Bayesian performance bound for time-delay of arrival based acoustic source tracking in a reverberant environment</a><div class="gs_gray">X Zhong, W Wang, M Naqvi, ES Chng</div><div class="gs_gray">17th International Conference on Information Fusion (FUSION), 1-8<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:DXE8ND7PrJAC" class="gsc_a_at">Analysis dictionary learning based on Nesterov's gradient with application to SAR image despeckling</a><div class="gs_gray">J Dong, W Wang</div><div class="gs_gray">2014 6th International Symposium on Communications, Control and Signal&nbsp;…<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:M0leSnx2MbUC" class="gsc_a_at">A constrained approach for extraction of pre-ictal discharges from scalp EEG</a><div class="gs_gray">S Shapoori, W Wang, S Sanei</div><div class="gs_gray">2013 IEEE International Workshop on Machine Learning for Signal Processing&nbsp;…<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:HtEfBTGE9r8C" class="gsc_a_at">Weighted SimCO: A novel algorithm for dictionary update</a><div class="gs_gray">X Zhao, G Zhou, W Wang, W Dai</div><div class="gs_gray">Sensor Signal Processing for Defence (SSPD 2012), 1-5<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:e84hm74t-eoC" class="gsc_a_at">Separation and enhancement of reverberant speech mixtures using binaural cues, statistical properties and precedence effect</a><div class="gs_gray">A Alinaghi, W Wang, PJB Jackson</div><div class="gs_gray">Proc. UK &amp; RI Speech Conf.(UK Speech 2012), 18-18<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:OzeSX8-yOCQC" class="gsc_a_at">Separation of underdetermined reverberant speech mixtures by monaural, binaural and statistical cue combination</a><div class="gs_gray">A Alinaghi, PJB Jackson, W Wang</div><div class="gs_gray">Proc. IMA Int. Conf. on Math. in Sig. Proc.(ICMSP’12)<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:V_vSwabWVtYC" class="gsc_a_at">Under-determined reverberant speech separation using binaural cues and blind source separation approach</a><div class="gs_gray">A Alinaghi, W Wang, PJB Jackson</div><div class="gs_gray">Proc. Audis Conference 2011: Signal Processing and Audiology–From Front-end&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:nPTYJWkExTIC" class="gsc_a_at">Robust Multi-Camera Audio-Visual Tracking</a><div class="gs_gray">S Grima, M Barnard, W Wang</div><div class="gs_gray">UKCI 2011 Accepted Papers, 189<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:sbeIDTyQOFgC" class="gsc_a_at">IEEE/WRI Global Congress on Intelligent Systems Proceedings</a><div class="gs_gray">S Zhou, W Wang</div><div class="gs_gray">IEEE Computer Society<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:3vbIHxFL9FgC" class="gsc_a_at">Subband Decomposition for Blind Speech Separation Using a Cochlear Filterbank</a><div class="gs_gray">W Wang, J Chambers, S Sanei</div><div class="gs_gray">Proc. IMA 6th International Conference on Mathematics in Signal Processing&nbsp;…<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:oynPyU19kbsC" class="gsc_a_at">Localization of P300 Sources in Schizophrenia Patients Using Constrained BSS</a><div class="gs_gray">LS Saeid Sanei, W Wang, JA Chambers</div><div class="gs_gray">Independent Component Analysis and Blind Signal Separation:... International&nbsp;…<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:wuD5JclIwkYC" class="gsc_a_at">Hybrid Scheme of Convolutive BSS and Beamforming for Speech Signal Separation Using Psychoacousitcs Filtering</a><div class="gs_gray">W Wang, S Sanei, J Chambers</div><div class="gs_gray">Proc. International Conference on Control Science and Engineering<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:c_xDhezhKKUC" class="gsc_a_at">利用自适应控制实现蔡氏电路的标量混沌信号同步</a><div class="gs_gray">王小军， 张学义， 王文武， 李殿璞</div><div class="gs_gray">计算机仿真 19 (2), 89-92<span class="gs_oph">, 2002</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2002</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:-f6ydRqryjwC" class="gsc_a_at">基于 VR 的潜艇航行训练模拟器视景系统设计与实现</a><div class="gs_gray">王文武， 孙枫</div><div class="gs_gray">计算机工程与应用 37 (022), 172-173<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:ybfzIt2tCtgC" class="gsc_a_at">Audio-Visual Speech Source Separation</a><div class="gs_gray">B Rivet, W Wang, SM Naqvi, JA Chambers</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:IHkkN1K1AlAC" class="gsc_a_at">INCORPORATING AUXILIARY DATA FOR URBAN SOUND TAGGING</a><div class="gs_gray">T Iqbal, Y Cao, MD Plumbley, W Wang</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:8RAEygVn5_EC" class="gsc_a_at">5.3 Automated statistical anomaly detection and incongruence determination</a><div class="gs_gray">C Zor, J Kittler, W Wang, I Kaloskampis, Y Hicks, A Hunter</div><div class="gs_gray">In Signal Processing, 148<span class="gs_oph">, 0</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:pUxgyZctzPYC" class="gsc_a_at">2.2 Signal separation and broadband beamforming</a><div class="gs_gray">M Barnard, W Wang, J Corr, S Weiss, Z Wang, J McWhirter, J Deeks, ...</div><div class="gs_gray">In Signal Processing, 42<span class="gs_oph">, 0</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:zzCxg_vo7cAC" class="gsc_a_at">Blind Deconvolution for Sparse Acoustic System</a><div class="gs_gray">J Guan, X Wang, W Wang, Z Xie</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:a2necdfpwlEC" class="gsc_a_at">Fisher Information Matrix Constrained Joint Array and Spatial Sparsity Optimisation for DoA Estimation</a><div class="gs_gray">M Chen, W Wang</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:T8_be82Iz5gC" class="gsc_a_at">Exploiting Joint Array and Spatial Sparsity for Broadband Source Localisation with Fisher Information Matrix Constraints</a><div class="gs_gray">M Chen, W Wang</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:tBlTYpvFGQIC" class="gsc_a_at">Sensor Signal Processing for Defence (SSPD 2010)</a><div class="gs_gray">Q Liu, W Wang, P Jackson, R Meng, RC de Lamare, VH Nascimento</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:cNe27ouKFcQC" class="gsc_a_at">潜艇航行训练模拟器视景系统的设计与实现</a><div class="gs_gray">王益鸟， 赵琳， 沈晓蓉， 王文武</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:3_LpOwP6eMYC" class="gsc_a_at">Audio assisted robust visual tracking with adaptive particle filtering</a><div class="gs_gray"></div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:H7nrzBkawXsC" class="gsc_a_at">Reverberant speech separation with probabilistic time-frequency masking for B-format recordings</a><div class="gs_gray"></div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:6VlyvFCUEfcC" class="gsc_a_at">CHARACTERIZATION OF ACOUSTIC CHANNEL IN NOISY SHALLOW OCEAN ENVIRONMENT USING A RAO-BLACKWELLIZED PARTICLE FILTER</a><div class="gs_gray">X Zhong, VN Hari, W Wang, AB Premkumar, CT Lau</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:R-LXmdHK_14C" class="gsc_a_at">Single Channel Music Sound Separation Based on Spectrogram Decomposition and Note Classification</a><div class="gs_gray">H Mustafa, W Wang</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=JQFnV5IAAAAJ&amp;cstart=300&amp;pagesize=100&amp;citation_for_view=JQFnV5IAAAAJ:xtoqd-5pKcoC" class="gsc_a_at">MCMC-PF Based Multiple Head Tracking in a Room Environment</a><div class="gs_gray">SM Naqvi, R Phan, W Wang, JA Chambers</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr></tbody></table><div id="gsc_a_sp" class=""></div><div id="gsc_a_err" class="gs_alrt">The system can't perform the operation now. Try again later.</div></div><div id="gsc_lwp"><span id="gsc_a_nn">Articles 1–340</span><div id="gsc_bpf"><button type="button" id="gsc_bpf_more" class="gs_btnPD gs_in_ib gs_btn_flat gs_btn_lrge gs_btn_lsu" disabled=""><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl">Show more</span></span></button></div></div></form></div></div></div></div><div id="gs_ftr_sp" role="presentation"></div><div id="gs_ftr" role="contentinfo"><div id="gs_ftr_rt"><a href="/intl/en/scholar/about.html">Help</a><a href="//www.google.com/intl/en/policies/privacy/">Privacy</a><a href="//www.google.com/intl/en/policies/terms/">Terms</a></div></div></div></body></html>