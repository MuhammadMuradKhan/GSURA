<html class="gs_el_sm gs_pfcs"><head><title>‪Jungong Han‬ - ‪Google Scholar‬</title><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=Edge"><meta name="referrer" content="origin-when-cross-origin"><meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=2"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="https://scholar.google.com/citations?user=hNi1gxAAAAAJ&amp;hl=en"><meta name="description" content="‪Professor and Chair in Computer Science, Aberystwyth University, UK‬ - ‪‪Cited by 7,779‬‬ - ‪Video Analytics‬ - ‪Computer Vision‬"><meta property="og:description" content="‪Professor and Chair in Computer Science, Aberystwyth University, UK‬ - ‪‪Cited by 7,779‬‬ - ‪Video Analytics‬ - ‪Computer Vision‬"><meta property="og:title" content="Jungong Han"><meta property="og:image" content="https://scholar.googleusercontent.com/citations?view_op=medium_photo&amp;user=hNi1gxAAAAAJ&amp;citpid=1"><meta property="og:type" content="website"><meta name="twitter:card" content="summary"><style>html,body,form,table,div,h1,h2,h3,h4,h5,h6,img,ol,ul,li,button{margin:0;padding:0;border:0;}table{border-collapse:collapse;border-width:0;empty-cells:show;}html,body{height:100%}#gs_top{position:relative;box-sizing:border-box;min-height:100%;min-width:964px;-webkit-tap-highlight-color:rgba(0,0,0,0);}#gs_top>*:not(#x){-webkit-tap-highlight-color:rgba(204,204,204,.5);}.gs_el_ph #gs_top,.gs_el_ta #gs_top{min-width:320px;}#gs_top.gs_nscl{position:fixed;width:100%;}body,td,input,button{font-size:13px;font-family:Arial,sans-serif;line-height:1.24;}body{background:#fff;color:#222;-webkit-text-size-adjust:100%;-moz-text-size-adjust:none;}.gs_gray{color:#777777}.gs_red{color:#dd4b39}.gs_grn{color:#006621}.gs_lil{font-size:11px}.gs_med{font-size:16px}.gs_hlt{font-weight:bold;}a:link{color:#1a0dab;text-decoration:none}a:visited{color:#660099;text-decoration:none}a:hover,a:hover .gs_lbl{text-decoration:underline}a:active,a:active .gs_lbl,a .gs_lbl:active{color:#d14836}.gs_el_tc a:hover,.gs_el_tc a:hover .gs_lbl{text-decoration:none}.gs_pfcs a:focus,.gs_pfcs button:focus,.gs_pfcs input:focus,.gs_pfcs label:focus{outline:none}.gs_a,.gs_a a:link,.gs_a a:visited{color:#006621}.gs_a a:active{color:#d14836}a.gs_fl:link,.gs_fl a:link{color:#1a0dab}a.gs_fl:visited,.gs_fl a:visited{color:#660099}a.gs_fl:active,.gs_fl a:active{color:#d14836}.gs_fl{color:#777777}.gs_ctc,.gs_ctu{vertical-align:middle;font-size:11px;font-weight:bold}.gs_ctc{color:#1a0dab}.gs_ctg,.gs_ctg2{font-size:13px;font-weight:bold}.gs_ctg{color:#1a0dab}a.gs_pda,.gs_pda a{padding:7px 0 5px 0}.gs_alrt{background:#f9edbe;border:1px solid #f0c36d;padding:0 16px;text-align:center;box-shadow:0 2px 4px rgba(0,0,0,.2);border-radius:2px;}.gs_spc{display:inline-block;width:12px}.gs_br{width:0;font-size:0}.gs_ibl{display:inline-block;}.gs_scl:after{content:"";display:table;clear:both;}.gs_ind{padding-left:8px;text-indent:-8px}.gs_ico,.gs_icm{display:inline-block;background:no-repeat url(/intl/en/scholar/images/1x/sprite_20161020.png);background-position:-23px -161px;background-size:169px;width:21px;height:21px;}@media(-webkit-min-device-pixel-ratio:1.5),(min-resolution:144dpi){.gs_ico,.gs_icm{background-image:url(/intl/en/scholar/images/2x/sprite_20161020.png);}}.gs_el_ta .gs_nta,.gs_ota,.gs_el_ph .gs_nph,.gs_oph{display:none}.gs_el_ta .gs_ota,.gs_el_ph .gs_oph{display:inline}.gs_el_ta div.gs_ota,.gs_el_ph div.gs_oph{display:block}.gs_sth_g{visibility:hidden;max-height:0;}.gs_sth_vis .gs_sth_g{max-height:1000px;}.gs_sth_vis .gs_sth_b{position:fixed;top:0;}@keyframes gs_anm_spin{0%{transform:rotate(0deg);}100%{transform:rotate(360deg);}}.gs_rimg{display:block;background-color:#e5e5e5;border-radius:50%;overflow:hidden;position:relative;z-index:1;}.gs_rimg>img{position:absolute;margin:auto;left:0;top:0;bottom:0;right:0;}.gs_in_txtw{display:inline-block;vertical-align:middle;}.gs_in_txtb{display:block;}.gs_in_txt{color:#000;background-color:#fff;font-size:16px;box-sizing:border-box;height:29px;line-height:23px;border:1px solid #d9d9d9;border-top-color:#c0c0c0;padding:3px 6px 1px 8px;border-radius:1px;outline:none;-webkit-appearance:none;-moz-appearance:none;}.gs_el_tc .gs_in_txt{font-size:18px;}.gs_in_txtb .gs_in_txt{width:100%;}.gs_in_txt:hover{border-color:#b9b9b9;border-top-color:#a0a0a0;box-shadow:inset 0 1px 2px rgba(0,0,0,.1);}.gs_in_txte .gs_in_txt{border-color:#dd4b39;}.gs_in_txt:focus{border-color:#4d90fe;box-shadow:inset 0 1px 2px rgba(0,0,0,.3);}.gs_in_txt:disabled{color:#b8b8b8;border-color:#f1f1f1;box-shadow:none;}.gs_in_txtm .gs_in_txt{font-size:13px;height:24px;line-height:16px;padding:3px 6px;}.gs_el_tc .gs_in_txtm .gs_in_txt{height:29px;line-height:21px;}.gs_in_txts{font-size:13px;line-height:18px;color:#666;}.gs_in_txte .gs_in_txts{color:#dd4b39;}button{position:relative;z-index:1;box-sizing:border-box;font-size:13px;cursor:pointer;height:29px;line-height:normal;min-width:72px;padding:0 8px;color:#444;border:1px solid rgba(0,0,0,.1);border-radius:3px;text-align:center;background-color:#f5f5f5;-webkit-user-select:none;user-select:none;}button.gs_btn_rnd{border-radius:14px;padding:0 12px;}button.gs_btn_rnd.gs_btn_rndci{padding-left:4px;}button.gs_btn_lrge{height:41px;min-width:82px;padding:0 9px;}button.gs_btn_lrge.gs_btn_rnd{border-radius:20px;padding:0 16px;}button.gs_btn_lrge.gs_btn_rnd.gs_btn_rndci{padding-left:10px;}button.gs_btn_cir{border-radius:14.5px;min-width:29px;}button.gs_btn_lrge.gs_btn_cir{border-radius:20.5px;min-width:41px;}button.gs_btn_mini{padding:0;border:0;}.gs_el_ph button.gs_btn_mph,.gs_el_ta button.gs_btn_mta{height:41px;}button .gs_wr{position:relative;display:inline-block;width:100%;height:100%;}button .gs_wr:before{content:"";width:0;height:100%;}button .gs_wr:before,button .gs_ico,button .gs_rdt,button .gs_lbl,button .gs_icm{display:inline-block;vertical-align:middle;}button .gs_wr{font-size:13px;text-transform:none;}.gs_btn_lrge .gs_wr{font-size:15px;}.gs_btn_lsb .gs_wr{font-size:11px;font-weight:bold;}.gs_btn_lsu .gs_wr{font-size:11px;text-transform:uppercase;}.gs_btn_lrge.gs_btn_lsb .gs_wr,.gs_btn_lrge.gs_btn_lsu .gs_wr{font-size:13px;}.gs_btn_half,.gs_el_ta .gs_btn_hta,.gs_el_ph .gs_btn_hph{min-width:36px;}.gs_btn_lrge.gs_btn_half,.gs_el_ta .gs_btn_lrge.gs_btn_hta,.gs_el_ph .gs_btn_lrge.gs_btn_hph,.gs_el_ta .gs_btn_mta,.gs_el_ph .gs_btn_mph{min-width:41px;}.gs_btn_slt{border-radius:3px 0 0 3px;}.gs_btn_srt{margin-left:-1px;border-radius:0 3px 3px 0;}.gs_btn_smd{margin-left:-1px;border-radius:0;}button:hover{z-index:2;color:#222;border-color:rgba(0,0,0,.2);background-color:#f8f8f8;}button.gs_sel{background-color:#dcdcdc;}button:active{z-index:2;background-color:#f1f1f1;}button:focus{z-index:2;}button::-moz-focus-inner{padding:0;border:0}button:-moz-focusring{outline:1px dotted ButtonText}.gs_pfcs button:-moz-focusring{outline:none}a.gs_in_ib{position:relative;display:inline-block;line-height:16px;padding:6px 0 7px 0;-webkit-user-select:none;user-select:none;}a.gs_btn_lrge{height:40px;padding:0;}a.gs_in_ib .gs_lbl{display:inline-block;padding-left:21px;color:#222;}a.gs_in_ib .gs_lbl:not(:empty){padding-left:29px;}button.gs_in_ib .gs_lbl:not(:empty){padding-left:4px;}a.gs_in_ib:active .gs_lbl,a.gs_in_ib .gs_lbl:active,a.gs_in_ib :active~.gs_lbl{color:#d14836;}.gs_el_ta .gs_btn_hta .gs_lbl,.gs_el_ph .gs_btn_hph .gs_lbl,.gs_el_ta .gs_btn_mta .gs_lbl,.gs_el_ph .gs_btn_mph .gs_lbl,.gs_el_ta .gs_btn_cta .gs_lbl,.gs_el_ph .gs_btn_cph .gs_lbl{display:none;}a.gs_in_ib .gs_ico{position:absolute;top:3px;left:0;}.gs_in_ib.gs_md_li .gs_ico{left:14px;}.gs_el_tc .gs_in_ib.gs_md_li .gs_ico{top:11px;}.gs_in_ib.gs_md_li.gs_md_lix .gs_ico{top:10px;left:16px;}a.gs_btn_lrge .gs_ico{top:50%;left:50%;margin:-10.5px 0 0 -10.5px;}.gs_in_ib .gs_ico{opacity:.55;}.gs_in_ib:hover .gs_ico{opacity:.72;}.gs_in_ib:active .gs_ico,.gs_in_ib .gs_ico:active,.gs_in_ib :active~.gs_ico{opacity:1;}.gs_in_ib:disabled .gs_ico,.gs_in_ib.gs_dis .gs_ico{opacity:.28;}.gs_in_ib.gs_btn_act .gs_ico,.gs_in_ib.gs_btn_cre .gs_ico{opacity:1;}.gs_btn_act:disabled .gs_ico,.gs_btn_cre:disabled .gs_ico{opacity:.72;}.gs_rdt{position:relative;width:0;height:21px;}.gs_rdt:before{content:"";position:absolute;top:2px;right:1px;width:5px;height:5px;border-radius:50%;background-color:#dd4b39;}button.gs_btn_flat{border-color:transparent;background-color:transparent;}button.gs_btn_flat:hover{background-color:rgba(0,0,0,.05);}button.gs_btn_flat:active{background-color:rgba(0,0,0,.1);}button.gs_btn_flat.gs_btn_flact{color:#1a0dab;}button.gs_btn_act{color:#fff;-webkit-font-smoothing:antialiased;background-color:#4d90fe;}button.gs_btn_act:hover{color:#fff;background-color:#3983fe;}button.gs_btn_act.gs_sel{background-color:#2f6bcc;}button.gs_btn_act:active{background-color:#357ae8;}button.gs_btn_cre{color:#fff;-webkit-font-smoothing:antialiased;background-color:#d14836;}button.gs_btn_cre:hover{color:#fff;background-color:#c53727;}button.gs_btn_cre.gs_sel{background-color:#992b1e;}html:not(.gs_pfcs) .gs_btn_act:focus:not(:active){box-shadow:inset 0 0 0 1px rgba(255,255,255,.5);}button.gs_btn_cre:active{background-color:#b0281a;}button:disabled,button:disabled:hover,button:disabled:active{cursor:default;color:#b8b8b8;border-color:rgba(0,0,0,.05);background-color:transparent;z-index:0;}button.gs_btn_flat:disabled{color:#b8b8b8;border-color:transparent;}button.gs_btn_act:disabled{color:#fff;background-color:#a6c8ff;}button.gs_btn_cre:disabled{color:#fff;background-color:#e8a49b;}a.gs_in_ib.gs_dis{cursor:default;pointer-events:none}a.gs_in_ib.gs_dis .gs_lbl{color:#b8b8b8;text-decoration:none}.gs_ttp{position:absolute;top:100%;right:50%;z-index:10;pointer-events:none;visibility:hidden;opacity:0;transition:visibility 0s .13s,opacity .13s ease-out;}button:hover .gs_ttp,button:focus .gs_ttp,a:hover .gs_ttp,a:focus .gs_ttp{transition:visibility 0s .3s,opacity .13s ease-in .3s;visibility:visible;opacity:1;}.gs_md_tb.gs_sel .gs_ttp{transition:none;visibility:hidden;}button.gs_btn_lrge.gs_btn_cir .gs_ttp{top:75%;}.gs_ttp .gs_aro,.gs_ttp .gs_aru{position:absolute;top:-2px;right:-5px;width:0;height:0;line-height:0;font-size:0;border:5px solid transparent;border-top:none;border-bottom-color:#595959;z-index:1;}.gs_ttp .gs_aro{top:-3px;right:-6px;border-width:6px;border-top:none;border-bottom-color:white;}.gs_ttp .gs_txt{display:block;position:relative;top:2px;right:-50%;padding:4px 6px;background:#595959;color:white;font-size:11px;font-weight:bold;line-height:normal;white-space:nowrap;border:1px solid white;border-radius:3px;box-shadow:inset 0 1px 4px rgba(0,0,0,.2);}.gs_press,.gs_in_se,.gs_tan{touch-action:none;}.gs_in_se .gs_lbl:not(:empty){padding-right:14px;}.gs_in_se .gs_icm{position:absolute;top:50%;margin-top:-5.5px;right:0;width:7px;height:11px;background-position:-21px -88px;opacity:.55;}.gs_in_se:hover .gs_icm{opacity:.72;}.gs_in_se:active .gs_icm{opacity:1;}.gs_in_se:disabled .gs_icm{opacity:.28;}.gs_el_ta .gs_btn_hta .gs_icm,.gs_el_ph .gs_btn_hph .gs_icm,.gs_el_ta .gs_btn_mta .gs_icm,.gs_el_ph .gs_btn_mph .gs_icm,.gs_el_ta .gs_btn_cta .gs_icm,.gs_el_ph .gs_btn_cph .gs_icm{display:none;}.gs_btn_mnu .gs_icm{margin-top:-3.5px;height:7px;background-position:0 -110px;}.gs_in_se.gs_btn_act .gs_icm,.gs_in_se.gs_btn_cre .gs_icm{margin-top:-3.5px;height:7px;background-position:-42px -44px;opacity:1;}.gs_btn_act:disabled .gs_icm,.gs_btn_cre:disabled .gs_icm{opacity:.72;}button.gs_btnG .gs_ico{width:21px;height:21px;background-position:-92px -253px;}button .gs_bs{position:absolute;top:50%;left:50%;margin-top:-10px;margin-left:-10px;box-sizing:border-box;width:20px;height:20px;border-radius:50%;border:2px solid #eee;border-top-color:#4d90fe;visibility:hidden;animation:gs_anm_spin .8s linear infinite;}button.gs_bsp .gs_bs{visibility:visible;transition:visibility 0s .4s;}.gs_md_d{text-transform:none;white-space:nowrap;position:absolute;top:0;left:0;border:1px solid #ccc;border-color:rgba(0,0,0,.2);background:#fff;box-shadow:0 2px 4px rgba(0,0,0,.2);z-index:1100;text-align:left;visibility:hidden;max-height:0;margin-top:-1000px;opacity:0;transition:opacity .13s,visibility 0s .13s,max-height 0s .13s,margin-top 0s .13s;}.gs_md_d.gs_vis{visibility:visible;max-height:10000px;margin-top:0;opacity:1;transition:all 0s;}.gs_el_tc .gs_md_d{transform-origin:100% 0;transform:scale(1,0);transition:opacity .218s ease-out,transform 0s .218s,visibility 0s .218s,max-height 0s .218s,margin-top 0s .218s;}.gs_el_ios .gs_md_d{-webkit-backface-visibility:hidden;}.gs_el_tc .gs_md_d.gs_ttzi{transform-origin:50% 50%;transform:scale(0,0);}.gs_el_tc .gs_md_d.gs_ttzr{transform:scale(0,0);}.gs_el_tc .gs_md_d.gs_vis{transform:scale(1,1);transition:transform .218s ease-out;}.gs_md_r{position:relative;display:inline-block;}.gs_md_rmb>.gs_md_d{top:29px}.gs_md_rmbl>.gs_md_d{top:41px}.gs_md_ul{list-style-type:none;word-wrap:break-word;display:inline-block;vertical-align:top;}.gs_md_ul.gs_md_ul_tb{display:block;}.gs_md_li,.gs_in_cb.gs_md_li,.gs_md_li:link,.gs_md_li:visited{display:block;padding:6px 44px 6px 16px;font-size:13px;line-height:16px;color:#222;cursor:pointer;text-decoration:none;position:relative;z-index:0;}a.gs_md_li:hover .gs_lbl,a.gs_md_li:active .gs_lbl{text-decoration:none}.gs_el_tc .gs_md_li{padding-top:14px;padding-bottom:10px;}.gs_md_li.gs_md_lix{font-size:16px;line-height:20px;padding:12px 16px 8px 16px;}.gs_md_li:before{content:"";background-color:#f1f1f1;position:absolute;left:0;right:0;top:0;bottom:0;opacity:0;transition:opacity .13s;z-index:-1;}.gs_md_li:hover:before,.gs_md_li:focus:before{opacity:1;transition:all 0s;}a.gs_in_ib.gs_md_li .gs_lbl{color:#222}a.gs_in_ib.gs_md_li.gs_in_gray .gs_lbl{color:#444}.gs_md_li:active:before{background-color:#ddd}.gs_md_li.gs_sel,a.gs_in_ib.gs_md_li.gs_sel .gs_lbl{color:#d14836}.gs_md_d:focus,.gs_md_li:focus{outline:none}a.gs_md_lix .gs_lbl,a.gs_md_lix .gs_lbl:not(:empty){padding:0 0 0 40px;}a.gs_in_cb:link,a.gs_in_cb:visited,a.gs_in_cb:active,a.gs_in_cb:hover{cursor:pointer;color:#222;text-decoration:none;}.gs_in_cb,.gs_in_ra{position:relative;line-height:16px;display:inline-block;-webkit-user-select:none;user-select:none;}.gs_in_cb.gs_md_li{padding:6px 44px 6px 16px;}.gs_in_cb input,.gs_in_ra input{position:absolute;top:1px;left:1px;width:15px;height:15px;margin:0;padding:0;opacity:0;z-index:2;}.gs_in_ra input{top:0;left:0}.gs_el_tc .gs_in_cb input{top:9px}.gs_el_tc .gs_in_ra input{top:8px}.gs_in_cb.gs_in_cbj input{top:15px;left:15px}.gs_in_cb label,.gs_in_cb .gs_lbl,.gs_in_ra label{display:inline-block;padding-left:21px;min-height:16px;}.gs_in_cb label:empty:before,.gs_in_cb .gs_lbl:empty:before,.gs_in_ra label:empty:before{content:"\200b";}.gs_el_tc .gs_in_cb label,.gs_el_tc .gs_in_cb .gs_lbl,.gs_el_tc .gs_in_ra label{padding-top:8px;padding-bottom:5px;}.gs_in_cb.gs_in_cbj label,.gs_in_cb.gs_in_cbj .gs_lbl{padding:13px 0 12px 41px;}.gs_in_cbb,.gs_in_cbb label,.gs_in_cbb .gs_lbl{display:block;}.gs_in_cb .gs_cbx,.gs_in_ra .gs_cbx{position:absolute}.gs_in_cb .gs_cbx{top:2px;left:2px;width:11px;height:11px;border:1px solid #c6c6c6;border-radius:1px;}.gs_md_li .gs_cbx{top:8px;left:18px}.gs_el_tc .gs_in_cb .gs_cbx{top:10px}.gs_el_tc .gs_md_li .gs_cbx{top:16px}.gs_in_cb.gs_in_cbj .gs_cbx{top:15px;left:15px}.gs_el_tc .gs_in_ra .gs_cbx{top:8px}.gs_in_ra .gs_cbx{top:0;left:0;border:1px solid #c6c6c6;width:13px;height:13px;border-radius:7px;}.gs_in_cb:hover .gs_cbx,.gs_in_ra:hover .gs_cbx{border-color:#666;box-shadow:inset 0 1px 1px rgba(0,0,0,.1);}button.gs_in_cb:hover .gs_cbx{border-color:#c6c6c6;}.gs_in_cb :focus~label,.gs_in_ra :focus~label{outline:1px dotted #222;outline:auto -webkit-focus-ring-color;}.gs_pfcs .gs_in_cb :focus~label,.gs_pfcs .gs_in_ra :focus~label{outline:none;}.gs_in_cb:active .gs_cbx,.gs_in_ra:active .gs_cbx,.gs_in_cb .gs_cbx:active,.gs_in_ra .gs_cbx:active,.gs_in_cb :active~.gs_cbx,.gs_in_ra :active~.gs_cbx{border-color:#666;background-color:#ebebeb;}button.gs_in_cb:active .gs_cbx{border-color:#a6a6a6;}.gs_in_cb :disabled~.gs_cbx,.gs_in_ra :disabled~.gs_cbx,button.gs_in_cb:disabled .gs_cbx{border-color:#f1f1f1;box-shadow:none;}.gs_in_cb :disabled~label,.gs_in_ra :disabled~label{color:#b8b8b8;}.gs_in_cb.gs_err .gs_cbx{border-color:#eda29b;}.gs_in_cb .gs_chk,.gs_in_ra .gs_chk{position:absolute;z-index:1;top:-3px;left:-2px;width:21px;height:21px;}.gs_md_li .gs_chk{top:3px;left:14px}.gs_el_tc .gs_in_cb .gs_chk{top:5px}.gs_el_tc .gs_md_li .gs_chk{top:11px}.gs_in_cb.gs_in_cbj .gs_chk{top:10px;left:11px}.gs_in_ra .gs_chk{top:4px;left:4px;width:7px;height:7px;border-radius:4px;}.gs_el_tc .gs_in_ra .gs_chk{top:12px}.gs_in_cb input:checked~.gs_chk,.gs_in_cb.gs_sel .gs_chk{background:no-repeat url(/intl/en/scholar/images/1x/sprite_20161020.png) -69px -67px;opacity:.62;}.gs_in_ra input:checked~.gs_chk{background-color:#666}.gs_in_cb.gs_par .gs_chk{background:no-repeat url(/intl/en/scholar/images/1x/sprite_20161020.png) -21px -44px;opacity:.55;}@media(-webkit-min-device-pixel-ratio:1.5),(min-resolution:144dpi){.gs_in_cb input:checked~.gs_chk,.gs_in_cb.gs_sel .gs_chk,.gs_in_cb.gs_par .gs_chk{background-image:url(/intl/en/scholar/images/2x/sprite_20161020.png);background-size:169px;}}.gs_in_cb input:checked:disabled~.gs_chk{opacity:.22}.gs_in_ra input:checked:disabled~.gs_chk{background-color:#f1f1f1}.gs_ico_x{background-position:-113px -22px;opacity:.55;}.gs_ico_x:hover{opacity:.72;}.gs_ico_x:active{opacity:1;}.gs_ico_X{background-position:-71px 0;opacity:.55;}.gs_ico_X:hover{opacity:.72;}.gs_ico_X:active{opacity:1;}.gs_el_tc .gs_ico_Xt{background-origin:content-box;background-clip:content-box;padding:10px 6px 10px 14px;}.gs_ico_P{background-position:0 0;opacity:.55;}.gs_ico_P:hover{opacity:.72;}.gs_ico_P:active{opacity:1;}.gs_btnP .gs_ico{background-position:-21px 0;}.gs_btnC .gs_ico{background-position:0 -66px;}.gs_btnL .gs_ico{background-position:-92px -44px;}.gs_ico_LB{background-position:-50px -44px;height:16px;}.gs_btnJ .gs_ico{background-position:-92px -22px;}.gs_btnM .gs_ico{background-position:-92px 0;}.gs_btnMW .gs_ico{background-position:-21px -22px;}.gs_btnSB .gs_ico{background-position:0 -44px;}.gs_btnTSB .gs_ico{background-position:-115px -253px;}.gs_btnPL .gs_ico{background-position:-148px -66px;}.gs_btnPR .gs_ico{background-position:-21px -66px;}.gs_btnPLW .gs_ico{background-position:-0 -230px;}.gs_btnPRW .gs_ico{background-position:-23px -230px;}.gs_btnZI .gs_ico{background-position:-148px -22px;}.gs_btnZO .gs_ico{background-position:-127px -44px;}.gs_btnDE .gs_ico{background-position:-134px 0;}.gs_btnFI .gs_ico{background-position:-50px -66px;}.gs_btnAD .gs_ico{background-position:-141px -88px;opacity:.55;}.gs_btnAD:hover .gs_ico{opacity:.72;}.gs_btnAD:active .gs_ico,.gs_btnAD .gs_ico:active,.gs_btnAD :active~.gs_ico{opacity:1;}.gs_btnBA .gs_ico{background-position:-50px -22px;}.gs_btnADD .gs_ico{background-position:-92px -66px;}.gs_btnMRG .gs_ico{background-position:-113px 0;}.gs_btnLBL .gs_ico{background-position:0 -161px;}.gs_btnCNCL .gs_ico{background-position:-71px 0;}.gs_btnDWL .gs_ico{background-position:-28px -88px;}.gs_btnMNU .gs_ico{background-position:0 -88px;}.gs_btnMNT .gs_ico{background-position:-46px -161px;}.gs_btnALT .gs_ico{background-position:-92px -161px;}.gs_btnART .gs_ico{background-position:-115px -161px;}.gs_btnGSL .gs_ico{background-position:-69px -161px;}.gs_btnCLS .gs_ico{background-position:-138px -161px;}.gs_btnXBLU .gs_ico{background-position:-138px -253px;}.gs_btnSSB .gs_ico{background-position:0 -276px;}.gs_btnSSW .gs_ico{background-position:-23px -276px;}.gs_btnFLT .gs_ico{background-position:0 -184px;}.gs_btnXT .gs_ico{background-position:-46px -184px;}.gs_btnPD .gs_ico{background-position:-69px -184px;}.gs_btnPU .gs_ico {background-position:-92px -276px;}.gs_btnCP .gs_ico{background-position:-92px -184px;}.gs_btnTP .gs_ico{background-position:-138px -184px;}.gs_btnML .gs_ico{background-position:-115px -276px;}.gs_btnCHK .gs_ico{background-position:-71px -66px;}.gs_btnDNB .gs_ico{background-position:-115px -230px;}.gs_btnDNW .gs_ico{background-position:0 -207px;}.gs_btnACA .gs_ico{background-position:-23px -207px;}.gs_btnAPT .gs_ico{background-position:-46px -207px;}.gs_btnAPTW .gs_ico{background-position:-92px -230px;}.gs_btnAFL .gs_ico{background-position:-69px -207px;}.gs_btnAN .gs_ico{background-position:-46px -276px;}.gs_btnAI .gs_ico{background-position:-69px -276px;}.gs_btnPBL .gs_ico{background-position:-92px -207px;}.gs_btnUCT .gs_ico{background-position:-115px -207px;}.gs_btnVRF .gs_ico{background-position:-138px -207px;}.gs_btnLSI .gs_ico{background-position:-46px -230px;}.gs_btnLSG .gs_ico{background-position:-69px -230px;}.gs_btnMOR .gs_ico{background-position:-23px -253px;}.gs_btnADV .gs_ico{background-position:-46px -253px;}.gs_btnPRO .gs_ico{background-position:-69px -253px;}.gs_ico_star{background-position:-71px -44px;width:13px;height:13px;}.gs_btnPLSW .gs_ico{background-position:-138px -230px;}.gs_btnPDF .gs_ico{background-position:0 -253px;}.gs_btnS .gs_ico{background-position:-138px -276px;}.gs_btnUNS .gs_ico{background-position:0 -299px;}.gs_btnMORR .gs_ico{background-position:-23px -299px;}.gs_btnTW .gs_ico{background-position:-46px -299px;}.gs_btnIN .gs_ico{background-position:-69px -299px;}.gs_btnFB .gs_ico{background-position:-92px -299px;}#gs_hdr_drs,#gs_hdr_drw{position:fixed;top:0;left:0;width:100%;height:100%;z-index:1200;visibility:hidden;}#gs_hdr_drs{opacity:0;background-color:#fff;transition:opacity .15s,visibility 0s .15s;}.gs_el_ta #gs_hdr_drs,.gs_el_ph #gs_hdr_drs{background-color:#666;}#gs_hdr_drs.gs_vis{visibility:visible;opacity:.5;transition:opacity .15s,visibility 0s;}.gs_el_tc #gs_hdr_drs{transition:opacity .218s,visibility 0s .218s;}.gs_el_tc #gs_hdr_drs.gs_vis{transition:opacity .218s,visibility 0s;}#gs_hdr_drw{overflow:auto;width:228px;background-color:#fff;box-shadow:2px 2px 4px rgba(0,0,0,.15);outline:none;transform:translate(-100%,0);transition:transform .15s ease-in-out,visibility 0s .15s;}#gs_hdr_drw.gs_vis{visibility:visible;transform:translate(0,0);transition:transform .15s ease-in-out,visibility 0s;}.gs_el_tc #gs_hdr_drw{transition:transform .3s cubic-bezier(.4,0,.6,1),visibility 0s .3s;}.gs_el_tc #gs_hdr_drw.gs_vis{transition:transform .225s cubic-bezier(0,0,.2,1),visibility 0s;}#gs_hdr_drw.gs_abt,.gs_el_tc #gs_hdr_drw.gs_abt{transition:none;}#gs_hdr_drw_in{position:relative;box-sizing:border-box;min-height:100%;padding:0 0 8px 0;}.gs_el_ta #gs_hdr_drw_in,.gs_el_ph #gs_hdr_drw_in{padding:0 0 65px 0;}#gs_hdr_drw_top{position:relative;height:63px;border-bottom:1px solid #e5e5e5;margin-bottom:8px;}.gs_el_ta #gs_hdr_drw_top,.gs_el_ph #gs_hdr_drw_top{height:57px;}#gs_hdr_drw_mnu,#gs_hdr_drw_lgo{position:absolute;top:0;height:100%;}#gs_hdr_drw_mnu{left:0;width:55px;}#gs_hdr_drw_lgo{left:56px;}.gs_hdr_drw_sec:before{display:block;content:" ";height:0;border-bottom:1px solid #e5e5e5;margin:8px 0;}.gs_hdr_drw_sec:first-child:before{display:none;}#gs_hdr_drw_bot{display:none;}.gs_el_ta #gs_hdr_drw_bot,.gs_el_ph #gs_hdr_drw_bot{display:block;position:absolute;left:0;bottom:0;width:100%;height:65px;}#gs_hdr_drw_bot .gs_md_li:before{opacity:0;}#gs_hdr_drw_bot .gs_hdr_pp{display:block;position:absolute;bottom:14px;left:15px;pointer-events:none;}#gs_hdr_drw_bot .gs_lbl{display:block;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;}#gs_hdr{position:relative;height:63px;background-color:#f5f5f5;border-bottom:1px solid #e5e5e5;display:flex;}.gs_el_ta #gs_hdr,.gs_el_ph #gs_hdr{height:57px;}#gs_hdr_mnu,#gs_hdr_bck,#gs_hdr_lgo,#gs_hdr_lgt,#gs_hdr_md,#gs_hdr_sre,#gs_hdr_act{display:inline-block;vertical-align:top;position:relative;height:100%;flex:0 0 auto;}#gs_hdr_md{flex:1 1 auto;}#gs_hdr .gs_hdr_mbo,#gs_hdr .gs_hdr_mbo,.gs_el_ta #gs_hdr .gs_hdr_dso,.gs_el_ph #gs_hdr .gs_hdr_dso{display:none;}.gs_el_ta #gs_hdr .gs_hdr_mbo,.gs_el_ph #gs_hdr .gs_hdr_mbo{display:inline-block;}#gs_hdr_mnu,#gs_hdr_bck,#gs_hdr_sre{width:55px;margin-right:1px;}#gs_hdr_lgo,#gs_hdr_drw_lgo{width:149px;background:no-repeat url('/intl/en/scholar/images/1x/scholar_logo_24dp.png') 0% 50%;background-size:149px;}@media(-webkit-min-device-pixel-ratio:1.5),(min-resolution:144dpi){#gs_hdr_lgo,#gs_hdr_drw_lgo{background-image:url('/intl/en/scholar/images/2x/scholar_logo_24dp.png');}}#gs_hdr_lgo{margin-right:31px;}.gs_el_ph #gs_hdr_lgo{margin-right:0;}#gs_hdr_lgt{min-width:164px;margin-right:16px;}#gs_hdr_lgt:empty{display:none;}#gs_hdr_md{margin-right:16px;min-width:1px;}#gs_hdr_lgt,#gs_hdr_md h1{padding:19px 0 0 0;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;font-size:20px;line-height:25px;font-weight:normal;color:#666;max-width:100%;text-align:left;}.gs_el_ta #gs_hdr_md h1,.gs_el_ph #gs_hdr_md h1{padding:16px 0 0 0;}#gs_hdr_srch{padding:14px 0 0 0;max-width:600px;}.gs_el_ta #gs_hdr_srch,.gs_el_ph #gs_hdr_srch{padding:10px 0 0 0;max-width:none;}#gs_hdr_frm{position:relative;padding-right:39px;}#gs_hdr_tsi{height:38px;border-radius:2px 0 0 2px;}#gs_hdr_tsi::-ms-clear{display:none;}#gs_hdr_tsc{display:none;position:absolute;top:3px;right:41px;width:21px;height:21px;padding:6px 10px 7px 10px;}.gs_in_acw[dir="rtl"]~#gs_hdr_tsc{right:auto;left:1px;}#gs_hdr_tsb{position:absolute;top:0;right:0;width:40px;height:38px;border-radius:0 2px 2px 0;}#gs_hdr_frm_ac{top:37px;right:40px;}.gs_el_ph #gs_hdr_frm_ac{right:0;}.gs_el_ph .gs_hdr_ifc #gs_hdr_mnu,.gs_el_ph .gs_hdr_ifc #gs_hdr_bck,.gs_hdr_src #gs_hdr_srch,.gs_hdr_src #gs_hdr_lgt,.gs_hdr_srx #gs_hdr_sre,.gs_hdr_srx #gs_hdr_md h1,.gs_hdr_srx #gs_hdr_md h1.gs_hdr_mbo,.gs_hdr_srx #gs_hdr_md h1.gs_hdr_dso,.gs_el_ta .gs_hdr_srx #gs_hdr_lgo,.gs_el_ph .gs_hdr_srx #gs_hdr_lgo,.gs_el_ph .gs_hdr_srx #gs_hdr_mnu,.gs_el_ph .gs_hdr_srx #gs_hdr_bck{display:none;}.gs_el_ph .gs_hdr_ifc #gs_hdr_md,.gs_el_ph .gs_hdr_srx #gs_hdr_md{margin-left:16px;}.gs_el_tc .gs_hdr_tsc #gs_hdr_tsi[dir="ltr"]{padding-right:41px;}.gs_el_tc .gs_hdr_tsc #gs_hdr_tsi[dir="rtl"]{padding-left:41px;}.gs_el_tc .gs_hdr_tsc .gs_in_acw~#gs_hdr_tsc{display:block;}#gs_hdr_act{min-width:64px;max-width:200px;text-align:right;float:right;}.gs_el_ta #gs_hdr_act,.gs_el_ph #gs_hdr_act{display:none;}#gs_hdr_act_i,#gs_hdr_act_s{display:inline-block;padding:23px 24px 23px 16px;max-width:100%;box-sizing:border-box;font-size:13px;line-height:17px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;color:#444;}#gs_hdr_act_s{text-transform:uppercase;}.gs_el_sm #gs_hdr_act_i,.gs_el_sm #gs_hdr_act_s{padding:23px 16px;}.gs_el_ta #gs_hdr_act_i,.gs_el_ta #gs_hdr_act_s,.gs_el_ph #gs_hdr_act_i,.gs_el_ph #gs_hdr_act_s{padding:20px 16px;}#gs_hdr_act_i:active,#gs_hdr_act_s:active{color:#d14836;}#gs_hdr_act_i,.gs_el_sm #gs_hdr_act_i{padding-top:15px;padding-bottom:16px;}.gs_el_ta #gs_hdr_act_i,.gs_el_ph #gs_hdr_act_i{padding-top:12px;padding-bottom:13px;}#gs_hdr_act_i .gs_hdr_pp{vertical-align:top;}#gs_hdr_act_d{top:63px;left:auto;right:24px;min-width:288px;max-width:400px;}.gs_el_sm #gs_hdr_act_d{right:16px;}.gs_el_ta #gs_hdr_act_d{top:57px;}.gs_el_ph #gs_hdr_act_d{top:57px;min-width:280px;max-width:280px;max-width:90vw;}/* Account dialog body. */#gs_hdr_act_aw,#gs_hdr_act_ap,.gs_hdr_act_am,#gs_hdr_act_ab{display:block;padding:10px 20px;word-wrap:break-word;white-space:normal;}#gs_hdr_act_aw{background-color:#fef9db;font-size:11px;}#gs_hdr_act_ap,.gs_hdr_act_am{border-bottom:1px solid #ccc;}#gs_hdr_act_ap{padding:20px;}.gs_el_ph #gs_hdr_act_ap{padding:10px;}#gs_hdr_act_apb{margin-top:12px;}#gs_hdr_act_aa:link,#gs_hdr_act_aa:visited{float:right;margin-left:8px;color:#1a0dab;}#gs_hdr_act_aa:active{color:#d14836}.gs_hdr_act_am:link,.gs_hdr_act_am:visited{color:#222;text-decoration:none;background:#fbfbfb;}.gs_hdr_act_am:hover,.gs_hdr_act_am:focus{background:#f1f1f1;}.gs_hdr_act_am:active{background:#eee;}#gs_hdr_act_ab{background:#fbfbfb;padding:10px 0;display:table;width:100%;white-space:nowrap;}#gs_hdr_act_aba,#gs_hdr_act_abs{display:table-cell;padding:0 20px;}#gs_hdr_act_abs{text-align:right;}.gs_el_ph #gs_hdr_act_aba,.gs_el_ph #gs_hdr_act_abs{display:block;padding:10px;text-align:center;}.gs_el_ph #gs_hdr_act_aba button,.gs_el_ph #gs_hdr_act_abs button{width:100%;}#gs_hdr_act_a1,#gs_hdr_act_a2{position:absolute;top:-9px;right:7.5px;width:0;height:0;z-index:1;border:8.5px solid transparent;border-top:none;border-bottom-color:#333;border-bottom-color:rgba(0,0,0,.2);}#gs_hdr_act_a2{top:-8px;border-bottom-color:#fff;}.gs_hdr_act_mw #gs_hdr_act_a2{border-bottom-color:#fef9db;}.gs_hdr_pp{border-radius:50%;overflow:hidden;}#gs_hdr_act_ap .gs_hdr_pp,.gs_hdr_act_am .gs_hdr_pp{float:left;}#gs_hdr_act_ap .gs_hdr_pm{margin-left:116px;}.gs_hdr_act_am .gs_hdr_pm{margin:6px 0 0 58px;}#gs_ab{position:relative;height:41px;border-bottom:1px solid #e5e5e5;display:flex;white-space:nowrap;background-color:#fff;z-index:1000;}.gs_el_ta #gs_ab.gs_nta,.gs_el_ph #gs_ab.gs_nph{display:none;}#gs_ab_g{height:42px;}.gs_sth_vis #gs_ab{position:fixed;}#gs_ab_ico,#gs_ab_ttl,#gs_ab_md,#gs_ab_btns{display:inline-block;vertical-align:top;position:relative;height:100%;flex:0 0 auto;}.gs_el_ph #gs_ab_md{display:block;}#gs_ab_ico{width:55px;margin-right:1px;}#gs_ab_ico .gs_ico{position:absolute;top:50%;left:50%;margin:-10.5px 0 0 -10.5px;}#gs_ab_ttl{min-width:172px;padding-right:8px;}.gs_el_sm #gs_ab_ttl{min-width:68px;}.gs_el_ta #gs_ab_ttl,.gs_el_ph #gs_ab_ttl{min-width:0;}#gs_ab_ttl,#gs_ab_ttll{font-size:18px;color:#666;text-transform:none;}.gs_el_sm #gs_ab_ttl,.gs_el_sm #gs_ab_ttll{font-size:16px;}#gs_ab_ttll{overflow:hidden;text-overflow:ellipsis;max-width:200px;}#gs_ab_md{flex:1 0 auto;}.gs_ab_st #gs_ab_md{flex:1 1 auto;font-size:13px;line-height:17px;padding:0 8px;color:#999;overflow:hidden;text-overflow:ellipsis;}.gs_el_ph .gs_ab_st #gs_ab_md{visibility:hidden;padding:0;}#gs_ab_btns{margin-right:8px;}.gs_el_sm #gs_ab_btns{margin-right:0;}.gs_el_ta #gs_ab_btns,.gs_el_ph #gs_ab_btns{margin-right:4px;}#gs_ab_ttl:before,#gs_ab_md:before,#gs_ab_btns:before{content:"";display:inline-block;width:0;height:100%;vertical-align:middle;}#gs_ab_md>button,#gs_ab_btns>button,#gs_ab_md>.gs_in_ib,#gs_ab_btns>.gs_in_ib,#gs_ab_md>.gs_md_r,#gs_ab_btns>.gs_md_r,#gs_ab .gs_ab_mdw,#gs_ab .gs_ab_btw{margin:0 8px;vertical-align:middle;}#gs_ab .gs_ab_mdw,.gs_ab_btw{display:inline-block;margin:0;}#gs_ab_btns>.gs_in_ib{margin:0 16px 0 8px;}#gs_ab .gs_ab_btw{margin:0 12px 0 16px;}.gs_el_ta .gs_ab_sel #gs_ab_ico,.gs_el_ph .gs_ab_sel #gs_ab_ico,.gs_el_ta .gs_ab_sel #gs_ab_ttl,.gs_el_ph .gs_ab_sel #gs_ab_ttl,.gs_el_ta .gs_ab_sel #gs_ab_btns,.gs_el_ph .gs_ab_sel #gs_ab_btns{display:none;}#gs_bdy{display:table;table-layout:fixed;width:100%;}#gs_bdy_sb{vertical-align:top;width:228px;word-wrap:break-word;display:none;}.gs_el_sm #gs_bdy_sb{}.gs_el_ta #gs_bdy_sb,.gs_el_ph #gs_bdy_sb{}.gs_bdy_sb_sec{margin:0 40px 0 56px;}.gs_bdy_sb_sec:before{display:block;content:" ";height:0;margin:13px 0;border-top:1px solid #eee;}.gs_bdy_sb_sec:first-child:before{margin:21px 0 0 0;border:none;}#gs_bdy_sb ul{list-style-type:none;}.gs_bdy_sb_sec a:link,.gs_bdy_sb_sec a:visited{color:#222;}.gs_bdy_sb_sec a:active{color:#d14836;}.gs_bdy_sb_sel a:link,.gs_bdy_sb_sel a:visited{color:#d14836;text-decoration:none;}.gs_el_tc .gs_bdy_sb_sec li.gs_ind,.gs_el_tc .gs_bdy_sb_sec li.gs_ind a{padding-top:8px;padding-bottom:5px;}.gs_el_tc .gs_bdy_sb_sec:first-child li.gs_ind:first-child{margin-top:-8px;}#gs_bdy_sb .gs_ind,#gs_bdy_sb .gs_inw{margin-bottom:4px;}.gs_el_tc #gs_bdy_sb .gs_ind,.gs_el_tc #gs_bdy_sb .gs_inw{margin-bottom:0;}#gs_bdy_ccl{display:table-cell;vertical-align:top;padding:0 24px 0 16px;}.gs_el_sm #gs_bdy_ccl{padding:0 16px;}.gs_el_ta #gs_bdy_ccl,.gs_el_ph #gs_bdy_ccl{padding:0 16px;}.gs_el_ph #gs_bdy_ccl{padding:0;}#gs_ftr_sp{height:62px;}.gs_el_sm #gs_ftr_sp{height:57px;}#gs_ftr{position:absolute;bottom:0;left:0;width:100%;white-space:nowrap;border-top:1px solid #e4e4e4;background-color:#f2f2f2;display:flex;}#gs_ftr_rt{box-sizing:border-box;max-width:100%;overflow-x:auto;margin-left:auto;padding:0 12px;}.gs_el_sm #gs_ftr_rt{padding:0 8px;}.gs_el_ph #gs_ftr_rt:after{content:" ";position:absolute;top:0;right:0;width:16px;height:100%;background-image:linear-gradient(to right,rgba(242,242,242,0),rgba(242,242,242,1) 80%);}#gs_ftr_rt a{display:inline-block;line-height:16px;padding:12px;white-space:nowrap;}.gs_el_sm #gs_ftr_rt a{padding:12px 8px;}#gs_ftr_rt a:link,#gs_ftr_rt a:visited{color:#666}#gs_ftr_rt a:active{color:#d14836}#gsc_a_t{width:100%;table-layout:fixed;}#gsc_a_tr0,#gsc_a_trh{box-sizing:border-box;}#gsc_a_tr0 th.gsc_a_x,#gsc_a_tr0 th.gsc_a_t,#gsc_a_tr0 th.gsc_a_c,#gsc_a_tr0 th.gsc_a_y{height:0;}#gsc_a_trh{z-index:700;background-color:#f5f5f5;height:42px;}.gs_el_ta #gsc_a_trh,.gs_el_ph #gsc_a_trh,.gs_el_ta #gsc_a_t td,.gs_el_ph #gsc_a_t td{background-color:#fff;border-bottom:1px solid #e5e5e5;}#gsc_a_t th.gsc_a_x,#gsc_a_t th.gsc_a_t,#gsc_a_t th.gsc_a_c,#gsc_a_t th.gsc_a_y{box-sizing:border-box;text-transform:uppercase;vertical-align:middle;padding-top:0;padding-bottom:0;}#gsc_x_all{z-index:1;}.gsc_a_x,.gsc_a_t,.gsc_a_c,.gsc_a_y,.gsc_a_e{font-weight:normal;padding:16px 16px 0 16px;vertical-align:top;text-align:right;}.gsc_a_c{padding:16px 8px 0 8px;}.gs_el_sm .gsc_a_x,.gs_el_sm .gsc_a_t,.gs_el_sm .gsc_a_c{padding:12px 8px 0 8px;}.gs_el_ta .gsc_a_x,.gs_el_ta .gsc_a_t,.gs_el_ta .gsc_a_c,.gs_el_ph .gsc_a_x,.gs_el_ph .gsc_a_t,.gs_el_ph .gsc_a_c{padding:12px 8px;}.gs_el_sm .gsc_a_y{padding:12px 8px 0 8px;}.gs_el_ta .gsc_a_y{padding-bottom:12px;}.gsc_a_x{width:41px;padding:4px 0 0 0;}.gs_el_sm .gsc_a_x{padding:0;}.gsc_a_t{text-align:left;}.gs_el_ph .gsc_a_t{padding-left:16px;}#gsc_a_ta{display:inline-block;vertical-align:middle;margin-right:16px;}.gs_el_ph #gsc_a_ta{display:none}.gs_el_ph .gsc_a_c{padding-right:16px;}th.gsc_a_c{width:64px;white-space:nowrap;}.gsc_art_sel #gsc_a_ta,.gsc_art_sel #gsc_a_ca,.gsc_art_sel .gsc_a_h{display:none;}.gsc_a_ac,.gsc_a_hc{margin-top:3px;}th.gsc_a_y{width:88px;white-space:nowrap;}.gs_el_sm th.gsc_a_y{width:58px;}.gs_el_ph th.gsc_a_y,.gs_el_ph td.gsc_a_y{width:0;padding:0;}.gs_el_ph .gsc_a_h{display:none}@media print{#gs_top th.gsc_a_y{width:58pt;}#gs_top #gsc_a_tr0{display:none}#gs_top #gsc_a_trh{position:static}}.gsc_a_e{padding:16px;text-align:center;}.gsc_a_a{padding:8px 0}.gsc_a_at{padding:8px 0;font-size:16px}a.gsc_a_acm{text-decoration:line-through;}a.gsc_a_acm:hover,a.gs_a_acm:active{text-decoration:underline;}.gsc_a_m{position:absolute;}.gs_el_ph .gsc_a_m{display:block;position:static;}.gsc_a_am{font-size:24px;position:absolute;top:-18px;left:-2px;padding:8px 12px 4px 8px;}.gs_el_ph .gsc_a_am{display:inline-block;position:static;padding:6px 16px;margin-bottom:-6px;}#gsc_a_sp{visibility:hidden;}#gsc_a_sp.gs_vis{visibility:visible;padding:16px 0;height:25px;border-bottom:1px solid #ccc;}#gsc_a_sp:after{display:block;height:100%;content:" ";background:url('/intl/en/scholar/images/spinner.gif') no-repeat 50% 50%;opacity:0;}#gsc_a_sp.gs_vis:after{opacity:1;transition:opacity 0s .4s;}#gsc_a_err{display:none;padding:28px 0;}#gsc_a_err.gs_vis{display:block;}#gsc_md_iad{width:800px;max-width:94%;}.gs_el_ph #gsc_md_iad{width:100%;max-width:100%;}#gsc_md_iad .gs_md_prg{min-height:400px;}.gs_el_ph #gsc_iads_res .gs_md_prg{margin:0 16px;}#gsc_iad_tart,.gsc_iad_tsel.gsc_iad_tart #gsc_iad_tart,.gsc_iad_tart #gsc_iad_tgrp,.gsc_iad_tsel #gsc_iad_tgrp,#gsc_iad_tsel,#gsc_napb_hdr #gsc_iad_tart,#gsc_napb_hdr #gsc_iad_tgrp{display:none;}#gsc_iad_tgrp,.gsc_iad_tart #gsc_iad_tart,.gsc_iad_tsel #gsc_iad_tsel,#gsc_napb_hdr #gsc_iad_tsel{display:inline-block;}#gsc_iad_t:not(.gsc_iad_tsel) #gsc_iad_tsel{pointer-events:none;color:#b5b5b5;}.gs_el_ph #gsc_napb #gsc_iads_frm{margin:0 16px;}#gsc_iads_res{position:relative;margin:8px 0 16px 0;min-height:80px;border-bottom:1px solid #e5e5e5;}.gs_el_ph #gsc_md_iad #gsc_iads_res{margin:8px -16px 16px -16px;}.gs_el_ph #gsc_napb #gsc_iads_pp{margin-right:16px;}#gsc_iadb_hdr{display:table;table-layout:fixed;width:100%;}#gsc_iadb_hdr_cb,#gsc_iadb_hdr_instr{display:table-cell;vertical-align:middle;height:41px;}#gsc_iadb_hdr_cb{width:41px;}#gsc_iadb_hdr_cb:empty{width:0;}.gs_el_ph #gsc_iadb_hdr_cb:empty{width:16px;}#gsc_iadb_hdr_instr{font-size:16px;}.gs_el_ph #gsc_iadb_hdr_instr{padding-right:16px;}.gsc_oic{position:relative;}.gsc_oic_cb{font-weight:normal;border-top:1px solid #e5e5e5;border-bottom:1px solid #e5e5e5;background-color:#fcfcfc;padding-right:16px;}.gsc_oict{display:block;overflow:hidden;}.gsc_oict_name{display:block;font-size:16px;line-height:20px;word-wrap:break-word;}.gsc_oict_inf{display:block;float:right;margin-left:16px;white-space:nowrap;}.gsc_oict_all,.gsc_oict_prf{font-size:13px;text-transform:uppercase;line-height:20px;}.gsc_oict_all[data-a]{color:#1a0dab;cursor:pointer;}.gsc_oict_all[data-a]:hover{text-decoration:underline;}.gsc_oict_all[data-a]:active{color:#d14836;}.gsc_oict_prf{padding-left:8px;margin-left:8px;border-left:1px solid #e0e0e0;}.gsc_oict_prf:empty{display:none;}.gs_el_ph .gsc_oict_all,.gs_el_ph .gsc_oict_prf{float:right;clear:both;margin:0;padding:0;border:none;}.gs_el_ph .gsc_oict_prf{margin-top:2px;}.gsc_oic_res{margin:8px 0 12px 41px;}.gs_el_ph .gsc_oic_res{margin-right:16px;}.gsc_oic_res h4{font-size:13px;font-weight:normal;}.gsc_oic_dis .gsc_oic_name,.gsc_oic_dis .gsc_oic_all,.gsc_oic_dis .gsc_oic_prf{color:#777;}.gsc_oic_dis .gsc_oict_all[data-a]{color:#1a0dab;opacity:.66;}.gsc_oic_dis .gsc_oic_res{opacity:.5;}.gsc_iadb_art{border-top:1px solid #e5e5e5;overflow:hidden;}.gsc_iadb_art_cb{float:left;}.gsc_iadb_art_added{float:right;margin:12px;font-size:11px;text-transform:uppercase;color:#777;}.gs_el_ph .gsc_iadb_art_added{display:block;float:none;text-align:right;margin:8px 16px;}.gsc_iadb_art_added:empty{display:none;}.gsc_iadb_art_body{margin:12px 0 12px 41px;}.gs_el_ph .gsc_iadb_art_body{margin:12px 16px 12px 41px;}.gsc_iadb_art_body h3{font-size:13px;font-weight:normal;}.gsc_iadb_art_dis .gsc_iadb_art_body{opacity:.5;}#gsc_md_mopt,#gsc_md_cbyd,#gsc_md_cbym{width:600px;}.gs_el_ta #gsc_md_mopt,.gs_el_ta #gsc_md_cbyd,.gs_el_ta #gsc_md_cbym{width:500px;}.gs_el_ph #gsc_md_mopt,.gs_el_ph #gsc_md_cbyd,.gs_el_ph #gsc_md_cbym{width:100%;}.gsc_mob_art{vertical-align:top;padding:8px 0;}.gs_el_tc .gsc_mob_art>.gs_in_ra{margin-top:-8px;}.gsc_mob_cby{vertical-align:top;text-align:right;padding:8px 12px;position:relative;}.gsc_mob_ttl,.gsc_mob_pub{display:block;}.gsc_mob_pub{color:#666;}.gsc_mob_cbym{text-decoration:line-through}.gsc_mob_cbm{font-size:24px;position:absolute;padding:4px 0 0 4px;line-height:16px;}.gs_fsvg line{stroke:#222222}a:link .gs_fsvg{fill:#1a0dab;}a:link .gs_fsvg line{stroke:#1a0dab;}a:visited .gs_fsvg{fill:#660099;}a:visited .gs_fsvg line{stroke:#660099;}a:active .gs_fsvg{fill:#d14836;}a:active .gs_fsvg line{stroke:#d14836;}a .gs_fsvg{border-bottom:1px solid transparent;}a:hover .gs_fsvg,a:focus .gs_fsvg{border-bottom-color:inherit;}.gs_fsml{font-size:13px}.gs_fscp{font-variant:small-caps}.gsh_clim{display:table-row}.gsh_clil,.gsh_clic{display:table-cell;padding-bottom:8px}.gsh_clil{padding-right:8px;}.gsh_lla{list-style-type:lower-alpha}.gsh_lua{list-style-type:upper-alpha}.gsh_llr{list-style-type:lower-roman}.gsh_lur{list-style-type:upper-roman}.gsh_l>li{margin-left:32px;}.gsh_h3{font-size:inherit;font-weight:normal}.gsh_h3,.gsh_csp{margin:16px 0}.gsh_h3+.gsh_csp{margin-top:-8px}.gsh_ovln{text-decoration:overline}.gsh_small .gsh_l .gsh_csp{margin:8px 0}.gsh_small .gsh_csp:first-child,.gsh_small .gsh_h3:first-child{margin-top:0}.gsh_small .gsh_csp:last-child{margin-bottom:0}.gsh_dspfr{text-align:center}.gsh_dspfr svg{margin:8px 0}.gs_pp_tn,.gs_el_ta .gs_pp_mo_tn,.gs_el_ph .gs_pp_mo_tn{width:32px;height:32px;}.gs_pp_sm,.gs_el_ta .gs_pp_mo_sm,.gs_el_ph .gs_pp_mo_sm{width:56px;height:56px;}.gs_pp_nm,.gs_el_ta .gs_pp_mo_nm,.gs_el_ph .gs_pp_mo_nm{width:128px;height:128px;}.gs_ai_pho{float:left;}.gs_ai_t{margin-left:72px;}.gs_ai_pho_pst+.gs_ai_t{margin-left:48px;}.gs_ai_t.gs_ai_pss{margin-left:64px;}.gs_ai_pho_pst+.gs_ai_t.gs_ai_pss{margin-left:40px;}.gs_ai_name{font-size:17px;font-weight:normal;margin-bottom:4px;}.gs_ai_name a{padding:6px 0 4px 0;}.gs_ai_name.gs_ai_name_nlsb{font-size:15px;}.gs_ai_name.gs_ai_name_nlsb a:link,.gs_ai_name.gs_ai_name_nlsb a:visited{padding:7px 0 5px 0; color:#222;}.gs_ai_name.gs_ai_name_nlsb a:active{color:#d14836;}.gs_ai_int{margin-top:5px;}.gs_ai_eml:empty,.gs_ai_int:empty,.gs_ai_cby:empty{display:none;}.gs_ai_one_int{vertical-align:top;font-size:13px;margin-right:8px;white-space:nowrap;display:inline-block;max-width:200px;text-overflow:ellipsis;overflow:hidden;}.gs_el_tc a.gs_ai_one_int{padding:8px 0 5px 0;}.gs_el_ph .gs_ai_eml,.gs_el_ph .gs_ai_cby{margin-top:8px;}.gs_ai_ilnl .gs_ai_int,.gs_ai_ilnl .gs_ai_cby{margin-top:8px;color:#666;}.gs_ai.gs_ai_chpr{position:relative;}.gs_ai_chpr .gs_ai_t{margin-right:276px;}.gs_el_sm .gs_ai_chpr .gs_ai_t{margin-right:156px;}.gs_el_ph .gs_ai_chpr .gs_ai_t{margin-right:0;}.gs_ai_chpr .gs_ai_cby{position:absolute;top:4px;right:0;text-align:right;}.gs_el_sm .gs_ai_chpr .gs_ai_cby,.gs_el_ta .gs_ai_chpr .gs_ai_cby{width:132px;word-wrap:break-word;}.gs_el_ph .gs_ai_chpr .gs_ai_cby{text-align:left;position:static;width:auto;}#gsc_bdy{position:relative;max-width:1200px;margin:0 auto;}.gs_el_ph #gsc_bdy,.gs_el_ta #gsc_bdy{display:flex;flex-flow:column;}.gsc_lcl{position:relative;margin:0 350px 0 0;order:3;}.gs_el_sm .gsc_lcl{margin-right:334px;}.gs_el_ta .gsc_lcl,.gs_el_ph .gsc_lcl{margin:0;}#gsc_prf_t_wrp{position:relative;order:2;overflow:hidden;}.gs_el_tc #gsc_prf_t_wrp:after{display:block;content:"";position:absolute;z-index:100;top:0;right:0;width:12px;height:100%;background-image:linear-gradient(to right,rgba(247,247,247,0),rgba(247,247,247,1) 80%);}#gsc_prf_t{width:100%;background-color:#f5f5f5;display:none;white-space:nowrap;overflow-x:auto;padding:0 4px;}.gs_el_ta #gsc_prf_t,.gs_el_ph #gsc_prf_t{display:block;}#gsc_prf_t:after{content:"\00A0";padding:0 4px;}.gsc_prf_tab,.gsc_prf_tab:link{font-size:13px;text-transform:uppercase;padding:13px 12px;display:inline-block;color:#666;cursor:pointer;}.gsc_prf_tab:hover{color:#000;text-decoration:none}.gsc_prf_tab:active{color:#4d90fe;}.gsc_prf_tab[aria-selected="true"]{border-bottom:2px solid #4d90fe;color:#0461f9;cursor:default;}.gs_el_ta #gsc_art,.gs_el_ph #gsc_art,.gs_el_ta #gsc_rsb_cit,.gs_el_ph #gsc_rsb_cit,.gs_el_ta #gsc_rsb_mnd,.gs_el_ph #gsc_rsb_mnd,.gs_el_ta #gsc_rsb_awd,.gs_el_ph #gsc_rsb_awd,.gs_el_ta #gsc_rsb_co,.gs_el_ph #gsc_rsb_co{display:none;}#gsc_bdy[data-tab="gsc_prf_t-art"] #gsc_art,#gsc_bdy[data-tab="gsc_prf_t-cit"] #gsc_rsb_cit,#gsc_bdy[data-tab="gsc_prf_t-mnd"] #gsc_rsb_mnd,#gsc_bdy[data-tab="gsc_prf_t-awd"] #gsc_rsb_awd,#gsc_bdy[data-tab="gsc_prf_t-ath"] #gsc_rsb_co{display:block;}.gsc_rsb{float:right;width:317px;order:4;border-left:1px solid #eee;margin-top:32px;}.gs_el_sm .gsc_rsb{margin-top:16px;}.gs_el_ph .gsc_rsb,.gs_el_ta .gsc_rsb{float:none;width:auto;border:none;margin:0;}.gsc_rsb_s{margin:0 0 48px 16px;position:relative;}.gs_el_sm .gsc_rsb_s{margin:0 0 32px 16px;}.gs_el_ph .gsc_rsb_s,.gs_el_ta .gsc_rsb_s{margin:0;}.gsc_rsb_s:last-child{margin-bottom:0;}.gsc_rsb_header{padding:8px 8px 12px 8px;border-bottom:1px solid #e5e5e5;font-weight:normal;font-size:15px;}.gs_el_sm .gsc_rsb_header{padding:4px 8px 9px 8px;}.gs_el_ph .gsc_rsb_header,.gs_el_ta .gsc_rsb_header{display:none;}.gsc_rsb_action{position:absolute;top:-3px;right:-2px;}.gs_el_sm .gsc_rsb_action{top:-8px;}.gsc_rsb_tap{display:block;position:absolute;right:2px;top:12px;opacity:.5;z-index:1;}.gs_el_ta .gsc_rsb_tap,.gs_el_ph .gsc_rsb_tap{top:24px;right:10px;}.gsc_rsb_hm{border-bottom:1px solid #e5e5e5;padding:3px 6px;}#gsc_rsb_gpl{display:block;margin-top:3px;padding:6px 16px;line-height:15px;color:#0461f9;border:1px solid #4d90fe;border-radius:2px;text-align:center;text-transform:uppercase;}.gs_el_sm #gsc_rsb_gpl{margin-top:0;}.gs_el_ta #gsc_rsb_gpl,.gs_el_ph #gsc_rsb_gpl{display:none;}#gsc_rsb_st{width:100%;}.gsc_rsb_std{text-align:right;padding-right:8px;}.gs_el_ta .gsc_rsb_std,.gs_el_ph .gsc_rsb_std{padding-right:16px;}.gsc_rsb_sc1{text-align:left;padding:2px 8px;}.gs_el_sm .gsc_rsb_sc1{padding:0 8px;}.gs_el_ta .gsc_rsb_sc1,.gs_el_ph .gsc_rsb_sc1{padding:4px 16px;}.gsc_rsb_sth{font-weight:normal;padding:8px 8px 8px 0;border-bottom:1px solid #e5e5e5;text-align:right;}.gs_el_sm .gsc_rsb_sth{padding:4px 8px 4px 0;}.gs_el_ta .gsc_rsb_sth,.gs_el_ph .gsc_rsb_sth{padding:16px 16px 16px 0;}#gsc_rsb_st tbody:before,#gsc_rsb_st tbody:after{content:'';display:block;height:8px;}.gs_el_sm #gsc_rsb_st tbody:before,.gs_el_sm #gsc_rsb_st tbody:after{height:4px;}.gs_el_ph #gsc_hist_opn,.gs_el_ta #gsc_hist_opn{display:none;}.gsc_rsb_f{max-width:118px;word-wrap:break-word;white-space:normal;}.gs_el_ta .gsc_rsb_f{max-width:none;}.gsc_rsb_f:link,.gsc_rsb_f:visited{color:#222;}.gsc_rsb_m_na{color:#dd4b39;}.gsc_rsb_m_a{color:#006621;float:right;position:relative;}.gsc_rsb_m_bar{width:100%;height:4px;margin:8px 0 8px 0;background:#006621;}.gsc_rsb_m_bar_na{background:#dd4b39;width:100%;height:100%;z-index:1;}.gsc_rsb_m{padding:8px;}.gs_el_ta .gsc_rsb_m,.gs_el_ph .gsc_rsb_m{padding:8px 16px;}.gsc_rsb_m_desc{padding-top:16px;color:#777;}.gsc_rsb_m_s{font-size:24px;position:absolute;line-height:0.3;}#gsc_lwp_mndt_lnk{text-transform:uppercase;margin-left:16px;margin-right:-9px;text-align:right;font-size:13px;padding:12px 9px;border-radius:3px;}#gsc_lwp_mndt_lnk:hover,#gsc_lwp_mndt_lnk:active,#gsc_lwp_mndt_lnk:visited{text-decoration:none;color:#1a0dab;}#gsc_lwp_mndt_lnk:hover{background-color:rgba(0,0,0,.05);}#gsc_lwp_mndt_lnk:active{background-color:rgba(0,0,0,.1);}.gsc_rsb_m_title{padding-bottom:12px;}.gsc_rsb_m_header{display:flex;align-items:flex-end;justify-content:space-between;padding:0 8px;}.gs_el_sm .gsc_rsb_m_header{padding:0 8px;}.gsc_rsb_hmv{text-align:center;padding-top:16px;}.gsc_rsb_a{list-style:none;}.gsc_rsb_a>li{position:relative;}.gs_el_ta .gsc_rsb_a>li,.gs_el_ph .gsc_rsb_a>li{border-bottom:1px solid #e5e5e5;}.gsc_rsb_a>li:first-child{margin-top:8px;}.gsc_rsb_a_pht{float:left;width:32px;height:32px;}.gsc_rsb_a_desc{margin:0 33px 0 48px;min-height:32px;display:block;}.gs_el_ph .gsc_rsb_a_desc,.gs_el_ta .gsc_rsb_a_desc{margin:0 33px 0 64px;min-height:56px;}.gsc_rsb_a_desc a{color:#222;}.gsc_rsb_a_ext{display:block;color:#777;font-size:13px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;}.gs_el_ph .gsc_rsb_a_ext,.gs_el_ta .gsc_rsb_a_ext{white-space:normal;}.gsc_rsb_a_ext2{display:none;}.gs_el_ph .gsc_rsb_a_ext2,.gs_el_ta .gsc_rsb_a_ext2{display:block;}.gsc_rsb_aa{display:block;padding:8px;line-height:normal;cursor:pointer;}.gs_el_ph .gsc_rsb_aa,.gs_el_ta .gsc_rsb_aa{font-size:17px;padding:12px 16px;}.gsc_rsb_aa:hover,.gsc_rsb_aa:active{text-decoration:none;background:#f1f1f1;}.gsc_rsb_aa a:hover{text-decoration:none;}#gsc_prf_w{order:1;padding:32px 0;overflow:hidden;}.gs_el_sm #gsc_prf_w{padding:16px 0;}#gsc_prf_pu{float:left;width:128px;height:128px;text-align:center;}.gs_el_ph #gsc_prf_pu{float:none;width:100%;margin:0 0 8px 0;}#gsc_prf_pua{line-height:0;width:128px;height:128px;}.gs_el_ph #gsc_prf_pua{margin:0 auto;}#gsc_prf_pufi{width:0;height:0;overflow:hidden;}.gsc_prf_pufo #gsc_prf_pufi{width:auto;height:auto;overflow:visible;position:relative;z-index:10;}.gsc_prf_pufo #gsc_prf_pufi2{display:inline-block;background:#fcfcfc;padding:8px 8px 8px 0;}.gsc_prf_puic{position:absolute;bottom:0;width:100%;padding:8px 0;background-color:#000;opacity:.6;}.gsc_prf_pel{cursor:pointer;}#gsc_prf_i{margin:0 16px 0 160px;}.gs_el_sm #gsc_prf_i{margin:0 16px 0 144px;}.gs_el_ph #gsc_prf_i{margin:0 16px;text-align:center;}#gsc_prf_btne{vertical-align:top;margin:-9px 4px;}.gs_el_ph #gsc_prf_btne{position:absolute;top:60px;right:8px;margin:0;}#gsc_prf_btnf{float:right;margin:3px 0 16px 16px;}.gs_el_sm #gsc_prf_btnf{margin-top:0;}.gs_el_ph #gsc_prf_btnf{float:none;margin:0;position:absolute;top:8px;right:8px;border-radius:50%;}#gsc_prf_btnf .gs_lbl{padding:0 4px;}#gsc_prf_in{font-size:24px;line-height:24px;padding:3px 0 12px 0;word-wrap:break-word;}.gs_el_sm #gsc_prf_in{font-size:22px;padding:3px 0 8px 0;}.gs_el_ph #gsc_prf_in{font-size:20px;padding:0 0 2px 0;}.gsc_prf_il{font-size:15px;line-height:18px;padding:1px 0;}.gs_el_ph .gsc_prf_il{font-size:13px;line-height:16px;}.gsc_prf_ila:link,.gsc_prf_ila:visited{text-decoration:underline;color:#222;}#gsc_prf_int{margin-top:5px;}#gsc_prf_int:empty{display:none;}.gsc_prf_inta{margin-right:16px;white-space:nowrap;max-width:200px;text-overflow:ellipsis;overflow:hidden;vertical-align:top;}.gsc_prf_inta:last-child{margin:0}.gs_el_tc .gsc_prf_ila,.gs_el_tc .gsc_prf_inta{padding:8px 0 5px 0;}.gsc_md_pro_tt,.gsc_md_pro_ch #gsc_md_pro_lgtm,#gsc_md_pro_save{display:none;}.gsc_md_pro_ed #gsc_md_pro_ted,.gsc_md_pro_aa #gsc_md_pro_taa,.gsc_md_pro_ra #gsc_md_pro_tra,.gsc_md_pro_an #gsc_md_pro_tan,.gsc_md_pro_ai #gsc_md_pro_tai,.gsc_md_pro_ch #gsc_md_pro_save{display:inline-block;}.gsc_md_pro_el{color:#777;}.gsc_md_pro_ev{padding:4px 0 16px 0;}#gsc_dd_add-d,#gsc_dd_exp-d,#gsc_dd_sort-d,#gsc_dd_mor-d{top:42px;}#gsc_dd_add-d,#gsc_dd_mor-d,#gsc_dd_sort-d{white-space:normal;word-wrap:break-word;width:208px;width:-webkit-max-content;width:max-content;min-width:100px;max-width:208px;}.gs_el_ph #gsc_dd_add-d{left:-9px;}.gs_el_ph #gsc_dd_exp-d{left:auto;right:12px;}.gs_el_ph #gsc_dd_mor-d{left:-58px;}.gs_el_ph #gsc_dd_sort-d{left:10px;}.gs_el_ph #gsc_dd_sort-r{margin-left:-10px;}.gsc_dd_sec,#gsc_dd_exp-d{padding:8px 0;}.gs_el_tc .gsc_dd_sec,.gs_el_tc #gsc_dd_exp-d{padding:4px 0 8px 0;}.gsc_dd_sep{border-top:1px solid #ebebeb;}#gsc_dd_mor-s .gsc_dd_mor-sel,#gsc_dd_sort-s .gsc_dd_sort-sel{color:#dd4b39;}#gsc_dd_mor-p{padding:14px 44px 14px 16px;color:#777;}.gs_el_tc #gsc_dd_mor-p{padding:18px 44px 18px 16px;}.gsc_art_sel #gsc_dd_add-r,.gsc_art_sel #gsc_dd_mor-r,#gsc_btn_mer,#gsc_btn_del,#gsc_dd_exp-r{display:none;}#gsc_dd_mor-r,.gsc_art_sel #gsc_btn_mer,.gsc_art_sel #gsc_btn_del,.gsc_art_sel #gsc_dd_exp-r{display:inline-block;}html:not(.gs_el_ph) #gsc_dd_sort-r{display:none;}#gsc_lwp{margin:24px 0;text-align:center;}.gs_el_sm #gsc_lwp{margin:16px 0;}#gsc_bpf{display:inline-block;verticle-align:middle;}#gsc_a_nn{display:inline-block;vertical-align:middle;padding-right:16px;font-size:13px;}.gs_el_ph #gsc_a_nn{display:none;}@media print{#gs_top #gs_md_s,#gs_top #gs_md_w,#gs_top #gs_hdr,#gs_top #gs_hdr_drs,#gs_top #gs_hdr_drw,#gs_top #gs_ftr,#gs_top #gsc_nag,#gs_top #gsc_prf_nbar_btns,#gs_top #gsc_prf_btne,#gs_top #gsc_prf_btnf,#gs_top #gsc_prf_ivh,#gs_top #gsc_prf_puf,#gs_top #gsc_rsb_co,#gs_top #gsc_bdy #gsc_rsb_co,#gs_top .gsc_g_hist_wrp,#gs_top #gsc_prf_t_wrp,#gs_top .gsc_rsb_header,#gs_top .gsc_a_tb,#gs_top .gsc_a_x,#gs_top #gsc_lwp,#gs_top .gsc_prf_puic,#gs_top #gsc_dd_add-r,#gs_top #gsc_dd_mor-r,#gs_top #gsc_dd_sort-r{display:none;}#gs_top,#gs_top #gsc_bdy,#gs_top #gsc_prf_w,#gs_top #gsc_prf,#gs_top #gsc_prf_pu,#gs_top #gsc_prf_pua,#gs_top #gsc_prf_i,#gs_top .gsc_rsb_s,#gs_top .gsc_lcl,#gs_top .gsc_rsb,#gs_top #gsc_a_tw,#gs_top #gsc_a_t,#gs_top .gsc_prf_il,#gs_top .gsc_prf_ila,#gs_top .gsc_prf_inta,#gs_top #gsc_rsb_st{background:none;border:none;padding:0;margin:0;height:auto;width:auto;min-width:0;max-width:none;float:none;display:block;position:static;color:black;font-weight:normal;font-size:12pt;text-decoration:none;}#gs_top .gsc_a_ac,#gs_top .gsc_a_a,#gs_top #gsc_a_ca,#gs_top .gsc_a_at,#gs_top .gsc_rsb_sc1,#gs_top .gsc_rsb_sth,#gs_top .gsc_rsb_std,#gs_top #gsc_bdy .gsc_a_x,#gs_top #gsc_bdy .gsc_a_t,#gs_top #gsc_bdy .gsc_a_c,#gs_top #gsc_bdy .gsc_a_y,#gs_top #gsc_a_trh,#gs_top .gsc_a_m,#gs_top .gsc_a_am{color:black;font-weight:normal;font-size:12pt;padding:0;margin:0;background:none;border:none;}#gs_top #gsc_a_trh,#gs_top #gsc_a_trh th{height:0;}#gs_top #gsc_a_ta,#gs_top #gsc_a_ca,#gs_top #gsc_a_ha,#gs_top .gsc_a_a{font-size:11pt;}#gs_top .gsc_a_ac{font-size:10pt}#gs_top #gsc_prf_pu{width:80pt;height:auto;float:left;margin:0 7pt 7pt 0;}#gs_top #gsc_prf_pua{left:auto;transform:none;border-radius:0;}#gs_top #gsc_prf_pua>img{position:static;}#gs_top #gsc_prf_i{margin:0 7pt 7pt 87pt;text-align:left;}#gs_top #gsc_prf_in{font-size:18pt;line-height:18pt;padding:0 0 4pt 0;}#gs_top .gsc_prf_il{padding:2pt 0;}#gs_top #gsc_prf_w{float:left;width:64%;}#gs_top .gsc_rsb{float:right;width:35%;}#gs_top #gsc_art{clear:both;}#gs_top #gsc_rsb_st{display:table;width:100%;max-width:none;margin-top:3pt;}#gs_top .gsc_rsb_sc1,#gs_top .gsc_rsb_sth,#gs_top .gsc_rsb_std{font-size:10pt;}#gs_top th.gsc_rsb_sc1,#gs_top .gsc_rsb_sth{border-bottom:1pt solid #ccc;}#gs_top .gsc_rsb_f{max-width:60pt;}#gs_top .gsc_rsb_sth{padding-left:14pt;}#gs_top #gsc_bdy .gsc_a_x,#gs_top #gsc_bdy .gsc_a_t,#gs_top #gsc_bdy .gsc_a_c,#gs_top #gsc_bdy .gsc_a_y,#gs_top #gsc_a_trh{padding:6pt 0;}#gs_top #gsc_a_trh{border-bottom:1pt solid #ccc;}#gs_top #gsc_a_ca{display:block;width:auto;}#gs_top #gsc_a_ta{display:inline-block;vertical-align:middle;margin-right:12pt;}#gs_top .gsc_a_h{display:inline;font-size:10pt;}#gs_top .gsc_a_at{color:#008;}#gs_top .gsc_a_m,#gs_top .gsc_a_am{display:inline;position:absolute;}#gs_top .gsc_a_am{padding: 11pt 0 0 8pt;}#gs_top .gsc_a_t .gs_gray{color:black;font-size:10pt;}}.gsc_lwpds_frm{position:relative;height:29px;}.gsc_lwpds_tsiw{position:absolute;top:0;left:0;right:38px;}.gsc_lwpds_tsiw input{border-radius:3px 0 0 3px;}.gsc_lwpds_tsbw{position:absolute;top:0;right:0;}.gsc_lwpds_tsbw button{border-radius:0 3px 3px 0;}.gsc_pgn{text-align:right;font-weight:bold;line-height:29px;}.gsc_pgn_ppn{margin:0 8px;}.gsc_ccb_ck{padding:11px 10px 9px 10px;}.gsc_ccb_svg{stroke:#666;stroke-width:2px;fill:#fff;width:21px;height:21px;vertical-align:top;}.gsc_ccb_lim .gsc_ccb_svg,.gsc_ccb_dis .gsc_ccb_svg{fill:#e2e2e2;stroke:#fff;}.gsc_ccb_lim .gsc_ccb_svg>circle,.gsc_ccb_dis .gsc_ccb_svg>circle{stroke:#e2e2e2;}.gsc_ccb_on .gsc_ccb_svg{fill:#4d90fe;stroke:#fff;}.gsc_ccb_on .gsc_ccb_svg>circle{stroke:#4d90fe;}.gsc_ccb_del:active .gsc_ccb_svg>circle,.gsc_ccb_add:active .gsc_ccb_svg>circle{fill:#2f6de1;}#gsc_md_cod{width:800px;max-width:94%;}.gs_el_ph #gsc_md_cod{width:100%;max-width:100%;}#gsc_md_cod .gs_md_prg{min-height:400px;}.gsc_codb_instr{font-size:16px;margin:1em 0;}#gsc_cods_res{position:relative;margin-bottom:24px;min-height:80px;border-bottom:1px solid #e5e5e5;}.gs_el_ph #gsc_cods_res{margin-bottom:16px;}.gsc_cods_hide,.gsc_cod_sugg #gsc_cod_tedit,.gsc_cod_sugg #gsc_cods_frm,.gsc_cod_sugg #gsc_cods_pp,.gsc_cod_lc #gsc_cod_tadd,.gsc_cod_changed #gsc_cod_tedit,.gsc_cod_changed #gsc_cod_tadd,.gsc_cod_lim #gsc_cod_tedit,.gsc_cod_lim #gsc_cod_tadd{display:none;}#gsc_cods_frm{margin:0 0 24px 0;}.gs_el_ph #gsc_cods_frm{margin:0 0 16px 0;}.gsc_ucoar{padding:24px 0;border-bottom:1px solid #eee;}.gs_el_ph .gsc_ucoar{padding:16px 0px;}.gsc_ucoar:first-child{padding-top:0;}.gsc_ucoar:last-child{border-bottom:none;}.gsc_ucoar_cb{float:right;margin-top:-8px;}#gsc_cod_trev{display:none;color:#666;pointer-events:none;}.gsc_cod_changed #gsc_cod_trev,.gsc_cod_lim #gsc_cod_trev{display:inline-block;}.gsc_cod_changed #gsc_cod_trev{color:#1a0dab;pointer-events:auto;}.gsc_fol_cr{margin:0 0 8px 0;}.gs_el_tc .gsc_fol_cr{margin:0;}.gs_el_tc .gsc_fol_cr:first-child{margin-top:-8px;}#gsc_fol_ml{display:block;color:#777;padding:12px 0 4px 0;}</style><script>!function(GSP){/*

 Copyright The Closure Library Authors.
 SPDX-License-Identifier: Apache-2.0
*/
var aa="function"==typeof Object.create?Object.create:function(a){var b=function(){};b.prototype=a;return new b},ba;if("function"==typeof Object.setPrototypeOf)ba=Object.setPrototypeOf;else{var da;a:{var ea={a:!0},fa={};try{fa.__proto__=ea;da=fa.a;break a}catch(a){}da=!1}ba=da?function(a,b){a.__proto__=b;if(a.__proto__!==b)throw new TypeError(a+" is not extensible");return a}:null}
var ha=ba,ia=function(a,b){a.prototype=aa(b.prototype);a.prototype.constructor=a;if(ha)ha(a,b);else for(var c in b)if("prototype"!=c)if(Object.defineProperties){var d=Object.getOwnPropertyDescriptor(b,c);d&&Object.defineProperty(a,c,d)}else a[c]=b[c];a.na=b.prototype},ja=function(){},ka=function(a,b){var c=Array.prototype.slice.call(arguments,1);return function(){var d=c.slice();d.push.apply(d,arguments);return a.apply(this,d)}};var g=function(){this.o=this.o;this.F=this.F};g.prototype.o=!1;g.prototype.isDisposed=function(){return this.o};g.prototype.T=function(){this.o||(this.o=!0,this.H())};g.prototype.H=function(){if(this.F)for(;this.F.length;)this.F.shift()()};function la(a){var b=[],c=0,d;for(d in a)b[c++]=d;return b};function l(a,b){a.classList.add(b)}function n(a,b){a.classList.remove(b)}function p(a,b){return a.classList?a.classList.contains(b):!1}function q(a,b,c){c=void 0!==c?c:!p(a,b);(c?l:n)(a,b)};function r(a){return 0<=(navigator.userAgent||"").indexOf(a)}var ma=r("iPhone")||r("iPad")||r("iPod"),na=r("iPhone")||r("Android")&&r("Mobile");function oa(){if(void 0===b){var a=window.screen;a={width:window.innerWidth,height:window.innerHeight,ma:a.width,la:a.height}}else a=b;var b=a;a=b.width;var c=b.height,d=b.ma;b=b.la;var e=4;if(600>a||48E4>d*b||na)e=1;else if(982>a)e=2;else if(1136>a||590>c)e=3;return e}var pa,qa=/[?&]tc=([01])/.exec(location.search||"");
pa=qa?0<+qa[1]:r("Android")?!0:window.matchMedia&&window.matchMedia("(pointer)").matches?window.matchMedia("(pointer:coarse)").matches:!r("Firefox")||r("Mobile")||r("Tablet")?ma||"ontouchstart"in window||0<(navigator.msMaxTouchPoints||0):!1;function ra(){if(void 0==sa){sa=!1;try{var a=Object.defineProperty({},"passive",{get:function(){sa=!0}});window.addEventListener("testPassive",ja,a);window.removeEventListener("testPassive",ja,a)}catch(b){}}return sa}var sa;var ta=function(a){this.Y=a},ua=new ta("INPUT"),va=new ta("TABLE");function t(a){return document.getElementById(a)}function x(a){return a.id||(a.id="gs_id"+wa++)}function xa(a){a=(void 0===a?null:a)||document.body;return"rtl"==(a?window.getComputedStyle(a,null):null).direction}
function ya(a){var b=[];a=a.elements;for(var c=a.length,d=0;d<c;d++){var e=a[d],f=encodeURIComponent(e.name||""),h=e.type;!f||e.disabled||!("checkbox"!=h&&"radio"!=h||e.checked)||b.push(f+"="+encodeURIComponent(e.value||""))}return b.join("&")}function za(a,b){var c=a.elements[b];c||(c=document.createElement(ua.Y),c.type="hidden",c.name=b,a.appendChild(c));return c}function Aa(a){t("gsc_md_cbyd_c").href=a&&a.match(Ba)?a:"javascript:void(0)"}function Ca(a){a.match(Ba)&&(window.location.href=a)}
var wa=100,Da=/\S+/g,Ba=/^(?:https?:|[^:/?#]*(?:[/?#]|$))/i,Ea=/^(?:#|\/[a-z0-9_-]*(?:[?].*)?$)/i;function y(a){return a.hasOwnProperty("gs_uid")?a.gs_uid:a.gs_uid=++Fa}var Fa=0;var z=function(){this.i=[];this.A={};this.O=this.v=0};z.prototype.add=function(a){var b=y(a);this.A[b]||(this.i.push(a),this.A[b]=this.i.length,++this.v)};z.prototype.remove=function(a){a=y(a);var b=this.A[a];b&&(this.i[b-1]=null,delete this.A[a],2*--this.v<this.i.length&&!this.O&&Ga(this))};z.prototype.notify=function(a){var b=this.i;try{++this.O;for(var c=0;c<b.length;c++){var d=b[c];d&&d.apply(null,arguments)}}finally{!--this.O&&2*this.v<b.length&&Ga(this)}};
var Ga=function(a){var b=a.i,c=b.length;a=a.A;for(var d=0,e=0;e<c;e++){var f=b[e];f&&(b[d]=f,a[y(f)]=++d)}b.length=d};function B(a,b,c,d,e){Ha(a,b,c,void 0===d?!1:d,void 0===e?!1:e,Ia)}function C(a,b,c,d){Ha(a,b,c,void 0===d?!1:d,!1,Ja)}function Ka(a,b,c,d){function e(h){C(f,a,e,c);b(h)}var f=document;c=void 0===c?!1:c;B(f,a,e,c,void 0===d?!1:d)}function D(a){La?La.add(a):a()}var Ma=window.requestAnimationFrame?function(a){window.requestAnimationFrame(a)}:function(a){setTimeout(a,33)};function Na(a){a.stopPropagation();a.preventDefault()}
function Oa(a){return(a.ctrlKey?1:0)|(a.altKey?2:0)|(a.metaKey?4:0)|(a.shiftKey?8:0)}function Ia(a,b,c,d,e){var f=a.addEventListener;e=e&&ra();f.call(a,b,c,e?{passive:e,capture:d}:d)}function Ja(a,b,c,d){a.removeEventListener(b,c,d)}function Ha(a,b,c,d,e,f){if("string"===typeof b)f(a,b,c,d,e);else for(var h=b.length,k=0;k<h;k++)f(a,b[k],c,d,e)}function Pa(){La.notify();La=null}function Qa(){"complete"==document.readyState&&(C(document,"readystatechange",Qa),Pa())}
var La,Ra=!!document.attachEvent,Sa=document.readyState;if(Ra?"complete"!=Sa:"loading"==Sa)La=new z,Ra?B(document,"readystatechange",Qa):Ka("DOMContentLoaded",Pa);function Ta(){Ka(["mousedown","touchstart"],function(){q(document.documentElement,"gs_pfcs",!0);B(document,"keydown",Ua,!0)},!0,!0)}function Ua(a){9==a.keyCode&&(q(document.documentElement,"gs_pfcs",!1),C(document,"keydown",Ua,!0),Ta())}Ta();function Va(a,b,c,d,e){var f=t(a);Wa(f,function(){l(f,"gs_vis");b&&b()},function(){n(f,"gs_vis");c&&c()},d,e)}function Wa(a,b,c,d,e){var f=x(a);if(!E[f]){var h=document.activeElement;Xa(Ya(a),!0);b&&b();G.push(function(k){delete E[f];try{k||(e||h).focus()}catch(m){}c&&c()});E[f]=G.length;h&&a.contains(h)||setTimeout(function(){var k=d,m=k&&"text"==k.type;if(!k||m&&pa)k=a;try{k.focus(),m&&(k.value=k.value)}catch(w){}},0)}}function H(a){Xa((E[a]||1E6)-1,!1)}
function Za(a){a=void 0===a?!1:a;G.pop()(a)}function Xa(a,b){for(b=void 0===b?!1:b;G.length>a;)Za(b||G.length>a+1)}function Ya(a){for(var b=0;a&&!(b=E[a.id]||0);)a=a.parentNode;return b}var G=[],E={};B(document,"click",function(a){var b=G.length;b&&!Oa(a)&&b>Ya(a.target)&&Za(!0)});B(document,"keydown",function(a){27==a.keyCode&&!Oa(a)&&G.length&&Za()});
B(document,"focus",function(a){var b=G.length;if(b)for(var c=Ya(a.target);c<b;){var d="",e;for(e in E)if(E[e]==b){d=e;break}a:{d=(t(d).getAttribute("data-wfc")||"").match(Da)||[];for(var f=0;f<d.length;f++){var h=t(d[f]);if(h&&h.offsetWidth){d=h;break a}}d=void 0}if(d){Na(a);d.focus();break}else Za(!0),--b}},!0);var $a={},ab={},bb;try{bb=window.sessionStorage}catch(a){};function J(a){return"object"==typeof a?a:null}function cb(a,b){b=db(b);a=eb(a);a=fb(a)||"#";gb=J(b);hb?window.history.pushState(b,"",a):window.location.assign(a)}function ib(a,b){b=db(b);a=eb(a);a=fb(a)||"#";gb=J(b);hb?window.history.replaceState(b,"",a):window.location.replace(a)}function fb(a){var b=[],c;for(c in a)b.push(encodeURIComponent(c)+"="+encodeURIComponent(a[c]));return(a=b.sort().join("&"))?"#"+a:""}
function jb(a){var b={};a=a.split("&");for(var c=0;c<a.length;c++){var d=a[c],e=d.indexOf("=");if(e+1){var f=d.substr(0,e);d=d.substr(e+1)}else f=d,d="";f&&(b[decodeURIComponent(f)]=decodeURIComponent(d))}return b}function kb(a){var b=a.indexOf("#")+1;return jb(b?a.substr(b):"")}function lb(a){var b=a.indexOf("?")+1;a=b?a.substr(b):"";b=a.indexOf("#");return jb(b+1?a.substr(0,b):a)}function mb(a,b){for(var c in b){var d=b[c];void 0!==d?a[c]=d:delete a[c]}}
function eb(a){var b=kb(window.location.hash);mb(b,a);return b}function db(a){var b=gb||J(window.history.state),c={},d;for(d in b)c[d]=b[d];mb(c,a);return c}function nb(){setTimeout(function(){if(!ob){var a=window.history.state;ob=!0;gb=J(a);rb.notify()}sb=!1},0)}var rb=new z,gb,ob=!1,sb=!0,hb="pushState"in window.history,tb;
if("undefined"==typeof GSP)tb=!1;else{var ub=.001*Date.now(),vb=GSP.eventId,wb=!1,K,xb=bb;if(!("nh"in $a)){var yb=xb&&xb.getItem("nh"),zb;if(yb)try{zb=JSON.parse(yb)}catch(a){}ab.nh=zb}K=ab.nh;K instanceof Array||(K=[]);for(var Ab=K.length,Bb=0,Cb=0;Cb<Ab;Cb++){var Db=K[Cb];if(Db instanceof Array&&2==Db.length){var Eb=Db[1]==vb;wb=wb||Eb;10>=Ab-Cb&&+Db[0]>ub-86400&&!Eb&&(K[Bb++]=Db)}}K.length=Bb;K.push([ub,vb]);var Fb=K,Gb=bb;ab.nh=Fb;try{Gb&&Gb.setItem("nh",JSON.stringify(Fb))}catch(a){}tb=wb}
var Hb=tb;"onpageshow"in window?B(window,"pageshow",nb):D(nb);B(window,hb?"popstate":"hashchange",function(a){"loading"!=document.readyState&&(a=a.state,ob=!0,gb=J(a),rb.notify())});function Ib(){Jb&&(C(t("gs_alrt_l"),"click",Jb),Jb=void 0)}function Kb(){var a=Lb();l(a,"gs_anm");l(a,"gs_vis");B(document,"click",Mb);clearTimeout(Nb);Nb=setTimeout(Mb,4E3);++Ob;setTimeout(Pb,0)}function Mb(){Ob||(C(document,"click",Mb),clearTimeout(Nb),Nb=void 0,Ib(),n(Lb(),"gs_vis"))}function Lb(){return t("gs_alrt")}function Pb(){Ob=0}var Nb,Ob=0,Jb;D(function(){var a=t("gs_alrt_m");a&&(a.innerHTML&&!Hb&&Kb(),B(window,"pagehide",function(){Ob=0;Mb();n(Lb(),"gs_anm")}))});function Qb(a,b,c){var d=new XMLHttpRequest;d.onreadystatechange=function(){if(4==d.readyState){var e=d.status,f=d.responseText,h=d.responseURL,k=window.location,m=k.protocol;k="//"+k.host+"/";h&&h.indexOf(m+k)&&h.indexOf("https:"+k)&&(e=0,f="");c(e,f)}};d.open(b?"POST":"GET",a,!0);d.setRequestHeader("X-Requested-With","XHR");b&&d.setRequestHeader("Content-Type","application/x-www-form-urlencoded");b?d.send(b):d.send();return d}function Rb(a){a&&(a.onreadystatechange=ja,a.abort())};var Sb=function(a,b,c){this.type=a;this.currentTarget=this.target=b;this.g=void 0===c?null:c;this.P=!1};Sb.prototype.stopPropagation=function(){this.g&&this.g.stopPropagation();this.P=!0};var L=function(a){a.g&&Na(a.g);a.P=!0};var M=function(a,b){this.R=a;this.ka=b},Tb=function(a,b,c){this.R=a;this.types=b;this.listener=c};function Ub(a,b){var c=b.length;if(c){var d=y(a),e=Vb[d];if(!e){e=Vb[d]=[];d=Wb(b[0].R);for(var f in d){var h=Xb[f];h||(h=Xb[f]=Object.create(null));for(var k in d[f]){var m=h[k];m||(m=h[k]=[]);m.push(a)}}Yb(a,e,b[0],Zb);for(f=1;f<c;f++)Yb(a,e,b[f],$b)}}}function O(a,b,c){ac(new Sb(a,b,void 0===c?null:c))}
function P(a,b,c){var d=bc;"string"===typeof b&&(cc[0]=b,b=cc);var e=b.length;a=Wb(a);for(var f in a)for(var h in a[f])for(var k=0;k<e;k++)d(f,h,b[k],c)}function Wb(a){"string"===typeof a&&(dc[0]=a,a=dc);for(var b=a.length,c=Object.create(null),d=0;d<b;d++){var e=a[d],f=e.charAt(0),h=e.substr(1);if("#"!=f&&"."!=f||!h)throw Error("bad selector: "+e);(e=c[f])||(e=c[f]=Object.create(null));e[h]=!0}return c}
function bc(a,b,c,d){var e=ec[c];e||("touchstart"!=c&&"mouseover"!=c&&"mouseout"!=c&&B(document,c,fc,"focus"==c||"blur"==c),e=ec[c]=Object.create(null));(c=e[a])||(c=e[a]=Object.create(null));(a=c[b])||(a=c[b]=new z);a.add(d)}function fc(a){var b=a.target;b&&3==b.nodeType&&(b=b.parentNode);ac(new Sb(a.type,b,a))}
function ac(a){for(var b=a.target;b&&b!=document&&!b.disabled&&!p(b,"gs_dis");){a.currentTarget=b;var c=b.id;if(c&&!gc("#",c,a))break;c=b.classList||[];for(var d=c.length,e=0;e<d;e++)if(!gc(".",c[e],a))return;b=b.parentNode}}function gc(a,b,c){var d=ec[c.type];(b=(a=d&&d[a])&&a[b])&&b.notify(c);return!c.P}function Yb(a,b,c,d){var e=c.R;c=c.ka;for(var f in c){var h=ka(d,a,c[f]);P(e,f,h);b.push(new Tb(e,f,h))}}function Zb(a,b,c){var d=c.currentTarget;a=hc(a,d)||a;a=ic(a,d);b.call(a,c)}
function $b(a,b,c){a:{for(var d=c.currentTarget;d&&d!=document;){var e=hc(a,d);if(e){a=ic(e,d);break a}d=d.parentNode}a=void 0}a&&b.call(a,c)}function ic(a,b){var c=jc(b),d=kc[c];d||(d=kc[c]=[]);for(var e=d.length,f=0;f<e;f++){var h=d[f];if(h instanceof a)return h}b=new a(b);d.push(b);a=y(a);(d=lc[a])||(d=lc[a]=[]);d.push(c);return b}function hc(a,b){var c,d=b.id;d&&(c=mc(a,c,"#",d));b=b.classList||[];d=b.length;for(var e=0;e<d;e++)c=mc(a,c,".",b[e]);return c}
function mc(a,b,c,d){c=(d=(c=Xb[c])&&c[d])?d.length:0;for(var e=0;e<c;e++){var f=d[e];!(f===a||f.prototype instanceof a)||b&&!(f===b||f.prototype instanceof b)||(b=f)}return b}function jc(a){var b=a.getAttribute("data-duid");b||a.setAttribute("data-duid",b=""+nc++);return b}var ec=Object.create(null),dc=[""],cc=[""],Xb=Object.create(null),Vb=Object.create(null),lc=Object.create(null),kc=Object.create(null),nc=100;window.gs_evt_dsp=fc;function oc(){var a=".gs_md_li";if("string"===typeof a){var b=a.charAt(0),c=a.slice(1);if("#"==b)a=function(d){return d.id==c&&0<d.offsetWidth};else if("."==b)a=function(d){return p(d,c)&&0<d.offsetWidth};else throw Error("bad selector: "+a);}return a}function pc(a,b){return a&&((void 0===b?0:b)?a.lastElementChild:a.firstElementChild)}function qc(a,b){return a&&((void 0===b?0:b)?a.previousElementSibling:a.nextElementSibling)}function rc(a,b,c){c=void 0===c?!1:c;return sc(a,b,oc(),c,!1)}
function sc(a,b,c,d,e){for(var f;b&&a;){if(c(b)){if(e)return b}else for(f=pc(b,d);f;f=qc(f,d))if(e=sc(f,f,c,d,!0))return e;for(e=!0;;){if(b==a)return null;f=b.parentNode;if(b=qc(b,d))break;b=f}}return null};function tc(a){return!!p(a,"gs_sel")+2*!!p(a,"gs_par")}function uc(a){return+a.getAttribute("data-s")}function vc(a,b,c){c=void 0===c?!1:c;q(a,"gs_sel",1==b);q(a,"gs_par",2==b);a.setAttribute("aria-checked",wc[b]);c||a.setAttribute("data-s",""+b)}var wc=["false","true","mixed"];var Q=function(){this.j=Object.create(null);this.l=0};Q.prototype.clear=function(){this.j=Object.create(null);this.l=0};Q.prototype.has=function(a){return a in this.j};Q.prototype.get=function(a){return this.j[a]};Q.prototype.set=function(a,b){this.has(a)||this.l++;this.j[a]=b};Q.prototype.delete=function(a){this.has(a)&&(delete this.j[a],this.l--)};var xc=function(a){var b=window,c=this;this.i=new z;this.V=0;this.S=[b,a,function(){c.V++||Ma(d)},!1];var d=function(){c.V=0;c.i.notify()}};xc.prototype.addListener=function(a){this.i.v||B.apply(null,this.S);this.i.add(a)};xc.prototype.removeListener=function(a){this.i.remove(a);this.i.v||C.apply(null,this.S)};var yc=new xc("scroll"),zc=new xc("resize");var Ac=new z;function Bc(){var a=document.documentElement,b=oa();b={gs_el_ph:1==b,gs_el_ta:2==b,gs_el_sm:4!=b,gs_el_tc:pa||1==b};var c;for(c in b){var d=b[c];if(p(a,c)!=d){var e=!0;q(a,c,d)}}e&&Ac.notify()}q(document.documentElement,"gs_el_ios",ma);Bc();zc.addListener(Bc);B(window,["pageshow","load"],Bc);function R(a,b,c,d){function e(){var u=ca&&p(h,"gs_el_ph");q(F,"gs_vis",!u);h.style.overflowY=Yd&&!u?"scroll":""}function f(){var u=h.clientHeight,I=+A.getAttribute("data-h");I||(w.style.maxHeight="none",I=m.offsetHeight);I=Math.max((u-I)/2,10);u=Math.max(u-48-2*I,10);var Jc=ca&&p(h,"gs_el_ph");m.style.top=Jc?"auto":I+"px";w.style.maxHeight=Jc?"none":u+"px";Cc(w)}b=void 0===b?"":b;c=void 0===c?"":c;d=void 0===d?"":d;var h=document.documentElement,k=t("gs_top"),m=t(a),w=t(a+"-bdy"),v=t(m.getAttribute("data-cid")||
m.id+"-bdy")||m,F=t(m.getAttribute("data-shd")||"gs_md_s"),A=Dc(m),ca=!!A&&p(A,"gs_md_wmw"),N=window.pageYOffset,Yd=k.scrollHeight>h.clientHeight,pb=!!E[a],qb=pb?"":S,Lc=b&&"#"!=b[0]&&!d,$d=a==S&&b==Ec&&c==T;Fc=b;Lc?(pb?q(v,"gs_md_ldg",!0):Gc(m,v,'<div class="gs_md_prg">'+t("gs_md_ldg").innerHTML+"</div>"),O("gs-md-ldin",v)):(d&&Gc(m,v,d),O("gs-md-lded",v));qb&&(++Hc,H(qb),--Hc);S=a;Ec=b;T=c;Ic=d;$d||Hc||(Kc+=1,(qb?ib:cb)(Mc(),Nc()));pb||Wa(m,function(){A&&l(A,"gs_vis");l(m,"gs_vis");q(m,"gs_abt",
sb);Oc(a);Ac.add(e);e();A&&w&&(f(),zc.addListener(f));l(k,"gs_nscl");k.style.top=-N+"px"},function(){Ac.remove(e);zc.removeListener(f);A&&n(A,"gs_vis");n(m,"gs_vis");n(m,"gs_abt");n(F,"gs_vis");h.style.overflowY="";n(k,"gs_nscl");k.style.top="auto";Rb(U);U=null;window.scrollTo(0,N);S=Ec=T=Ic="";var u=Kc;Kc=0;Hc||(0<u?window.history.go(-u):ib(Mc(),Nc()))},Pc(m),Qc(m));Lc&&(Rb(U),U=null,U=Qb(b,c,function(u,I){U=null;u=200==u;Gc(m,v,u?I:Rc());u&&a==S&&b==Ec&&c==T&&(Ic=I,ib(Mc(),Nc()));O("gs-md-lded",
v)}))}function Dc(a){a=a.parentNode;return p(a,"gs_md_wnw")?a:null}function Pc(a){return(a=a.getAttribute("data-ifc"))?t(a):null}function Qc(a){return(a=a.getAttribute("data-cfc"))?t(a):null}
function Gc(a,b,c){q(b,"gs_md_ldg",!1);for(var d=b.querySelectorAll("[data-duid]"),e=d.length,f={},h=0;h<e;h++){for(var k=jc(d[h]),m=kc[k],w=m?m.length:0,v=0;v<w;v++){var F=m[v],A=y(F.constructor),ca=f[A];ca||(ca=f[A]={});ca[k]=!0;F&&"function"==typeof F.T&&F.T()}delete kc[k]}for(var N in f){N=+N;d=f[N];h=(e=lc[N])?e.length:0;for(m=k=0;m<h;m++)w=e[m],w in d||(e[k++]=w);k?e.length=k:delete lc[N]}b.innerHTML=c;Oc(a.id);Rb(U);U=null}
function Oc(a){if(a=document.querySelector("#"+a+">.gs_md_bdy"))a.scrollTop=a.scrollLeft=0,Cc(a)}function Cc(a){var b=a.style,c="padding"+(xa(a)?"Left":"Right");b[c]="";var d=a.offsetWidth-a.clientWidth;2<d&&(a=parseInt(window.getComputedStyle(a,null)[c],10)||0,b[c]=Math.max(a-d,0)+"px")}function Rc(){return'<div class="gs_md_prg"><div class="gs_alrt">'+t("gs_md_err").innerHTML+"</div></div>"}function Mc(){return{d:S||void 0,u:Ec||void 0,p:T?"1":void 0}}function Nc(){return{n:Kc,p:T,h:Ic}}
var U=null,Fc="",S="",Ec="",T="",Ic="",Kc=0,Hc=0;rb.add(function(){var a=kb(window.location.hash),b=a.d||"",c=b?t(b):null;++Hc;if(c){c=a.u||"";a=0<+a.p;var d=gb||J(window.history.state)||{},e=+d.n||0,f=""+(d.p||"");d=""+(d.h||"");c.match(Ea)||(c="");a!=!!f?R(b,"","",Rc()):b==S&&c==Ec&&f==T&&d==Ic||R(b,c,f,d);Kc=e}else S&&H(S);--Hc});var Sc=function(a){g.call(this);this.D=a;this.K=Object.create(null);this.C=null;a=a.querySelectorAll(".gs_in_txtw>input[type=text]");for(var b=a.length;b--;){var c=a[b],d=c.parentNode.querySelector(".gs_in_txts");c=c.name;d&&c&&(this.K[c]=d.innerHTML)}};ia(Sc,g);Sc.prototype.H=function(){Rb(this.C);this.D=this.C=null;g.prototype.H.call(this)};
Sc.prototype.ga=function(a){var b=this;L(a);if((a=this.D)&&!this.C){var c="json=&"+ya(a);Tc(this,!0);this.C=Qb(a.action,c,function(d,e){b.C=null;Tc(b,!1);var f=b.D,h=f.getAttribute("data-alrt");if(h=h?t(h):null)h.innerHTML="";try{var k=200==d&&JSON.parse(e)}catch(A){}k&&"object"==typeof k||(Uc(h,t("gs_md_err").innerHTML),k={});if(d=k.L)Ca(""+d);else{(d=k.M)&&Uc(h,d);d=1E6;if(h&&h.innerHTML){var m=h;d=h.getBoundingClientRect().top}f=f.elements;k=k.E;"object"==typeof k||(k=Object.create(null));for(var w in b.K){h=
f[w];e=void 0;var v=""+(k[w]||""),F=h.parentNode.querySelector(".gs_in_txts");q(h.parentNode,"gs_in_txte",!!v);F&&(F.innerHTML=v||b.K[w]||"");v&&(e=h.getBoundingClientRect().top)<d&&(m=h,d=e)}m&&m.scrollIntoView&&(0>d||d+20>window.innerHeight)&&m.scrollIntoView()}})}};
var Tc=function(a,b){a=a.D;var c=a.getAttribute("data-bsel");a=c?document.querySelectorAll(c):a.querySelectorAll("button");for(c=a.length;c--;){var d=a[c];d.disabled=b;q(d,"gs_bsp",b)}},Uc=function(a,b){if(a)a.innerHTML=b;else{var c=void 0===c?"":c;var d=void 0===d?"":d;var e=void 0===e?[]:e;t("gs_alrt_m").innerHTML=b;Lb().action=d.match(Ba)?d:"";a=t("gs_alrt_l");a.textContent=c;c=t("gs_alrt_h");c.innerHTML="";for(var f in e)b=document.createElement("input"),b.type="hidden",b.name=f,b.value=e[f],
c.appendChild(b);Ib();q(a,"gs_fm_s",!0);Kb()}};Ub(Sc,[new M(".gs_ajax_frm",{submit:Sc.prototype.ga})]);var Vc=[[1,0,1],[2,0,1]];P(".gs_cb_gen","click",function(a){var b=a.currentTarget,c=tc(b),d=2==+b.getAttribute("data-s");vc(b,Vc[+d][c],!0);O("gs-change",b,a.g)});P(".gs_cb_gen",["keydown","keyup"],function(a){var b=a.currentTarget,c=a.g.keyCode;"BUTTON"!=b.tagName||13!=c&&32!=c||(L(a),"keydown"==a.type&&b.click())});P([".gs_cb_gen",".gs_md_li"],"keydown",function(a){var b=a.currentTarget,c=b.tagName,d=a.g.keyCode;"BUTTON"!=c&&(32==d||13==d&&"A"!=c)&&(L(a),b.click())});var Wc=["click","contextmenu","mouseup"].concat(navigator.sendBeacon?[]:["mousedown","touchstart"]),Xc="",Yc=null;function Zc(){Yc=null}function $c(a){navigator.sendBeacon?navigator.sendBeacon(a):Yc&&a==Yc.src||((Yc=new Image).src=a,setTimeout(Zc,1E3))}function ad(){var a=lb(document.location.href).hl||"";a="/scholar_bfnav?url="+encodeURIComponent(document.location.href)+"&hl="+encodeURIComponent(a)+"&ei="+GSP.eventId;$c(a)}D(function(){Xc=Hb?"&bn=1":"";Hb&&ad()});
B(window,"pageshow",function(a){a.persisted&&(Xc="&bn=1",ad())});
B(document,Wc,function(a){if(!("click"==a.type&&a.button||"mouseup"==a.type&&1!=a.button)){var b,c;a:{for(a=a.target;a;){var d=a.nodeName;if("A"==d)break a;if("SPAN"==d||"B"==d||"I"==d||"EM"==d||"IMG"==d)a=a.parentNode;else break}a=null}a&&(b=a.getAttribute("href"))&&(c=a.getAttribute("data-clk"))&&(b="/scholar_url?url="+encodeURIComponent(b)+"&"+c+"&ws="+window.innerWidth+"x"+window.innerHeight+"&at=",c=encodeURIComponent,a=(a=a.getAttribute("data-clk-atid"))&&t(a),b=b+c(a&&a.innerText||"")+Xc,$c(b))}},
!1,!0);P(".gs_fm_s","click",function(a){a=a.currentTarget.getAttribute("data-fm")||"";(a=t(a))&&a.submit()});var V=function(a){this.m=x(a.querySelector(".gs_md_d"));this.G=x(a.querySelector(".gs_md_tb"))};V.prototype.I=function(a){var b=t(this.m);return void 0!==a?rc(b,b,a):null};V.prototype.open=function(a){a=this.I(a);if(p(t(this.G),"gs_sel"))try{a&&a.focus()}catch(c){}else{var b=t(this.G);Va(this.m,function(){l(b,"gs_sel")},function(){n(b,"gs_sel")},a,b)}};V.prototype.close=function(){H(this.m)};V.prototype.Z=function(a){L(a);p(t(this.G),"gs_sel")?this.close():this.open("keydown"==a.g.type?!1:void 0)};
V.prototype.U=function(a){var b=a.g.keyCode;if(38==b||40==b)L(a),this.open(38==b)};V.prototype.aa=function(a){a.target.id==this.m&&this.U(a)};Ub(V,[new M(".gs_md_rmb",{}),new M(".gs_md_tb",{"gs-press":V.prototype.Z,keydown:V.prototype.U}),new M(".gs_md_d",{keydown:V.prototype.aa})]);var W=function(a){V.call(this,a);this.ia=x(a.querySelector(".gs_md_in"));this.ja=x(a.querySelector(".gs_md_tb .gs_lbl"))};ia(W,V);W.prototype.I=function(){return t(this.m).querySelector(".gs_md_li[aria-selected]")};W.prototype.ba=function(a){bd(this,a)};W.prototype.J=function(a){var b=a.g.keyCode;13!=b&&32!=b||bd(this,a)};
var bd=function(a,b){var c=b.currentTarget,d=t(a.ia),e=a.I();c!=e&&(d.value=c.getAttribute("data-v"),t(a.ja).innerHTML=c.innerHTML,e&&cd(e,!1),cd(c,!0));L(b);a.close();O("gs-change",d,b.g)},cd=function(a,b){q(a,"gs_sel",b);b?a.setAttribute("aria-selected","true"):a.removeAttribute("aria-selected")};Ub(W,[new M(".gs_md_ris",{}),new M(".gs_md_li",{click:W.prototype.ba,keydown:W.prototype.J})]);P("#gs_lp","click",function(a){L(a);R("gs_lp_d")});P("#gs_lp_cur","click",function(a){L(a);H("gs_lp_d")});var dd=function(a){this.W=x(a)};dd.prototype.J=function(a){var b=a.currentTarget,c=a.g.keyCode;if(38==c||40==c){var d=t(this.W);d=rc(d,b,38==c)||rc(d,d,38==c)}else if(37==c||39==c)a:{c=!!(37==c^xa(b.parentNode));d=b.parentNode;var e=d.children,f=e.length;if(d.id!=this.W){for(;e[--f]!=b;);d=qc(d,c)||pc(d.parentNode,c);e=d.children;if(f=Math.min(f+1,e.length))if(d=e[f-1],p(d,"gs_md_li")&&d.offsetLeft!=b.offsetLeft)break a}d=void 0}d&&(L(a),d.focus())};
Ub(dd,[new M(".gs_md_ulr",{}),new M(".gs_md_li",{keydown:dd.prototype.J})]);P("#gs_hdr_mnu","click",function(a){L(a);R("gs_hdr_drw")});P("#gs_hdr_drw_mnu","click",function(a){L(a);H("gs_hdr_drw")});P("#gs_hdr_act_i","click",function(a){L(a);1==oa()?Ca(document.querySelector("#gs_hdr_drw_bot>a").href):Va("gs_hdr_act_d")});P("#gs_hdr_drw","keydown",function(a){var b=a.g.keyCode;if(38==b||40==b){var c=a.currentTarget;if(b=rc(c,c,38==b))L(a),b.focus()}});
P("#gs_hdr_tsi",["focus","blur"],function(a){function b(){var h=d.getBoundingClientRect().top-10;10<Math.abs(h)&&window.scrollBy(0,h);clearTimeout(e);c()}function c(){C(window,f,b)}var d=a.target;a="focus"==a.type;q(t("gs_hdr"),"gs_hdr_ifc",a);if(a&&pa&&!(749<window.innerHeight)){var e=setTimeout(c,1E3),f=["scroll","resize"];B(window,f,b)}});P("#gs_hdr_tsi",["input","gs-change"],function(a){q(t("gs_hdr_frm"),"gs_hdr_tsc",!!a.currentTarget.value)});
P("#gs_hdr_tsc","mousedown",function(a){L(a);var b=t("gs_hdr_tsi");b.value="";b.focus();O("input",b,a.g)});P("#gs_hdr_sre","click",function(a){L(a);var b=t("gs_hdr");Va("gs_hdr_frm",function(){n(b,"gs_hdr_src");l(b,"gs_hdr_srx")},function(){l(b,"gs_hdr_src");n(b,"gs_hdr_srx")},t("gs_hdr_tsi"))});P(".gs_md_x","click",function(a){(a=a.currentTarget.getAttribute("data-mdx"))&&H(a)});var X=function(){},ed,fd;X.prototype.$=function(a){a.g.button||(L(a),gd(a))};X.prototype.ca=function(a){hd(a)&&(L(a),gd(a))};X.prototype.da=function(a){hd(a)&&L(a)};X.prototype.ea=function(a){if(!a.g.button){L(a);var b=a.g;b&&(id=b.clientX||0,jd=b.clientY||0,B(document,kd,ld,!0),clearTimeout(ed),ed=setTimeout(md,2E3));gd(a)}};X.prototype.ha=function(a){L(a);if(nd){var b=a.g;if(b=(b=b&&b.touches)&&1==b.length&&b[0])od=b.clientX,pd=b.clientY,B(document,qd,rd,!0),clearTimeout(fd),fd=setTimeout(sd,2E3)}gd(a)};
var hd=function(a){a=a.g.keyCode;return 32==a||13==a},gd=function(a){O("gs-press",a.currentTarget,a.g)},md=function(){C(document,kd,ld,!0);clearTimeout(ed);ed=void 0},ld=function(a){"mousedown"!=a.type&&10>Math.abs(a.clientX-id)&&10>Math.abs(a.clientY-jd)?(Na(a),"click"==a.type&&md()):md()},sd=function(){C(document,qd,rd,!0);clearTimeout(fd);fd=void 0},rd=function(a){"touchstart"!=a.type&&10>Math.abs(a.clientX-od)&&10>Math.abs(a.clientY-pd)?(Na(a),"click"==a.type&&sd()):sd()},id=0,jd=0,kd=["mousedown",
"mouseup","click"],nd=r("Android")&&!r("Chrome"),od=0,pd=0,qd=["touchstart","mousedown","mouseup","click"];Ub(X,[new M(".gs_press",{click:X.prototype.$,keydown:X.prototype.ca,keyup:X.prototype.da,mousedown:X.prototype.ea,touchstart:X.prototype.ha})]);function td(){var a=0>ud.getBoundingClientRect().top;vd!=a&&(vd=a,q(wd,"gs_sth_vis",a),a?xd():(yd.style.left="",yd.style.width="",zd()))}function xd(){if(vd){var a=ud.getBoundingClientRect();yd.style.left=a.left+"px";yd.style.width=a.width+"px";zd()}}function zd(){O("gs-sth-change",t("gs_sth"))}var wd,ud,yd,vd=!1;D(function(){if(wd=t("gs_sth"))ud=wd.querySelector(".gs_sth_g"),yd=wd.querySelector(".gs_sth_b"),yc.addListener(td),zc.addListener(xd),td()});function Ad(){var a=t("gsc_rsb_co");if(a){a=a.querySelectorAll("img.gs_pp_df");for(var b=0;b<a.length;b++){var c=a[b];c.getAttribute("data-srcset")&&(c.setAttribute("srcset",c.getAttribute("data-srcset")),c.removeAttribute("data-srcset"));c.getAttribute("data-src")&&(c.setAttribute("src",c.getAttribute("data-src")),c.removeAttribute("data-src"))}}};var Bd=/\S+@\S+\.\S+/;function Cd(a){return p(a,"gsc_ccb_dis")||p(a,"gsc_ccb_lim")}function Dd(){for(var a=0>=Ed(),b=t("gsc_cods_res").querySelectorAll(".gsc_ccb_add"),c=b.length;c--;){var d=b[c];p(d,"gsc_ccb_on")||q(d,"gsc_ccb_lim",a)}};var Fd=function(a){this.X=a};Fd.prototype.fa=function(a){L(a);a=a.currentTarget.getAttribute("data-a");this.X.setAttribute("data-a",a||"");O("gsc-navigate",this.X)};var Gd=[new M(".gsc_pgn",{}),new M([".gsc_pgn_ppr",".gsc_pgn_pnx"],{click:Fd.prototype.fa})];function Hd(a,b){b=void 0===b?"":b;var c=t("gsc_md_cod");a+=fb({t:Id});R(c.id,a,"",b)}function Jd(a){if(Id!=a){var b=t("gsc_md_cod");n(b,Id);l(b,a);Id=a}}function Kd(){var a=kb(Fc).t;"gsc_cod_sugg"!=a&&"gsc_cod_lc"!=a||Jd(a)}function Ld(){var a=Md();a=a?a.value:"";var b=(t("gsc_cods_urls").getAttribute("data-sa")||"").replace(Nd,"$1"+encodeURIComponent(a));a=a?b:t("gsc_cods_urls").getAttribute("data-lc")||"";Hd(a)}
function Od(a){var b=t("gsc_cods_frm");if(b){b=b.elements;var c=b[1];b[0].disabled=c.disabled=a;q(c,"gs_bsp",a)}a=a?null:t("gsc_codb_data");if(c=t("gsc_cods_pp")){var d=a&&a.getAttribute("data-prev");b=a&&a.getAttribute("data-next");var e=a&&a.getAttribute("data-start"),f=a&&a.getAttribute("data-end");c.querySelector(".gsc_pgn_ppn").textContent=e&&f?e+" - "+f:"";e=c.querySelector(".gsc_pgn_ppr");e.disabled=!d;e.setAttribute("data-a",d||"");c=c.querySelector(".gsc_pgn_pnx");c.disabled=!b;c.setAttribute("data-a",
b||"")}a&&(Pd=+a.getAttribute("data-max")||0,za(t("gsc_cods_save"),"xsrf").value=a.getAttribute("data-xsrf")||"")}function Qd(){var a=0<Y.l||0<Z.l,b=Ed(),c=0>=b;t("gsc_cod_done").disabled=!a||0>b;q(t("gsc_cod_t"),"gsc_cod_changed",a);a=t("gsc_cod_trev");a.textContent=a.getAttribute(c?"data-lim":"data-txt")||"";q(t("gsc_cod_t"),"gsc_cod_lim",c)}function Ed(){return Pd-Y.l+("gsc_cod_sugg"==Id?0:Z.l)}function Md(){return t("gsc_cods_tsi")}
function Rd(a){for(var b="",c=la(a.j),d=c.length;d--;)b+=a.get(c[d]);return b}var Id="gsc_cod_lc",Pd=0,Nd=/([?&]mauthors=)([^&]*)/,Y=new Q,Z=new Q;function Sd(a){q(t("gsc_a_sp"),"gs_vis",0==a);q(t("gsc_a_err"),"gs_vis",2==a)}function Td(){return document.querySelectorAll("#gsc_a_t input[type=checkbox]")}function Ud(){O("gsc-works-change",t("gsc_a_t"))}function Vd(){var a=t("gsc_x_all");if(a){var b=document.querySelectorAll("#gsc_a_t input[type=checkbox]:checked");var c=b.length;var d=Td().length;c=c?c==d?1:2:0;vc(a,c);2==c&&(Wd=b)}Ud()}var Wd=[];var Xd="",Zd=0,ae=0;function be(a){for(var b=[!1,!1,!1],c=0;c<b.length;c++){var d=t(ce[c]);d&&(b[c]=!!a(d))}return b}function de(){var a=t("gsc_fol_m");if(a){var b=t("gsc_fol_b");if(!(a=!Bd.test(a.value))){a:{a=be(tc);for(var c=be(uc),d=0;d<a.length;d++)if(a[d]!=c[d]){a=!0;break a}a=!1}a=!a}b.disabled=a}}var ce=["gsc_fol_a","gsc_fol_c","gsc_fol_r"],ee=["follow_articles_btn","follow_citations_btn","follow_related_btn"];function fe(){p(document.documentElement,"gs_el_ph")||p(document.documentElement,"gs_el_ta")||Ad()};function ge(a){if(a){a.id&&a.removeAttribute("id");for(var b=0;b<a.children.length;b++)ge(a.children[b])}};function he(){var a=t("gsc_prf_pufii");if(r("MSIE ")){var b=t("gsc_prf_puf");Va("gsc_prf_pufi",function(){l(b,"gsc_prf_pufo")},function(){n(b,"gsc_prf_pufo")},a)}else a.click()};function ie(){var a=document.querySelectorAll(".gsc_prf_pnl"),b=document.documentElement;b=p(b,"gs_el_ph")||p(b,"gs_el_ta");for(var c=0;c<a.length;c++)a[c].setAttribute("role",b?"tabpanel":"region")};var je=kb(window.location.hash),ke=je.u||"";"gs_md_cita-d"==je.d&&ke.match(Ea)&&0<=ke.indexOf("view_citation")&&Ca(ke);P("#gsc_md_cod","gs-md-ldin",function(){Kd();Od(!0)});P("#gsc_md_cod","gs-md-lded",function(){Kd();Od(!1);for(var a=t("gsc_cods_res").querySelectorAll(".gsc_ccb_ck"),b=a.length;b--;){var c=a[b];if(!Cd(c)){var d=c.getAttribute("data-authorid")||"";d=(p(c,"gsc_ccb_add")?Y:Z).has(d);q(c,"gsc_ccb_on",d)}}Dd();Qd();a=lb(Fc);(b=Md())&&(b.value=a.mauthors||"")});
P("#gsc_cods_frm","gsc-lwpds-submit",Ld);P("#gsc_cods_pp","gsc-navigate",function(a){(a=a.currentTarget.getAttribute("data-a"))&&Hd(a)});
P([".gsc_ccb_add",".gsc_ccb_del"],"click",function(a){a=a.currentTarget;if(!Cd(a)){var b=!p(a,"gsc_ccb_on");q(a,"gsc_ccb_on",b);var c=p(a,"gsc_ccb_add")?".gsc_ccb_del":".gsc_ccb_add",d=a.parentNode;(c=d&&d.querySelector(c))&&n(c,"gsc_ccb_on");c=a.getAttribute("data-authorid")||"";Y.delete(c);Z.delete(c);b&&(p(a,"gsc_ccb_add")?Y:Z).set(c,t("gsc_ucoar-"+c).outerHTML);Dd();Qd()}});
P("#gsc_cod_trev","click",function(){var a=t("gsc_cods_res").cloneNode(!0),b=a.querySelector("#gsc_codb_content");b||(b=document.createElement("div"),b.id="gsc_codb_content",a.appendChild(b));var c=Rd(Y)+Rd(Z);b.innerHTML=c;(b=Md())&&(b.value="");Hd("",a.innerHTML)});P("#gsc_cod_done","click",function(){var a=t("gsc_cods_save");za(a,"colleague_add").value=la(Y.j).join(",");za(a,"colleague_del").value=la(Z.j).join(",");a.submit()});
P(["#gsc_coauth_opn",".gsc_rsb_btne",".gsc_rsb_btnv"],"click",function(){Jd("gsc_cod_lc");Pd=0;Y.clear();Z.clear();var a=Md();a&&(a.value="");Ld()});P(".gsc_rsb_aa",["click","keydown"],function(a){if("keydown"!=a.type||a.g&&!Oa(a.g)&&13==a.g.keyCode)a.g&&Na(a.g),(a=(a=a.currentTarget.querySelector("a"))?a.getAttribute("href"):"")&&Ca(a)});P("#gsc_prf_t-ath","click",function(){Ad()});D(function(){Ac.add(fe);fe()});P(".gsc_lwpds_frm","submit",function(a){L(a);O("gsc-lwpds-submit",a.target)});
var le=window.location.href.split("#")[0];Xd=le.replace(/([?&])(cstart|pagesize)=[^&]*/g,"$1");Zd=Math.max(+le.replace(/.*[?&]cstart=([^&]*).*/,"$1")||0,0);ae=+le.replace(/.*[?&]pagesize=([^&]*).*/,"$1")||0;ae=Math.max(Math.min(ae,100),20);
P("#gsc_bpf_more","click",function(a){var b=a.currentTarget,c=ae,d=100>c?100-c:100;a=(Xd+"&cstart="+(Zd+c)+"&pagesize="+d).replace(/([?&])&+/g,"$1");Sd(0);b.disabled=!0;Qb(a,"json=1",function(e,f){b.disabled=!1;try{var h=200==e&&JSON.parse(f)}catch(m){}if(h&&"object"==typeof h){ae=c+=d;Sd(1);e=t("gsc_a_b");f=document.createElement(va.Y);f.innerHTML=""+h.B;f=Array.prototype.slice.call(f.rows);for(var k=0;k<f.length;k++)e.appendChild(f[k]);Vd();if(e=t("gsc_a_nn"))f=e.innerHTML.replace(/[0-9]+$/,""+
t("gsc_a_b").rows.length),e.innerHTML=f;b.disabled=!h.N}else Sd(2)})});P(["#gsc_fol_a","#gsc_fol_c","#gsc_fol_r"],"gs-change",de);P("#gsc_fol_m","input",de);P("#gsc_fol_f","submit",function(a){a.g&&a.g.preventDefault();a=t("gsc_fol_f");var b=t("gsc_fol_inp");b.innerHTML="";for(var c=be(tc),d=be(uc),e=0;e<c.length;e++)if(c[e]!=d[e]){var f=ee[e],h=document.createElement("input");h.type="hidden";h.name=c[e]?f:"un"+f;b.appendChild(h)}O("gsc-fol-submit",a)});P("#gsc_fol_f","gsc-fol-submit",function(a){a.currentTarget.submit()});
P("#gsc_md_hist","gs-md-lded",function(){var a=t("gsc_md_hist_c");if(!a.innerHTML){var b=document.getElementsByClassName("gsc_g_hist_wrp");1==b.length&&(a.appendChild(b[0].cloneNode(!0)),ge(a.lastChild))}});P(["#gsc_hist_opn",".gsc_md_hist_b"],"click",function(){var a=document.documentElement;!t("gsc_hist_opn")||p(a,"gs_el_ph")||p(a,"gs_el_ta")||R("gsc_md_hist")});
P("#gsc_lwp_mndt_lnk","click",function(a){var b=a.currentTarget.getAttribute("href")+"&tzom="+(new Date).getTimezoneOffset();window.location.assign(b);a.g.preventDefault()});P("#gsc_prf_btne","click",function(){var a=t("gsc_md_pro-d");a.setAttribute("data-ifc","");R(a.id,fb({t:"gsc_md_pro_ed"}))});P("#gsc_prf_btnf","click",function(){R("gsc_md_fol")});P("#gsc_md_fol_pub","click",function(){t("gsc_fol_mpf").submit()});P("#gsc_prf_iv_tg","click",function(){q(t("gsc_prf_w"),"gsc_prf_why")});
P(".gsc_prf_pel",["click","keydown"],function(a){("keydown"!=a.type||13==a.g.keyCode&&a.g&&!Oa(a.g))&&he()});P("#gsc_prf_pufii","change",function(){t("gsc_prf_puf").submit()});P(".gsc_prf_tab","click",function(a){var b=t("gsc_bdy");b.setAttribute("data-tab",a.currentTarget.id);b=b.querySelectorAll(".gsc_prf_tab");for(var c=0;c<b.length;c++){var d=b[c];d.setAttribute("aria-selected",""+(d==a.currentTarget))}});D(function(){Ac.add(ie);ie()});
P("#gsc_md_cbyd","gs-md-ldin",function(){var a=t("gsc_md_cbyd_merge");a&&(a.disabled=!0);Aa("")});P("#gsc_md_cbyd","gs-md-lded",function(){var a=t("gsc_md_cbyd_f"),b=t("gsc_md_cbyd_merge"),c=Fc,d=lb(c).s||"";c=kb(c).c||"";a.elements.s.value=d;Aa(c);b&&a.elements.choose&&(b.disabled=!1,b.getBoundingClientRect().bottom<window.innerHeight&&b.focus())});
P("#gsc_md_cbym",["gs-md-ldin","gs-md-lded"],function(){var a=lb(Fc).s||"",b=t("gsc_md_cbym_e");b&&a&&0>a.indexOf("&")&&b.setAttribute("data-href",(b.getAttribute("data-href")||"").replace(/(&citation_for_view=)[^&]*/,"$1"+a))});P("#gsc_md_cbym_e","click",function(a){a=a.currentTarget.getAttribute("data-href")||"";R("gs_md_cita-d",a)});Ub(Fd,Gd);D(function(){return setTimeout(Vd,0)});P(".gsc_a_x","change",Vd);
P("#gsc_x_all","gs-change",function(a){a=tc(a.currentTarget);for(var b=2==a?Wd:Td(),c=b.length;c--;)b[c].checked=0!=a;Ud()});P(".gsc_a_acm","click",function(a){L(a);var b=a.currentTarget;a=b.href;var c=b.getAttribute("data-eid")||"";b=b.getAttribute("data-eud")||"";a=t("gsc_md_cbyd_f").action+"&update_op=merge_options&s="+(b+","+c)+fb({c:a});R("gsc_md_cbyd",a)});
P(".gsc_a_am","click",function(a){a=a.currentTarget.getAttribute("data-eid")||"";a=(t("gsc_md_cbym_l").getAttribute("data-act")||"")+"&update_op=merge_options&s="+a;R("gsc_md_cbym",a)});P("#gs_sth","gs-sth-change",function(a){var b=t("gsc_a_tr0"),c=t("gsc_a_trh"),d=b.querySelector(".gsc_a_t"),e=c.querySelector(".gsc_a_t");p(a.currentTarget,"gs_sth_vis")?(e.style.width=d.offsetWidth+"px",b.style.height=c.offsetHeight+"px"):e.style.width=b.style.height="auto"});
P("#gs_md_cita-b-save","click",function(){var a=t("gsc_ecd_form");za(a,"continue").value=window.location.pathname+window.location.search;O("submit",a)});P(".gsc_ecd_form_tsel","click",function(a){var b=t("gsc_ecd_table"),c=za(t("gsc_ecd_form"),"articletype");a=a.currentTarget;c.value=a.getAttribute("data-type")||"";b.className=a.getAttribute("data-class")||"";b=document.querySelectorAll("#gsc_ecd_citation_type button");for(c=b.length;c--;)q(b[c],"gs_sel",b[c]==a)});
}({"customAC":2,"eventId":"xpEyYfL6JcX_mQGOg4WwDQ"});</script></head><body><div id="gs_top" onclick=""><style>#gs_md_s,.gs_md_wnw{z-index:1200;position:fixed;top:0;left:0;width:100%;height:100%;visibility:hidden;}#gs_md_s{background-color:#fff;opacity:.5;}.gs_el_ta #gs_md_s,.gs_el_ph #gs_md_s{background-color:#666;}.gs_md_wnw{transition:all 0s .218s;}#gs_md_s.gs_vis,.gs_md_wnw.gs_vis{visibility:visible;transition:all 0s;}.gs_md_wnw>.gs_md_d{position:relative;margin:0 auto;width:464px;box-shadow:2px 2px 8px rgba(0,0,0,.2);white-space:normal;}.gs_el_ta .gs_md_wnw>.gs_md_d,.gs_el_ph .gs_md_wnw>.gs_md_d{box-shadow:2px 2px 8px rgba(0,0,0,.65);}.gs_el_ph .gs_md_wnw>.gs_md_d{width:80%;max-width:440px;}.gs_el_ph .gs_md_wmw>.gs_md_d{width:100%;height:100%;max-width:none;border:none;box-shadow:none;transform:translate(0,100%);transform:translate(0,100vh);transition:transform .27s cubic-bezier(.4,0,.6,1),opacity 0s .27s,visibility 0s .27s,max-height 0s .27s;}.gs_el_ph .gs_md_wmw>.gs_md_d.gs_vis{transform:translate(0,0);transition:transform .3s cubic-bezier(0,0,.2,1);}.gs_md_wmw>.gs_md_d.gs_abt,.gs_el_ph .gs_md_wmw>.gs_md_d.gs_abt{transition:none;}.gs_md_hdr{display:flex;align-items:center;height:47px;border-bottom:1px solid #e0e0e0;border-bottom-color:rgba(0,0,0,.12);background-color:#f5f5f5;}.gs_md_hdr>a,.gs_md_hdr>a.gs_btn_lrge{flex:0 0 auto;width:41px;height:47px;}.gs_el_ph .gs_md_hdr>a{margin:0 2px 0 0;}.gs_el_ph a.gs_md_hdr_c{margin:0 0 0 2px;}.gs_md_hdr_b{margin:0 41px 0 16px;}.gs_el_ph .gs_md_hdr_b{margin:0 16px;}.gs_md_hdr_t:empty~.gs_md_hdr_b{margin-left:0;}.gs_md_hdr_b:empty{width:41px;margin:0;}.gs_el_ph .gs_md_hdr_b:empty{margin-right:2px;}.gs_md_hdr_b:empty:not(:last-child){display:none;}.gs_md_hdr_b>button{min-width:51px;height:33px;}.gs_md_hdr_t{flex:1 1 auto;font-size:18px;font-weight:normal;color:#666;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;text-align:center;}.gs_md_bdy{overflow-y:auto;box-sizing:border-box;padding:24px 41px 0 41px;}.gs_md_bdy:after{display:block;content:"";clear:both;padding-bottom:24px;}.gs_el_ph .gs_md_bdy{padding:16px 16px 0 16px;}.gs_el_ph .gs_md_bdy:after{padding-bottom:16px;}.gs_el_ph .gs_md_wmw .gs_md_bdy{position:absolute;width:100%;top:48px;bottom:0;}.gs_md_lbl{display:block;font-size:16px;margin:0 0 16px 0;word-wrap:break-word;}.gs_md_btns{margin:24px 0 0 0;white-space:nowrap;}.gs_el_ph .gs_md_btns{margin:16px 0 0 0;}.gs_md_btns button{margin-right:16px;}.gs_md_btns button:last-child{margin-right:0;}.gs_md_prg{margin:24px 0;text-align:center;}.gs_md_prg .gs_alrt{padding:4px 16px;}.gs_md_ldg:before{content:"";position:absolute;top:0;left:0;bottom:0;right:0;background-color:#fff;opacity:.5;z-index:100;}</style><div id="gs_md_ldg" style="display:none">Loading...</div><div id="gs_md_err" style="display:none">The system can't perform the operation now. Try again later.</div><div id="gs_md_s"></div><div data-h="0" class="gs_md_wnw"><div id="gsc_md_hist" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gsc_md_hist-t" data-wfc="gsc_md_hist-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_hist-x" role="button" aria-label="Cancel" data-mdx="gsc_md_hist" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_hist-t" class="gs_md_hdr_t">Citations per year</h2><div class="gs_md_hdr_b"></div></div><div id="gsc_md_hist-bdy" class="gs_md_bdy"><style>#gsc_md_hist{width:80%;max-width:386px;}#gsc_md_hist_c{position:relative;width:100%;}</style><div id="gsc_md_hist_c"></div></div></div></div><div data-h="600" class="gs_md_wnw gs_md_wmw"><div id="gsc_md_cbyd" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gsc_md_cbyd-t" data-cid="gsc_md_cbyd_l" data-wfc="gsc_md_cbyd-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_cbyd-x" role="button" aria-label="Cancel" data-mdx="gsc_md_cbyd" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_cbyd-t" class="gs_md_hdr_t">Duplicate citations</h2><div class="gs_md_hdr_b"></div></div><div id="gsc_md_cbyd-bdy" class="gs_md_bdy"><form id="gsc_md_cbyd_f" action="/citations?hl=en&amp;user=hNi1gxAAAAAJ&amp;view_op=list_works" method="post"><input type="hidden" name="s" value=""><div class="gs_md_lbl">The following articles are merged in Scholar. Their <a id="gsc_md_cbyd_c" href="javascript:void(0)">combined citations</a> are counted only for the first article.</div><div id="gsc_md_cbyd_l"></div></form></div></div></div><div data-h="600" class="gs_md_wnw gs_md_wmw"><div id="gsc_md_cbym" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gsc_md_cbym-t" data-cid="gsc_md_cbym_l" data-wfc="gsc_md_cbym-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_cbym-x" role="button" aria-label="Cancel" data-mdx="gsc_md_cbym" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_cbym-t" class="gs_md_hdr_t">Merged citations</h2><div class="gs_md_hdr_b"></div></div><div id="gsc_md_cbym-bdy" class="gs_md_bdy"><div class="gs_md_lbl">This "Cited by" count includes citations to the following articles in Scholar. The ones marked <span id="gsc_md_cbym_s">*</span> may be different from the article in the profile.</div><div id="gsc_md_cbym_l" data-act="/citations?hl=en&amp;user=hNi1gxAAAAAJ&amp;view_op=list_works"></div></div></div></div><div data-h="900" class="gs_md_wnw gs_md_wmw"><div id="gsc_md_cod" class="gs_md_d gs_ttzi gsc_cod_lc" role="dialog" tabindex="-1" aria-labelledby="gsc_md_cod-t" data-cid="gsc_cods_res" data-wfc="gsc_md_cod-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_cod-x" role="button" aria-label="Cancel" data-mdx="gsc_md_cod" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_cod-t" class="gs_md_hdr_t"><span id="gsc_cod_t"><span id="gsc_cod_tadd">Add co-authors</span><span id="gsc_cod_tedit">Co-authors</span><a id="gsc_cod_trev" href="javascript:void(0)" data-txt="Review" data-lim="Limit reached"></a></span></h2><div class="gs_md_hdr_b"><button type="button" id="gsc_cod_done" aria-label="Add co-authors" disabled="" class="gs_btnDNW gs_in_ib gs_btn_act gs_btn_half gs_btn_lsb"><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl"></span></span></button></div></div><div id="gsc_md_cod-bdy" class="gs_md_bdy"><div id="gsc_cods_urls" class="gsc_cods_hide" data-ls="" data-lc="/citations?view_op=list_colleagues&amp;hl=en&amp;json=&amp;user=hNi1gxAAAAAJ" data-sa=""></div><form id="gsc_cods_save" action="" method="POST"><input type="hidden" name="colleague_add"><input type="hidden" name="colleague_del"></form><div id="gsc_cods_res"></div></div></div></div><div data-h="800" class="gs_md_wnw gs_md_wmw"><div id="gs_md_cita-d" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gs_md_cita-d-t" data-cid="gs_md_cita-l" data-wfc="gs_md_cita-d-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gs_md_cita-d-x" role="button" aria-label="Cancel" data-mdx="gs_md_cita-d" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gs_md_cita-d-t" class="gs_md_hdr_t"></h2><div class="gs_md_hdr_b"><button type="button" id="gs_md_cita-b-save" aria-label="Save" class="gs_btnDNW gs_in_ib gs_btn_act gs_btn_half gs_btn_lsb"><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl"></span></span></button></div></div><div id="gs_md_cita-d-bdy" class="gs_md_bdy"><style>#gs_md_cita-d{width:90%;max-width:1000px;}.gs_el_ph #gs_md_cita-d{width:100%;max-width:none;}#gs_md_cita-d .gs_md_prg{min-height:600px;}</style><div id="gs_md_cita-l" aria-live="assertive"></div></div></div></div><div data-h="0" class="gs_md_wnw gs_md_wmw"><div id="gsc_md_fol" class="gs_md_d gs_ttzi" role="dialog" tabindex="-1" aria-labelledby="gsc_md_fol-t" data-wfc="gsc_md_fol-x"><div class="gs_md_hdr"><a href="javascript:void(0)" id="gsc_md_fol-x" role="button" aria-label="Cancel" data-mdx="gsc_md_fol" class="gs_btnCLS gs_md_x gs_md_hdr_c gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><h2 id="gsc_md_fol-t" class="gs_md_hdr_t">Follow this author</h2><div class="gs_md_hdr_b"></div></div><div id="gsc_md_fol-bdy" class="gs_md_bdy"><form method="post" id="gsc_fol_f" action="/citations?hl=en&amp;user=hNi1gxAAAAAJ&amp;view_op=list_works"><input type="hidden" name="xsrf" value="AMD79ooAAAAAYTPjRrCSwQLE6gzB5ZxrOjXzvbHbjuoL"><input type="hidden" name="user" value="hNi1gxAAAAAJ"><div id="gsc_fol_inp"></div><div id="gsc_fol_cb"><div class="gsc_fol_cr"><a href="javascript:void(0)" id="gsc_fol_a" role="checkbox" aria-checked="false" data-s="0" class="gs_cb_gen gs_in_cb"><span class="gs_lbl">New articles by this author</span><span class="gs_chk"></span><span class="gs_cbx"></span></a></div><div class="gsc_fol_cr"><a href="javascript:void(0)" id="gsc_fol_c" role="checkbox" aria-checked="false" data-s="0" class="gs_cb_gen gs_in_cb"><span class="gs_lbl">New citations to this author</span><span class="gs_chk"></span><span class="gs_cbx"></span></a></div><div class="gsc_fol_cr"><a href="javascript:void(0)" id="gsc_fol_r" role="checkbox" aria-checked="false" data-s="0" class="gs_cb_gen gs_in_cb"><span class="gs_lbl">New articles related to this author's research</span><span class="gs_chk"></span><span class="gs_cbx"></span></a></div></div><div id="gsc_fol_email"><label id="gsc_fol_ml" for="gsc_fol_m">Email address for updates</label><div class="gs_in_txtw gs_in_txtb"><input type="text" class="gs_in_txt" name="email_for_op" value="" id="gsc_fol_m" maxlength="100" autocapitalize="off" autocorrect="off"></div></div><div class="gs_md_btns"><button type="submit" id="gsc_fol_b" disabled="" class=" gs_btn_act gs_btn_lrge gs_btn_lsu"><span class="gs_wr"><span class="gs_lbl">Done</span></span></button></div></form></div></div></div><!--[if lte IE 9]><div class="gs_alrt" style="padding:16px"><div>Sorry, some features may not work in this version of Internet Explorer.</div><div>Please use <a href="//www.google.com/chrome/">Google Chrome</a> or <a href="//www.mozilla.com/firefox/">Mozilla Firefox</a> for the best experience.</div></div><![endif]--><div id="gs_hdr_drs"></div><div id="gs_hdr_drw" class="gs_md_ulr" role="dialog" tabindex="-1" data-shd="gs_hdr_drs" data-wfc="gs_hdr_drw_mnu" data-cfc="gs_hdr_mnu"><div id="gs_hdr_drw_in"><div id="gs_hdr_drw_top"><a href="javascript:void(0)" id="gs_hdr_drw_mnu" role="button" aria-controls="gs_hdr_drw" aria-label="Options" class="gs_btnMNT gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><a id="gs_hdr_drw_lgo" href="/schhp?hl=en" aria-label="Homepage"></a></div><div><div class="gs_hdr_drw_sec"><a href="/citations?hl=en" role="menuitem" class="gs_btnPRO gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">My profile</span></a><a href="/scholar?scilib=1&amp;hl=en" role="menuitem" class="gs_btnL gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">My library</span></a><a href="/citations?view_op=metrics_intro&amp;hl=en" role="menuitem" class="gs_btnJ gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">Metrics</span></a><a href="/scholar_alerts?view_op=list_alerts&amp;hl=en" role="menuitem" class="gs_btnM gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">Alerts</span></a></div><div class="gs_hdr_drw_sec"><a href="/scholar_settings?hl=en" role="menuitem" class="gs_btnP gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">Settings</span></a></div></div><div id="gs_hdr_drw_bot" class="gs_hdr_drw_sec"><a href="https://accounts.google.com/Login?hl=en&amp;continue=https://scholar.google.com/schhp%3Fhl%3Den" class=" gs_in_ib gs_md_li gs_md_lix gs_in_gray"><span class="gs_ico"></span><span class="gs_lbl">Sign in</span></a></div></div></div><div id="gs_hdr" role="banner" class="gs_hdr_src"><a href="javascript:void(0)" id="gs_hdr_mnu" role="button" aria-controls="gs_hdr_drw" class="gs_btnMNT gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><a id="gs_hdr_lgo" class="" href="/schhp?hl=en" aria-label="Homepage"></a><div id="gs_hdr_md"><div id="gs_hdr_srch"><form id="gs_hdr_frm" action="/citations"><input type="hidden" name="view_op" value="search_authors"><input type="hidden" name="hl" value="en"><div class="gs_in_txtw gs_in_txtb"><input type="text" class="gs_in_txt" name="mauthors" value="" id="gs_hdr_tsi" placeholder="Search profiles" size="50" maxlength="2048" autocapitalize="off" aria-label="Search"></div><span id="gs_hdr_tsc"><span class="gs_ico gs_ico_X"></span></span><button type="submit" id="gs_hdr_tsb" name="btnG" aria-label="Search" class="gs_btnG gs_in_ib gs_btn_act gs_btn_half gs_btn_lsb"><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl"></span></span></button></form></div></div><a href="javascript:void(0)" id="gs_hdr_sre" role="button" aria-controls="gs_hdr_frm" aria-label="Search" class="gs_btnTSB gs_in_ib gs_btn_lrge"><span class="gs_ico"></span><span class="gs_lbl"></span></a><div id="gs_hdr_act"><a id="gs_hdr_act_s" href="https://accounts.google.com/Login?hl=en&amp;continue=https://scholar.google.com/schhp%3Fhl%3Den">Sign in</a></div></div><style>#gs_alrt{position:fixed;bottom:48px;left:16px;max-width:384px;z-index:1250;display:flex;justify-content:space-between;align-items:center;font-size:13px;line-height:16px;color:#e2e2e2;background:#333;text-align:left;border-radius:3px;box-shadow:0 3px 5px -1px rgba(0,0,0,.2),0 6px 10px 0 rgba(0,0,0,.14),0 1px 18px 0 rgba(0,0,0,.12);visibility:hidden;transform-origin:center;transform:scale(0.8,0.8) translate(0,100%);}.gs_el_ph #gs_alrt{bottom:0;left:0;width:100%;max-width:none;border-radius:0;box-shadow:none;transform:scale(1,1) translate(0,100%);}#gs_alrt.gs_vis{visibility:visible;transform:scale(1,1) translate(0,0);}#gs_alrt.gs_anm{transition:transform .067s cubic-bezier(.4,0,1,1),visibility 0s .067s;}#gs_alrt.gs_vis.gs_anm{transition:transform .067s cubic-bezier(0,0,.2,1);}.gs_el_ph #gs_alrt.gs_anm{transition:transform .084s cubic-bezier(.4,0,1,1),visibility 0s .084s;}.gs_el_ph #gs_alrt.gs_vis.gs_anm{transition:transform .1s cubic-bezier(0,0,.2,1);}#gs_alrt_m{display:block;padding:16px;}#gs_alrt_l{display:block;padding:8px;margin:0 8px 0 -8px;border-radius:3px;color:#fcc934;text-transform:uppercase;text-decoration:none;}#gs_alrt_l:hover{background-color:rgba(255,255,255,.05)}#gs_alrt_l:active{background-color:rgba(255,255,255,.1)}#gs_alrt_l:empty{display:none}#gs_alrt_m a{padding:8px 0;color:#e2e2e2;text-decoration:underline;}#gs_alrt_m a:active{color:#f6aea9}</style><form action="" method="post" id="gs_alrt"><span id="gs_alrt_m"></span><span id="gs_alrt_h"></span><a id="gs_alrt_l" href="javascript:void(0)" class="gs_fm_s" data-fm="gs_alrt"></a></form><div id="gs_bdy"><div id="gs_bdy_sb" role="navigation"><div id="gs_bdy_sb_in"></div></div><div id="gs_bdy_ccl" role="main"><div id="gsc_bdy" class="gs_scl" data-tab="gsc_prf_t-art"><div class="gsc_rsb" role="navigation"><a id="gsc_rsb_gpl" class="gsc_rsb_s" href="/citations?hl=en">Get my own profile</a><div class="gsc_rsb_s gsc_prf_pnl" id="gsc_rsb_cit" role="region" aria-labelledby="gsc_prf_t-cit"><h3 class="gsc_rsb_header"><span class="gsc_rsb_title">Cited by</span><button type="button" id="gsc_hist_opn" class=" gs_btn_flat gs_btn_flact gs_btn_lrge gs_btn_half gs_btn_lsu gsc_rsb_action"><span class="gs_wr"><span class="gs_lbl">View all</span></span></button></h3><table id="gsc_rsb_st"><thead><tr><th class="gsc_rsb_sth"></th><th class="gsc_rsb_sth">All</th><th class="gsc_rsb_sth">Since 2016</th></tr></thead><tbody><tr><td class="gsc_rsb_sc1"><a href="javascript:void(0)" class="gsc_rsb_f gs_ibl" title="This is the number of citations to all publications. The second column has the &quot;recent&quot; version of this metric which is the number of new citations in the last 5 years to all publications.">Citations</a></td><td class="gsc_rsb_std">7779</td><td class="gsc_rsb_std">6725</td></tr><tr><td class="gsc_rsb_sc1"><a href="javascript:void(0)" class="gsc_rsb_f gs_ibl" title="h-index is the largest number h such that h publications have at least h citations. The second column has the &quot;recent&quot; version of this metric which is the largest number h such that h publications have at least h new citations in the last 5 years.">h-index</a></td><td class="gsc_rsb_std">45</td><td class="gsc_rsb_std">43</td></tr><tr><td class="gsc_rsb_sc1"><a href="javascript:void(0)" class="gsc_rsb_f gs_ibl" title="i10-index is the number of publications with at least 10 citations. The second column has the &quot;recent&quot; version of this metric which is the number of publications that have received at least 10 new citations in the last 5 years.">i10-index</a></td><td class="gsc_rsb_std">144</td><td class="gsc_rsb_std">131</td></tr></tbody></table><style>.gsc_g_t{position:absolute;bottom:0;color:#777;font-size:11px;}.gsc_g_a{position:absolute;bottom:13px;width:15px;background:#777;}.gsc_g_a:hover,.gsc_g_a:focus,.gsc_g_a:active{text-decoration:none;cursor:default;}.gsc_g_al{position:absolute;bottom:15px;left:7px;color:#222;background:white;font-size:11px;padding:1px;border:1px solid #777;border-radius:1px;visibility:hidden;opacity:0;transition:opacity .218s,visibility 0s .218s;}.gsc_g_a:hover .gsc_g_al,.gsc_g_a:focus .gsc_g_al,.gsc_g_a:active .gsc_g_al{visibility:visible;opacity:1;transition:all 0s;}#gsc_md_hist{max-width:550px;}.gsc_md_hist_w{position:relative;overflow:hidden;margin-right:43px;}.gs_md_bdy .gsc_md_hist_w,.gs_el_ph .gsc_md_hist_w,.gs_el_ta .gsc_md_hist_w{overflow-x:auto;padding-bottom:16px;}.gsc_md_hist_b{position:relative;height:174px;width:100%;}.gsc_md_hist_b .gsc_g_a{bottom:auto;}.gsc_md_hist_b .gsc_g_t{bottom:auto;top:161px;}.gsc_md_hist_b:after{position:absolute;right:504px;content:"\00A0";}.gsc_g_hist_x{position:relative;margin-right:45px;}.gsc_g_hist_xl{position:absolute;right:8px;width:35px;}.gs_el_ta .gsc_g_hist_xl,.gs_el_ph .gsc_g_hist_xl{right:16px;}.gsc_g_hist_wrp{padding-top:32px;position:relative;}.gs_el_ta .gsc_g_hist_wrp,.gs_el_ph .gsc_g_hist_wrp{padding-right:8px;}.gs_md_bdy .gsc_g_hist_wrp{border-top:0;}.gs_el_tc .gs_md_bdy .gsc_g_hist_wrp:after,.gs_el_tc.gs_el_ph .gsc_g_hist_wrp:after,.gs_el_tc.gs_el_ta .gsc_g_hist_wrp:after{display:block;content:"";position:absolute;z-index:100;top:0;left:0;width:20px;height:100%;background-image:linear-gradient(to left,rgba(255,255,255,0),rgba(255,255,255,1) 80%);}.gsc_g_x,.gsc_g_xt{position:absolute;left:0;border-bottom:1px solid #eee;width:100%;text-align:right;}.gsc_g_x{border-bottom:1px solid #eee;}.gsc_g_xtl{position:absolute;color:#777;}.gsc_g_gtr{position:absolute;}.gsc_g_a:last-child .gsc_g_al{right:0;left:auto;}</style><div class="gsc_g_hist_wrp" dir="rtl"><div class="gsc_g_hist_x"><div class="gsc_g_x" style="top:160px;"></div><div class="gsc_g_xt" style="top:0px;"></div><div class="gsc_g_xt" style="top:80px;"></div><div class="gsc_g_xt" style="top:120px;"></div><div class="gsc_g_xt" style="top:40px;"></div></div><div class="gsc_g_hist_xl"><div class="gsc_g_xtl" style="top:153px;">0</div><div class="gsc_g_xtl" style="top:-7px;">1700</div><div class="gsc_g_xtl" style="top:73px;">850</div><div class="gsc_g_xtl" style="top:113px;">425</div><div class="gsc_g_xtl" style="top:33px;">1275</div></div><div class="gsc_md_hist_w"><div class="gsc_md_hist_b"><span class="gsc_g_t" style="right:451px">2007</span><span class="gsc_g_t" style="right:419px">2008</span><span class="gsc_g_t" style="right:387px">2009</span><span class="gsc_g_t" style="right:355px">2010</span><span class="gsc_g_t" style="right:323px">2011</span><span class="gsc_g_t" style="right:291px">2012</span><span class="gsc_g_t" style="right:259px">2013</span><span class="gsc_g_t" style="right:227px">2014</span><span class="gsc_g_t" style="right:195px">2015</span><span class="gsc_g_t" style="right:163px">2016</span><span class="gsc_g_t" style="right:131px">2017</span><span class="gsc_g_t" style="right:99px">2018</span><span class="gsc_g_t" style="right:67px">2019</span><span class="gsc_g_t" style="right:35px">2020</span><span class="gsc_g_t" style="right:3px">2021</span><a href="javascript:void(0)" class="gsc_g_a" style="right:456px;top:158px;height:2px;z-index:15"><span class="gsc_g_al">29</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:424px;top:158px;height:2px;z-index:14"><span class="gsc_g_al">24</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:392px;top:158px;height:2px;z-index:13"><span class="gsc_g_al">28</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:360px;top:156px;height:4px;z-index:12"><span class="gsc_g_al">51</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:328px;top:155px;height:5px;z-index:11"><span class="gsc_g_al">63</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:296px;top:153px;height:7px;z-index:10"><span class="gsc_g_al">82</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:264px;top:151px;height:9px;z-index:9"><span class="gsc_g_al">104</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:232px;top:137px;height:23px;z-index:8"><span class="gsc_g_al">254</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:200px;top:130px;height:30px;z-index:7"><span class="gsc_g_al">327</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:168px;top:122px;height:38px;z-index:6"><span class="gsc_g_al">414</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:136px;top:96px;height:64px;z-index:5"><span class="gsc_g_al">680</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:104px;top:55px;height:105px;z-index:4"><span class="gsc_g_al">1116</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:72px;top:32px;height:128px;z-index:3"><span class="gsc_g_al">1360</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:40px;top:4px;height:156px;z-index:2"><span class="gsc_g_al">1659</span></a><a href="javascript:void(0)" class="gsc_g_a" style="right:8px;top:21px;height:139px;z-index:1"><span class="gsc_g_al">1478</span></a></div></div></div></div><div class="gsc_rsb_s gsc_prf_pnl" id="gsc_rsb_mnd" role="region" aria-labelledby="gsc_prf_t-mnd"><div class="gsc_rsb_header gsc_rsb_m_header"><div class="gsc_rsb_m_title">Public access</div><a href="/citations?view_op=list_mandates&amp;hl=en&amp;user=hNi1gxAAAAAJ" id="gsc_lwp_mndt_lnk">View all</a></div><div class="gsc_rsb_hm gs_ota gs_oph"><button type="button" onclick="window.location='/citations?view_op\x3dlist_mandates\x26hl\x3den\x26user\x3dhNi1gxAAAAAJ'" class=" gs_btn_flat gs_btn_flact gs_btn_lrge gs_btn_half gs_btn_lsu"><span class="gs_wr"><span class="gs_lbl">View all</span></span></button></div><div class="gsc_rsb_m"><div class="gsc_rsb_m_a"><span>92 articles</span></div><div class="gsc_rsb_m_na"><div>17 articles</div></div><div class="gsc_rsb_m_bar"><div class="gsc_rsb_m_bar_na" style="width:16%"></div></div><div class="gsc_rsb_m_a"><span>available</span></div><div class="gsc_rsb_m_na"><span>not available</span></div><div class="gsc_rsb_m_desc">Based on funding mandates</div></div></div></div><div class="gsc_lcl" role="main" id="gsc_prf_w"><div id="gsc_prf"><button type="button" id="gsc_prf_btnf" class="gs_btnMW gs_in_ib gs_btn_act gs_btn_lsu gs_btn_mph"><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl">Follow</span></span></button><div id="gsc_prf_pu"><div id="gsc_prf_pua" class="gs_rimg"><style>#gsc_prf_pup-img{width:128px;height:114px;}@media print{#gs_top #gsc_prf_pup-img{width:80pt;height:71pt;}}</style><img alt="Jungong Han" sizes="print 80px,128px" src="https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=hNi1gxAAAAAJ&amp;citpid=1" id="gsc_prf_pup-img" srcset="https://scholar.googleusercontent.com/citations?view_op=view_photo&amp;user=hNi1gxAAAAAJ&amp;citpid=1 128w,https://scholar.googleusercontent.com/citations?view_op=medium_photo&amp;user=hNi1gxAAAAAJ&amp;citpid=1 174w"></div></div><div id="gsc_prf_i"><div id="gsc_prf_in">Jungong Han</div><div class="gsc_prf_il">Professor and Chair in Computer Science, <a href="/citations?view_op=view_org&amp;hl=en&amp;org=5570769680569323558" class="gsc_prf_ila">Aberystwyth University</a>, UK</div><div class="gsc_prf_il" id="gsc_prf_ivh">Verified email at aber.ac.uk - <a href="https://sites.google.com/site/jungonghan77/" rel="nofollow" class="gsc_prf_ila">Homepage</a></div><div class="gsc_prf_il" id="gsc_prf_int"><a href="/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:video_analytics" class="gsc_prf_inta gs_ibl">Video Analytics</a><a href="/citations?view_op=search_authors&amp;hl=en&amp;mauthors=label:computer_vision" class="gsc_prf_inta gs_ibl">Computer Vision</a></div></div></div></div><div id="gsc_prf_t_wrp" role="navigation"><div id="gsc_prf_t" role="tablist"><a id="gsc_prf_t-art" class="gsc_prf_tab" href="javascript:void(0)" role="tab" aria-controls="gsc_art" aria-selected="true">Articles</a><a id="gsc_prf_t-cit" class="gsc_prf_tab" href="javascript:void(0)" role="tab" aria-controls="gsc_rsb_cit">Cited by</a><a id="gsc_prf_t-mnd" class="gsc_prf_tab" href="javascript:void(0)" role="tab" aria-controls="gsc_rsb_mnd">Public access</a></div></div><div class="gsc_lcl gsc_prf_pnl" id="gsc_art" role="region" aria-labelledby="gsc_prf_t-art"><form method="post" action="/citations?hl=en&amp;user=hNi1gxAAAAAJ&amp;view_op=list_works"><input type="hidden" name="xsrf" value="AMD79ooAAAAAYTPjRrCSwQLE6gzB5ZxrOjXzvbHbjuoL"><div id="gsc_a_tw"><table id="gsc_a_t"><thead><tr id="gsc_a_tr0" aria-hidden="true"><th class="gsc_a_t"></th><th class="gsc_a_c"></th><th class="gsc_a_y"></th></tr><tr id="gsc_a_trh"><th class="gsc_a_t" scope="col"><span id="gsc_a_ta"><a href="/citations?hl=en&amp;user=hNi1gxAAAAAJ&amp;view_op=list_works&amp;sortby=title" class="gsc_a_a">Title</a></span><div id="gsc_dd_sort-r" class="gs_md_r gs_md_rmb gs_md_rmbl"><button type="button" id="gsc_dd_sort-b" aria-controls="gsc_dd_sort-d" aria-haspopup="true" ontouchstart="gs_evt_dsp(event)" class=" gs_in_se gs_btn_mnu gs_btn_flat gs_btn_lrge gs_btn_half gs_btn_lsu gs_press gs_md_tb"><span class="gs_wr"><span class="gs_lbl">Sort</span><span class="gs_icm"></span></span></button><div id="gsc_dd_sort-d" class="gs_md_d gs_md_ulr" role="menu" tabindex="-1"><div id="gsc_dd_sort-s" class="gs_oph gsc_dd_sec gsc_dd_sep"><a role="menuitem" href="/citations?hl=en&amp;user=hNi1gxAAAAAJ&amp;view_op=list_works" tabindex="-1" class="gs_md_li gsc_dd_sort-sel">Sort by citations</a><a role="menuitem" href="/citations?hl=en&amp;user=hNi1gxAAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" tabindex="-1" class="gs_md_li">Sort by year</a><a role="menuitem" href="/citations?hl=en&amp;user=hNi1gxAAAAAJ&amp;view_op=list_works&amp;sortby=title" tabindex="-1" class="gs_md_li">Sort by title</a></div></div></div></th><th class="gsc_a_c" scope="col" dir="rtl"><span id="gsc_a_ca"><div class="gs_nph">Cited by</div><div class="gs_oph">Cited by</div></span></th><th class="gsc_a_y" scope="col"><span class="gsc_a_h" id="gsc_a_ha"><a href="/citations?hl=en&amp;user=hNi1gxAAAAAJ&amp;view_op=list_works&amp;sortby=pubdate" class="gsc_a_a">Year</a></span></th></tr></thead><tbody id="gsc_a_b"><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:_xSYboBqXhAC" class="gsc_a_at">Enhanced computer vision with microsoft kinect sensor: A review</a><div class="gs_gray">J Han, L Shao, D Xu, J Shotton</div><div class="gs_gray">IEEE transactions on cybernetics 43 (5), 1318-1334<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6646555533058724062,8609547787945380793,9117759040284240431" class="gsc_a_ac gs_ibl">1706</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:hMsQuOkrut0C" class="gsc_a_at">Gabor convolutional networks</a><div class="gs_gray">S Luan, C Chen, B Zhang, J Han, J Liu</div><div class="gs_gray">IEEE Transactions on Image Processing 27 (9), 4357-4366<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16973401618714958804" class="gsc_a_ac gs_ibl">218</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:kuK5TVdYjLIC" class="gsc_a_at">Sparse representation based multi-sensor image fusion for multi-focus and multi-modality images: A review</a><div class="gs_gray">Q Zhang, Y Liu, RS Blum, J Han, D Tao</div><div class="gs_gray">Information Fusion 40, 57-75<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10387914111904388056" class="gsc_a_ac gs_ibl">210</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:2osOgNQ5qMEC" class="gsc_a_at">Automatic video-based human motion analyzer for consumer surveillance system</a><div class="gs_gray">W Lao, J Han</div><div class="gs_gray">IEEE Transactions on Consumer Electronics 55 (2), 591-598<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14605673646397263309" class="gsc_a_ac gs_ibl">151</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:N5tVd3kTz84C" class="gsc_a_at">Cosaliency detection based on intrasaliency prior transfer and deep intersaliency mining</a><div class="gs_gray">D Zhang, J Han, J Han, L Shao</div><div class="gs_gray">IEEE transactions on neural networks and learning systems 27 (6), 1163-1176<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1520934723336271902" class="gsc_a_ac gs_ibl">149</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:W5xh706n7nkC" class="gsc_a_at">RGB-D datasets using microsoft kinect or similar sensors: a survey</a><div class="gs_gray">Z Cai, J Han, L Liu, L Shao</div><div class="gs_gray">Multimedia Tools and Applications 76 (3), 4313-4355<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10271559152382051902" class="gsc_a_ac gs_ibl">126</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:fEOibwPWpKIC" class="gsc_a_at">Cross-view retrieval via probability-based semantics-preserving hashing</a><div class="gs_gray">Z Lin, G Ding, J Han, J Wang</div><div class="gs_gray">IEEE transactions on cybernetics 47 (12), 4342-4355<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14356554712956146699" class="gsc_a_ac gs_ibl">125</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:b1wdh0AR-JQC" class="gsc_a_at">Action recognition using 3D histograms of texture and a multi-class boosting classifier</a><div class="gs_gray">B Zhang, Y Yang, C Chen, L Yang, J Han, L Shao</div><div class="gs_gray">IEEE Transactions on Image processing 26 (10), 4648-4660<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13940924153702532076" class="gsc_a_ac gs_ibl">123</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:XiVPGOgt02cC" class="gsc_a_at">Employing a RGB-D sensor for real-time tracking of humans across multiple re-entries in a smart environment</a><div class="gs_gray">J Han, EJ Pauwels, PM de Zeeuw, PHN de With</div><div class="gs_gray">IEEE Transactions on Consumer Electronics 58 (2), 255-263<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=466974632814593542" class="gsc_a_ac gs_ibl">118</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:ILKRHgRFtOwC" class="gsc_a_at">From zero-shot learning to conventional supervised classification: Unseen visual data synthesis</a><div class="gs_gray">Y Long, L Liu, L Shao, F Shen, G Ding, J Han</div><div class="gs_gray">Proceedings of the IEEE Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14865160090709677242,8667940373733095313" class="gsc_a_ac gs_ibl">115</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:uDGL6kOW6j0C" class="gsc_a_at">Acnet: Strengthening the kernel skeletons for powerful cnn via asymmetric convolution blocks</a><div class="gs_gray">X Ding, Y Guo, G Ding, J Han</div><div class="gs_gray">Proceedings of the IEEE/CVF International Conference on Computer Vision&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5275895745266096976" class="gsc_a_ac gs_ibl">113</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:IjCSPb-OGe4C" class="gsc_a_at">Video-based fall detection in the home using principal component analysis</a><div class="gs_gray">L Hazelhoff, J Han</div><div class="gs_gray">International Conference on Advanced Concepts for Intelligent Vision Systems&nbsp;…<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2249861274444101555,11273143802557200824,11409201614646402104" class="gsc_a_ac gs_ibl">102</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:L7CI7m0gUJcC" class="gsc_a_at">Zero-shot learning with transferred samples</a><div class="gs_gray">Y Guo, G Ding, J Han, Y Gao</div><div class="gs_gray">IEEE Transactions on Image Processing 26 (7), 3277-3290<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17721309492018472245" class="gsc_a_ac gs_ibl">94</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:epqYDVWIO7EC" class="gsc_a_at">Learning to hash with optimized anchor embedding for scalable retrieval</a><div class="gs_gray">Y Guo, G Ding, L Liu, J Han, L Shao</div><div class="gs_gray">IEEE Transactions on Image Processing 26 (3), 1344-1354<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11067615487873316674" class="gsc_a_ac gs_ibl">86</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:u5HHmVD_uO8C" class="gsc_a_at">Fast camera calibration for the analysis of sport sequences</a><div class="gs_gray">D Farin, J Han, PHN de With</div><div class="gs_gray">2005 IEEE International Conference on Multimedia and Expo, 4 pp.<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6509738103249216303" class="gsc_a_ac gs_ibl">82</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:ns9cj8rnVeAC" class="gsc_a_at">Visible and infrared image registration in man-made environments employing hybrid visual features</a><div class="gs_gray">J Han, EJ Pauwels, P De Zeeuw</div><div class="gs_gray">Pattern Recognition Letters 34 (1), 42-51<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13466452411173483881" class="gsc_a_ac gs_ibl">79</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:uVUOdF_882EC" class="gsc_a_at">Unsupervised deep video hashing via balanced code for large-scale video retrieval</a><div class="gs_gray">G Wu, J Han, Y Guo, L Liu, G Ding, Q Ni, L Shao</div><div class="gs_gray">IEEE Transactions on Image Processing 28 (4), 1993-2007<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10125732539209212433" class="gsc_a_ac gs_ibl">78</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:kh2fBNsKQNwC" class="gsc_a_at">Automatic modulation classification based on deep learning for unmanned aerial vehicles</a><div class="gs_gray">D Zhang, W Ding, B Zhang, C Xie, H Li, C Liu, J Han</div><div class="gs_gray">Sensors 18 (3), 924<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14632417544211988681" class="gsc_a_ac gs_ibl">76</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:_OXeSy2IsFwC" class="gsc_a_at">Centripetal sgd for pruning very deep convolutional networks with complicated structure</a><div class="gs_gray">X Ding, G Ding, Y Guo, J Han</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17050571465031021795" class="gsc_a_ac gs_ibl">75</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;citation_for_view=hNi1gxAAAAAJ:LI9QrySNdTsC" class="gsc_a_at">Dynamic multi-view hashing for online image retrieval</a><div class="gs_gray">L Xie, J Shen, J Han, L Zhu, L Shao</div><div class="gs_gray">IJCAI<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15192445470217290767" class="gsc_a_ac gs_ibl">75</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:D03iK_w7-QYC" class="gsc_a_at">Fast saliency-aware multi-modality image fusion</a><div class="gs_gray">J Han, EJ Pauwels, P De Zeeuw</div><div class="gs_gray">Neurocomputing 111, 70-80<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12169250159653956728" class="gsc_a_ac gs_ibl">74</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:Tyk-4Ss8FVUC" class="gsc_a_at">Broadcast court-net sports video analysis using fast 3-D camera modeling</a><div class="gs_gray">J Han, D Farin, PHN de With</div><div class="gs_gray">Circuits and Systems for Video Technology, IEEE Transactions on 18 (11&nbsp;…<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15887547092360921103,11127014162870599499,15357159084766455896" class="gsc_a_ac gs_ibl">73</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="hNi1gxAAAAAJ:Tyk-4Ss8FVUC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:Ug5p-4gJ2f0C" class="gsc_a_at">End-to-end video background subtraction with 3d convolutional neural networks</a><div class="gs_gray">D Sakkos, H Liu, J Han, L Shao</div><div class="gs_gray">Multimedia Tools and Applications 77 (17), 23023-23041<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4877862969151909361" class="gsc_a_ac gs_ibl">70</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:z_wVstp3MssC" class="gsc_a_at">Sequential discrete hashing for scalable cross-modality similarity retrieval</a><div class="gs_gray">L Liu, Z Lin, L Shao, F Shen, G Ding, J Han</div><div class="gs_gray">IEEE Transactions on Image Processing 26 (1), 107-118<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6356232235309604542" class="gsc_a_ac gs_ibl">70</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:ZfRJV9d4-WMC" class="gsc_a_at">3D Action Recognition Using Multi-Temporal Depth Motion Maps and Fisher Vector.</a><div class="gs_gray">C Chen, M Liu, B Zhang, J Han, J Jiang, H Liu</div><div class="gs_gray">IJCAI, 3331-3337<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12627130225936962393" class="gsc_a_ac gs_ibl">69</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:FAceZFleit8C" class="gsc_a_at">Memory attention networks for skeleton-based action recognition</a><div class="gs_gray">C Li, C Xie, B Zhang, J Han, X Zhen, J Chen</div><div class="gs_gray">IEEE Transactions on Neural Networks and Learning Systems<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10384940257546257238" class="gsc_a_ac gs_ibl">64</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:k8Z6L05lTy4C" class="gsc_a_at">Approximating discrete probability distribution of image emotions by multi-modal features fusion</a><div class="gs_gray">S Zhao, G Ding, Y Gao, J Han</div><div class="gs_gray">Transfer 1000 (1), 4669-4675<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17437406396935281864" class="gsc_a_ac gs_ibl">63</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:GnPB-g6toBAC" class="gsc_a_at">Flexible human behavior analysis framework for video surveillance applications</a><div class="gs_gray">W Lao, J Han</div><div class="gs_gray">International Journal of Digital Multimedia Broadcasting 2010<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16610468014265166412,3094527688487826137,12784742564454112128,9594790513233963945" class="gsc_a_ac gs_ibl">61</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="hNi1gxAAAAAJ:GnPB-g6toBAC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:lgwcVrK6X84C" class="gsc_a_at">Global sparse momentum sgd for pruning very deep neural networks</a><div class="gs_gray">X Ding, G Ding, X Zhou, Y Guo, J Han, J Liu</div><div class="gs_gray">arXiv preprint arXiv:1909.12778<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17035988967323546960" class="gsc_a_ac gs_ibl">58</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:hCrLmN-GePgC" class="gsc_a_at">Auto-balanced filter pruning for efficient convolutional neural networks</a><div class="gs_gray">X Ding, G Ding, J Han, S Tang</div><div class="gs_gray">Proceedings of the AAAI Conference on Artificial Intelligence 32 (1)<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5821589767300582034" class="gsc_a_ac gs_ibl">58</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:9vf0nzSNQJEC" class="gsc_a_at">Learning computational models of video memorability from fMRI brain imaging</a><div class="gs_gray">J Han, C Chen, L Shao, X Hu, J Han, T Liu</div><div class="gs_gray">IEEE transactions on cybernetics 45 (8), 1692-1703<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1139573566836392500" class="gsc_a_ac gs_ibl">58</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:Aul-kAQHnToC" class="gsc_a_at">Synthesizing samples fro zero-shot learning</a><div class="gs_gray">Y Guo, G Ding, J Han, Y Gao</div><div class="gs_gray">IJCAI<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6012005357779544414" class="gsc_a_ac gs_ibl">57</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:4JMBOYKVnBMC" class="gsc_a_at">A mixed-reality system for broadcasting sports video to mobile devices</a><div class="gs_gray">J Han, D Farin, P de With</div><div class="gs_gray">IEEE MultiMedia 18 (2), 72-84<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15708195300917612294,139264950173129858" class="gsc_a_ac gs_ibl">56</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="hNi1gxAAAAAJ:4JMBOYKVnBMC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:w0F2JDEymm0C" class="gsc_a_at">Reference based LSTM for image captioning</a><div class="gs_gray">M Chen, G Ding, S Zhao, H Chen, Q Liu, J Han</div><div class="gs_gray">Thirty-first AAAI conference on artificial intelligence<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11609682963394047413" class="gsc_a_ac gs_ibl">55</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:foquWX3nUaYC" class="gsc_a_at">Computer vision and machine learning with RGB-D sensors</a><div class="gs_gray">L Shao, J Han, P Kohli, Z Zhang</div><div class="gs_gray">Springer<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9385441738571004077" class="gsc_a_ac gs_ibl">55</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:lmc2jWPfTJgC" class="gsc_a_at">LLE score: A new filter-based unsupervised feature selection method based on nonlinear manifold embedding and its application to image recognition</a><div class="gs_gray">C Yao, YF Liu, B Jiang, J Han, J Han</div><div class="gs_gray">IEEE Transactions on Image Processing 26 (11), 5257-5269<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2957962255646025949" class="gsc_a_ac gs_ibl">53</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:artPoR2Yc-kC" class="gsc_a_at">Approximated oracle filter pruning for destructive cnn width optimization</a><div class="gs_gray">X Ding, G Ding, Y Guo, J Han, C Yan</div><div class="gs_gray">International Conference on Machine Learning, 1607-1616<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=979238780615518812" class="gsc_a_ac gs_ibl">51</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:F2UWTTQJPOcC" class="gsc_a_at">Robust quantization for general similarity search</a><div class="gs_gray">Y Guo, G Ding, J Han</div><div class="gs_gray">IEEE Transactions on Image Processing 27 (2), 949-963<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16384191123308278048" class="gsc_a_ac gs_ibl">51</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:pAkWuXOU-OoC" class="gsc_a_at">Joint image-text hashing for fast large-scale cross-media retrieval using self-supervised deep learning</a><div class="gs_gray">G Wu, J Han, Z Lin, G Ding, B Zhang, Q Ni</div><div class="gs_gray">IEEE Transactions on Industrial Electronics 66 (12), 9868-9877<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14758327594078441322" class="gsc_a_ac gs_ibl">49</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:VN7nJs4JPk0C" class="gsc_a_at">Unsupervised Deep Hashing via Binary Latent Factor Models for Large-scale Cross-modal Retrieval.</a><div class="gs_gray">G Wu, Z Lin, J Han, L Liu, G Ding, B Zhang, J Shen</div><div class="gs_gray">IJCAI, 2854-2860<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15724380073410864234" class="gsc_a_ac gs_ibl">48</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:Dip1O2bNi0gC" class="gsc_a_at">Latent constrained correlation filter</a><div class="gs_gray">B Zhang, S Luan, C Chen, J Han, W Wang, A Perina, L Shao</div><div class="gs_gray">IEEE Transactions on Image Processing 27 (3), 1038-1048<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7586941642750114468" class="gsc_a_ac gs_ibl">47</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:rmuvC79q63oC" class="gsc_a_at">Attribute-guided network for cross-modal zero-shot hashing</a><div class="gs_gray">Z Ji, Y Sun, Y Yu, Y Pang, J Han</div><div class="gs_gray">IEEE transactions on neural networks and learning systems 31 (1), 321-330<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8157117275601443093" class="gsc_a_ac gs_ibl">46</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:_axFR9aDTf0C" class="gsc_a_at">One-two-one networks for compression artifacts reduction in remote sensing</a><div class="gs_gray">B Zhang, J Gu, C Chen, J Han, X Su, X Cao, J Liu</div><div class="gs_gray">ISPRS journal of Photogrammetry and Remote sensing 145, 184-196<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16615794261911698413,4767396999109772108" class="gsc_a_ac gs_ibl">46</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:q3CdL3IzO_QC" class="gsc_a_at">Real-time scalable visual tracking via quadrangle kernelized correlation filters</a><div class="gs_gray">G Ding, W Chen, S Zhao, J Han, Q Liu</div><div class="gs_gray">IEEE Transactions on Intelligent Transportation Systems 19 (1), 140-150<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6244954741003830193" class="gsc_a_ac gs_ibl">45</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:S16KYo8Pm5AC" class="gsc_a_at">Multi-temporal depth motion maps-based local binary patterns for 3-D human action recognition</a><div class="gs_gray">C Chen, M Liu, H Liu, B Zhang, J Han, N Kehtarnavaz</div><div class="gs_gray">IEEE Access 5, 22590-22604<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15227365621096866445" class="gsc_a_ac gs_ibl">45</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:5awf1xo2G04C" class="gsc_a_at">Auto-encoder-based shared mid-level visual dictionary learning for scene classification using very high resolution remote sensing images</a><div class="gs_gray">G Cheng, P Zhou, J Han, L Guo, J Han</div><div class="gs_gray">IET Computer Vision 9 (5), 639-647<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6104941308219596625" class="gsc_a_ac gs_ibl">45</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:5qfkUJPXOUwC" class="gsc_a_at">Deep Fisher discriminant learning for mobile hand gesture recognition</a><div class="gs_gray">C Li, C Xie, B Zhang, C Chen, J Han</div><div class="gs_gray">Pattern Recognition 77, 276-288<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8380497224577496602" class="gsc_a_ac gs_ibl">44</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:7wO8s98CvbsC" class="gsc_a_at">Episode-based prototype generating network for zero-shot learning</a><div class="gs_gray">Y Yu, Z Ji, J Han, Z Zhang</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15377338687069834231,15414205836886455831" class="gsc_a_ac gs_ibl">43</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:OP4eGU-M3BUC" class="gsc_a_at">Projection convolutional neural networks for 1-bit cnns via discrete back propagation</a><div class="gs_gray">J Gu, C Li, B Zhang, J Han, X Cao, J Liu, D Doermann</div><div class="gs_gray">Proceedings of the AAAI Conference on Artificial Intelligence 33 (01), 8344-8351<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9638421931831741703" class="gsc_a_ac gs_ibl">43</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:4fGpz3EwCPoC" class="gsc_a_at">Discrete probability distribution prediction of image emotions with shared sparse learning</a><div class="gs_gray">S Zhao, G Ding, Y Gao, X Zhao, Y Tang, J Han, H Yao, Q Huang</div><div class="gs_gray">IEEE Transactions on Affective Computing 11 (4), 574-587<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7994685582119264885" class="gsc_a_ac gs_ibl">41</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:B3FOqHPlNUQC" class="gsc_a_at">Computer vision for RGB-D sensors: Kinect and its applications [special issue intro.]</a><div class="gs_gray">L Shao, J Han, D Xu, J Shotton</div><div class="gs_gray">IEEE transactions on cybernetics 43 (5), 1314-1317<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8448238494485254569" class="gsc_a_ac gs_ibl">41</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:IRz6iEL74y4C" class="gsc_a_at">Zero shot learning via low-rank embedded semantic autoencoder.</a><div class="gs_gray">Y Liu, Q Gao, J Li, J Han, L Shao</div><div class="gs_gray">IJCAI, 2490-2496<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14349339329285449403" class="gsc_a_ac gs_ibl">40</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:LhH-TYMQEocC" class="gsc_a_at">DECODE: Deep confidence network for robust image classification</a><div class="gs_gray">G Ding, Y Guo, K Chen, C Chu, J Han, Q Dai</div><div class="gs_gray">IEEE Transactions on Image Processing 28 (8), 3752-3765<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13867288562804126482" class="gsc_a_ac gs_ibl">37</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:BrmTIyaxlBUC" class="gsc_a_at">Real-time video content analysis tool for consumer media storage system</a><div class="gs_gray">J Han, D Farin, PHN de With, W Lao</div><div class="gs_gray">IEEE transactions on Consumer Electronics 52 (3), 870-878<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9704101481332479120,15815627267506230924,17912438414930523016,10510932940651874958" class="gsc_a_ac gs_ibl">37</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="hNi1gxAAAAAJ:BrmTIyaxlBUC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:ubry08Y2EpUC" class="gsc_a_at">Hierarchical shot detector</a><div class="gs_gray">J Cao, Y Pang, J Han, X Li</div><div class="gs_gray">Proceedings of the IEEE/CVF International Conference on Computer Vision&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2349522124394529949" class="gsc_a_ac gs_ibl">36</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:_5tno0g5mFcC" class="gsc_a_at">Show, Observe and Tell: Attribute-driven Attention Model for Image Captioning.</a><div class="gs_gray">H Chen, G Ding, Z Lin, S Zhao, J Han</div><div class="gs_gray">IJCAI, 606-612<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8215020796660705730" class="gsc_a_ac gs_ibl">35</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:kRWSkSYxWN8C" class="gsc_a_at">A subset method for improving Linear Discriminant Analysis</a><div class="gs_gray">C Yao, Z Lu, J Li, Y Xu, J Han</div><div class="gs_gray">Neurocomputing 138, 310-315<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14540124439084501775" class="gsc_a_ac gs_ibl">35</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:v1_lew4L6wgC" class="gsc_a_at">RGB-T salient object detection via fusing multi-level CNN features</a><div class="gs_gray">Q Zhang, N Huang, L Yao, D Zhang, C Shan, J Han</div><div class="gs_gray">IEEE Transactions on Image Processing 29, 3321-3335<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3665428635629504811" class="gsc_a_ac gs_ibl">34</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:DUooU5lO8OsC" class="gsc_a_at">Action recognition from arbitrary views using transferable dictionary learning</a><div class="gs_gray">J Zhang, HPH Shum, J Han, L Shao</div><div class="gs_gray">IEEE transactions on image processing 27 (10), 4709-4723<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2438064002275434818" class="gsc_a_ac gs_ibl">34</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:e_rmSamDkqQC" class="gsc_a_at">Hyperspectral band selection using improved classification map</a><div class="gs_gray">X Cao, C Wei, J Han, L Jiao</div><div class="gs_gray">IEEE geoscience and remote sensing letters 14 (11), 2147-2151<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17237264882382353875" class="gsc_a_ac gs_ibl">34</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:MpfHP-DdYjUC" class="gsc_a_at">Imram: Iterative matching with recurrent attention memory for cross-modal image-text retrieval</a><div class="gs_gray">H Chen, G Ding, X Liu, Z Lin, J Liu, J Han</div><div class="gs_gray">Proceedings of the IEEE/CVF conference on computer vision and pattern&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5242365097575219545" class="gsc_a_ac gs_ibl">32</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:sJsF-0ZLhtgC" class="gsc_a_at">Recurrent attention model for pedestrian attribute recognition</a><div class="gs_gray">X Zhao, L Sang, G Ding, J Han, N Di, C Yan</div><div class="gs_gray">Proceedings of the AAAI Conference on Artificial Intelligence 33 (01), 9275-9282<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9898488368999284412" class="gsc_a_ac gs_ibl">31</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:fFSKOagxvKUC" class="gsc_a_at">Personalized emotion recognition by personality-aware high-order learning of physiological signals</a><div class="gs_gray">S Zhao, A Gholaminejad, G Ding, Y Gao, J Han, K Keutzer</div><div class="gs_gray">ACM Transactions on Multimedia Computing, Communications, and Applications&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7282535399950138976" class="gsc_a_ac gs_ibl">31</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:43bX7VzcjpAC" class="gsc_a_at">Employing deep part-object relationships for salient object detection</a><div class="gs_gray">Y Liu, Q Zhang, D Zhang, J Han</div><div class="gs_gray">Proceedings of the IEEE/CVF International Conference on Computer Vision&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8575132662914163036" class="gsc_a_ac gs_ibl">30</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:fbc8zXXH2BUC" class="gsc_a_at">Saliency-guided attention network for image-sentence matching</a><div class="gs_gray">Z Ji, H Wang, J Han, Y Pang</div><div class="gs_gray">Proceedings of the IEEE/CVF International Conference on Computer Vision&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4053711254150377492" class="gsc_a_ac gs_ibl">30</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:mNrWkgRL2YcC" class="gsc_a_at">Single image super-resolution using multi-scale deep encoder–decoder with phase congruency edge map guidance</a><div class="gs_gray">H Liu, Z Fu, J Han, L Shao, S Hou, Y Chu</div><div class="gs_gray">Information Sciences 473, 44-58<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7705589149636312317" class="gsc_a_ac gs_ibl">30</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:9pM33mqn1YgC" class="gsc_a_at">Salient object detection via two-stage graphs</a><div class="gs_gray">Y Liu, J Han, Q Zhang, L Wang</div><div class="gs_gray">IEEE Transactions on Circuits and Systems for Video Technology 29 (4), 1023-1037<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4473530838420303366" class="gsc_a_ac gs_ibl">29</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:FPJr55Dyh1AC" class="gsc_a_at">Learning visual emotion distributions via multi-modal features fusion</a><div class="gs_gray">S Zhao, G Ding, Y Gao, J Han</div><div class="gs_gray">Proceedings of the 25th ACM international conference on Multimedia, 369-377<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8883098233982914665" class="gsc_a_ac gs_ibl">28</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:wbdj-CoPYUoC" class="gsc_a_at">Spatial and temporal visual attention prediction in videos using eye movement data</a><div class="gs_gray">J Han, L Sun, X Hu, J Han, L Shao</div><div class="gs_gray">Neurocomputing 145, 140-153<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1149083623331344719" class="gsc_a_ac gs_ibl">28</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:DBa1UEJaJKAC" class="gsc_a_at">Learning from multiple experts: Self-paced knowledge distillation for long-tailed classification</a><div class="gs_gray">L Xiang, G Ding, J Han</div><div class="gs_gray">European Conference on Computer Vision, 247-263<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10072224309423455263" class="gsc_a_ac gs_ibl">27</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:Ak0FvsSvgGUC" class="gsc_a_at">JCS-Net: Joint classification and super-resolution network for small-scale pedestrian detection in surveillance images</a><div class="gs_gray">Y Pang, J Cao, J Wang, J Han</div><div class="gs_gray">IEEE Transactions on Information Forensics and Security 14 (12), 3322-3331<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1905185438685534870" class="gsc_a_ac gs_ibl">27</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:MLfJN-KU85MC" class="gsc_a_at">SitNet: Discrete Similarity Transfer Network for Zero-shot Hashing.</a><div class="gs_gray">Y Guo, G Ding, J Han, Y Gao</div><div class="gs_gray">IJCAI, 1767-1773<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17781552467625356912" class="gsc_a_ac gs_ibl">26</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:gsN89kCJA0AC" class="gsc_a_at">Unconstrained face recognition using a set-to-set distance measure on deep learned features</a><div class="gs_gray">J Zhao, J Han, L Shao</div><div class="gs_gray">IEEE Transactions on Circuits and Systems for Video Technology 28 (10), 2679&nbsp;…<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10939736347318661229" class="gsc_a_ac gs_ibl">26</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:NXb4pA-qfm4C" class="gsc_a_at">Robust sparse representation based multi-focus image fusion with dictionary construction and local spatial consistency</a><div class="gs_gray">Q Zhang, T Shi, F Wang, RS Blum, J Han</div><div class="gs_gray">Pattern Recognition 83, 299-313<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14341891991686080496" class="gsc_a_ac gs_ibl">25</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:Ri6SYOTghG4C" class="gsc_a_at">Single satellite imagery simultaneous super-resolution and colorization using multi-task deep neural networks</a><div class="gs_gray">H Liu, Z Fu, J Han, L Shao, H Liu</div><div class="gs_gray">Journal of Visual Communication and Image Representation 53, 20-30<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11393497689254534554" class="gsc_a_ac gs_ibl">25</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:KNjnJ3z-R6IC" class="gsc_a_at">Unsupervised deep video hashing with balanced rotation</a><div class="gs_gray">G Wu, L Liu, Y Guo, G Ding, J Han, J Shen, L Shao</div><div class="gs_gray">IJCAI<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16048047384951463015" class="gsc_a_ac gs_ibl">25</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:FiDNX6EVdGUC" class="gsc_a_at">Neural image caption generation with weighted training and reference</a><div class="gs_gray">G Ding, M Chen, S Zhao, H Chen, J Han, Q Liu</div><div class="gs_gray">Cognitive Computation 11 (6), 763-777<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=404830859761240321" class="gsc_a_ac gs_ibl">24</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:0CzhzZyukY4C" class="gsc_a_at">Deep salient object detection with contextual information guidance</a><div class="gs_gray">Y Liu, J Han, Q Zhang, C Shan</div><div class="gs_gray">IEEE Transactions on Image Processing 29, 360-374<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4431482554123938012" class="gsc_a_ac gs_ibl">24</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:ClCfbGk0d_YC" class="gsc_a_at">Temporal-difference learning with sampling baseline for image captioning</a><div class="gs_gray">H Chen, G Ding, S Zhao, J Han</div><div class="gs_gray">Proceedings of the AAAI Conference on Artificial Intelligence 32 (1)<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14895950687661559718" class="gsc_a_ac gs_ibl">24</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:yqoGN6RLRZoC" class="gsc_a_at">Modulated convolutional networks</a><div class="gs_gray">X Wang, B Zhang, C Li, R Ji, J Han, X Cao, J Liu</div><div class="gs_gray">Proceedings of the IEEE Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15568774975927530832" class="gsc_a_ac gs_ibl">24</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:AvfA0Oy_GE0C" class="gsc_a_at">Large-scale image retrieval with sparse embedded hashing</a><div class="gs_gray">G Ding, J Zhou, Y Guo, Z Lin, S Zhao, J Han</div><div class="gs_gray">Neurocomputing 257, 24-36<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1458439865270860931" class="gsc_a_ac gs_ibl">24</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:OBSaB-F7qqsC" class="gsc_a_at">Repvgg: Making vgg-style convnets great again</a><div class="gs_gray">X Ding, X Zhang, N Ma, J Han, G Ding, J Sun</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13451922491452459802" class="gsc_a_ac gs_ibl">23</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:6ZxmRoH8BuwC" class="gsc_a_at">Personality-Aware Personalized Emotion Recognition from Physiological Signals.</a><div class="gs_gray">S Zhao, G Ding, J Han, Y Gao</div><div class="gs_gray">IJCAI, 1660-1667<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3551480986069313744" class="gsc_a_ac gs_ibl">23</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:kWvqk_afx_IC" class="gsc_a_at">Pixel-level semantics guided image colorization</a><div class="gs_gray">J Zhao, L Liu, CGM Snoek, J Han, L Shao</div><div class="gs_gray">arXiv preprint arXiv:1808.01597<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1458594178656972631" class="gsc_a_ac gs_ibl">22</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:Br1UauaknNIC" class="gsc_a_at">Cross-modality deep feature learning for brain tumor segmentation</a><div class="gs_gray">D Zhang, G Huang, Q Zhang, J Han, J Han, Y Yu</div><div class="gs_gray">Pattern Recognition 110, 107562<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9996985989367741127" class="gsc_a_ac gs_ibl">21</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:TIZ-Mc8IlK0C" class="gsc_a_at">End-to-end feature-aware label space encoding for multilabel classification with many classes</a><div class="gs_gray">Z Lin, G Ding, J Han, L Shao</div><div class="gs_gray">IEEE transactions on neural networks and learning systems 29 (6), 2472-2487<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3203003065704105206" class="gsc_a_ac gs_ibl">21</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:ZHo1McVdvXMC" class="gsc_a_at">Visible and infrared image registration employing line-based geometric analysis</a><div class="gs_gray">J Han, E Pauwels, P de Zeeuw</div><div class="gs_gray">Internatinoal Workshop on computational Intelligence for Multimedia&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7703879141957370559" class="gsc_a_ac gs_ibl">21</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:buQ7SEKw-1sC" class="gsc_a_at">Graph and Autoencoder Based Feature Extraction for Zero-shot Learning.</a><div class="gs_gray">Y Liu, DY Xie, Q Gao, J Han, S Wang, X Gao</div><div class="gs_gray">IJCAI, 3038-3044<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7859705753073625023" class="gsc_a_ac gs_ibl">20</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:0N-VGjzr574C" class="gsc_a_at">Zero-shot learning with attribute selection</a><div class="gs_gray">Y Guo, G Ding, J Han, S Tang</div><div class="gs_gray">Thirty-Second AAAI Conference on Artificial Intelligence<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7665214336144629020" class="gsc_a_ac gs_ibl">20</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:oNZyr7d5Mn4C" class="gsc_a_at">Image reconstruction via manifold constrained convolutional sparse coding for image sets</a><div class="gs_gray">L Yang, C Li, J Han, C Chen, Q Ye, B Zhang, X Cao, W Liu</div><div class="gs_gray">IEEE Journal of Selected Topics in Signal Processing 11 (7), 1072-1081<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14901864994715339965" class="gsc_a_ac gs_ibl">20</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:uWiczbcajpAC" class="gsc_a_at">Band selection and evaluation with spatial information</a><div class="gs_gray">X Cao, J Han, S Yang, D Tao, L Jiao</div><div class="gs_gray">International Journal of Remote Sensing 37 (19), 4501-4520<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3208873356405254953" class="gsc_a_ac gs_ibl">20</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:-_dYPAW6P2MC" class="gsc_a_at">Dense invariant feature-based support vector ranking for cross-camera person reidentification</a><div class="gs_gray">S Tan, F Zheng, L Liu, J Han, L Shao</div><div class="gs_gray">IEEE Transactions on Circuits and Systems for Video Technology 28 (2), 356-363<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5093949111754231715" class="gsc_a_ac gs_ibl">20</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:U4n9YNQMCAIC" class="gsc_a_at">Shallow feature based dense attention network for crowd counting</a><div class="gs_gray">Y Miao, Z Lin, G Ding, J Han</div><div class="gs_gray">Proceedings of the AAAI Conference on Artificial Intelligence 34 (07), 11765&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7147641160410622359" class="gsc_a_ac gs_ibl">19</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:ce2CqMG-AY4C" class="gsc_a_at">Pixelated semantic colorization</a><div class="gs_gray">J Zhao, J Han, L Shao, CGM Snoek</div><div class="gs_gray">International Journal of Computer Vision, 1-17<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3774825458663909062" class="gsc_a_ac gs_ibl gsc_a_acm" data-eid="hNi1gxAAAAAJ:ce2CqMG-AY4C" data-eud="hNi1gxAAAAAJ:KbBQZpvPDL4C">19</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:KbBQZpvPDL4C" class="gsc_a_at">Pixelated semantic colorization</a><div class="gs_gray">J Zhao, J Han, L Shao, CGM Snoek</div><div class="gs_gray">International Journal of Computer Vision, 1-17<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3774825458663909062" class="gsc_a_ac gs_ibl">19</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:jgBuDB5drN8C" class="gsc_a_at">Cross-modal image-text retrieval with semantic consistency</a><div class="gs_gray">H Chen, G Ding, Z Lin, S Zhao, J Han</div><div class="gs_gray">Proceedings of the 27th ACM International Conference on Multimedia, 1749-1757<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1226344821032931792" class="gsc_a_ac gs_ibl">19</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:LkGwnXOMwfcC" class="gsc_a_at">High-level traffic-violation detection for embedded traffic analysis</a><div class="gs_gray">JA Vijverberg, NAHM de Koning, J Han, PHN de With, D Cornelissen</div><div class="gs_gray">2007 IEEE International Conference on Acoustics, Speech and Signal&nbsp;…<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11719198608940294461" class="gsc_a_ac gs_ibl">19</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:wMgC3FpKEyYC" class="gsc_a_at">Label-activating framework for zero-shot learning</a><div class="gs_gray">Y Liu, X Gao, Q Gao, J Han, L Shao</div><div class="gs_gray">Neural Networks 121, 1-9<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8187435755137787499" class="gsc_a_ac gs_ibl">18</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:QYdC8u9Cj1oC" class="gsc_a_at">Discriminant Analysis via Joint Euler Transform and<svg class="gs_fsvg" aria-label="\ell_{2,1}" width="25px" height="17px" style="vertical-align:-6px;"><g transform="matrix(0.01700, 0.00000, 0.00000, 0.01700, 0.00000, 11.98500)"><g><path transform="scale(0.48828, -0.48828)" d="M 49 152  Q 40 152 30 163  T 20 184  Q 20 201 190 356  Q 190 365 189 371  T 188 383  Q 188 471 202 562  T 240 745  T 302 935  T 377 1108  Q 443 1243 521 1343  T 694 1444  Q 759 1444 787 1399  T 815 1288  Q 815 913 317 406  Q 309 318 309 281  Q 309 25 426 25  Q 476 25 525 51  T 610 109  T 709 201  Q 713 205 721 205  Q 732 205 742 193  T 752 170  Q 752 163 743 156  Q 652 67 579 18  T 422 -31  Q 314 -31 261 62  T 195 283  Q 140 228 61 156  Q 59 152 49 152  Z M 334 504  Q 443 620 538 748  T 696 1017  T 760 1294  Q 760 1391 692 1391  Q 619 1391 543 1216  T 413 839  T 334 504  Z "></path><g transform="translate(416.67001, 150.00000)"><g><path transform="scale(0.34180, -0.34180)" d="M 129 0  V 59  Q 129 68 137 76  L 502 432  Q 523 454 535 466  T 571 502  Q 692 623 759 727  T 827 956  Q 827 1024 804 1083  T 739 1187  T 641 1254  T 516 1278  Q 425 1278 349 1231  T 236 1104  H 242  Q 291 1104 322 1071  T 354 991  Q 354 945 322 912  T 242 879  Q 195 879 162 912  T 129 991  Q 129 1101 190 1185  T 349 1314  T 551 1360  Q 675 1360 786 1313  T 965 1174  T 1034 956  Q 1034 865 993 786  T 892 648  T 726 505  T 588 395  L 338 182  H 526  Q 603 182 687 182  T 836 185  T 905 193  Q 923 212 934 261  T 956 381  H 1034  L 973 0  H 129  Z "></path><path transform="matrix(0.34180, 0.00000, 0.00000, -0.34180, 398.60800, 0.00000)" d="M 238 -360  Q 238 -350 246 -342  Q 325 -275 368 -181  T 412 18  V 29  Q 380 0 332 0  Q 279 0 244 35  T 209 123  Q 209 174 244 209  T 332 244  Q 407 244 442 174  T 477 18  Q 477 -99 427 -208  T 291 -391  Q 282 -397 274 -397  Q 262 -397 250 -385  T 238 -360  Z "></path><path transform="matrix(0.34180, 0.00000, 0.00000, -0.34180, 624.98102, 0.00000)" d="M 233 0  V 82  Q 516 82 516 143  V 1202  Q 401 1147 219 1147  V 1229  Q 341 1229 447 1258  T 629 1360  H 666  Q 685 1355 690 1335  V 143  Q 690 82 973 82  V 0  H 233  Z "></path></g></g></g></g></svg>-Norm</a><div class="gs_gray">S Liao, Q Gao, Z Yang, F Chen, F Nie, J Han</div><div class="gs_gray">IEEE Transactions on Image Processing 27 (11), 5668-5682<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15710845594356409683" class="gsc_a_ac gs_ibl">18</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=20&amp;pagesize=80&amp;citation_for_view=hNi1gxAAAAAJ:OTTXONDVkokC" class="gsc_a_at">Where to Prune: Using LSTM to Guide End-to-end Pruning.</a><div class="gs_gray">J Zhong, G Ding, Y Guo, J Han, B Wang</div><div class="gs_gray">IJCAI, 3205-3211<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13456311393519262710" class="gsc_a_ac gs_ibl">18</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:5icHVeHT4IsC" class="gsc_a_at">Zero-shot recognition via direct classifier learning with transferred samples and pseudo labels</a><div class="gs_gray">Y Guo, G Ding, J Han, Y Gao</div><div class="gs_gray">Proceedings of the AAAI Conference on Artificial Intelligence 31 (1)<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9209372415416422256" class="gsc_a_ac gs_ibl">18</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:7T2F9Uy0os0C" class="gsc_a_at">Intelligent trainee behavior assessment system for medical training employing video analysis</a><div class="gs_gray">J Han, PHN de With, A Merien, G Oei</div><div class="gs_gray">Pattern Recognition Letters 33 (4), 453-461<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8087447867060459946,14397471082106582593" class="gsc_a_ac gs_ibl">18</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="hNi1gxAAAAAJ:7T2F9Uy0os0C">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:WF5omc3nYNoC" class="gsc_a_at">Variable block-size transform and entropy coding at the enhancement layer of FGS [fine granularity scalable video coding]</a><div class="gs_gray">J Han, X Sung, F Wu, S Li, Z Lu</div><div class="gs_gray">2004 International Conference on Image Processing, 2004. ICIP'04. 1, 481-484<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12542878694562037533" class="gsc_a_ac gs_ibl">18</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:P7Ujq4OLJYoC" class="gsc_a_at">Multi-layer attention based CNN for target-dependent sentiment classification</a><div class="gs_gray">S Zhang, X Xu, Y Pang, J Han</div><div class="gs_gray">Neural processing letters 51 (3), 2089-2103<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10319040284758480346" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:cK4Rrx0J3m0C" class="gsc_a_at">Nas-count: Counting-by-density with neural architecture search</a><div class="gs_gray">Y Hu, X Jiang, X Liu, B Zhang, J Han, X Cao, D Doermann</div><div class="gs_gray">Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6615973662152615966" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:kVjdVfd2voEC" class="gsc_a_at">Taking a look at small-scale pedestrians and occluded pedestrians</a><div class="gs_gray">J Cao, Y Pang, J Han, B Gao, X Li</div><div class="gs_gray">IEEE transactions on image processing 29, 3143-3152<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10768132645699779461" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:8xutWZnSdmoC" class="gsc_a_at">Flexible unsupervised feature extraction for image classification</a><div class="gs_gray">Y Liu, F Nie, Q Gao, X Gao, J Han, L Shao</div><div class="gs_gray">Neural Networks 115, 65-71<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2027971503606581075" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:jL-93Qbq4QoC" class="gsc_a_at">Visdrone-sot2018: The vision meets drone single-object tracking challenge results</a><div class="gs_gray">L Wen, P Zhu, D Du, X Bian, H Ling, Q Hu, C Liu, H Cheng, X Liu, W Ma, ...</div><div class="gs_gray">Proceedings of the European Conference on Computer Vision (ECCV) Workshops, 0-0<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16780492309650671340" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:KUbvn5osdkgC" class="gsc_a_at">Salient object detection based on super-pixel clustering and unified low-rank representation</a><div class="gs_gray">Q Zhang, Y Liu, S Zhu, J Han</div><div class="gs_gray">Computer Vision and Image Understanding 161, 51-64<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4634942915708441363" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:8AbLer7MMksC" class="gsc_a_at">Video abstraction based on fMRI-driven visual attention model</a><div class="gs_gray">J Han, K Li, L Shao, X Hu, S He, L Guo, J Han, T Liu</div><div class="gs_gray">Information sciences 281, 781-796<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15899010016278608000" class="gsc_a_ac gs_ibl">17</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:WC23djZS0W4C" class="gsc_a_at">BidNet: Binocular image dehazing without explicit disparity estimation</a><div class="gs_gray">Y Pang, J Nie, J Xie, J Han, X Li</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15198649879268679651" class="gsc_a_ac gs_ibl">16</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:bKqednn6t2AC" class="gsc_a_at">Class-specific synthesized dictionary model for zero-shot learning</a><div class="gs_gray">Z Ji, J Wang, Y Yu, Y Pang, J Han</div><div class="gs_gray">Neurocomputing 329, 339-347<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13683963842479827049" class="gsc_a_ac gs_ibl">16</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:VaXvl8Fpj5cC" class="gsc_a_at">TUCH: turning cross-view hashing into single-view hashing via generative adversarial nets</a><div class="gs_gray">X Zhao, G Ding, Y Guo, J Han, Y Gao</div><div class="gs_gray">IJCAI<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5827604832840460951" class="gsc_a_ac gs_ibl">16</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:tzM49s52ZIMC" class="gsc_a_at">Robust object representation by boosting-like deep learning architecture</a><div class="gs_gray">L Wang, B Zhang, J Han, L Shen, C Qian</div><div class="gs_gray">Signal Processing: Image Communication 47, 490-499<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3961684547807653143" class="gsc_a_ac gs_ibl">16</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:4fKUyHm3Qg0C" class="gsc_a_at">Image visual attention computation and application via the learning of object attributes</a><div class="gs_gray">J Han, D Wang, L Shao, X Qian, G Cheng, J Han</div><div class="gs_gray">Machine vision and applications 25 (7), 1671-1683<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18367184121883679408" class="gsc_a_ac gs_ibl">16</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:d1gkVwhDpl0C" class="gsc_a_at">Real-time and distributed AV content analysis system for consumer electronics networks</a><div class="gs_gray">J Nesvadba, P Fonseca, A Sinitsyn, F De Lange, M Thijssen, P Van Kaam, ...</div><div class="gs_gray">2005 IEEE International Conference on Multimedia and Expo, 1549-1552<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7705808713779657687" class="gsc_a_ac gs_ibl">16</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:NyGDZy8z5eUC" class="gsc_a_at">Adaptive robust principal component analysis</a><div class="gs_gray">Y Liu, X Gao, Q Gao, L Shao, J Han</div><div class="gs_gray">Neural Networks 119, 85-92<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12956483980690928072" class="gsc_a_ac gs_ibl">15</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:3bvyWxjaHKcC" class="gsc_a_at">Robust iterative quantization for efficient lp-norm similarity search</a><div class="gs_gray">Y Guo, G Ding, J Han, X Jin</div><div class="gs_gray">Proceedings of the twenty-fifth international joint conference on artificial&nbsp;…<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3724818412051339909" class="gsc_a_ac gs_ibl">15</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:WqliGbK-hY8C" class="gsc_a_at">Saliency-aware image-to-class distances for image classification</a><div class="gs_gray">P Peng, L Shao, J Han, J Han</div><div class="gs_gray">Neurocomputing 166, 337-345<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17345515908629294402" class="gsc_a_ac gs_ibl">15</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:Ehil0879vHcC" class="gsc_a_at">Salient object detection employing a local tree-structured low-rank representation and foreground consistency</a><div class="gs_gray">Q Zhang, Z Huo, Y Liu, Y Pan, C Shan, J Han</div><div class="gs_gray">Pattern Recognition 92, 119-134<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13629186970459767586" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:lvd772isFD0C" class="gsc_a_at">Deep manifold structure transfer for action recognition</a><div class="gs_gray">C Li, B Zhang, C Chen, Q Ye, J Han, G Guo, R Ji</div><div class="gs_gray">IEEE transactions on image processing 28 (9), 4646-4658<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5114476605249565436" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:l7t_Zn2s7bgC" class="gsc_a_at">Feature-based motion compensated interpolation for frame rate up-conversion</a><div class="gs_gray">D Guo, L Shao, J Han</div><div class="gs_gray">Neurocomputing 123, 390-397<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17723134545537763903" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:Se3iqnhoufwC" class="gsc_a_at">Behavioral state detection of newborns based on facial expression analysis</a><div class="gs_gray">L Hazelhoff, J Han, S Bambang-Oetomo</div><div class="gs_gray">International Conference on Advanced Concepts for Intelligent Vision Systems&nbsp;…<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13991586068412724367" class="gsc_a_ac gs_ibl">14</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:MhiOAD_qIWkC" class="gsc_a_at">Deep attentive video summarization with distribution consistency learning</a><div class="gs_gray">Z Ji, Y Zhao, Y Pang, X Li, J Han</div><div class="gs_gray">IEEE transactions on neural networks and learning systems 32 (4), 1765-1775<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7824751228841183506" class="gsc_a_ac gs_ibl">13</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:5nxA0vEk-isC" class="gsc_a_at">Real-time multiple people tracking for automatic group-behavior evaluation in delivery simulation training</a><div class="gs_gray">J Han</div><div class="gs_gray">Multimedia Tools and Applications 51 (3), 913-933<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4340499702750687577" class="gsc_a_ac gs_ibl">13</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:Z5m8FVwuT1cC" class="gsc_a_at">Fast detection and modeling of human-body parts from monocular video</a><div class="gs_gray">W Lao, J Han</div><div class="gs_gray">International Conference on Articulated Motion and Deformable Objects, 380-389<span class="gs_oph">, 2008</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15039843656136261067" class="gsc_a_ac gs_ibl">13</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2008</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:gVv57TyPmFsC" class="gsc_a_at">Learning object context for dense captioning</a><div class="gs_gray">X Li, S Jiang, J Han</div><div class="gs_gray">Proceedings of the AAAI conference on artificial intelligence 33 (01), 8650-8657<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8072850415729994703" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:ZzlSgRqYykMC" class="gsc_a_at">ST-CNN: Spatial-Temporal Convolutional Neural Network for crowd counting in videos</a><div class="gs_gray">Y Miao, J Han, Y Gao, B Zhang</div><div class="gs_gray">Pattern Recognition Letters 125, 113-118<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9831747922438639896" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:LgRImbQfgY4C" class="gsc_a_at">Incremental few-shot learning for pedestrian attribute recognition</a><div class="gs_gray">L Xiang, X Jin, G Ding, J Han, L Li</div><div class="gs_gray">arXiv preprint arXiv:1906.00330<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14302278203555388005" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:YohjEiUPhakC" class="gsc_a_at">Secure and privacy-preserving data sharing in the cloud based on lossless image coding</a><div class="gs_gray">F Khelifi, T Brahimi, J Han, X Li</div><div class="gs_gray">Signal Processing 148, 91-101<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7124218949600498894" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:edDO8Oi4QzsC" class="gsc_a_at">On trivial solution and high correlation problems in deep supervised hashing</a><div class="gs_gray">Y Guo, X Zhao, G Ding, J Han</div><div class="gs_gray">Thirty-Second AAAI Conference on Artificial Intelligence<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4033767117894316963" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:BUYA1_V_uYcC" class="gsc_a_at">Attribute-based supervised deep learning model for action recognition.</a><div class="gs_gray">K Chen, G Ding, J Han</div><div class="gs_gray">Frontiers Comput. Sci. 11 (2), 219-229<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9826926765466058273" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:0izLItjtcgwC" class="gsc_a_at">Arbitrary view action recognition via transfer dictionary learning on synthetic training data</a><div class="gs_gray">J Zhang, L Zhang, HPH Shum, L Shao</div><div class="gs_gray">2016 IEEE International Conference on Robotics and Automation (ICRA), 1678-1684<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4985051462826578001" class="gsc_a_ac gs_ibl">12</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:LPtt_HFRSbwC" class="gsc_a_at">Revisiting feature fusion for rgb-t salient object detection</a><div class="gs_gray">Q Zhang, T Xiao, N Huang, D Zhang, J Han</div><div class="gs_gray">IEEE Transactions on Circuits and Systems for Video Technology 31 (5), 1804-1818<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1955282785582134956" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:nVrZBo8bIpAC" class="gsc_a_at">SAR image change detection based on deep denoising and CNN</a><div class="gs_gray">X Cao, Y Ji, L Wang, B Ji, L Jiao, J Han</div><div class="gs_gray">IET Image Processing 13 (9), 1509-1515<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11140987287267263007" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:4X0JR2_MtJMC" class="gsc_a_at">Attentive temporal pyramid network for dynamic scene classification</a><div class="gs_gray">Y Huang, X Cao, X Zhen, J Han</div><div class="gs_gray">Proceedings of the AAAI Conference on Artificial Intelligence 33 (01), 8497-8504<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9938750243041616724" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:8d8msizDQcsC" class="gsc_a_at">Fast hyperspectral band selection based on spatial feature extraction</a><div class="gs_gray">X Cao, Y Ji, L Wang, B Ji, L Jiao, J Han</div><div class="gs_gray">Journal of Real-Time Image Processing 15 (3), 555-564<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17841833654361719379" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:XoXfffV-tXoC" class="gsc_a_at">Single image super-resolution using a deep encoder–decoder symmetrical network with iterative back projection</a><div class="gs_gray">H Liu, J Han, S Hou, L Shao, Y Ruan</div><div class="gs_gray">Neurocomputing 282, 52-59<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3939843029310479514" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:PoWvk5oyLR8C" class="gsc_a_at">Salient object detection employing robust sparse representation and local consistency</a><div class="gs_gray">L Yi, Z Qiang, H Jungong, W Long</div><div class="gs_gray">Image and Vision Computing 69, 155-167<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4061292866104816966" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:tkaPQYYpVKoC" class="gsc_a_at">Analysis of music/speech via integration of audio content and functional brain response</a><div class="gs_gray">X Ji, J Han, X Jiang, X Hu, L Guo, J Han, L Shao, T Liu</div><div class="gs_gray">Information Sciences 297, 271-282<span class="gs_oph">, 2015</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3815684307395919978" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2015</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:qjMakFHDy7sC" class="gsc_a_at">Automatic sports video analysis using audio clues and context knowledge</a><div class="gs_gray">W Lao, J Han, PHN de With</div><div class="gs_gray">Proceedings of the 24th IASTED international conference on Internet and&nbsp;…<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11356154674321010218,2983913571046473853,9216046611153321491" class="gsc_a_ac gs_ibl">11</a><span class="gsc_a_m"><a href="javascript:void(0)" class="gsc_a_am" data-eid="hNi1gxAAAAAJ:qjMakFHDy7sC">*</a></span></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:URolC5Kub84C" class="gsc_a_at">Automatic tracking method for sports video analysis</a><div class="gs_gray">J Han, D Farin</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=40540645603940777" class="gsc_a_ac gs_ibl">11</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:WJVC3Jt7v1AC" class="gsc_a_at">Implicit Non-linear Similarity Scoring for Recognizing Unseen Classes.</a><div class="gs_gray">Y Guo, G Ding, J Han, S Zhao, B Wang</div><div class="gs_gray">IJCAI, 4898-4904<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4770387194558367217" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:1qzjygNMrQYC" class="gsc_a_at">Clustering and retrieval of video shots based on natural stimulus fMRI</a><div class="gs_gray">J Han, X Ji, X Hu, J Han, T Liu</div><div class="gs_gray">Neurocomputing 144, 128-137<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8765660650005976894" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:sSrBHYA8nusC" class="gsc_a_at">Efficient highlight removal of metal surfaces</a><div class="gs_gray">D Yu, J Han, X Jin, J Han</div><div class="gs_gray">Signal processing 103, 367-379<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=539216335811197409" class="gsc_a_ac gs_ibl">10</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:6bLC7aUMtPcC" class="gsc_a_at">Exploring task structure for brain tumor segmentation from multi-modality MR images</a><div class="gs_gray">D Zhang, G Huang, Q Zhang, J Han, J Han, Y Wang, Y Yu</div><div class="gs_gray">IEEE Transactions on Image Processing 29, 9032-9043<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3938573577102775076" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:OcBU2YAGkTUC" class="gsc_a_at">Hyperspectral image denoising via minimizing the partial sum of singular values and superpixel segmentation</a><div class="gs_gray">Y Liu, C Shan, Q Gao, X Gao, J Han, R Cui</div><div class="gs_gray">Neurocomputing 330, 465-482<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7149819487963663951" class="gsc_a_ac gs_ibl">9</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:j7_hQOaDUrUC" class="gsc_a_at">Attention module-based spatial–temporal graph convolutional networks for skeleton-based action recognition</a><div class="gs_gray">Y Kong, L Li, K Zhang, Q Ni, J Han</div><div class="gs_gray">Journal of Electronic Imaging 28 (4), 043032<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6018573986080799388" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:ipzZ9siozwsC" class="gsc_a_at">Active learning with cross-class similarity transfer</a><div class="gs_gray">Y Guo, G Ding, Y Gao, J Han</div><div class="gs_gray">Proceedings of the AAAI Conference on Artificial Intelligence 31 (1)<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18121657197514753139" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:70eg2SAEIzsC" class="gsc_a_at">Multimodality and Multiresolution Image Fusion.</a><div class="gs_gray">PM de Zeeuw, EJ Pauwels, J Han</div><div class="gs_gray">VISAPP (1), 151-157<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9926446581640934786" class="gsc_a_ac gs_ibl">8</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:F1b5ZUV5XREC" class="gsc_a_at">Image captioning with memorized knowledge</a><div class="gs_gray">H Chen, G Ding, Z Lin, Y Guo, C Shan, J Han</div><div class="gs_gray">Cognitive Computation 13 (4), 807-820<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1023043506450245418" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:KaMxkj08jr0C" class="gsc_a_at">Automatic pancreas segmentation based on lightweight DCNN modules and spatial prior propagation</a><div class="gs_gray">D Zhang, J Zhang, Q Zhang, J Han, S Zhang, J Han</div><div class="gs_gray">Pattern Recognition 114, 107762<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8549785596001093141" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:yxmsSjX2EkcC" class="gsc_a_at">Pruning convolutional neural networks with an attention mechanism for remote sensing image classification</a><div class="gs_gray">S Zhang, G Wu, J Gu, J Han</div><div class="gs_gray">Electronics 9 (8), 1209<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5534219382445590403" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:nRpfm8aw39MC" class="gsc_a_at">Using generative adversarial networks to break and protect text captchas</a><div class="gs_gray">G Ye, Z Tang, D Fang, Z Zhu, Y Feng, P Xu, X Chen, J Han, Z Wang</div><div class="gs_gray">ACM Transactions on Privacy and Security (TOPS) 23 (2), 1-29<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5243146420874088668" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:gKiMpY-AVTkC" class="gsc_a_at">Heterogeneous deep model fusion for automatic modulation classification</a><div class="gs_gray">D Zhang, W Ding, B Zhang, C Xie, C Liu, J Han, H Li</div><div class="gs_gray">Preprints<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11301156965722466278" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:0KyAp5RtaNEC" class="gsc_a_at">Adaptive multi-class correlation filters</a><div class="gs_gray">L Yang, C Chen, H Wang, B Zhang, J Han</div><div class="gs_gray">Pacific rim conference on multimedia, 680-688<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=214829574469551294" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:abG-DnoFyZgC" class="gsc_a_at">Archeological treasures protection based on early forest wildfire multi-band imaging detection system</a><div class="gs_gray">B Gouverneur, S Verstockt, E Pauwels, J Han, PM de Zeeuw, J Vermeiren</div><div class="gs_gray">Electro-Optical and Infrared Systems: Technology and Applications IX 8541&nbsp;…<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5504685665581954475" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:SdhP9T11ey4C" class="gsc_a_at">Water region and multiple ship detection for port surveillance</a><div class="gs_gray">X Bao, S Zinger</div><div class="gs_gray">in [Proc. the 33rd WIC Symposium on Information Theory in the Benelux<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10268697185421914761" class="gsc_a_ac gs_ibl">7</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:CdxZDUztZiMC" class="gsc_a_at">Cascaded hierarchical atrous spatial pyramid pooling module for semantic segmentation</a><div class="gs_gray">X Lian, Y Pang, J Han, J Pan</div><div class="gs_gray">Pattern Recognition 110, 107622<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4299550880899090487" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:WC9gN4BGCRcC" class="gsc_a_at">On aggregation of unsupervised deep binary descriptor with weak bits</a><div class="gs_gray">G Wu, Z Lin, G Ding, Q Ni, J Han</div><div class="gs_gray">IEEE Transactions on Image Processing 29, 9266-9278<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16288220241997734588" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:6yz0xqPARnAC" class="gsc_a_at">Dual-view ranking with hardness assessment for zero-shot learning</a><div class="gs_gray">Y Guo, G Ding, J Han, X Ding, S Zhao, Z Wang, C Yan, Q Dai</div><div class="gs_gray">Proceedings of the AAAI Conference on Artificial Intelligence 33 (01), 8360-8367<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12877700482099885095" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:QD3KBmkZPeQC" class="gsc_a_at">Low Shot Box Correction for Weakly Supervised Object Detection.</a><div class="gs_gray">T Pan, B Wang, G Ding, J Han, JH Yong</div><div class="gs_gray">IJCAI, 890-896<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15440116181372954617" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:3htObqc8RwsC" class="gsc_a_at">Euler sparse representation for image classification</a><div class="gs_gray">Y Liu, Q Gao, J Han, S Wang</div><div class="gs_gray">Proceedings of the AAAI Conference on Artificial Intelligence 32 (1)<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12105711646703815013" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:4DMP91E08xMC" class="gsc_a_at">Analysis and retargeting of ball sports video</a><div class="gs_gray">S Kopf, B Guthier, D Farin, J Han</div><div class="gs_gray">2011 IEEE Workshop on Applications of Computer Vision (WACV), 9-14<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7321995772249752848" class="gsc_a_ac gs_ibl">6</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:-jrNzM816MMC" class="gsc_a_at">Part-object relational visual saliency</a><div class="gs_gray">Y Liu, D Zhang, Q Zhang, J Han</div><div class="gs_gray">IEEE Transactions on Pattern Analysis and Machine Intelligence<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5966950740339244944" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:LdasjJ6CEcoC" class="gsc_a_at">Multi-focus image fusion based on non-negative sparse representation and patch-level consistency rectification</a><div class="gs_gray">Q Zhang, G Li, Y Cao, J Han</div><div class="gs_gray">Pattern Recognition 104, 107325<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15635267271086121807" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:1taIhTC69MYC" class="gsc_a_at">SMAN: Stacked multimodal attention network for cross-modal image-text retrieval</a><div class="gs_gray">Z Ji, H Wang, J Han, Y Pang</div><div class="gs_gray">IEEE transactions on cybernetics<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=353185779398571513" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:OR75R8vi5nAC" class="gsc_a_at">The structure transfer machine theory and applications</a><div class="gs_gray">B Zhang, W Yang, Z Wang, L Zhuo, J Han, X Zhen</div><div class="gs_gray">IEEE Transactions on Image Processing 29, 2889-2902<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7795603280916995406" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:sNmaIFBj_lkC" class="gsc_a_at">Method and device for generating fingerprints of information signals</a><div class="gs_gray">J Han, GC Langelaar</div><div class="gs_gray">US Patent 10,248,723<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4260049079337669584" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:HE397vMXCloC" class="gsc_a_at">RGB-D human identification and tracking in a smart environment</a><div class="gs_gray">J Han, J Han</div><div class="gs_gray">Computer Vision and Machine Learning with RGB-D Sensors, 195-211<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8087594636256888596" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:_FxGoFyzp5QC" class="gsc_a_at">DCT-based embedded coding scheme for stereo image</a><div class="gs_gray">J Han, Z Lu</div><div class="gs_gray">2004 International Conference on Communications, Circuits and Systems (IEEE&nbsp;…<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7360070163107070970" class="gsc_a_ac gs_ibl">5</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:AXkvAH5U_nMC" class="gsc_a_at">Few-cost salient object detection with adversarial-paced learning</a><div class="gs_gray">D Zhang, H Tian, J Han</div><div class="gs_gray">arXiv preprint arXiv:2104.01928<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4856598179246722955" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:mUJArPsKIAAC" class="gsc_a_at">Employing Bilinear Fusion and Saliency Prior Information for RGB-D Salient Object Detection</a><div class="gs_gray">N Huang, Y Yang, D Zhang, Q Zhang, J Han</div><div class="gs_gray">IEEE Transactions on Multimedia<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10797030595242579117" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:1DsIQWDZLl8C" class="gsc_a_at">Multiview Subspace Clustering by an Enhanced Tensor Nuclear Norm</a><div class="gs_gray">W Xia, X Zhang, Q Gao, X Shu, J Han, X Gao</div><div class="gs_gray">IEEE Transactions on Cybernetics<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4765139358415873487" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:FiytvqdAVhgC" class="gsc_a_at">Fast simultaneous image super-resolution and motion deblurring with decoupled cooperative learning</a><div class="gs_gray">H Liu, J Qin, Z Fu, X Li, J Han</div><div class="gs_gray">Journal of Real-time Image Processing 17, 1787-1800<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5105084000640009130" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:-mN3Mh-tlDkC" class="gsc_a_at">Pedestrian attribute recognition based on multiple time steps attention</a><div class="gs_gray">Z Ji, Z Hu, E He, J Han, Y Pang</div><div class="gs_gray">Pattern Recognition Letters 138, 170-176<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14462263026733349846" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:hsZV8lGYWTMC" class="gsc_a_at">Joint cross-modal and unimodal features for RGB-D salient object detection</a><div class="gs_gray">N Huang, Y Liu, Q Zhang, J Han</div><div class="gs_gray">IEEE Transactions on Multimedia<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5692336170194200734" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:BzfGm06jWhQC" class="gsc_a_at">Autonomous semantic community detection via adaptively weighted low-rank approximation</a><div class="gs_gray">L Yang, Y Wang, J Gu, X Cao, X Wang, D Jin, G Ding, J Han, W Zhang</div><div class="gs_gray">ACM Transactions on Multimedia Computing, Communications, and Applications&nbsp;…<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4754177522442484033" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:ALROH1vI_8AC" class="gsc_a_at">Aggregation signature for small object tracking</a><div class="gs_gray">C Liu, W Ding, J Yang, V Murino, B Zhang, J Han, G Guo</div><div class="gs_gray">IEEE Transactions on Image Processing 29, 1738-1747<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=18207424863350615428" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:a3BOlSfXSfwC" class="gsc_a_at">Survey on GAN-based face hallucination with its model development</a><div class="gs_gray">H Liu, X Zheng, J Han, Y Chu, T Tao</div><div class="gs_gray">IET Image Processing 13 (14), 2662-2672<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4878657961360461015" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:7H_MAutzIkAC" class="gsc_a_at">Complex deep learning and evolutionary computing models in computer vision</a><div class="gs_gray">L Zhang, CP Lim, J Han</div><div class="gs_gray">Complexity 2019<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7293069905110917873" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:_FM0Bhl9EiAC" class="gsc_a_at">Optimized projection for hashing</a><div class="gs_gray">C Chu, D Gong, K Chen, Y Guo, J Han, G Ding</div><div class="gs_gray">Pattern Recognition Letters 117, 169-178<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17789175969387778693" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:HtS1dXgVpQUC" class="gsc_a_at">Attend to knowledge: Memory-enhanced attention network for image captioning</a><div class="gs_gray">H Chen, G Ding, Z Lin, Y Guo, J Han</div><div class="gs_gray">International Conference on Brain Inspired Cognitive Systems, 161-171<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=286786945846288742" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:tYavs44e6CUC" class="gsc_a_at">Deep spatio-temporal manifold network for action recognition</a><div class="gs_gray">C Li, C Chen, B Zhang, Q Ye, J Han, R Ji</div><div class="gs_gray">arXiv preprint arXiv:1705.03148<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4815214831452899394" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:VL0QpB8kHFEC" class="gsc_a_at">An improved Fisher discriminant vector employing updated between-scatter matrix</a><div class="gs_gray">C Yao, Z Lu, J Li, W Jiang, J Han</div><div class="gs_gray">Neurocomputing 173, 154-162<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15196245456674328632" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:RoXSNcbkSzsC" class="gsc_a_at">Peter HN De With,“</a><div class="gs_gray">W Lao, J Han</div><div class="gs_gray">Automatic video-based human motion analyzer for consumer surveillance system&nbsp;…<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11979818426122075667" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:08ZZubdj9fEC" class="gsc_a_at">A Disparity Estimation Algorithm for Stereo Image Coding with an Adaptive Block Matching</a><div class="gs_gray">H Jungong, L Zhaoyang</div><div class="gs_gray">Journal of Xidian University 31 (3), 347-351<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17348525609960283237" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:roLk4NBRz8UC" class="gsc_a_at">Implementation of Coding Algorithm Based on DT-mesh in MPEC-4</a><div class="gs_gray">J Han, Z LU, Y TIAN, X GAO</div><div class="gs_gray">Acta Electronica Sinica 31 (4), 631-634<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13894576166695978913" class="gsc_a_ac gs_ibl">4</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:Dem6FJhTUoYC" class="gsc_a_at">Perception consistency ultrasound image super-resolution via self-supervised CycleGAN</a><div class="gs_gray">H Liu, J Liu, S Hou, T Tao, J Han</div><div class="gs_gray">Neural Computing and Applications, 1-11<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16161115381368239424" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:1Ye0OR6EYb4C" class="gsc_a_at">Where to prune: Using LSTM to guide data-dependent soft pruning</a><div class="gs_gray">G Ding, S Zhang, Z Jia, J Zhong, J Han</div><div class="gs_gray">IEEE Transactions on Image Processing 30, 293-304<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11793039075498773821" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:XUvXOeBm_78C" class="gsc_a_at">Lossless cnn channel pruning via gradient resetting and convolutional re-parameterization</a><div class="gs_gray">X Ding, T Hao, J Liu, J Han, Y Guo, G Ding</div><div class="gs_gray">arXiv preprint arXiv:2007.03260 1<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1810443135019944193" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:IaI1MmNe2tcC" class="gsc_a_at">Incremental instance-oriented 3D semantic mapping via RGB-D cameras for unknown indoor scene</a><div class="gs_gray">W Li, J Gu, B Chen, J Han</div><div class="gs_gray">Discrete Dynamics in Nature and Society 2020<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13580431687712028091" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:bz8QjSJIRt4C" class="gsc_a_at">A semi-supervised spatially aware wrapper method for hyperspectral band selection</a><div class="gs_gray">X Cao, Y Ji, T Liang, Z Li, X Li, J Han, L Jiao</div><div class="gs_gray">International journal of remote sensing 39 (12), 4020-4039<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12499027312762541721" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:dfsIfKJdRG4C" class="gsc_a_at">Delaunay Triangulation Mesh Based Stereo Image Coding Algorithm [J]</a><div class="gs_gray">HJL Zhaoyang</div><div class="gs_gray">Journal of Computer Aided Design &amp; Computer Graphics 12<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3866703847954352229" class="gsc_a_ac gs_ibl">3</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:2l5NCbZemmgC" class="gsc_a_at">Solo-to-Collaborative Dual-Attention Network for One-Shot Object Detection in Remote Sensing Images</a><div class="gs_gray">L Li, X Yao, G Cheng, M Xu, J Han, J Han</div><div class="gs_gray">IEEE Transactions on Geoscience and Remote Sensing<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13877309337283797367" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:kF1pexMAQbMC" class="gsc_a_at">RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition</a><div class="gs_gray">X Ding, X Zhang, J Han, G Ding</div><div class="gs_gray">arXiv preprint arXiv:2105.01883<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3625632640924211479" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:Ade32sEp0pkC" class="gsc_a_at">Ultrasound tissue classification: a review</a><div class="gs_gray">C Shan, T Tan, J Han, D Huang</div><div class="gs_gray">Artificial Intelligence Review 54 (4), 3055-3088<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=212620906612529411" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:NDuN12AVoxsC" class="gsc_a_at">DGIG-Net: Dynamic Graph-in-Graph Networks for Few-Shot Human-Object Interaction</a><div class="gs_gray">X Liu, Z Ji, Y Pang, J Han, X Li</div><div class="gs_gray">IEEE Transactions on Cybernetics<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8162152361231657867" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:-nhnvRiOwuoC" class="gsc_a_at">Diverse Branch Block: Building a Convolution as an Inception-like Unit</a><div class="gs_gray">X Ding, X Zhang, J Han, G Ding</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7567904351838028390" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=100&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:MAUkC_7iAq8C" class="gsc_a_at">Zero-Shot Learning via Discriminative Dual Semantic Auto-Encoder</a><div class="gs_gray">N Xing, Y Liu, H Zhu, J Wang, J Han</div><div class="gs_gray">IEEE Access 9, 733-742<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17091457864390182907" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:AHdEip9mkN0C" class="gsc_a_at">Indoor scene understanding via RGB-D image segmentation employing depth-based CNN and CRFs</a><div class="gs_gray">W Li, J Gu, Y Dong, Y Dong, J Han</div><div class="gs_gray">Multimedia Tools and Applications 79 (47), 35475-35489<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12885410535850182294" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:jE2MZjpN3IcC" class="gsc_a_at">Efficient Selective Context Network for Accurate Object Detection</a><div class="gs_gray">J Nie, Y Pang, S Zhao, J Han, X Li</div><div class="gs_gray">IEEE Transactions on Circuits and Systems for Video Technology<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9686521245245686707" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:otzGkya1bYkC" class="gsc_a_at">Zero-shot Learning with Many Classes by High-rank Deep Embedding Networks.</a><div class="gs_gray">Y Guo, G Ding, J Han, H Shao, X Lou, Q Dai</div><div class="gs_gray">IJCAI, 2428-2434<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2652804261846685559" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:2tRrZ1ZAMYUC" class="gsc_a_at">Dual-Resolution Dual-Path Convolutional Neural Networks for Fast Object Detection</a><div class="gs_gray">J Pan, H Sun, Z Song, J Han</div><div class="gs_gray">Sensors 19 (14), 3111<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13959093206670472771" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:GtLg2Ama23sC" class="gsc_a_at">Are mid-air dynamic gestures applicable to user identification?</a><div class="gs_gray">H Liu, L Dai, S Hou, J Han, H Liu</div><div class="gs_gray">Pattern Recognition Letters 117, 179-185<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13996518287919391892" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:dBIO0h50nwkC" class="gsc_a_at">High-Fidelity Inhomogeneous Ground Clutter Simulation of Airborne Phased Array PD Radar Aided by Digital Elevation Model and Digital Land Classification Data</a><div class="gs_gray">H Li, J Wang, Y Fan, J Han</div><div class="gs_gray">Sensors 18 (9), 2925<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17430914761844087676" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:2KloaMYe4IUC" class="gsc_a_at">Guest editorial special section on visual saliency computing and learning</a><div class="gs_gray">J Han, L Shao, N Vasconcelos, J Han, D Xu</div><div class="gs_gray">IEEE Transactions on Neural Networks and Learning Systems 27 (6), 1118-1121<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2251159926860539546" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:YFjsv_pBGBYC" class="gsc_a_at">Multimodal monitoring of cultural heritage sites and the FIRESENSE project</a><div class="gs_gray">AA Salah, J Han, E Pauwels, P de Zeeuw</div><div class="gs_gray">Proceedings of the 4th International Symposium on Applied Sciences in&nbsp;…<span class="gs_oph">, 2011</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15613193794408529959" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2011</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:1yQoGdGgb4wC" class="gsc_a_at">∗ Mean-Shift Algorithm</a><div class="gs_gray">J Han</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13391342024800391157" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:YOwf2qJgpHMC" class="gsc_a_at">Multi-level human motion analysis for surveillance applications</a><div class="gs_gray">W Lao, J Han</div><div class="gs_gray">Visual Communications and Image Processing 2009 7257, 72570C<span class="gs_oph">, 2009</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1991079610375175263" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:owLR8QvbtFgC" class="gsc_a_at">PHN de With,“</a><div class="gs_gray">W Lao, J Han</div><div class="gs_gray">Human motion analysis using simultaneous trajectory and body detection and&nbsp;…<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17086528555844298671" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:HeT0ZceujKMC" class="gsc_a_at">A matching-based approach for human motion analysis</a><div class="gs_gray">W Lao, J Han</div><div class="gs_gray">International Conference on Multimedia Modeling, 405-414<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13197877617423936726" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:umqufdRvDiIC" class="gsc_a_at">LU Zhao-yang i′ an710071, China); A disparity estimation algorithm for stereo image coding with an adaptive block matching [J]</a><div class="gs_gray">HAN Jun-gong</div><div class="gs_gray">Journal of Xidian University 3<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10112522474582272795" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:J-pR_7NvFogC" class="gsc_a_at">A novel disparity estimation algorithm for stereo image encoding</a><div class="gs_gray">JG Han, Z Lu</div><div class="gs_gray">CHINESE JOURNAL OF COMPUTERS-CHINESE EDITION- 26 (12), 1717-1721<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14308165995512903969" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:35N4QoGY0k4C" class="gsc_a_at">A Novel Disparity Estimation Algorithm for Stereo Image Encoding [J]</a><div class="gs_gray">HANJGLU Zhao-Yang</div><div class="gs_gray">Chinese Journal of Computers 12<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11520633421187614364" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:ufrVoPGSRksC" class="gsc_a_at">Realization of a video retrieval system based on color information</a><div class="gs_gray">J HAN, Y QIN, Z LU</div><div class="gs_gray">Tv Engineering 1<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16908104090515612006" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:AXPGKjj_ei8C" class="gsc_a_at">An improved DT-mesh coding algorithm adaptive to MPEG-4</a><div class="gs_gray">H Jungong, L Zhaoyang, T Yike, G Xiquan</div><div class="gs_gray">6th International Conference on Signal Processing, 2002. 2, 949-952<span class="gs_oph">, 2002</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15983869221196580679" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2002</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:YsMSGLbcyi4C" class="gsc_a_at">Novel image retrieval technique using salient edges</a><div class="gs_gray">JW Han, J Han, L Guo</div><div class="gs_gray">Storage and Retrieval for Media Databases 2002 4676, 69-78<span class="gs_oph">, 2001</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=339424983781461870" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2001</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:U_HPUtbDl20C" class="gsc_a_at">deWith1, Flexible Human Behavior Analysis Framework for Video Surveillance Applications</a><div class="gs_gray">W Lao, J Han, HN Peter</div><div class="gs_gray">Hindawi Publishing Corporation International Journal of Digital Multimedia&nbsp;…<span class="gs_oph">, 0</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10011357392347177447" class="gsc_a_ac gs_ibl">2</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:rTD5ala9j4wC" class="gsc_a_at">Relation-based Discriminative Cooperation Network for Zero-Shot Classification</a><div class="gs_gray">Y Liu, X Gao, Q Gao, J Han, L Shao</div><div class="gs_gray">Pattern Recognition 118, 108024<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16574190598535087863" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:69ZgNCALVd0C" class="gsc_a_at">SAENet: Self-Supervised Adversarial and Equivariant Network for Weakly Supervised Object Detection in Remote Sensing Images</a><div class="gs_gray">X Feng, X Yao, G Cheng, J Han, J Han</div><div class="gs_gray">IEEE Transactions on Geoscience and Remote Sensing<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16702699069955430532" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:jFemdcug13IC" class="gsc_a_at">Exploring a unified low rank representation for multi-focus image fusion</a><div class="gs_gray">Q Zhang, F Wang, Y Luo, J Han</div><div class="gs_gray">Pattern Recognition 113, 107752<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5376989403885370809" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:oi2SiIJ9l4AC" class="gsc_a_at">Alignment Enhancement Network for Fine-grained&lt;? brk?&gt; Visual Categorization</a><div class="gs_gray">Y Hu, X Liu, B Zhang, J Han, X Cao</div><div class="gs_gray">ACM Transactions on Multimedia Computing, Communications, and Applications&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7909627981215472430" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:O0nohqN1r9EC" class="gsc_a_at">Modulated Convolutional Networks</a><div class="gs_gray">B Zhang, R Wang, X Wang, J Han, R Ji</div><div class="gs_gray">IEEE transactions on neural networks and learning systems<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14165703869599531243" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:WHdLCjDvYFkC" class="gsc_a_at">Semantic segmentation with hybrid pyramid pooling and stacked pyramid structure</a><div class="gs_gray">X Lian, Y Pang, J Han, J Pan</div><div class="gs_gray">Neurocomputing 410, 454-467<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16690490040515816181" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:3NQIlFlcGxIC" class="gsc_a_at">Exploring Multi-scale Deep Encoder-Decoder and PatchGAN for Perceptual Ultrasound Image Super-Resolution</a><div class="gs_gray">J Liu, H Liu, X Zheng, J Han</div><div class="gs_gray">International Conference on Neural Computing for Advanced Applications, 47-59<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11388938402755025542" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:7BrZ7Jt4UNcC" class="gsc_a_at">ACMNet: Adaptive confidence matching network for human behavior analysis via cross-modal retrieval</a><div class="gs_gray">H Chen, G Ding, Z Lin, S Zhao, X Gu, W Xu, J Han</div><div class="gs_gray">ACM Transactions on Multimedia Computing, Communications, and Applications&nbsp;…<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7014140989882860828" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:PaBasH6fAo0C" class="gsc_a_at">Heterogeneous transfer learning with weighted instance-correspondence data</a><div class="gs_gray">Y He, X Jin, G Ding, Y Guo, J Han, J Zhang, S Zhao</div><div class="gs_gray">Proceedings of the AAAI Conference on Artificial Intelligence 34 (04), 4099-4106<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9728653798931324503" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:zCSUwVk65WsC" class="gsc_a_at">Deep feature-preserving based face hallucination: Feature discrimination versus pixels approximation</a><div class="gs_gray">X Zheng, H Liu, J Han, S Hou</div><div class="gs_gray">Chinese Conference on Pattern Recognition and Computer Vision (PRCV), 114-125<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3771095149584006196" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:-7ulzOJl1JYC" class="gsc_a_at">Ground clutter suppression method based on FNN for dual-polarisation weather radar</a><div class="gs_gray">H Li, J Ren, J Han, Y Fan</div><div class="gs_gray">The Journal of Engineering 2019 (19), 6043-6047<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9159545268802743316" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:4xDN1ZYqzskC" class="gsc_a_at">Complementary Features with Reasonable Receptive Field for Road Scene 3D Object Detection</a><div class="gs_gray">Y Wu, Y Pang, B Gao, J Han</div><div class="gs_gray">2019 IEEE International Conference on Image Processing (ICIP), 3905-3909<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6494161182473645981" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:cWzG1nlazyYC" class="gsc_a_at">Zero-shot multi-label learning via label factorisation</a><div class="gs_gray">H Shao, Y Guo, G Ding, J Han</div><div class="gs_gray">IET Computer Vision 13 (2), 117-124<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17375878995888549144" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:uc_IGeMz5qoC" class="gsc_a_at">Guest Editorial: Feature Learning from RGB-D Data for Multimedia Applications</a><div class="gs_gray">B Zhang, J Han, L Shao</div><div class="gs_gray">Multimedia Tools and Applications 76 (3), 4243-4248<span class="gs_oph">, 2017</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7424717195638238913" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2017</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:L1USKYWJimsC" class="gsc_a_at">Extracting semantics from multi-spectrum video</a><div class="gs_gray">J Han, E Pauwels, F Wu</div><div class="gs_gray">Pattern Recognition Letters 34 (1), 1-2<span class="gs_oph">, 2013</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11870150200406815481" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2013</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:RGFaLdJalmkC" class="gsc_a_at">Neonatal monitoring based on facial expression analysis</a><div class="gs_gray">J Han, L Hazelhoff</div><div class="gs_gray">Neonatal monitoring technologies: design for integrated solutions, 303-323<span class="gs_oph">, 2012</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10005878554890095199" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2012</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:KlAtU1dfN6UC" class="gsc_a_at">A mesh-based algorithm for disparity estimation and occlusion points detection</a><div class="gs_gray">J HAN, Z LU</div><div class="gs_gray">Journal of Circuits and Systems 1<span class="gs_oph">, 2005</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12646841400449262232" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2005</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:CB2v5VPnA5kC" class="gsc_a_at">A novel stereo image coding algorithm based on delaunay triangulation mesh</a><div class="gs_gray">J Han, Z Lu</div><div class="gs_gray">Visual Communications and Image Processing 2004 5308, 1169-1180<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1538368561828929610" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:0EnyYjriUFMC" class="gsc_a_at">A Moving Foreground Segmentation Approach in Image Sequence [J]</a><div class="gs_gray">Q WANG, J HAN, Z LU</div><div class="gs_gray">Computer Engineering 19<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=459415267496512430" class="gsc_a_ac gs_ibl">1</a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:eO3_k5sD8BwC" class="gsc_a_at">Graph embedding clustering: Graph attention auto-encoder with cluster-specificity distribution</a><div class="gs_gray">H Xu, W Xia, Q Gao, J Han, X Gao</div><div class="gs_gray">Neural Networks 142, 221-230<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:SnGPuo6Feq8C" class="gsc_a_at">Learning Transformation-Invariant Local Descriptors with Low-Coupling Binary Codes</a><div class="gs_gray">Y Miao, Z Lin, X Ma, G Ding, J Han</div><div class="gs_gray">IEEE Transactions on Image Processing<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:QUX0mv85b1cC" class="gsc_a_at">Stereo Refinement Dehazing Network</a><div class="gs_gray">J Nie, Y Pang, J Xie, J Pan, J Han</div><div class="gs_gray">IEEE Transactions on Circuits and Systems for Video Technology<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:DkZNVXde3BIC" class="gsc_a_at">Zero-Shot Learning via A Specific Rank-controlled Semantic Autoencoder</a><div class="gs_gray">Y Liu, X Gao, J Han, L Liu, L Shao</div><div class="gs_gray">Pattern Recognition, 108237<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:pS0ncopqnHgC" class="gsc_a_at">Engaging Part-whole Hierarchies and Contrast Cues for Salient Object Detection</a><div class="gs_gray">Q Zhang, M Duanmu, Y Luo, Y Liu, J Han</div><div class="gs_gray">IEEE Transactions on Circuits and Systems for Video Technology<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:mWEH9CqjF64C" class="gsc_a_at">Deep image compression with multi-stage representation</a><div class="gs_gray">Z Wang, G Ding, J Han, F Li</div><div class="gs_gray">Journal of Visual Communication and Image Representation 79, 103226<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:SGW5VrABaM0C" class="gsc_a_at">Manipulating Identical Filter Redundancy for Efficient Pruning on Deep and Complicated CNN</a><div class="gs_gray">X Ding, T Hao, J Han, Y Guo, G Ding</div><div class="gs_gray">arXiv preprint arXiv:2107.14444<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:kzcSZmkxUKAC" class="gsc_a_at">Dual Attention with the Self-Attention Alignment for Efficient Video Super-resolution</a><div class="gs_gray">Y Chu, Y Qiao, H Liu, J Han</div><div class="gs_gray">Cognitive Computation, 1-12<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:WAzi4Gm8nLoC" class="gsc_a_at">Exploring Modality-shared Appearance Features and Modality-invariant Relation Features for Cross-modality Person Re-Identification</a><div class="gs_gray">N Huang, J Liu, Q Zhang, J Han</div><div class="gs_gray">arXiv preprint arXiv:2104.11539<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:raTqNPD5sRQC" class="gsc_a_at">Middle-level Fusion for Lightweight RGB-D Salient Object Detection</a><div class="gs_gray">N Huang, Q Zhang, J Han</div><div class="gs_gray">arXiv preprint arXiv:2104.11543<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:YsrPvlHIBpEC" class="gsc_a_at">SiamCDA: Complementarity-and distractor-aware RGB-T tracking based on Siamese network</a><div class="gs_gray">T Zhang, X Liu, Q Zhang, J Han</div><div class="gs_gray">IEEE Transactions on Circuits and Systems for Video Technology<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:w1MjKQ0l0TYC" class="gsc_a_at">Onfocus Detection: Identifying Individual-Camera Eye Contact from Unconstrained Images</a><div class="gs_gray">D Zhang, B Wang, G Wang, Q Zhang, J Zhang, J Han, Z You</div><div class="gs_gray">arXiv preprint arXiv:2103.15307<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:PyEswDtIyv0C" class="gsc_a_at">Densely Nested Top-Down Flows for Salient Object Detection</a><div class="gs_gray">C Fang, H Tian, D Zhang, Q Zhang, J Han, J Han</div><div class="gs_gray">arXiv preprint arXiv:2102.09133<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:5bg8sr1QxYwC" class="gsc_a_at">ABMDRNet: Adaptive-weighted Bi-directional Modality Difference Reduction Network for RGB-T Semantic Segmentation</a><div class="gs_gray">Q Zhang, S Zhao, Y Luo, D Zhang, N Huang, J Han</div><div class="gs_gray">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern&nbsp;…<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:1yWc8FF-_SYC" class="gsc_a_at">Learning modulation filter networks for weak signal detection in noise</a><div class="gs_gray">D Zhang, W Ding, B Zhang, C Liu, J Han, D Doermann</div><div class="gs_gray">Pattern Recognition 109, 107590<span class="gs_oph">, 2021</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2021</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:HGTzPopzzJcC" class="gsc_a_at">Guest Editorial: Computer Vision for Smart Cameras and Camera Networks</a><div class="gs_gray">C Shan, J Han, L Marcenaro, N Conci</div><div class="gs_gray">IET Computer Vision 14 (7), 415-416<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:An6A6Jpfc1oC" class="gsc_a_at">Lossless CNN Channel Pruning via Decoupling Remembering and Forgetting</a><div class="gs_gray">X Ding, T Hao, J Tan, J Liu, J Han, Y Guo, G Ding</div><div class="gs_gray">arXiv preprint arXiv:2007.03260<span class="gs_oph">, 2020</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2020</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:PVgj2kMGcgYC" class="gsc_a_at">Guest editorial: Automatic facial and bodily expression perception for human behaviour understanding</a><div class="gs_gray">L Zhang, CP Lim, J Han</div><div class="gs_gray">Multimedia Tools and Applications 78 (21), 30331-30334<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:mlAyqtXpCwEC" class="gsc_a_at">Video Synchronization Based on Projective-Invariant Descriptor</a><div class="gs_gray">Q Zhang, L Yao, Y Li, J Han</div><div class="gs_gray">Neural Processing Letters 49 (3), 1093-1110<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:F9fV5C73w3QC" class="gsc_a_at">Taylor Convolutional Networks for Image Classification</a><div class="gs_gray">X Wang, C Li, Y Mou, B Zhang, J Han, J Liu</div><div class="gs_gray">2019 IEEE Winter Conference on Applications of Computer Vision (WACV), 1271-1279<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:CaZNVDsoPx4C" class="gsc_a_at">Landmark Selection for Zero-shot Learning.</a><div class="gs_gray">Y Guo, G Ding, J Han, C Yan, J Zhang, Q Dai</div><div class="gs_gray">IJCAI, 2435-2441<span class="gs_oph">, 2019</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2019</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:4vMrXwiscB8C" class="gsc_a_at">Editorial Note: Few-Shot Learning for Multimedia Content Understanding</a><div class="gs_gray">G Ding, J Han, E Pauwels</div><div class="gs_gray">Multimedia Tools and Applications 77 (22), 29757-29757<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:EPG8bYD4jVwC" class="gsc_a_at">Unconstrained Face Recognition Using</a><div class="gs_gray">J Zhao, J Han, L Shao</div><div class="gs_gray">by: IEEE<span class="gs_oph">, 2018</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2018</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:yB1At4FlUx8C" class="gsc_a_at">Latent Constrained Correlation Filters for Object Localization</a><div class="gs_gray">S Luan, B Zhang, J Han, C Chen, L Shao, A Perina, L Shen</div><div class="gs_gray">arXiv preprint arXiv:1606.02170<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:QyXJ3EUuO1IC" class="gsc_a_at">Robust Iterative Quantization for Efficient ℓ</a><div class="gs_gray">Y Guo, G Ding, J Han, X Jin</div><div class="gs_gray">IJCAI<span class="gs_oph">, 2016</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2016</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:V3AGJWp-ZtQC" class="gsc_a_at">Guest Editorial: Special issue on advanced computing for image-guided intervention</a><div class="gs_gray">F Zuo, J Han, P Yan, H Van Assen, K Suzuki</div><div class="gs_gray">Neurocomputing 144, 1-2<span class="gs_oph">, 2014</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2014</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:Zph67rFs4hoC" class="gsc_a_at">Video analysis, abstraction, and retrieval: techniques and applications</a><div class="gs_gray">J Han, L Shao, L Guan</div><div class="gs_gray">International Journal of Digital Multimedia Broadcasting 2010<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:GFxP56DSvIMC" class="gsc_a_at">MUST 2010: Welcome message from workshop organizers: FutureTech 2010</a><div class="gs_gray">B Prabhakaran, W Bailer, S Rho, M Bertini, GC De Silva, S Kopf, JH Park, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:anf4URPfarAC" class="gsc_a_at">Regression-based occlusion handling using silhouette data in video surveillance</a><div class="gs_gray">M Feng, J Han</div><div class="gs_gray">Proceedings of the 29th Symposium on Information Theory in the Benelux, May&nbsp;…<span class="gs_oph">, 2010</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:ruyezt5ZtCIC" class="gsc_a_at">DATICS-2010: Welcome message from workshop organizers: FutureTech 2010</a><div class="gs_gray">KL Man, M Mercaldi, V Hahanov, P Prinetto, M Poncino, A MacIi, J Choi, ...</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2010</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:4TOpqqG69KYC" class="gsc_a_at">Human motion analysis using simultaneous trajectory and body detection and modeling</a><div class="gs_gray">W Lao, J Han</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2009</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:HDshCWvjkbEC" class="gsc_a_at">Multi-module human motion analysis from a monocular video</a><div class="gs_gray">W Lao, J Han</div><div class="gs_gray">Multimedia Content Access: Algorithms and Systems 6506, 65060M<span class="gs_oph">, 2007</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2007</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:9ZlFYXVOiuMC" class="gsc_a_at">Content-based model template adaptation and real-time system for behavior interpretation in sports video</a><div class="gs_gray">J Han</div><div class="gs_gray">International Conference on Advanced Concepts for Intelligent Vision Systems&nbsp;…<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:aqlVkmm33-oC" class="gsc_a_at">Scene-Level Analysis for Tennis Sports Video using Weighted Linear Combination of Visual Cues.</a><div class="gs_gray">J Han, W Lao, Peter HN de With</div><div class="gs_gray">EuroIMSA, 193-197<span class="gs_oph">, 2006</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2006</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:ZeXyd9-uunAC" class="gsc_a_at">A cooperative stereo matching and occlusion detection algorithm for stereo coding</a><div class="gs_gray">J Han, Z Lu</div><div class="gs_gray">Machine Graphics and Vision 13 (1/2), 25-38<span class="gs_oph">, 2004</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2004</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:M7yex6snE4oC" class="gsc_a_at">A novel stereo pair coding algorithm based on hybrid block matching disparity estimation</a><div class="gs_gray">J Han, Z Lu</div><div class="gs_gray">Internet Imaging V 5304, 264-275<span class="gs_oph">, 2003</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2003</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:eMMeJKvmdy0C" class="gsc_a_at">A new wavelet image coding algorithm for network</a><div class="gs_gray">H Jungong, L Zhaoyang</div><div class="gs_gray">6th International Conference on Signal Processing, 2002. 1, 672-675<span class="gs_oph">, 2002</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl">2002</span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:HhcuHIWmDEUC" class="gsc_a_at">jialie Shen. 2018. Unsupervised deep hashing via binary latent factor models for large-scale cross-modal retrieval</a><div class="gs_gray">G Wu, Z Lin, J Han, L Liu, G Ding, B Zhang</div><div class="gs_gray">Proc. 27th Inter. Joint Conf. Artif. Intel, 2854-2860<span class="gs_oph">, 0</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:1lhNe0rCu4AC" class="gsc_a_at">End-to-end video background subtraction with 3D convolutional networks</a><div class="gs_gray">D Sakkos, H Liu, J Han, L Shao</div><div class="gs_gray">Illumination 20, 6<span class="gs_oph">, 0</span></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:Bg7qf7VwUHIC" class="gsc_a_at">Unconstrained Face Recognition Using A Set-to-Set Distance Measure</a><div class="gs_gray">J Zhao, J Han, L Shao</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr><tr class="gsc_a_tr"><td class="gsc_a_t"><a href="/citations?view_op=view_citation&amp;hl=en&amp;user=hNi1gxAAAAAJ&amp;cstart=200&amp;pagesize=100&amp;citation_for_view=hNi1gxAAAAAJ:zLWjf1WUPmwC" class="gsc_a_at">Advanced Topics Multimedia Video Coding (5DD50), Module 07</a><div class="gs_gray">J Han</div><div class="gs_gray"></div></td><td class="gsc_a_c"><a href="" class="gsc_a_ac gs_ibl"></a></td><td class="gsc_a_y"><span class="gsc_a_h gsc_a_hc gs_ibl"></span></td></tr></tbody></table><div id="gsc_a_sp" class=""></div><div id="gsc_a_err" class="gs_alrt">The system can't perform the operation now. Try again later.</div></div><div id="gsc_lwp"><span id="gsc_a_nn">Articles 1–279</span><div id="gsc_bpf"><button type="button" id="gsc_bpf_more" class="gs_btnPD gs_in_ib gs_btn_flat gs_btn_lrge gs_btn_lsu" disabled=""><span class="gs_wr"><span class="gs_ico"></span><span class="gs_lbl">Show more</span></span></button></div></div></form></div></div></div></div><div id="gs_ftr_sp" role="presentation"></div><div id="gs_ftr" role="contentinfo"><div id="gs_ftr_rt"><a href="/intl/en/scholar/about.html">Help</a><a href="//www.google.com/intl/en/policies/privacy/">Privacy</a><a href="//www.google.com/intl/en/policies/terms/">Terms</a></div></div></div></body></html>